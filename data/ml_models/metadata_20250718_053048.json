{
  "last_training_time": "2025-07-18T05:30:48.220074",
  "training_data_size": 1240,
  "model_performance": {
    "time_predictor": {
      "mae": 121.62254197376764,
      "relative_error": 1.4284150438572125,
      "oob_score": 0.5876628234333419
    },
    "memory_predictor": {
      "mae": 1.1386688114727084,
      "relative_error": 0.9084510034655655,
      "oob_score": 0.5904269369833679
    },
    "success_classifier": {
      "accuracy": 0.9919354838709677,
      "oob_score": 0.9848790322580645
    },
    "batch_size_predictor": {
      "mae": 0.008082884082818546,
      "oob_score": 0.0064275458679415864
    },
    "fewshot_predictor": {
      "mae": 0.002654402399979752,
      "oob_score": -0.0712099176086316
    }
  },
  "feature_names": [
    "model_size_numeric",
    "model_size_category",
    "model_type",
    "task_name",
    "task_type",
    "task_complexity",
    "gpu_memory_available",
    "gpu_utilization",
    "gpu_temperature",
    "cpu_percent",
    "ram_available",
    "historical_avg_time",
    "historical_avg_memory",
    "historical_success_rate",
    "historical_oom_rate",
    "historical_sample_count",
    "model_avg_time",
    "model_avg_memory",
    "model_run_count",
    "hour",
    "day_of_week",
    "num_gpus"
  ],
  "label_encoders": {
    "model_size_category": {
      "classes_": [
        "large",
        "medium",
        "small",
        "xlarge"
      ]
    },
    "model_type": {
      "classes_": [
        "exaone",
        "gemma",
        "llama",
        "mistral",
        "other",
        "qwen"
      ]
    },
    "task_name": {
      "classes_": [
        "arc_challenge",
        "arc_easy",
        "csatqa",
        "haerae",
        "hellaswag",
        "humaneval",
        "kmmlu",
        "kmmlu_hard",
        "kobest",
        "komt_bench",
        "kormedmcqa",
        "mmlu"
      ]
    },
    "task_type": {
      "classes_": [
        "coding",
        "knowledge",
        "korean",
        "language",
        "other",
        "reasoning"
      ]
    }
  }
}