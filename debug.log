2025-07-23 03:15:21,995 - INFO - Using experiment directory: /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase1_accuracy_convergence_20250723_031517
2025-07-23 03:15:21,995 - INFO - ============================================================
2025-07-23 03:15:21,995 - INFO - BASELINE MODE - Traditional Execution
2025-07-23 03:15:21,995 - INFO - ============================================================
2025-07-23 03:15:21,995 - INFO - Processing 4 medium models sequentially
2025-07-23 03:15:22,021 - INFO - [Process 818637] Llama-3.1-8B_harness_1 assigned to cuda:0
2025-07-23 03:15:22,021 - INFO - [Process 818637] Llama-3.1-8B_harness_1 - full_run: False, limit: 2
2025-07-23 03:15:22,027 - INFO - WandB run initialized: Llama-3.1-8B_20250723_031522 (ID: fea3999e)
2025-07-23 03:15:22,402 - INFO - Llama-3.1-8B_harness_1: Test mode (limit=2), setting num_fewshot=0
2025-07-23 03:15:22,402 - INFO - Llama-3.1-8B_harness_1: Processing task 1/10: kmmlu
2025-07-23 03:15:22,402 - INFO - Llama-3.1-8B_harness_1: Task 'kmmlu' will use num_fewshot=0
2025-07-23 03:15:22,402 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-23 03:15:22,403 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-23 03:16:38,229 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-23 03:16:38,229 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-23 03:16:38,230 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-23 03:16:38,231 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-23 03:16:38,232 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-23 03:16:38,232 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-23 03:16:38,232 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-23 03:16:38,232 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-23 03:16:45,168 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-23 03:16:45,168 - INFO - 
============================================================
2025-07-23 03:16:45,169 - INFO - Task 'kmmlu' Results:
2025-07-23 03:16:45,169 - INFO - ============================================================
2025-07-23 03:16:45,169 - INFO -   kmmlu:
2025-07-23 03:16:45,169 - INFO -     - accuracy: 0.3000
2025-07-23 03:16:45,169 - INFO -   kmmlu_applied_science:
2025-07-23 03:16:45,169 - INFO -     - accuracy: 0.2083
2025-07-23 03:16:45,169 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-23 03:16:45,169 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,169 - INFO -   kmmlu_electronics_engineering:
2025-07-23 03:16:45,169 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,169 - INFO -   kmmlu_energy_management:
2025-07-23 03:16:45,169 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,169 - INFO -   kmmlu_environmental_science:
2025-07-23 03:16:45,169 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,169 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-23 03:16:45,169 - INFO -     - accuracy: 1.0000
2025-07-23 03:16:45,169 - INFO -   kmmlu_geomatics:
2025-07-23 03:16:45,169 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,169 - INFO -   kmmlu_industrial_engineer:
2025-07-23 03:16:45,169 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,169 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-23 03:16:45,169 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,170 - INFO -   kmmlu_maritime_engineering:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,170 - INFO -   kmmlu_nondestructive_testing:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,170 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,170 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,170 - INFO -   kmmlu_humss:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.3636
2025-07-23 03:16:45,170 - INFO -   kmmlu_accounting:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,170 - INFO -   kmmlu_criminal_law:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,170 - INFO -   kmmlu_economics:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,170 - INFO -   kmmlu_education:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,170 - INFO -   kmmlu_korean_history:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,170 - INFO -   kmmlu_law:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,170 - INFO -   kmmlu_management:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,170 - INFO -   kmmlu_political_science_and_sociology:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,170 - INFO -   kmmlu_psychology:
2025-07-23 03:16:45,170 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,170 - INFO -   kmmlu_social_welfare:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,171 - INFO -   kmmlu_taxation:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,171 - INFO -   kmmlu_other:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.2727
2025-07-23 03:16:45,171 - INFO -   kmmlu_agricultural_sciences:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,171 - INFO -   kmmlu_construction:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,171 - INFO -   kmmlu_fashion:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,171 - INFO -   kmmlu_food_processing:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,171 - INFO -   kmmlu_health:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,171 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,171 - INFO -   kmmlu_marketing:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,171 - INFO -   kmmlu_patent:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,171 - INFO -   kmmlu_public_safety:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,171 - INFO -   kmmlu_real_estate:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,171 - INFO -   kmmlu_refrigerating_machinery:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,171 - INFO -   kmmlu_stem:
2025-07-23 03:16:45,171 - INFO -     - accuracy: 0.3636
2025-07-23 03:16:45,171 - INFO -   kmmlu_biology:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,172 - INFO -   kmmlu_chemical_engineering:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,172 - INFO -   kmmlu_chemistry:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 1.0000
2025-07-23 03:16:45,172 - INFO -   kmmlu_civil_engineering:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,172 - INFO -   kmmlu_computer_science:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 1.0000
2025-07-23 03:16:45,172 - INFO -   kmmlu_ecology:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,172 - INFO -   kmmlu_electrical_engineering:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,172 - INFO -   kmmlu_information_technology:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 0.5000
2025-07-23 03:16:45,172 - INFO -   kmmlu_materials_engineering:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,172 - INFO -   kmmlu_math:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 0.0000
2025-07-23 03:16:45,172 - INFO -   kmmlu_mechanical_engineering:
2025-07-23 03:16:45,172 - INFO -     - accuracy: 1.0000
2025-07-23 03:16:45,172 - INFO - ============================================================

2025-07-23 03:16:45,205 - INFO - Llama-3.1-8B_harness_1: Processing task 2/10: kmmlu_hard
2025-07-23 03:16:45,205 - INFO - Llama-3.1-8B_harness_1: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-23 03:16:45,205 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-23 03:16:45,206 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-23 03:18:00,628 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-23 03:18:00,629 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-23 03:18:00,630 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-23 03:18:00,631 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-23 03:18:00,631 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-23 03:18:00,631 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-23 03:18:00,631 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-23 03:18:00,631 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-23 03:18:00,631 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-23 03:18:00,631 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-23 03:18:00,631 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-23 03:18:06,609 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-23 03:18:06,609 - INFO - 
============================================================
2025-07-23 03:18:06,609 - INFO - Task 'kmmlu_hard' Results:
2025-07-23 03:18:06,609 - INFO - ============================================================
2025-07-23 03:18:06,609 - INFO -   kmmlu_hard:
2025-07-23 03:18:06,609 - INFO -     - accuracy: 0.2333
2025-07-23 03:18:06,609 - INFO -   kmmlu_hard_applied_science:
2025-07-23 03:18:06,609 - INFO -     - accuracy: 0.3750
2025-07-23 03:18:06,609 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-23 03:18:06,609 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,609 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-23 03:18:06,609 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_energy_management:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_environmental_science:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_geomatics:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_humss:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.2273
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_accounting:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_criminal_law:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_economics:
2025-07-23 03:18:06,610 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,610 - INFO -   kmmlu_hard_education:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_korean_history:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_law:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_management:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 1.0000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_psychology:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_social_welfare:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_taxation:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_other:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.2727
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_construction:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_fashion:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_food_processing:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_health:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-23 03:18:06,611 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,611 - INFO -   kmmlu_hard_marketing:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_patent:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_public_safety:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_real_estate:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 1.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_stem:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0455
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_biology:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_chemistry:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_civil_engineering:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_computer_science:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_ecology:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_information_technology:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_materials_engineering:
2025-07-23 03:18:06,612 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,612 - INFO -   kmmlu_hard_math:
2025-07-23 03:18:06,613 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,613 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-23 03:18:06,613 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:06,613 - INFO - ============================================================

2025-07-23 03:18:06,647 - INFO - Llama-3.1-8B_harness_1: Processing task 3/10: haerae
2025-07-23 03:18:06,647 - INFO - Llama-3.1-8B_harness_1: Task 'haerae' will use num_fewshot=0
2025-07-23 03:18:06,647 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'haerae' with num_fewshot=0
2025-07-23 03:18:06,648 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-23 03:18:26,287 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-23 03:18:26,287 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-23 03:18:26,287 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-23 03:18:26,288 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-23 03:18:26,288 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-23 03:18:30,768 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'haerae' with 6 subtasks
2025-07-23 03:18:30,768 - INFO - 
============================================================
2025-07-23 03:18:30,769 - INFO - Task 'haerae' Results:
2025-07-23 03:18:30,769 - INFO - ============================================================
2025-07-23 03:18:30,769 - INFO -   haerae:
2025-07-23 03:18:30,769 - INFO -     - accuracy: 0.4000
2025-07-23 03:18:30,769 - INFO -     - accuracy_norm: 0.4000
2025-07-23 03:18:30,769 - INFO -   haerae_general_knowledge:
2025-07-23 03:18:30,769 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:30,769 - INFO -     - accuracy_norm: 0.5000
2025-07-23 03:18:30,769 - INFO -   haerae_history:
2025-07-23 03:18:30,769 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:30,769 - INFO -     - accuracy_norm: 0.0000
2025-07-23 03:18:30,769 - INFO -   haerae_loan_word:
2025-07-23 03:18:30,769 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:30,769 - INFO -     - accuracy_norm: 0.5000
2025-07-23 03:18:30,769 - INFO -   haerae_rare_word:
2025-07-23 03:18:30,769 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:30,769 - INFO -     - accuracy_norm: 0.0000
2025-07-23 03:18:30,770 - INFO -   haerae_standard_nomenclature:
2025-07-23 03:18:30,770 - INFO -     - accuracy: 1.0000
2025-07-23 03:18:30,770 - INFO -     - accuracy_norm: 1.0000
2025-07-23 03:18:30,770 - INFO - ============================================================

2025-07-23 03:18:30,804 - INFO - Llama-3.1-8B_harness_1: Processing task 4/10: kobest
2025-07-23 03:18:30,804 - INFO - Llama-3.1-8B_harness_1: Task 'kobest' will use num_fewshot=0
2025-07-23 03:18:30,804 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kobest' with num_fewshot=0
2025-07-23 03:18:30,805 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-23 03:18:54,314 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-23 03:18:54,314 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-23 03:18:54,314 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-23 03:18:54,315 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-23 03:18:54,315 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-23 03:18:58,096 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kobest' with 6 subtasks
2025-07-23 03:18:58,097 - INFO - 
============================================================
2025-07-23 03:18:58,097 - INFO - Task 'kobest' Results:
2025-07-23 03:18:58,097 - INFO - ============================================================
2025-07-23 03:18:58,097 - INFO -   kobest:
2025-07-23 03:18:58,097 - INFO -     - accuracy: 0.6000
2025-07-23 03:18:58,097 - INFO -     - accuracy_norm: 0.5000
2025-07-23 03:18:58,097 - INFO -     - f1: 0.5333
2025-07-23 03:18:58,097 - INFO -   kobest_boolq:
2025-07-23 03:18:58,097 - INFO -     - accuracy: 1.0000
2025-07-23 03:18:58,097 - INFO -     - f1: 1.0000
2025-07-23 03:18:58,097 - INFO -   kobest_copa:
2025-07-23 03:18:58,098 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:58,098 - INFO -     - f1: 0.3333
2025-07-23 03:18:58,098 - INFO -   kobest_hellaswag:
2025-07-23 03:18:58,098 - INFO -     - accuracy: 0.0000
2025-07-23 03:18:58,098 - INFO -     - accuracy_norm: 0.5000
2025-07-23 03:18:58,098 - INFO -     - f1: 0.0000
2025-07-23 03:18:58,098 - INFO -   kobest_sentineg:
2025-07-23 03:18:58,098 - INFO -     - accuracy: 0.5000
2025-07-23 03:18:58,098 - INFO -     - f1: 0.3333
2025-07-23 03:18:58,098 - INFO -   kobest_wic:
2025-07-23 03:18:58,098 - INFO -     - accuracy: 1.0000
2025-07-23 03:18:58,098 - INFO -     - f1: 1.0000
2025-07-23 03:18:58,098 - INFO - ============================================================

2025-07-23 03:18:58,132 - INFO - Llama-3.1-8B_harness_1: Processing task 5/10: csatqa
2025-07-23 03:18:58,133 - INFO - Llama-3.1-8B_harness_1: Task 'csatqa' detected as zero-shot task
2025-07-23 03:18:58,133 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'csatqa' with num_fewshot=0
2025-07-23 03:18:58,133 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-23 03:19:13,965 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-23 03:19:13,965 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-23 03:19:13,965 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-23 03:19:13,965 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-23 03:19:13,965 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-23 03:19:13,965 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-23 03:19:24,184 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'csatqa' with 7 subtasks
2025-07-23 03:19:24,185 - INFO - 
============================================================
2025-07-23 03:19:24,185 - INFO - Task 'csatqa' Results:
2025-07-23 03:19:24,185 - INFO - ============================================================
2025-07-23 03:19:24,185 - INFO -   csatqa:
2025-07-23 03:19:24,185 - INFO -     - accuracy: 0.1667
2025-07-23 03:19:24,185 - INFO -     - accuracy_norm: 0.1667
2025-07-23 03:19:24,185 - INFO -   csatqa_gr:
2025-07-23 03:19:24,185 - INFO -     - accuracy: 0.0000
2025-07-23 03:19:24,185 - INFO -     - accuracy_norm: 0.0000
2025-07-23 03:19:24,185 - INFO -   csatqa_li:
2025-07-23 03:19:24,186 - INFO -     - accuracy: 0.0000
2025-07-23 03:19:24,186 - INFO -     - accuracy_norm: 0.0000
2025-07-23 03:19:24,186 - INFO -   csatqa_rch:
2025-07-23 03:19:24,186 - INFO -     - accuracy: 0.5000
2025-07-23 03:19:24,186 - INFO -     - accuracy_norm: 0.5000
2025-07-23 03:19:24,186 - INFO -   csatqa_rcs:
2025-07-23 03:19:24,186 - INFO -     - accuracy: 0.0000
2025-07-23 03:19:24,186 - INFO -     - accuracy_norm: 0.0000
2025-07-23 03:19:24,186 - INFO -   csatqa_rcss:
2025-07-23 03:19:24,186 - INFO -     - accuracy: 0.5000
2025-07-23 03:19:24,186 - INFO -     - accuracy_norm: 0.5000
2025-07-23 03:19:24,186 - INFO -   csatqa_wr:
2025-07-23 03:19:24,186 - INFO -     - accuracy: 0.0000
2025-07-23 03:19:24,186 - INFO -     - accuracy_norm: 0.0000
2025-07-23 03:19:24,186 - INFO - ============================================================

2025-07-23 03:19:24,225 - INFO - Llama-3.1-8B_harness_1: Processing task 6/10: kormedmcqa
2025-07-23 03:19:24,225 - INFO - Llama-3.1-8B_harness_1: Task 'kormedmcqa' will use num_fewshot=0
2025-07-23 03:19:24,225 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-23 03:19:24,226 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-23 03:19:45,125 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-23 03:19:45,125 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-23 03:19:45,125 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-23 03:19:45,125 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-23 03:19:55,142 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-23 03:19:55,143 - INFO - 
============================================================
2025-07-23 03:19:55,143 - INFO - Task 'kormedmcqa' Results:
2025-07-23 03:19:55,143 - INFO - ============================================================
2025-07-23 03:19:55,143 - INFO -   kormedmcqa:
2025-07-23 03:19:55,143 - INFO -     - exact_match: 0.0000
2025-07-23 03:19:55,143 - INFO -   kormedmcqa_dentist:
2025-07-23 03:19:55,143 - INFO -     - exact_match: 0.0000
2025-07-23 03:19:55,143 - INFO -   kormedmcqa_doctor:
2025-07-23 03:19:55,143 - INFO -     - exact_match: 0.0000
2025-07-23 03:19:55,143 - INFO -   kormedmcqa_nurse:
2025-07-23 03:19:55,144 - INFO -     - exact_match: 0.0000
2025-07-23 03:19:55,144 - INFO -   kormedmcqa_pharm:
2025-07-23 03:19:55,144 - INFO -     - exact_match: 0.0000
2025-07-23 03:19:55,144 - INFO - ============================================================

2025-07-23 03:19:55,177 - INFO - Llama-3.1-8B_harness_1: Processing task 7/10: mmlu
2025-07-23 03:19:55,178 - INFO - Llama-3.1-8B_harness_1: Task 'mmlu' will use num_fewshot=0
2025-07-23 03:19:55,178 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'mmlu' with num_fewshot=0
2025-07-23 03:19:55,179 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-23 03:22:11,685 - INFO - Using experiment directory: /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase1_accuracy_convergence_20250723_032206
2025-07-23 03:22:11,685 - INFO - ============================================================
2025-07-23 03:22:11,685 - INFO - BASELINE MODE - Traditional Execution
2025-07-23 03:22:11,685 - INFO - ============================================================
2025-07-23 03:22:11,686 - INFO - Processing 4 medium models sequentially
2025-07-23 03:22:11,712 - INFO - [Process 820220] Llama-3.1-8B_harness_1 assigned to cuda:0
2025-07-23 03:22:11,712 - INFO - [Process 820220] Llama-3.1-8B_harness_1 - full_run: False, limit: 2
2025-07-23 03:22:11,717 - INFO - WandB run initialized: Llama-3.1-8B_20250723_032211 (ID: fea3999e)
2025-07-23 03:22:12,020 - INFO - Llama-3.1-8B_harness_1: Test mode (limit=2), setting num_fewshot=0
2025-07-23 03:22:12,020 - INFO - Llama-3.1-8B_harness_1: Processing task 1/10: kmmlu
2025-07-23 03:22:12,020 - INFO - Llama-3.1-8B_harness_1: Task 'kmmlu' will use num_fewshot=0
2025-07-23 03:22:12,020 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-23 03:22:12,021 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-23 03:23:26,632 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-23 03:23:26,632 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-23 03:23:26,632 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-23 03:23:26,632 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-23 03:23:26,632 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-23 03:23:26,632 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-23 03:23:26,632 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-23 03:23:26,632 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-23 03:23:26,632 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-23 03:23:26,633 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-23 03:23:26,634 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-23 03:23:32,913 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-23 03:23:32,913 - INFO - 
============================================================
2025-07-23 03:23:32,914 - INFO - Task 'kmmlu' Results:
2025-07-23 03:23:32,914 - INFO - ============================================================
2025-07-23 03:23:32,914 - INFO -   kmmlu:
2025-07-23 03:23:32,914 - INFO -     - accuracy: 0.3000
2025-07-23 03:23:32,914 - INFO -   kmmlu_applied_science:
2025-07-23 03:23:32,914 - INFO -     - accuracy: 0.2083
2025-07-23 03:23:32,914 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-23 03:23:32,914 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,914 - INFO -   kmmlu_electronics_engineering:
2025-07-23 03:23:32,914 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,914 - INFO -   kmmlu_energy_management:
2025-07-23 03:23:32,914 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,914 - INFO -   kmmlu_environmental_science:
2025-07-23 03:23:32,914 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,914 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-23 03:23:32,914 - INFO -     - accuracy: 1.0000
2025-07-23 03:23:32,914 - INFO -   kmmlu_geomatics:
2025-07-23 03:23:32,914 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,914 - INFO -   kmmlu_industrial_engineer:
2025-07-23 03:23:32,914 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,914 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-23 03:23:32,914 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,915 - INFO -   kmmlu_maritime_engineering:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,915 - INFO -   kmmlu_nondestructive_testing:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,915 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,915 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,915 - INFO -   kmmlu_humss:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.3636
2025-07-23 03:23:32,915 - INFO -   kmmlu_accounting:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,915 - INFO -   kmmlu_criminal_law:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,915 - INFO -   kmmlu_economics:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,915 - INFO -   kmmlu_education:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,915 - INFO -   kmmlu_korean_history:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,915 - INFO -   kmmlu_law:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,915 - INFO -   kmmlu_management:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,915 - INFO -   kmmlu_political_science_and_sociology:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,915 - INFO -   kmmlu_psychology:
2025-07-23 03:23:32,915 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,915 - INFO -   kmmlu_social_welfare:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,916 - INFO -   kmmlu_taxation:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,916 - INFO -   kmmlu_other:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.2727
2025-07-23 03:23:32,916 - INFO -   kmmlu_agricultural_sciences:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,916 - INFO -   kmmlu_construction:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,916 - INFO -   kmmlu_fashion:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,916 - INFO -   kmmlu_food_processing:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,916 - INFO -   kmmlu_health:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,916 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,916 - INFO -   kmmlu_marketing:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,916 - INFO -   kmmlu_patent:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,916 - INFO -   kmmlu_public_safety:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,916 - INFO -   kmmlu_real_estate:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,916 - INFO -   kmmlu_refrigerating_machinery:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,916 - INFO -   kmmlu_stem:
2025-07-23 03:23:32,916 - INFO -     - accuracy: 0.3636
2025-07-23 03:23:32,917 - INFO -   kmmlu_biology:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,917 - INFO -   kmmlu_chemical_engineering:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,917 - INFO -   kmmlu_chemistry:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 1.0000
2025-07-23 03:23:32,917 - INFO -   kmmlu_civil_engineering:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,917 - INFO -   kmmlu_computer_science:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 1.0000
2025-07-23 03:23:32,917 - INFO -   kmmlu_ecology:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,917 - INFO -   kmmlu_electrical_engineering:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,917 - INFO -   kmmlu_information_technology:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 0.5000
2025-07-23 03:23:32,917 - INFO -   kmmlu_materials_engineering:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,917 - INFO -   kmmlu_math:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 0.0000
2025-07-23 03:23:32,917 - INFO -   kmmlu_mechanical_engineering:
2025-07-23 03:23:32,917 - INFO -     - accuracy: 1.0000
2025-07-23 03:23:32,917 - INFO - ============================================================

2025-07-23 03:23:32,951 - INFO - Llama-3.1-8B_harness_1: Processing task 2/10: kmmlu_hard
2025-07-23 03:23:32,951 - INFO - Llama-3.1-8B_harness_1: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-23 03:23:32,951 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-23 03:23:32,951 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:27:24,104 - INFO - Using experiment directory: /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_032724
2025-07-28 03:27:24,117 - INFO - ============================================================
2025-07-28 03:27:24,117 - INFO - BASELINE MODE - Traditional Execution
2025-07-28 03:27:24,117 - INFO - ============================================================
2025-07-28 03:27:24,117 - INFO - Processing 4 medium models sequentially
2025-07-28 03:27:24,145 - INFO - [Process 1795506] Llama-3.1-8B_harness_1 assigned to cuda:0
2025-07-28 03:27:24,145 - INFO - [Process 1795506] Llama-3.1-8B_harness_1 - using custom limit: 20
2025-07-28 03:27:26,168 - INFO - WandB run initialized: Llama-3.1-8B_20250728_032724 (ID: fea3999e)
2025-07-28 03:27:26,474 - INFO - Llama-3.1-8B_harness_1: Test mode (limit=2), setting num_fewshot=0
2025-07-28 03:27:26,474 - INFO - Llama-3.1-8B_harness_1: Processing task 1/10: kmmlu
2025-07-28 03:27:26,474 - INFO - Llama-3.1-8B_harness_1: Task 'kmmlu' will use num_fewshot=0
2025-07-28 03:27:26,474 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 03:27:26,476 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:28:44,070 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 03:28:44,070 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 03:28:44,070 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 03:28:44,070 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 03:28:44,070 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 03:28:44,070 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 03:28:44,071 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 03:28:44,071 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 03:28:44,071 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 03:28:44,071 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 03:28:44,071 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 03:28:44,071 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 03:28:44,071 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 03:28:44,071 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 03:28:44,071 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 03:28:44,071 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 03:28:44,072 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 03:28:44,072 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 03:28:44,072 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 03:28:44,072 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 03:28:44,072 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 03:28:44,072 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 03:28:44,072 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 03:28:44,072 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 03:28:44,072 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 03:28:44,072 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 03:28:44,073 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 03:28:44,074 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 03:28:44,074 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 03:28:44,074 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 03:28:44,074 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 03:28:44,074 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 03:28:44,074 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 03:28:44,074 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 03:28:44,074 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 03:29:16,613 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 03:29:16,614 - INFO - 
============================================================
2025-07-28 03:29:16,614 - INFO - Task 'kmmlu' Results:
2025-07-28 03:29:16,614 - INFO - ============================================================
2025-07-28 03:29:16,614 - INFO -   kmmlu:
2025-07-28 03:29:16,615 - INFO -     - accuracy: 0.3289
2025-07-28 03:29:16,615 - INFO -   kmmlu_applied_science:
2025-07-28 03:29:16,615 - INFO -     - accuracy: 0.2667
2025-07-28 03:29:16,615 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 03:29:16,615 - INFO -     - accuracy: 0.2000
2025-07-28 03:29:16,615 - INFO -   kmmlu_electronics_engineering:
2025-07-28 03:29:16,615 - INFO -     - accuracy: 0.1000
2025-07-28 03:29:16,615 - INFO -   kmmlu_energy_management:
2025-07-28 03:29:16,615 - INFO -     - accuracy: 0.1000
2025-07-28 03:29:16,616 - INFO -   kmmlu_environmental_science:
2025-07-28 03:29:16,616 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,616 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 03:29:16,616 - INFO -     - accuracy: 0.3500
2025-07-28 03:29:16,616 - INFO -   kmmlu_geomatics:
2025-07-28 03:29:16,616 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,616 - INFO -   kmmlu_industrial_engineer:
2025-07-28 03:29:16,616 - INFO -     - accuracy: 0.3500
2025-07-28 03:29:16,616 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 03:29:16,616 - INFO -     - accuracy: 0.4500
2025-07-28 03:29:16,617 - INFO -   kmmlu_maritime_engineering:
2025-07-28 03:29:16,617 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,617 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 03:29:16,617 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,617 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 03:29:16,617 - INFO -     - accuracy: 0.3000
2025-07-28 03:29:16,617 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 03:29:16,617 - INFO -     - accuracy: 0.3500
2025-07-28 03:29:16,617 - INFO -   kmmlu_humss:
2025-07-28 03:29:16,617 - INFO -     - accuracy: 0.3591
2025-07-28 03:29:16,617 - INFO -   kmmlu_accounting:
2025-07-28 03:29:16,618 - INFO -     - accuracy: 0.4500
2025-07-28 03:29:16,618 - INFO -   kmmlu_criminal_law:
2025-07-28 03:29:16,618 - INFO -     - accuracy: 0.3000
2025-07-28 03:29:16,618 - INFO -   kmmlu_economics:
2025-07-28 03:29:16,618 - INFO -     - accuracy: 0.5000
2025-07-28 03:29:16,618 - INFO -   kmmlu_education:
2025-07-28 03:29:16,618 - INFO -     - accuracy: 0.3000
2025-07-28 03:29:16,618 - INFO -   kmmlu_korean_history:
2025-07-28 03:29:16,618 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,618 - INFO -   kmmlu_law:
2025-07-28 03:29:16,618 - INFO -     - accuracy: 0.3500
2025-07-28 03:29:16,619 - INFO -   kmmlu_management:
2025-07-28 03:29:16,619 - INFO -     - accuracy: 0.3000
2025-07-28 03:29:16,619 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 03:29:16,619 - INFO -     - accuracy: 0.5500
2025-07-28 03:29:16,619 - INFO -   kmmlu_psychology:
2025-07-28 03:29:16,619 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,619 - INFO -   kmmlu_social_welfare:
2025-07-28 03:29:16,619 - INFO -     - accuracy: 0.5000
2025-07-28 03:29:16,619 - INFO -   kmmlu_taxation:
2025-07-28 03:29:16,619 - INFO -     - accuracy: 0.2000
2025-07-28 03:29:16,620 - INFO -   kmmlu_other:
2025-07-28 03:29:16,620 - INFO -     - accuracy: 0.2955
2025-07-28 03:29:16,620 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 03:29:16,620 - INFO -     - accuracy: 0.1500
2025-07-28 03:29:16,620 - INFO -   kmmlu_construction:
2025-07-28 03:29:16,620 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,620 - INFO -   kmmlu_fashion:
2025-07-28 03:29:16,620 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,620 - INFO -   kmmlu_food_processing:
2025-07-28 03:29:16,620 - INFO -     - accuracy: 0.3500
2025-07-28 03:29:16,620 - INFO -   kmmlu_health:
2025-07-28 03:29:16,621 - INFO -     - accuracy: 0.5000
2025-07-28 03:29:16,621 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 03:29:16,621 - INFO -     - accuracy: 0.3500
2025-07-28 03:29:16,621 - INFO -   kmmlu_marketing:
2025-07-28 03:29:16,621 - INFO -     - accuracy: 0.4500
2025-07-28 03:29:16,621 - INFO -   kmmlu_patent:
2025-07-28 03:29:16,621 - INFO -     - accuracy: 0.2000
2025-07-28 03:29:16,621 - INFO -   kmmlu_public_safety:
2025-07-28 03:29:16,621 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,621 - INFO -   kmmlu_real_estate:
2025-07-28 03:29:16,621 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,622 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 03:29:16,622 - INFO -     - accuracy: 0.2500
2025-07-28 03:29:16,622 - INFO -   kmmlu_stem:
2025-07-28 03:29:16,622 - INFO -     - accuracy: 0.4000
2025-07-28 03:29:16,622 - INFO -   kmmlu_biology:
2025-07-28 03:29:16,622 - INFO -     - accuracy: 0.3000
2025-07-28 03:29:16,622 - INFO -   kmmlu_chemical_engineering:
2025-07-28 03:29:16,622 - INFO -     - accuracy: 0.3500
2025-07-28 03:29:16,622 - INFO -   kmmlu_chemistry:
2025-07-28 03:29:16,622 - INFO -     - accuracy: 0.3500
2025-07-28 03:29:16,623 - INFO -   kmmlu_civil_engineering:
2025-07-28 03:29:16,623 - INFO -     - accuracy: 0.4000
2025-07-28 03:29:16,623 - INFO -   kmmlu_computer_science:
2025-07-28 03:29:16,623 - INFO -     - accuracy: 0.6500
2025-07-28 03:29:16,623 - INFO -   kmmlu_ecology:
2025-07-28 03:29:16,623 - INFO -     - accuracy: 0.4500
2025-07-28 03:29:16,623 - INFO -   kmmlu_electrical_engineering:
2025-07-28 03:29:16,623 - INFO -     - accuracy: 0.4000
2025-07-28 03:29:16,623 - INFO -   kmmlu_information_technology:
2025-07-28 03:29:16,623 - INFO -     - accuracy: 0.5000
2025-07-28 03:29:16,623 - INFO -   kmmlu_materials_engineering:
2025-07-28 03:29:16,624 - INFO -     - accuracy: 0.3000
2025-07-28 03:29:16,624 - INFO -   kmmlu_math:
2025-07-28 03:29:16,624 - INFO -     - accuracy: 0.3500
2025-07-28 03:29:16,624 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 03:29:16,624 - INFO -     - accuracy: 0.3500
2025-07-28 03:29:16,624 - INFO - ============================================================

2025-07-28 03:29:16,659 - INFO - Llama-3.1-8B_harness_1: Processing task 2/10: kmmlu_hard
2025-07-28 03:29:16,659 - INFO - Llama-3.1-8B_harness_1: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 03:29:16,659 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 03:29:16,660 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:30:33,976 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 03:30:33,976 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 03:30:33,976 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 03:30:33,977 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 03:30:33,977 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 03:30:33,977 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 03:30:33,977 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 03:30:33,977 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 03:30:33,977 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 03:30:33,977 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 03:30:33,977 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 03:30:33,977 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 03:30:33,977 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 03:30:33,978 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 03:30:33,979 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 03:30:33,980 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 03:30:33,980 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 03:30:33,980 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 03:30:33,980 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 03:30:33,980 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 03:30:33,980 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 03:30:33,980 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 03:30:33,980 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 03:30:33,980 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 03:31:06,341 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 03:31:06,342 - INFO - 
============================================================
2025-07-28 03:31:06,342 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 03:31:06,342 - INFO - ============================================================
2025-07-28 03:31:06,343 - INFO -   kmmlu_hard:
2025-07-28 03:31:06,343 - INFO -     - accuracy: 0.2600
2025-07-28 03:31:06,343 - INFO -   kmmlu_hard_applied_science:
2025-07-28 03:31:06,343 - INFO -     - accuracy: 0.3083
2025-07-28 03:31:06,343 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 03:31:06,343 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,343 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 03:31:06,343 - INFO -     - accuracy: 0.3000
2025-07-28 03:31:06,343 - INFO -   kmmlu_hard_energy_management:
2025-07-28 03:31:06,344 - INFO -     - accuracy: 0.3500
2025-07-28 03:31:06,344 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 03:31:06,344 - INFO -     - accuracy: 0.4500
2025-07-28 03:31:06,344 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 03:31:06,344 - INFO -     - accuracy: 0.2500
2025-07-28 03:31:06,344 - INFO -   kmmlu_hard_geomatics:
2025-07-28 03:31:06,344 - INFO -     - accuracy: 0.5500
2025-07-28 03:31:06,344 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 03:31:06,344 - INFO -     - accuracy: 0.4500
2025-07-28 03:31:06,344 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 03:31:06,344 - INFO -     - accuracy: 0.1500
2025-07-28 03:31:06,345 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 03:31:06,345 - INFO -     - accuracy: 0.1500
2025-07-28 03:31:06,345 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 03:31:06,345 - INFO -     - accuracy: 0.2500
2025-07-28 03:31:06,345 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 03:31:06,345 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,345 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 03:31:06,345 - INFO -     - accuracy: 0.4000
2025-07-28 03:31:06,345 - INFO -   kmmlu_hard_humss:
2025-07-28 03:31:06,345 - INFO -     - accuracy: 0.2182
2025-07-28 03:31:06,346 - INFO -   kmmlu_hard_accounting:
2025-07-28 03:31:06,346 - INFO -     - accuracy: 0.1500
2025-07-28 03:31:06,346 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 03:31:06,346 - INFO -     - accuracy: 0.1000
2025-07-28 03:31:06,346 - INFO -   kmmlu_hard_economics:
2025-07-28 03:31:06,346 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,346 - INFO -   kmmlu_hard_education:
2025-07-28 03:31:06,346 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,346 - INFO -   kmmlu_hard_korean_history:
2025-07-28 03:31:06,346 - INFO -     - accuracy: 0.3000
2025-07-28 03:31:06,346 - INFO -   kmmlu_hard_law:
2025-07-28 03:31:06,347 - INFO -     - accuracy: 0.2500
2025-07-28 03:31:06,347 - INFO -   kmmlu_hard_management:
2025-07-28 03:31:06,347 - INFO -     - accuracy: 0.3000
2025-07-28 03:31:06,347 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 03:31:06,347 - INFO -     - accuracy: 0.4000
2025-07-28 03:31:06,347 - INFO -   kmmlu_hard_psychology:
2025-07-28 03:31:06,347 - INFO -     - accuracy: 0.1500
2025-07-28 03:31:06,347 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 03:31:06,347 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,347 - INFO -   kmmlu_hard_taxation:
2025-07-28 03:31:06,347 - INFO -     - accuracy: 0.1500
2025-07-28 03:31:06,348 - INFO -   kmmlu_hard_other:
2025-07-28 03:31:06,348 - INFO -     - accuracy: 0.2727
2025-07-28 03:31:06,348 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 03:31:06,348 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,348 - INFO -   kmmlu_hard_construction:
2025-07-28 03:31:06,348 - INFO -     - accuracy: 0.4000
2025-07-28 03:31:06,348 - INFO -   kmmlu_hard_fashion:
2025-07-28 03:31:06,348 - INFO -     - accuracy: 0.3000
2025-07-28 03:31:06,348 - INFO -   kmmlu_hard_food_processing:
2025-07-28 03:31:06,348 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,348 - INFO -   kmmlu_hard_health:
2025-07-28 03:31:06,349 - INFO -     - accuracy: 0.2500
2025-07-28 03:31:06,349 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 03:31:06,349 - INFO -     - accuracy: 0.3000
2025-07-28 03:31:06,349 - INFO -   kmmlu_hard_marketing:
2025-07-28 03:31:06,349 - INFO -     - accuracy: 0.4500
2025-07-28 03:31:06,349 - INFO -   kmmlu_hard_patent:
2025-07-28 03:31:06,349 - INFO -     - accuracy: 0.0500
2025-07-28 03:31:06,349 - INFO -   kmmlu_hard_public_safety:
2025-07-28 03:31:06,349 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,349 - INFO -   kmmlu_hard_real_estate:
2025-07-28 03:31:06,349 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,350 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 03:31:06,350 - INFO -     - accuracy: 0.4500
2025-07-28 03:31:06,350 - INFO -   kmmlu_hard_stem:
2025-07-28 03:31:06,350 - INFO -     - accuracy: 0.2364
2025-07-28 03:31:06,350 - INFO -   kmmlu_hard_biology:
2025-07-28 03:31:06,350 - INFO -     - accuracy: 0.2500
2025-07-28 03:31:06,350 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 03:31:06,350 - INFO -     - accuracy: 0.1500
2025-07-28 03:31:06,350 - INFO -   kmmlu_hard_chemistry:
2025-07-28 03:31:06,350 - INFO -     - accuracy: 0.3000
2025-07-28 03:31:06,350 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 03:31:06,351 - INFO -     - accuracy: 0.1500
2025-07-28 03:31:06,351 - INFO -   kmmlu_hard_computer_science:
2025-07-28 03:31:06,351 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,351 - INFO -   kmmlu_hard_ecology:
2025-07-28 03:31:06,351 - INFO -     - accuracy: 0.3500
2025-07-28 03:31:06,351 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 03:31:06,351 - INFO -     - accuracy: 0.3000
2025-07-28 03:31:06,351 - INFO -   kmmlu_hard_information_technology:
2025-07-28 03:31:06,351 - INFO -     - accuracy: 0.3000
2025-07-28 03:31:06,351 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 03:31:06,351 - INFO -     - accuracy: 0.2000
2025-07-28 03:31:06,352 - INFO -   kmmlu_hard_math:
2025-07-28 03:31:06,352 - INFO -     - accuracy: 0.1500
2025-07-28 03:31:06,352 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 03:31:06,352 - INFO -     - accuracy: 0.2500
2025-07-28 03:31:06,352 - INFO - ============================================================

2025-07-28 03:31:06,389 - INFO - Llama-3.1-8B_harness_1: Processing task 3/10: haerae
2025-07-28 03:31:06,390 - INFO - Llama-3.1-8B_harness_1: Task 'haerae' will use num_fewshot=0
2025-07-28 03:31:06,390 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 03:31:06,391 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:31:26,010 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 03:31:26,011 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 03:31:26,011 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 03:31:26,011 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 03:31:26,011 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 03:31:43,148 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 03:31:43,149 - INFO - 
============================================================
2025-07-28 03:31:43,150 - INFO - Task 'haerae' Results:
2025-07-28 03:31:43,150 - INFO - ============================================================
2025-07-28 03:31:43,150 - INFO -   haerae:
2025-07-28 03:31:43,151 - INFO -     - accuracy: 0.4800
2025-07-28 03:31:43,151 - INFO -     - accuracy_norm: 0.4800
2025-07-28 03:31:43,151 - INFO -   haerae_general_knowledge:
2025-07-28 03:31:43,151 - INFO -     - accuracy: 0.6000
2025-07-28 03:31:43,151 - INFO -     - accuracy_norm: 0.6000
2025-07-28 03:31:43,151 - INFO -   haerae_history:
2025-07-28 03:31:43,151 - INFO -     - accuracy: 0.3000
2025-07-28 03:31:43,151 - INFO -     - accuracy_norm: 0.3000
2025-07-28 03:31:43,152 - INFO -   haerae_loan_word:
2025-07-28 03:31:43,152 - INFO -     - accuracy: 0.5500
2025-07-28 03:31:43,152 - INFO -     - accuracy_norm: 0.5500
2025-07-28 03:31:43,152 - INFO -   haerae_rare_word:
2025-07-28 03:31:43,152 - INFO -     - accuracy: 0.2500
2025-07-28 03:31:43,152 - INFO -     - accuracy_norm: 0.2500
2025-07-28 03:31:43,152 - INFO -   haerae_standard_nomenclature:
2025-07-28 03:31:43,152 - INFO -     - accuracy: 0.7000
2025-07-28 03:31:43,152 - INFO -     - accuracy_norm: 0.7000
2025-07-28 03:31:43,152 - INFO - ============================================================

2025-07-28 03:31:43,187 - INFO - Llama-3.1-8B_harness_1: Processing task 4/10: kobest
2025-07-28 03:31:43,188 - INFO - Llama-3.1-8B_harness_1: Task 'kobest' will use num_fewshot=0
2025-07-28 03:31:43,188 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 03:31:43,189 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:32:06,292 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 03:32:06,293 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 03:32:06,293 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 03:32:06,293 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 03:32:06,293 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 03:32:16,297 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 03:32:16,298 - INFO - 
============================================================
2025-07-28 03:32:16,298 - INFO - Task 'kobest' Results:
2025-07-28 03:32:16,299 - INFO - ============================================================
2025-07-28 03:32:16,299 - INFO -   kobest:
2025-07-28 03:32:16,299 - INFO -     - accuracy: 0.6000
2025-07-28 03:32:16,299 - INFO -     - accuracy_norm: 0.7500
2025-07-28 03:32:16,299 - INFO -     - f1: 0.5294
2025-07-28 03:32:16,299 - INFO -   kobest_boolq:
2025-07-28 03:32:16,300 - INFO -     - accuracy: 0.6500
2025-07-28 03:32:16,300 - INFO -     - f1: 0.5611
2025-07-28 03:32:16,300 - INFO -   kobest_copa:
2025-07-28 03:32:16,300 - INFO -     - accuracy: 0.7500
2025-07-28 03:32:16,300 - INFO -     - f1: 0.7494
2025-07-28 03:32:16,300 - INFO -   kobest_hellaswag:
2025-07-28 03:32:16,300 - INFO -     - accuracy: 0.3500
2025-07-28 03:32:16,300 - INFO -     - accuracy_norm: 0.7500
2025-07-28 03:32:16,300 - INFO -     - f1: 0.3388
2025-07-28 03:32:16,300 - INFO -   kobest_sentineg:
2025-07-28 03:32:16,300 - INFO -     - accuracy: 0.7000
2025-07-28 03:32:16,301 - INFO -     - f1: 0.6429
2025-07-28 03:32:16,301 - INFO -   kobest_wic:
2025-07-28 03:32:16,301 - INFO -     - accuracy: 0.5500
2025-07-28 03:32:16,301 - INFO -     - f1: 0.3548
2025-07-28 03:32:16,301 - INFO - ============================================================

2025-07-28 03:32:16,336 - INFO - Llama-3.1-8B_harness_1: Processing task 5/10: csatqa
2025-07-28 03:32:16,337 - INFO - Llama-3.1-8B_harness_1: Task 'csatqa' detected as zero-shot task
2025-07-28 03:32:16,337 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 03:32:16,338 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:32:31,547 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 03:32:31,548 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 03:32:31,548 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 03:32:31,548 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 03:32:31,548 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 03:32:31,548 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 03:33:47,003 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 03:33:47,004 - INFO - 
============================================================
2025-07-28 03:33:47,005 - INFO - Task 'csatqa' Results:
2025-07-28 03:33:47,005 - INFO - ============================================================
2025-07-28 03:33:47,005 - INFO -   csatqa:
2025-07-28 03:33:47,005 - INFO -     - accuracy: 0.2703
2025-07-28 03:33:47,006 - INFO -     - accuracy_norm: 0.2703
2025-07-28 03:33:47,006 - INFO -   csatqa_gr:
2025-07-28 03:33:47,006 - INFO -     - accuracy: 0.1000
2025-07-28 03:33:47,006 - INFO -     - accuracy_norm: 0.1000
2025-07-28 03:33:47,006 - INFO -   csatqa_li:
2025-07-28 03:33:47,006 - INFO -     - accuracy: 0.2000
2025-07-28 03:33:47,006 - INFO -     - accuracy_norm: 0.2000
2025-07-28 03:33:47,007 - INFO -   csatqa_rch:
2025-07-28 03:33:47,007 - INFO -     - accuracy: 0.3500
2025-07-28 03:33:47,007 - INFO -     - accuracy_norm: 0.3500
2025-07-28 03:33:47,007 - INFO -   csatqa_rcs:
2025-07-28 03:33:47,007 - INFO -     - accuracy: 0.3000
2025-07-28 03:33:47,007 - INFO -     - accuracy_norm: 0.3000
2025-07-28 03:33:47,007 - INFO -   csatqa_rcss:
2025-07-28 03:33:47,007 - INFO -     - accuracy: 0.4000
2025-07-28 03:33:47,007 - INFO -     - accuracy_norm: 0.4000
2025-07-28 03:33:47,007 - INFO -   csatqa_wr:
2025-07-28 03:33:47,007 - INFO -     - accuracy: 0.2727
2025-07-28 03:33:47,007 - INFO -     - accuracy_norm: 0.2727
2025-07-28 03:33:47,008 - INFO - ============================================================

2025-07-28 03:33:47,050 - INFO - Llama-3.1-8B_harness_1: Processing task 6/10: kormedmcqa
2025-07-28 03:33:47,050 - INFO - Llama-3.1-8B_harness_1: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 03:33:47,051 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 03:33:47,051 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:34:08,658 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 03:34:08,659 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 03:34:08,659 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 03:34:08,659 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 03:35:52,014 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 03:35:52,015 - INFO - 
============================================================
2025-07-28 03:35:52,015 - INFO - Task 'kormedmcqa' Results:
2025-07-28 03:35:52,015 - INFO - ============================================================
2025-07-28 03:35:52,015 - INFO -   kormedmcqa:
2025-07-28 03:35:52,016 - INFO -     - exact_match: 0.0875
2025-07-28 03:35:52,016 - INFO -   kormedmcqa_dentist:
2025-07-28 03:35:52,016 - INFO -     - exact_match: 0.0000
2025-07-28 03:35:52,017 - INFO -   kormedmcqa_doctor:
2025-07-28 03:35:52,017 - INFO -     - exact_match: 0.0500
2025-07-28 03:35:52,017 - INFO -   kormedmcqa_nurse:
2025-07-28 03:35:52,017 - INFO -     - exact_match: 0.2500
2025-07-28 03:35:52,017 - INFO -   kormedmcqa_pharm:
2025-07-28 03:35:52,017 - INFO -     - exact_match: 0.0500
2025-07-28 03:35:52,017 - INFO - ============================================================

2025-07-28 03:35:52,054 - INFO - Llama-3.1-8B_harness_1: Processing task 7/10: mmlu
2025-07-28 03:35:52,055 - INFO - Llama-3.1-8B_harness_1: Task 'mmlu' will use num_fewshot=0
2025-07-28 03:35:52,055 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 03:35:52,056 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:38:48,610 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 03:38:48,610 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 03:38:48,610 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 03:38:48,610 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 03:38:48,610 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 03:38:48,610 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 03:38:48,610 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 03:38:48,611 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 03:38:48,612 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 03:38:48,613 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 03:38:48,614 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 03:38:48,615 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 03:38:48,615 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 03:38:48,615 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 03:38:48,615 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 03:38:48,615 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 03:39:28,723 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 03:39:28,723 - INFO - 
============================================================
2025-07-28 03:39:28,724 - INFO - Task 'mmlu' Results:
2025-07-28 03:39:28,724 - INFO - ============================================================
2025-07-28 03:39:28,724 - INFO -   mmlu:
2025-07-28 03:39:28,725 - INFO -     - accuracy: 0.6623
2025-07-28 03:39:28,725 - INFO -   mmlu_humanities:
2025-07-28 03:39:28,725 - INFO -     - accuracy: 0.7000
2025-07-28 03:39:28,725 - INFO -   mmlu_formal_logic:
2025-07-28 03:39:28,725 - INFO -     - accuracy: 0.4500
2025-07-28 03:39:28,725 - INFO -   mmlu_high_school_european_history:
2025-07-28 03:39:28,725 - INFO -     - accuracy: 0.7000
2025-07-28 03:39:28,725 - INFO -   mmlu_high_school_us_history:
2025-07-28 03:39:28,725 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,726 - INFO -   mmlu_high_school_world_history:
2025-07-28 03:39:28,726 - INFO -     - accuracy: 0.9500
2025-07-28 03:39:28,726 - INFO -   mmlu_international_law:
2025-07-28 03:39:28,726 - INFO -     - accuracy: 0.8500
2025-07-28 03:39:28,726 - INFO -   mmlu_jurisprudence:
2025-07-28 03:39:28,726 - INFO -     - accuracy: 0.7500
2025-07-28 03:39:28,726 - INFO -   mmlu_logical_fallacies:
2025-07-28 03:39:28,726 - INFO -     - accuracy: 0.7500
2025-07-28 03:39:28,726 - INFO -   mmlu_moral_disputes:
2025-07-28 03:39:28,726 - INFO -     - accuracy: 0.5500
2025-07-28 03:39:28,727 - INFO -   mmlu_moral_scenarios:
2025-07-28 03:39:28,727 - INFO -     - accuracy: 0.3500
2025-07-28 03:39:28,727 - INFO -   mmlu_philosophy:
2025-07-28 03:39:28,727 - INFO -     - accuracy: 0.6500
2025-07-28 03:39:28,727 - INFO -   mmlu_prehistory:
2025-07-28 03:39:28,727 - INFO -     - accuracy: 0.8500
2025-07-28 03:39:28,727 - INFO -   mmlu_professional_law:
2025-07-28 03:39:28,727 - INFO -     - accuracy: 0.6000
2025-07-28 03:39:28,727 - INFO -   mmlu_world_religions:
2025-07-28 03:39:28,727 - INFO -     - accuracy: 0.8500
2025-07-28 03:39:28,728 - INFO -   mmlu_other:
2025-07-28 03:39:28,728 - INFO -     - accuracy: 0.6385
2025-07-28 03:39:28,728 - INFO -   mmlu_business_ethics:
2025-07-28 03:39:28,728 - INFO -     - accuracy: 0.6500
2025-07-28 03:39:28,728 - INFO -   mmlu_clinical_knowledge:
2025-07-28 03:39:28,728 - INFO -     - accuracy: 0.6500
2025-07-28 03:39:28,728 - INFO -   mmlu_college_medicine:
2025-07-28 03:39:28,728 - INFO -     - accuracy: 0.7000
2025-07-28 03:39:28,728 - INFO -   mmlu_global_facts:
2025-07-28 03:39:28,728 - INFO -     - accuracy: 0.3500
2025-07-28 03:39:28,728 - INFO -   mmlu_human_aging:
2025-07-28 03:39:28,729 - INFO -     - accuracy: 0.4000
2025-07-28 03:39:28,729 - INFO -   mmlu_management:
2025-07-28 03:39:28,729 - INFO -     - accuracy: 0.8500
2025-07-28 03:39:28,729 - INFO -   mmlu_marketing:
2025-07-28 03:39:28,729 - INFO -     - accuracy: 0.7500
2025-07-28 03:39:28,729 - INFO -   mmlu_medical_genetics:
2025-07-28 03:39:28,729 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,729 - INFO -   mmlu_miscellaneous:
2025-07-28 03:39:28,729 - INFO -     - accuracy: 0.8500
2025-07-28 03:39:28,729 - INFO -   mmlu_nutrition:
2025-07-28 03:39:28,729 - INFO -     - accuracy: 0.7500
2025-07-28 03:39:28,730 - INFO -   mmlu_professional_accounting:
2025-07-28 03:39:28,730 - INFO -     - accuracy: 0.2500
2025-07-28 03:39:28,730 - INFO -   mmlu_professional_medicine:
2025-07-28 03:39:28,730 - INFO -     - accuracy: 0.7000
2025-07-28 03:39:28,730 - INFO -   mmlu_virology:
2025-07-28 03:39:28,730 - INFO -     - accuracy: 0.6000
2025-07-28 03:39:28,730 - INFO -   mmlu_social_sciences:
2025-07-28 03:39:28,730 - INFO -     - accuracy: 0.7667
2025-07-28 03:39:28,730 - INFO -   mmlu_econometrics:
2025-07-28 03:39:28,730 - INFO -     - accuracy: 0.4500
2025-07-28 03:39:28,730 - INFO -   mmlu_high_school_geography:
2025-07-28 03:39:28,731 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,731 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 03:39:28,731 - INFO -     - accuracy: 0.9000
2025-07-28 03:39:28,731 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 03:39:28,731 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,731 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 03:39:28,731 - INFO -     - accuracy: 0.6500
2025-07-28 03:39:28,731 - INFO -   mmlu_high_school_psychology:
2025-07-28 03:39:28,731 - INFO -     - accuracy: 0.9000
2025-07-28 03:39:28,731 - INFO -   mmlu_human_sexuality:
2025-07-28 03:39:28,731 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,732 - INFO -   mmlu_professional_psychology:
2025-07-28 03:39:28,732 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,732 - INFO -   mmlu_public_relations:
2025-07-28 03:39:28,732 - INFO -     - accuracy: 0.6000
2025-07-28 03:39:28,732 - INFO -   mmlu_security_studies:
2025-07-28 03:39:28,732 - INFO -     - accuracy: 0.7500
2025-07-28 03:39:28,732 - INFO -   mmlu_sociology:
2025-07-28 03:39:28,732 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,732 - INFO -   mmlu_us_foreign_policy:
2025-07-28 03:39:28,732 - INFO -     - accuracy: 0.9500
2025-07-28 03:39:28,733 - INFO -   mmlu_stem:
2025-07-28 03:39:28,733 - INFO -     - accuracy: 0.5868
2025-07-28 03:39:28,733 - INFO -   mmlu_abstract_algebra:
2025-07-28 03:39:28,733 - INFO -     - accuracy: 0.3000
2025-07-28 03:39:28,733 - INFO -   mmlu_anatomy:
2025-07-28 03:39:28,733 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,733 - INFO -   mmlu_astronomy:
2025-07-28 03:39:28,733 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,733 - INFO -   mmlu_college_biology:
2025-07-28 03:39:28,733 - INFO -     - accuracy: 0.8500
2025-07-28 03:39:28,733 - INFO -   mmlu_college_chemistry:
2025-07-28 03:39:28,734 - INFO -     - accuracy: 0.4000
2025-07-28 03:39:28,734 - INFO -   mmlu_college_computer_science:
2025-07-28 03:39:28,734 - INFO -     - accuracy: 0.4500
2025-07-28 03:39:28,734 - INFO -   mmlu_college_mathematics:
2025-07-28 03:39:28,734 - INFO -     - accuracy: 0.4000
2025-07-28 03:39:28,734 - INFO -   mmlu_college_physics:
2025-07-28 03:39:28,734 - INFO -     - accuracy: 0.5500
2025-07-28 03:39:28,734 - INFO -   mmlu_computer_security:
2025-07-28 03:39:28,734 - INFO -     - accuracy: 0.7500
2025-07-28 03:39:28,734 - INFO -   mmlu_conceptual_physics:
2025-07-28 03:39:28,734 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,735 - INFO -   mmlu_electrical_engineering:
2025-07-28 03:39:28,735 - INFO -     - accuracy: 0.5500
2025-07-28 03:39:28,735 - INFO -   mmlu_elementary_mathematics:
2025-07-28 03:39:28,735 - INFO -     - accuracy: 0.5000
2025-07-28 03:39:28,735 - INFO -   mmlu_high_school_biology:
2025-07-28 03:39:28,735 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,735 - INFO -   mmlu_high_school_chemistry:
2025-07-28 03:39:28,735 - INFO -     - accuracy: 0.6000
2025-07-28 03:39:28,735 - INFO -   mmlu_high_school_computer_science:
2025-07-28 03:39:28,735 - INFO -     - accuracy: 0.8000
2025-07-28 03:39:28,735 - INFO -   mmlu_high_school_mathematics:
2025-07-28 03:39:28,736 - INFO -     - accuracy: 0.3000
2025-07-28 03:39:28,736 - INFO -   mmlu_high_school_physics:
2025-07-28 03:39:28,736 - INFO -     - accuracy: 0.5500
2025-07-28 03:39:28,736 - INFO -   mmlu_high_school_statistics:
2025-07-28 03:39:28,736 - INFO -     - accuracy: 0.6000
2025-07-28 03:39:28,736 - INFO -   mmlu_machine_learning:
2025-07-28 03:39:28,736 - INFO -     - accuracy: 0.3500
2025-07-28 03:39:28,736 - INFO - ============================================================

2025-07-28 03:39:28,773 - INFO - Llama-3.1-8B_harness_1: Processing task 8/10: arc_challenge
2025-07-28 03:39:28,775 - INFO - Llama-3.1-8B_harness_1: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 03:39:28,775 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 03:39:28,776 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:39:39,069 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 03:39:44,223 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 03:39:44,224 - INFO - 
============================================================
2025-07-28 03:39:44,225 - INFO - Task 'arc_challenge' Results:
2025-07-28 03:39:44,225 - INFO - ============================================================
2025-07-28 03:39:44,225 - INFO -   arc_challenge:
2025-07-28 03:39:44,225 - INFO -     - accuracy: 0.4000
2025-07-28 03:39:44,225 - INFO -     - accuracy_norm: 0.3500
2025-07-28 03:39:44,225 - INFO - ============================================================

2025-07-28 03:39:44,260 - INFO - Llama-3.1-8B_harness_1: Processing task 9/10: arc_easy
2025-07-28 03:39:44,261 - INFO - Llama-3.1-8B_harness_1: Task 'arc_easy' will use num_fewshot=0
2025-07-28 03:39:44,262 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 03:39:44,262 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:39:53,732 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 03:39:58,781 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 03:39:58,783 - INFO - 
============================================================
2025-07-28 03:39:58,783 - INFO - Task 'arc_easy' Results:
2025-07-28 03:39:58,783 - INFO - ============================================================
2025-07-28 03:39:58,784 - INFO -   arc_easy:
2025-07-28 03:39:58,784 - INFO -     - accuracy: 0.8500
2025-07-28 03:39:58,784 - INFO -     - accuracy_norm: 0.7500
2025-07-28 03:39:58,784 - INFO - ============================================================

2025-07-28 03:39:58,819 - INFO - Llama-3.1-8B_harness_1: Processing task 10/10: hellaswag
2025-07-28 03:39:58,820 - INFO - Llama-3.1-8B_harness_1: Task 'hellaswag' will use num_fewshot=0
2025-07-28 03:39:58,820 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 03:39:58,821 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:40:17,151 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 03:40:22,535 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 03:40:22,536 - INFO - 
============================================================
2025-07-28 03:40:22,537 - INFO - Task 'hellaswag' Results:
2025-07-28 03:40:22,537 - INFO - ============================================================
2025-07-28 03:40:22,537 - INFO -   hellaswag:
2025-07-28 03:40:22,537 - INFO -     - accuracy: 0.4500
2025-07-28 03:40:22,537 - INFO -     - accuracy_norm: 0.6500
2025-07-28 03:40:22,538 - INFO - ============================================================

2025-07-28 03:40:22,573 - INFO - Llama-3.1-8B_harness_1: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 03:40:22,576 - INFO - [Process 1795506] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_032724/model_results/Llama-3.1-8B/Llama-3.1-8B_harness_1.json
2025-07-28 03:40:22,577 - INFO - [Process 1795506] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Llama-3.1-8B/Llama-3.1-8B_harness_1.json
2025-07-28 03:40:22,915 - INFO - Results uploaded to WandB as artifact
2025-07-28 03:40:22,924 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 03:40:22,925 - INFO - [Process 1795506] Successfully completed Llama-3.1-8B_harness_1
2025-07-28 03:40:25,306 - INFO - Run Llama-3.1-8B_harness_1 finished successfully
2025-07-28 03:40:25,306 - INFO - [Process 1795506] Mistral-7B-v0.3_harness_4 assigned to cuda:0
2025-07-28 03:40:25,307 - INFO - [Process 1795506] Mistral-7B-v0.3_harness_4 - using custom limit: 20
2025-07-28 03:40:26,677 - INFO - WandB run initialized: Mistral-7B-v0.3_20250728_034025 (ID: 8881a0b4)
2025-07-28 03:40:26,897 - INFO - Mistral-7B-v0.3_harness_4: Test mode (limit=2), setting num_fewshot=0
2025-07-28 03:40:26,897 - INFO - Mistral-7B-v0.3_harness_4: Processing task 1/10: kmmlu
2025-07-28 03:40:26,897 - INFO - Mistral-7B-v0.3_harness_4: Task 'kmmlu' will use num_fewshot=0
2025-07-28 03:40:26,898 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 03:40:26,898 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:41:44,136 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 03:41:44,136 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 03:41:44,137 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 03:41:44,137 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 03:41:44,137 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 03:41:44,137 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 03:41:44,137 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 03:41:44,137 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 03:41:44,137 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 03:41:44,137 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 03:41:44,138 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 03:41:44,138 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 03:41:44,138 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 03:41:44,138 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 03:41:44,138 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 03:41:44,138 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 03:41:44,138 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 03:41:44,138 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 03:41:44,138 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 03:41:44,138 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 03:41:44,139 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 03:41:44,139 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 03:41:44,139 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 03:41:44,139 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 03:41:44,139 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 03:41:44,139 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 03:41:44,139 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 03:41:44,139 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 03:41:44,139 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 03:41:44,139 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 03:41:44,140 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 03:41:44,140 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 03:41:44,140 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 03:41:44,140 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 03:41:44,140 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 03:41:44,140 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 03:41:44,140 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 03:41:44,140 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 03:41:44,140 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 03:41:44,140 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 03:41:44,141 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 03:41:44,141 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 03:41:44,141 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 03:41:44,141 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 03:41:44,141 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 03:42:18,994 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 03:42:18,995 - INFO - 
============================================================
2025-07-28 03:42:18,995 - INFO - Task 'kmmlu' Results:
2025-07-28 03:42:18,995 - INFO - ============================================================
2025-07-28 03:42:18,995 - INFO -   kmmlu:
2025-07-28 03:42:18,996 - INFO -     - accuracy: 0.3044
2025-07-28 03:42:18,996 - INFO -   kmmlu_applied_science:
2025-07-28 03:42:18,996 - INFO -     - accuracy: 0.2458
2025-07-28 03:42:18,996 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 03:42:18,996 - INFO -     - accuracy: 0.1000
2025-07-28 03:42:18,996 - INFO -   kmmlu_electronics_engineering:
2025-07-28 03:42:18,996 - INFO -     - accuracy: 0.1000
2025-07-28 03:42:18,996 - INFO -   kmmlu_energy_management:
2025-07-28 03:42:18,996 - INFO -     - accuracy: 0.2500
2025-07-28 03:42:18,997 - INFO -   kmmlu_environmental_science:
2025-07-28 03:42:18,997 - INFO -     - accuracy: 0.1000
2025-07-28 03:42:18,997 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 03:42:18,997 - INFO -     - accuracy: 0.5000
2025-07-28 03:42:18,997 - INFO -   kmmlu_geomatics:
2025-07-28 03:42:18,997 - INFO -     - accuracy: 0.2000
2025-07-28 03:42:18,997 - INFO -   kmmlu_industrial_engineer:
2025-07-28 03:42:18,997 - INFO -     - accuracy: 0.2500
2025-07-28 03:42:18,997 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 03:42:18,997 - INFO -     - accuracy: 0.3000
2025-07-28 03:42:18,997 - INFO -   kmmlu_maritime_engineering:
2025-07-28 03:42:18,998 - INFO -     - accuracy: 0.2000
2025-07-28 03:42:18,998 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 03:42:18,998 - INFO -     - accuracy: 0.4500
2025-07-28 03:42:18,998 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 03:42:18,998 - INFO -     - accuracy: 0.2500
2025-07-28 03:42:18,998 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 03:42:18,998 - INFO -     - accuracy: 0.2500
2025-07-28 03:42:18,998 - INFO -   kmmlu_humss:
2025-07-28 03:42:18,998 - INFO -     - accuracy: 0.3000
2025-07-28 03:42:18,998 - INFO -   kmmlu_accounting:
2025-07-28 03:42:18,999 - INFO -     - accuracy: 0.2500
2025-07-28 03:42:18,999 - INFO -   kmmlu_criminal_law:
2025-07-28 03:42:18,999 - INFO -     - accuracy: 0.1500
2025-07-28 03:42:18,999 - INFO -   kmmlu_economics:
2025-07-28 03:42:18,999 - INFO -     - accuracy: 0.3000
2025-07-28 03:42:18,999 - INFO -   kmmlu_education:
2025-07-28 03:42:18,999 - INFO -     - accuracy: 0.2500
2025-07-28 03:42:18,999 - INFO -   kmmlu_korean_history:
2025-07-28 03:42:18,999 - INFO -     - accuracy: 0.5500
2025-07-28 03:42:18,999 - INFO -   kmmlu_law:
2025-07-28 03:42:18,999 - INFO -     - accuracy: 0.4000
2025-07-28 03:42:19,000 - INFO -   kmmlu_management:
2025-07-28 03:42:19,000 - INFO -     - accuracy: 0.4000
2025-07-28 03:42:19,000 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 03:42:19,000 - INFO -     - accuracy: 0.2500
2025-07-28 03:42:19,000 - INFO -   kmmlu_psychology:
2025-07-28 03:42:19,000 - INFO -     - accuracy: 0.1500
2025-07-28 03:42:19,000 - INFO -   kmmlu_social_welfare:
2025-07-28 03:42:19,000 - INFO -     - accuracy: 0.3000
2025-07-28 03:42:19,000 - INFO -   kmmlu_taxation:
2025-07-28 03:42:19,000 - INFO -     - accuracy: 0.3000
2025-07-28 03:42:19,001 - INFO -   kmmlu_other:
2025-07-28 03:42:19,001 - INFO -     - accuracy: 0.3091
2025-07-28 03:42:19,001 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 03:42:19,001 - INFO -     - accuracy: 0.3500
2025-07-28 03:42:19,001 - INFO -   kmmlu_construction:
2025-07-28 03:42:19,001 - INFO -     - accuracy: 0.1500
2025-07-28 03:42:19,001 - INFO -   kmmlu_fashion:
2025-07-28 03:42:19,001 - INFO -     - accuracy: 0.2000
2025-07-28 03:42:19,001 - INFO -   kmmlu_food_processing:
2025-07-28 03:42:19,001 - INFO -     - accuracy: 0.3500
2025-07-28 03:42:19,001 - INFO -   kmmlu_health:
2025-07-28 03:42:19,002 - INFO -     - accuracy: 0.1000
2025-07-28 03:42:19,002 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 03:42:19,002 - INFO -     - accuracy: 0.3000
2025-07-28 03:42:19,002 - INFO -   kmmlu_marketing:
2025-07-28 03:42:19,002 - INFO -     - accuracy: 0.3500
2025-07-28 03:42:19,002 - INFO -   kmmlu_patent:
2025-07-28 03:42:19,002 - INFO -     - accuracy: 0.3500
2025-07-28 03:42:19,002 - INFO -   kmmlu_public_safety:
2025-07-28 03:42:19,002 - INFO -     - accuracy: 0.3500
2025-07-28 03:42:19,002 - INFO -   kmmlu_real_estate:
2025-07-28 03:42:19,002 - INFO -     - accuracy: 0.4500
2025-07-28 03:42:19,003 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 03:42:19,003 - INFO -     - accuracy: 0.4500
2025-07-28 03:42:19,003 - INFO -   kmmlu_stem:
2025-07-28 03:42:19,003 - INFO -     - accuracy: 0.3682
2025-07-28 03:42:19,003 - INFO -   kmmlu_biology:
2025-07-28 03:42:19,003 - INFO -     - accuracy: 0.3000
2025-07-28 03:42:19,003 - INFO -   kmmlu_chemical_engineering:
2025-07-28 03:42:19,003 - INFO -     - accuracy: 0.6000
2025-07-28 03:42:19,003 - INFO -   kmmlu_chemistry:
2025-07-28 03:42:19,003 - INFO -     - accuracy: 0.2500
2025-07-28 03:42:19,004 - INFO -   kmmlu_civil_engineering:
2025-07-28 03:42:19,004 - INFO -     - accuracy: 0.2000
2025-07-28 03:42:19,004 - INFO -   kmmlu_computer_science:
2025-07-28 03:42:19,004 - INFO -     - accuracy: 0.5500
2025-07-28 03:42:19,004 - INFO -   kmmlu_ecology:
2025-07-28 03:42:19,004 - INFO -     - accuracy: 0.5000
2025-07-28 03:42:19,004 - INFO -   kmmlu_electrical_engineering:
2025-07-28 03:42:19,004 - INFO -     - accuracy: 0.2000
2025-07-28 03:42:19,004 - INFO -   kmmlu_information_technology:
2025-07-28 03:42:19,004 - INFO -     - accuracy: 0.4000
2025-07-28 03:42:19,004 - INFO -   kmmlu_materials_engineering:
2025-07-28 03:42:19,005 - INFO -     - accuracy: 0.3000
2025-07-28 03:42:19,005 - INFO -   kmmlu_math:
2025-07-28 03:42:19,005 - INFO -     - accuracy: 0.3000
2025-07-28 03:42:19,005 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 03:42:19,005 - INFO -     - accuracy: 0.4500
2025-07-28 03:42:19,005 - INFO - ============================================================

2025-07-28 03:42:19,039 - INFO - Mistral-7B-v0.3_harness_4: Processing task 2/10: kmmlu_hard
2025-07-28 03:42:19,041 - INFO - Mistral-7B-v0.3_harness_4: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 03:42:19,041 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 03:42:19,042 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:43:33,292 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 03:43:33,292 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 03:43:33,292 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 03:43:33,292 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 03:43:33,293 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 03:43:33,294 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 03:43:33,295 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 03:43:33,296 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 03:43:33,296 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 03:43:33,296 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 03:43:33,296 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 03:43:33,296 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 03:43:33,296 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 03:43:33,296 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 03:43:33,296 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 03:44:08,263 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 03:44:08,263 - INFO - 
============================================================
2025-07-28 03:44:08,263 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 03:44:08,263 - INFO - ============================================================
2025-07-28 03:44:08,263 - INFO -   kmmlu_hard:
2025-07-28 03:44:08,264 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,265 - INFO -   kmmlu_hard_applied_science:
2025-07-28 03:44:08,265 - INFO -     - accuracy: 0.2958
2025-07-28 03:44:08,265 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 03:44:08,265 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,265 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 03:44:08,265 - INFO -     - accuracy: 0.3500
2025-07-28 03:44:08,265 - INFO -   kmmlu_hard_energy_management:
2025-07-28 03:44:08,265 - INFO -     - accuracy: 0.3500
2025-07-28 03:44:08,265 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 03:44:08,265 - INFO -     - accuracy: 0.3500
2025-07-28 03:44:08,266 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 03:44:08,266 - INFO -     - accuracy: 0.3000
2025-07-28 03:44:08,266 - INFO -   kmmlu_hard_geomatics:
2025-07-28 03:44:08,266 - INFO -     - accuracy: 0.3000
2025-07-28 03:44:08,266 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 03:44:08,266 - INFO -     - accuracy: 0.5500
2025-07-28 03:44:08,266 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 03:44:08,266 - INFO -     - accuracy: 0.1500
2025-07-28 03:44:08,266 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 03:44:08,266 - INFO -     - accuracy: 0.2000
2025-07-28 03:44:08,267 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 03:44:08,267 - INFO -     - accuracy: 0.3000
2025-07-28 03:44:08,267 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 03:44:08,267 - INFO -     - accuracy: 0.2000
2025-07-28 03:44:08,267 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 03:44:08,267 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,267 - INFO -   kmmlu_hard_humss:
2025-07-28 03:44:08,267 - INFO -     - accuracy: 0.1909
2025-07-28 03:44:08,267 - INFO -   kmmlu_hard_accounting:
2025-07-28 03:44:08,267 - INFO -     - accuracy: 0.1000
2025-07-28 03:44:08,267 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 03:44:08,268 - INFO -     - accuracy: 0.1500
2025-07-28 03:44:08,268 - INFO -   kmmlu_hard_economics:
2025-07-28 03:44:08,268 - INFO -     - accuracy: 0.1500
2025-07-28 03:44:08,268 - INFO -   kmmlu_hard_education:
2025-07-28 03:44:08,268 - INFO -     - accuracy: 0.3000
2025-07-28 03:44:08,268 - INFO -   kmmlu_hard_korean_history:
2025-07-28 03:44:08,268 - INFO -     - accuracy: 0.4000
2025-07-28 03:44:08,268 - INFO -   kmmlu_hard_law:
2025-07-28 03:44:08,268 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,268 - INFO -   kmmlu_hard_management:
2025-07-28 03:44:08,268 - INFO -     - accuracy: 0.0500
2025-07-28 03:44:08,269 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 03:44:08,269 - INFO -     - accuracy: 0.1500
2025-07-28 03:44:08,269 - INFO -   kmmlu_hard_psychology:
2025-07-28 03:44:08,269 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,269 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 03:44:08,269 - INFO -     - accuracy: 0.1500
2025-07-28 03:44:08,269 - INFO -   kmmlu_hard_taxation:
2025-07-28 03:44:08,269 - INFO -     - accuracy: 0.1500
2025-07-28 03:44:08,269 - INFO -   kmmlu_hard_other:
2025-07-28 03:44:08,269 - INFO -     - accuracy: 0.2409
2025-07-28 03:44:08,270 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 03:44:08,270 - INFO -     - accuracy: 0.1500
2025-07-28 03:44:08,270 - INFO -   kmmlu_hard_construction:
2025-07-28 03:44:08,270 - INFO -     - accuracy: 0.2000
2025-07-28 03:44:08,270 - INFO -   kmmlu_hard_fashion:
2025-07-28 03:44:08,270 - INFO -     - accuracy: 0.2000
2025-07-28 03:44:08,270 - INFO -   kmmlu_hard_food_processing:
2025-07-28 03:44:08,270 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,270 - INFO -   kmmlu_hard_health:
2025-07-28 03:44:08,270 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,270 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 03:44:08,271 - INFO -     - accuracy: 0.4000
2025-07-28 03:44:08,271 - INFO -   kmmlu_hard_marketing:
2025-07-28 03:44:08,271 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,271 - INFO -   kmmlu_hard_patent:
2025-07-28 03:44:08,271 - INFO -     - accuracy: 0.3500
2025-07-28 03:44:08,271 - INFO -   kmmlu_hard_public_safety:
2025-07-28 03:44:08,271 - INFO -     - accuracy: 0.1000
2025-07-28 03:44:08,271 - INFO -   kmmlu_hard_real_estate:
2025-07-28 03:44:08,271 - INFO -     - accuracy: 0.3500
2025-07-28 03:44:08,271 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 03:44:08,272 - INFO -     - accuracy: 0.1500
2025-07-28 03:44:08,272 - INFO -   kmmlu_hard_stem:
2025-07-28 03:44:08,272 - INFO -     - accuracy: 0.2682
2025-07-28 03:44:08,272 - INFO -   kmmlu_hard_biology:
2025-07-28 03:44:08,272 - INFO -     - accuracy: 0.3000
2025-07-28 03:44:08,272 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 03:44:08,272 - INFO -     - accuracy: 0.3500
2025-07-28 03:44:08,272 - INFO -   kmmlu_hard_chemistry:
2025-07-28 03:44:08,272 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,272 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 03:44:08,272 - INFO -     - accuracy: 0.3000
2025-07-28 03:44:08,273 - INFO -   kmmlu_hard_computer_science:
2025-07-28 03:44:08,273 - INFO -     - accuracy: 0.2000
2025-07-28 03:44:08,273 - INFO -   kmmlu_hard_ecology:
2025-07-28 03:44:08,273 - INFO -     - accuracy: 0.2000
2025-07-28 03:44:08,273 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 03:44:08,273 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,273 - INFO -   kmmlu_hard_information_technology:
2025-07-28 03:44:08,273 - INFO -     - accuracy: 0.2500
2025-07-28 03:44:08,273 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 03:44:08,273 - INFO -     - accuracy: 0.3000
2025-07-28 03:44:08,274 - INFO -   kmmlu_hard_math:
2025-07-28 03:44:08,274 - INFO -     - accuracy: 0.4000
2025-07-28 03:44:08,274 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 03:44:08,274 - INFO -     - accuracy: 0.1500
2025-07-28 03:44:08,274 - INFO - ============================================================

2025-07-28 03:44:08,309 - INFO - Mistral-7B-v0.3_harness_4: Processing task 3/10: haerae
2025-07-28 03:44:08,310 - INFO - Mistral-7B-v0.3_harness_4: Task 'haerae' will use num_fewshot=0
2025-07-28 03:44:08,310 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 03:44:08,311 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:44:26,711 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 03:44:26,712 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 03:44:26,712 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 03:44:26,712 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 03:44:26,712 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 03:44:45,100 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 03:44:45,101 - INFO - 
============================================================
2025-07-28 03:44:45,102 - INFO - Task 'haerae' Results:
2025-07-28 03:44:45,102 - INFO - ============================================================
2025-07-28 03:44:45,102 - INFO -   haerae:
2025-07-28 03:44:45,102 - INFO -     - accuracy: 0.4400
2025-07-28 03:44:45,102 - INFO -     - accuracy_norm: 0.4400
2025-07-28 03:44:45,102 - INFO -   haerae_general_knowledge:
2025-07-28 03:44:45,102 - INFO -     - accuracy: 0.7500
2025-07-28 03:44:45,102 - INFO -     - accuracy_norm: 0.7500
2025-07-28 03:44:45,102 - INFO -   haerae_history:
2025-07-28 03:44:45,103 - INFO -     - accuracy: 0.3000
2025-07-28 03:44:45,103 - INFO -     - accuracy_norm: 0.3000
2025-07-28 03:44:45,103 - INFO -   haerae_loan_word:
2025-07-28 03:44:45,103 - INFO -     - accuracy: 0.5000
2025-07-28 03:44:45,103 - INFO -     - accuracy_norm: 0.5000
2025-07-28 03:44:45,103 - INFO -   haerae_rare_word:
2025-07-28 03:44:45,103 - INFO -     - accuracy: 0.3000
2025-07-28 03:44:45,103 - INFO -     - accuracy_norm: 0.3000
2025-07-28 03:44:45,103 - INFO -   haerae_standard_nomenclature:
2025-07-28 03:44:45,103 - INFO -     - accuracy: 0.3500
2025-07-28 03:44:45,103 - INFO -     - accuracy_norm: 0.3500
2025-07-28 03:44:45,104 - INFO - ============================================================

2025-07-28 03:44:45,137 - INFO - Mistral-7B-v0.3_harness_4: Processing task 4/10: kobest
2025-07-28 03:44:45,139 - INFO - Mistral-7B-v0.3_harness_4: Task 'kobest' will use num_fewshot=0
2025-07-28 03:44:45,139 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 03:44:45,140 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:45:06,503 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 03:45:06,504 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 03:45:06,504 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 03:45:06,504 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 03:45:06,504 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 03:45:16,863 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 03:45:16,864 - INFO - 
============================================================
2025-07-28 03:45:16,864 - INFO - Task 'kobest' Results:
2025-07-28 03:45:16,864 - INFO - ============================================================
2025-07-28 03:45:16,864 - INFO -   kobest:
2025-07-28 03:45:16,864 - INFO -     - accuracy: 0.5300
2025-07-28 03:45:16,864 - INFO -     - accuracy_norm: 0.5500
2025-07-28 03:45:16,865 - INFO -     - f1: 0.4254
2025-07-28 03:45:16,865 - INFO -   kobest_boolq:
2025-07-28 03:45:16,865 - INFO -     - accuracy: 0.5500
2025-07-28 03:45:16,865 - INFO -     - f1: 0.4357
2025-07-28 03:45:16,865 - INFO -   kobest_copa:
2025-07-28 03:45:16,865 - INFO -     - accuracy: 0.6500
2025-07-28 03:45:16,865 - INFO -     - f1: 0.6491
2025-07-28 03:45:16,865 - INFO -   kobest_hellaswag:
2025-07-28 03:45:16,871 - INFO -     - accuracy: 0.3500
2025-07-28 03:45:16,871 - INFO -     - accuracy_norm: 0.5500
2025-07-28 03:45:16,871 - INFO -     - f1: 0.3326
2025-07-28 03:45:16,871 - INFO -   kobest_sentineg:
2025-07-28 03:45:16,872 - INFO -     - accuracy: 0.5500
2025-07-28 03:45:16,872 - INFO -     - f1: 0.3548
2025-07-28 03:45:16,872 - INFO -   kobest_wic:
2025-07-28 03:45:16,872 - INFO -     - accuracy: 0.5500
2025-07-28 03:45:16,872 - INFO -     - f1: 0.3548
2025-07-28 03:45:16,872 - INFO - ============================================================

2025-07-28 03:45:16,905 - INFO - Mistral-7B-v0.3_harness_4: Processing task 5/10: csatqa
2025-07-28 03:45:16,907 - INFO - Mistral-7B-v0.3_harness_4: Task 'csatqa' detected as zero-shot task
2025-07-28 03:45:16,908 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 03:45:16,908 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:45:29,979 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 03:45:29,979 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 03:45:29,979 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 03:45:29,979 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 03:45:29,979 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 03:45:29,979 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 03:47:26,057 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 03:47:26,059 - INFO - 
============================================================
2025-07-28 03:47:26,059 - INFO - Task 'csatqa' Results:
2025-07-28 03:47:26,059 - INFO - ============================================================
2025-07-28 03:47:26,059 - INFO -   csatqa:
2025-07-28 03:47:26,059 - INFO -     - accuracy: 0.2252
2025-07-28 03:47:26,059 - INFO -     - accuracy_norm: 0.2252
2025-07-28 03:47:26,060 - INFO -   csatqa_gr:
2025-07-28 03:47:26,060 - INFO -     - accuracy: 0.1000
2025-07-28 03:47:26,060 - INFO -     - accuracy_norm: 0.1000
2025-07-28 03:47:26,060 - INFO -   csatqa_li:
2025-07-28 03:47:26,060 - INFO -     - accuracy: 0.4000
2025-07-28 03:47:26,060 - INFO -     - accuracy_norm: 0.4000
2025-07-28 03:47:26,060 - INFO -   csatqa_rch:
2025-07-28 03:47:26,060 - INFO -     - accuracy: 0.2500
2025-07-28 03:47:26,060 - INFO -     - accuracy_norm: 0.2500
2025-07-28 03:47:26,060 - INFO -   csatqa_rcs:
2025-07-28 03:47:26,061 - INFO -     - accuracy: 0.2000
2025-07-28 03:47:26,061 - INFO -     - accuracy_norm: 0.2000
2025-07-28 03:47:26,061 - INFO -   csatqa_rcss:
2025-07-28 03:47:26,061 - INFO -     - accuracy: 0.2000
2025-07-28 03:47:26,061 - INFO -     - accuracy_norm: 0.2000
2025-07-28 03:47:26,061 - INFO -   csatqa_wr:
2025-07-28 03:47:26,061 - INFO -     - accuracy: 0.1818
2025-07-28 03:47:26,061 - INFO -     - accuracy_norm: 0.1818
2025-07-28 03:47:26,061 - INFO - ============================================================

2025-07-28 03:47:26,100 - INFO - Mistral-7B-v0.3_harness_4: Processing task 6/10: kormedmcqa
2025-07-28 03:47:26,100 - INFO - Mistral-7B-v0.3_harness_4: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 03:47:26,101 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 03:47:26,102 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:47:45,714 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 03:47:45,715 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 03:47:45,715 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 03:47:45,715 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 03:47:56,089 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 03:47:56,090 - INFO - 
============================================================
2025-07-28 03:47:56,090 - INFO - Task 'kormedmcqa' Results:
2025-07-28 03:47:56,091 - INFO - ============================================================
2025-07-28 03:47:56,091 - INFO -   kormedmcqa:
2025-07-28 03:47:56,091 - INFO -     - exact_match: 0.4375
2025-07-28 03:47:56,091 - INFO -   kormedmcqa_dentist:
2025-07-28 03:47:56,091 - INFO -     - exact_match: 0.3500
2025-07-28 03:47:56,091 - INFO -   kormedmcqa_doctor:
2025-07-28 03:47:56,091 - INFO -     - exact_match: 0.3500
2025-07-28 03:47:56,092 - INFO -   kormedmcqa_nurse:
2025-07-28 03:47:56,092 - INFO -     - exact_match: 0.4000
2025-07-28 03:47:56,092 - INFO -   kormedmcqa_pharm:
2025-07-28 03:47:56,092 - INFO -     - exact_match: 0.6500
2025-07-28 03:47:56,092 - INFO - ============================================================

2025-07-28 03:47:56,125 - INFO - Mistral-7B-v0.3_harness_4: Processing task 7/10: mmlu
2025-07-28 03:47:56,127 - INFO - Mistral-7B-v0.3_harness_4: Task 'mmlu' will use num_fewshot=0
2025-07-28 03:47:56,127 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 03:47:56,128 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:50:40,608 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 03:50:40,609 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 03:50:40,609 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 03:50:40,609 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 03:50:40,609 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 03:50:40,609 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 03:50:40,609 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 03:50:40,609 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 03:50:40,609 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 03:50:40,609 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 03:50:40,610 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 03:50:40,611 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 03:50:40,612 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 03:50:40,613 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 03:50:40,614 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 03:50:40,614 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 03:51:20,857 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 03:51:20,858 - INFO - 
============================================================
2025-07-28 03:51:20,858 - INFO - Task 'mmlu' Results:
2025-07-28 03:51:20,858 - INFO - ============================================================
2025-07-28 03:51:20,858 - INFO -   mmlu:
2025-07-28 03:51:20,859 - INFO -     - accuracy: 0.6088
2025-07-28 03:51:20,859 - INFO -   mmlu_humanities:
2025-07-28 03:51:20,859 - INFO -     - accuracy: 0.6423
2025-07-28 03:51:20,859 - INFO -   mmlu_formal_logic:
2025-07-28 03:51:20,859 - INFO -     - accuracy: 0.3500
2025-07-28 03:51:20,859 - INFO -   mmlu_high_school_european_history:
2025-07-28 03:51:20,859 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,860 - INFO -   mmlu_high_school_us_history:
2025-07-28 03:51:20,860 - INFO -     - accuracy: 0.7500
2025-07-28 03:51:20,860 - INFO -   mmlu_high_school_world_history:
2025-07-28 03:51:20,860 - INFO -     - accuracy: 0.8500
2025-07-28 03:51:20,860 - INFO -   mmlu_international_law:
2025-07-28 03:51:20,860 - INFO -     - accuracy: 0.8500
2025-07-28 03:51:20,860 - INFO -   mmlu_jurisprudence:
2025-07-28 03:51:20,860 - INFO -     - accuracy: 0.6500
2025-07-28 03:51:20,860 - INFO -   mmlu_logical_fallacies:
2025-07-28 03:51:20,861 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,861 - INFO -   mmlu_moral_disputes:
2025-07-28 03:51:20,861 - INFO -     - accuracy: 0.5500
2025-07-28 03:51:20,861 - INFO -   mmlu_moral_scenarios:
2025-07-28 03:51:20,861 - INFO -     - accuracy: 0.2500
2025-07-28 03:51:20,861 - INFO -   mmlu_philosophy:
2025-07-28 03:51:20,861 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,861 - INFO -   mmlu_prehistory:
2025-07-28 03:51:20,861 - INFO -     - accuracy: 0.5500
2025-07-28 03:51:20,861 - INFO -   mmlu_professional_law:
2025-07-28 03:51:20,861 - INFO -     - accuracy: 0.5500
2025-07-28 03:51:20,862 - INFO -   mmlu_world_religions:
2025-07-28 03:51:20,862 - INFO -     - accuracy: 0.9000
2025-07-28 03:51:20,862 - INFO -   mmlu_other:
2025-07-28 03:51:20,862 - INFO -     - accuracy: 0.6346
2025-07-28 03:51:20,862 - INFO -   mmlu_business_ethics:
2025-07-28 03:51:20,862 - INFO -     - accuracy: 0.6500
2025-07-28 03:51:20,862 - INFO -   mmlu_clinical_knowledge:
2025-07-28 03:51:20,862 - INFO -     - accuracy: 0.5500
2025-07-28 03:51:20,862 - INFO -   mmlu_college_medicine:
2025-07-28 03:51:20,863 - INFO -     - accuracy: 0.6000
2025-07-28 03:51:20,863 - INFO -   mmlu_global_facts:
2025-07-28 03:51:20,863 - INFO -     - accuracy: 0.3000
2025-07-28 03:51:20,863 - INFO -   mmlu_human_aging:
2025-07-28 03:51:20,863 - INFO -     - accuracy: 0.6000
2025-07-28 03:51:20,863 - INFO -   mmlu_management:
2025-07-28 03:51:20,863 - INFO -     - accuracy: 0.6500
2025-07-28 03:51:20,863 - INFO -   mmlu_marketing:
2025-07-28 03:51:20,863 - INFO -     - accuracy: 0.8000
2025-07-28 03:51:20,864 - INFO -   mmlu_medical_genetics:
2025-07-28 03:51:20,864 - INFO -     - accuracy: 0.8500
2025-07-28 03:51:20,864 - INFO -   mmlu_miscellaneous:
2025-07-28 03:51:20,864 - INFO -     - accuracy: 0.9000
2025-07-28 03:51:20,864 - INFO -   mmlu_nutrition:
2025-07-28 03:51:20,864 - INFO -     - accuracy: 0.8000
2025-07-28 03:51:20,864 - INFO -   mmlu_professional_accounting:
2025-07-28 03:51:20,864 - INFO -     - accuracy: 0.4500
2025-07-28 03:51:20,864 - INFO -   mmlu_professional_medicine:
2025-07-28 03:51:20,865 - INFO -     - accuracy: 0.6500
2025-07-28 03:51:20,865 - INFO -   mmlu_virology:
2025-07-28 03:51:20,865 - INFO -     - accuracy: 0.4500
2025-07-28 03:51:20,865 - INFO -   mmlu_social_sciences:
2025-07-28 03:51:20,865 - INFO -     - accuracy: 0.6750
2025-07-28 03:51:20,865 - INFO -   mmlu_econometrics:
2025-07-28 03:51:20,865 - INFO -     - accuracy: 0.3500
2025-07-28 03:51:20,865 - INFO -   mmlu_high_school_geography:
2025-07-28 03:51:20,865 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,866 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 03:51:20,866 - INFO -     - accuracy: 0.9000
2025-07-28 03:51:20,866 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 03:51:20,866 - INFO -     - accuracy: 0.6500
2025-07-28 03:51:20,866 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 03:51:20,866 - INFO -     - accuracy: 0.5500
2025-07-28 03:51:20,866 - INFO -   mmlu_high_school_psychology:
2025-07-28 03:51:20,866 - INFO -     - accuracy: 0.7500
2025-07-28 03:51:20,866 - INFO -   mmlu_human_sexuality:
2025-07-28 03:51:20,866 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,867 - INFO -   mmlu_professional_psychology:
2025-07-28 03:51:20,867 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,867 - INFO -   mmlu_public_relations:
2025-07-28 03:51:20,867 - INFO -     - accuracy: 0.5000
2025-07-28 03:51:20,867 - INFO -   mmlu_security_studies:
2025-07-28 03:51:20,867 - INFO -     - accuracy: 0.8500
2025-07-28 03:51:20,867 - INFO -   mmlu_sociology:
2025-07-28 03:51:20,867 - INFO -     - accuracy: 0.6000
2025-07-28 03:51:20,868 - INFO -   mmlu_us_foreign_policy:
2025-07-28 03:51:20,868 - INFO -     - accuracy: 0.8500
2025-07-28 03:51:20,868 - INFO -   mmlu_stem:
2025-07-28 03:51:20,868 - INFO -     - accuracy: 0.5263
2025-07-28 03:51:20,868 - INFO -   mmlu_abstract_algebra:
2025-07-28 03:51:20,868 - INFO -     - accuracy: 0.4000
2025-07-28 03:51:20,868 - INFO -   mmlu_anatomy:
2025-07-28 03:51:20,868 - INFO -     - accuracy: 0.5000
2025-07-28 03:51:20,868 - INFO -   mmlu_astronomy:
2025-07-28 03:51:20,868 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,869 - INFO -   mmlu_college_biology:
2025-07-28 03:51:20,869 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,869 - INFO -   mmlu_college_chemistry:
2025-07-28 03:51:20,869 - INFO -     - accuracy: 0.4000
2025-07-28 03:51:20,869 - INFO -   mmlu_college_computer_science:
2025-07-28 03:51:20,869 - INFO -     - accuracy: 0.5000
2025-07-28 03:51:20,869 - INFO -   mmlu_college_mathematics:
2025-07-28 03:51:20,869 - INFO -     - accuracy: 0.5500
2025-07-28 03:51:20,869 - INFO -   mmlu_college_physics:
2025-07-28 03:51:20,870 - INFO -     - accuracy: 0.5000
2025-07-28 03:51:20,870 - INFO -   mmlu_computer_security:
2025-07-28 03:51:20,870 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,870 - INFO -   mmlu_conceptual_physics:
2025-07-28 03:51:20,870 - INFO -     - accuracy: 0.6000
2025-07-28 03:51:20,870 - INFO -   mmlu_electrical_engineering:
2025-07-28 03:51:20,870 - INFO -     - accuracy: 0.3000
2025-07-28 03:51:20,870 - INFO -   mmlu_elementary_mathematics:
2025-07-28 03:51:20,870 - INFO -     - accuracy: 0.3000
2025-07-28 03:51:20,871 - INFO -   mmlu_high_school_biology:
2025-07-28 03:51:20,871 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,871 - INFO -   mmlu_high_school_chemistry:
2025-07-28 03:51:20,871 - INFO -     - accuracy: 0.5000
2025-07-28 03:51:20,871 - INFO -   mmlu_high_school_computer_science:
2025-07-28 03:51:20,871 - INFO -     - accuracy: 0.7000
2025-07-28 03:51:20,871 - INFO -   mmlu_high_school_mathematics:
2025-07-28 03:51:20,871 - INFO -     - accuracy: 0.2000
2025-07-28 03:51:20,871 - INFO -   mmlu_high_school_physics:
2025-07-28 03:51:20,872 - INFO -     - accuracy: 0.6500
2025-07-28 03:51:20,872 - INFO -   mmlu_high_school_statistics:
2025-07-28 03:51:20,872 - INFO -     - accuracy: 0.6000
2025-07-28 03:51:20,872 - INFO -   mmlu_machine_learning:
2025-07-28 03:51:20,872 - INFO -     - accuracy: 0.5000
2025-07-28 03:51:20,872 - INFO - ============================================================

2025-07-28 03:51:20,906 - INFO - Mistral-7B-v0.3_harness_4: Processing task 8/10: arc_challenge
2025-07-28 03:51:20,907 - INFO - Mistral-7B-v0.3_harness_4: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 03:51:20,908 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 03:51:20,908 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:51:30,011 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 03:51:35,351 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 03:51:35,352 - INFO - 
============================================================
2025-07-28 03:51:35,353 - INFO - Task 'arc_challenge' Results:
2025-07-28 03:51:35,353 - INFO - ============================================================
2025-07-28 03:51:35,353 - INFO -   arc_challenge:
2025-07-28 03:51:35,353 - INFO -     - accuracy: 0.4500
2025-07-28 03:51:35,353 - INFO -     - accuracy_norm: 0.5000
2025-07-28 03:51:35,353 - INFO - ============================================================

2025-07-28 03:51:35,386 - INFO - Mistral-7B-v0.3_harness_4: Processing task 9/10: arc_easy
2025-07-28 03:51:35,388 - INFO - Mistral-7B-v0.3_harness_4: Task 'arc_easy' will use num_fewshot=0
2025-07-28 03:51:35,388 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 03:51:35,389 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:51:44,816 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 03:51:50,003 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 03:51:50,004 - INFO - 
============================================================
2025-07-28 03:51:50,004 - INFO - Task 'arc_easy' Results:
2025-07-28 03:51:50,004 - INFO - ============================================================
2025-07-28 03:51:50,004 - INFO -   arc_easy:
2025-07-28 03:51:50,004 - INFO -     - accuracy: 0.8500
2025-07-28 03:51:50,004 - INFO -     - accuracy_norm: 0.7000
2025-07-28 03:51:50,005 - INFO - ============================================================

2025-07-28 03:51:50,037 - INFO - Mistral-7B-v0.3_harness_4: Processing task 10/10: hellaswag
2025-07-28 03:51:50,039 - INFO - Mistral-7B-v0.3_harness_4: Task 'hellaswag' will use num_fewshot=0
2025-07-28 03:51:50,039 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 03:51:50,040 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:52:05,191 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 03:52:10,558 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 03:52:10,559 - INFO - 
============================================================
2025-07-28 03:52:10,559 - INFO - Task 'hellaswag' Results:
2025-07-28 03:52:10,560 - INFO - ============================================================
2025-07-28 03:52:10,560 - INFO -   hellaswag:
2025-07-28 03:52:10,560 - INFO -     - accuracy: 0.4500
2025-07-28 03:52:10,560 - INFO -     - accuracy_norm: 0.7500
2025-07-28 03:52:10,561 - INFO - ============================================================

2025-07-28 03:52:10,595 - INFO - Mistral-7B-v0.3_harness_4: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 03:52:10,597 - INFO - [Process 1795506] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_032724/model_results/Mistral-7B-v0.3/Mistral-7B-v0.3_harness_4.json
2025-07-28 03:52:10,598 - INFO - [Process 1795506] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Mistral-7B-v0.3/Mistral-7B-v0.3_harness_4.json
2025-07-28 03:52:10,863 - INFO - Results uploaded to WandB as artifact
2025-07-28 03:52:10,871 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 03:52:10,873 - INFO - [Process 1795506] Successfully completed Mistral-7B-v0.3_harness_4
2025-07-28 03:52:12,780 - INFO - Run Mistral-7B-v0.3_harness_4 finished successfully
2025-07-28 03:52:12,781 - INFO - [Process 1795506] Qwen3-8B_harness_5 assigned to cuda:0
2025-07-28 03:52:12,781 - INFO - [Process 1795506] Qwen3-8B_harness_5 - using custom limit: 20
2025-07-28 03:52:14,028 - INFO - WandB run initialized: Qwen3-8B_20250728_035212 (ID: 2d5a7535)
2025-07-28 03:52:15,239 - INFO - Qwen3-8B_harness_5: Test mode (limit=2), setting num_fewshot=0
2025-07-28 03:52:15,239 - INFO - Qwen3-8B_harness_5: Processing task 1/10: kmmlu
2025-07-28 03:52:15,239 - INFO - Qwen3-8B_harness_5: Task 'kmmlu' will use num_fewshot=0
2025-07-28 03:52:15,239 - INFO - Qwen3-8B_harness_5: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 03:52:15,240 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:53:31,500 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 03:53:31,500 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 03:53:31,500 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 03:53:31,501 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 03:53:31,501 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 03:53:31,501 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 03:53:31,501 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 03:53:31,501 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 03:53:31,501 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 03:53:31,501 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 03:53:31,501 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 03:53:31,501 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 03:53:31,501 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 03:53:31,502 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 03:53:31,502 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 03:53:31,502 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 03:53:31,502 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 03:53:31,502 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 03:53:31,502 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 03:53:31,502 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 03:53:31,502 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 03:53:31,502 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 03:53:31,503 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 03:53:31,504 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 03:53:31,504 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 03:53:31,504 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 03:53:31,504 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 03:53:31,504 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 03:53:31,504 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 03:53:31,504 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 03:53:31,504 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 03:53:31,504 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 03:53:31,504 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 03:53:31,505 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 03:53:31,505 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 03:54:14,283 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 03:54:14,284 - INFO - 
============================================================
2025-07-28 03:54:14,285 - INFO - Task 'kmmlu' Results:
2025-07-28 03:54:14,285 - INFO - ============================================================
2025-07-28 03:54:14,286 - INFO -   kmmlu:
2025-07-28 03:54:14,286 - INFO -     - accuracy: 0.4333
2025-07-28 03:54:14,286 - INFO -   kmmlu_applied_science:
2025-07-28 03:54:14,286 - INFO -     - accuracy: 0.3500
2025-07-28 03:54:14,286 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 03:54:14,286 - INFO -     - accuracy: 0.3000
2025-07-28 03:54:14,286 - INFO -   kmmlu_electronics_engineering:
2025-07-28 03:54:14,287 - INFO -     - accuracy: 0.5500
2025-07-28 03:54:14,287 - INFO -   kmmlu_energy_management:
2025-07-28 03:54:14,287 - INFO -     - accuracy: 0.1500
2025-07-28 03:54:14,287 - INFO -   kmmlu_environmental_science:
2025-07-28 03:54:14,287 - INFO -     - accuracy: 0.3000
2025-07-28 03:54:14,287 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 03:54:14,287 - INFO -     - accuracy: 0.5500
2025-07-28 03:54:14,287 - INFO -   kmmlu_geomatics:
2025-07-28 03:54:14,287 - INFO -     - accuracy: 0.2500
2025-07-28 03:54:14,287 - INFO -   kmmlu_industrial_engineer:
2025-07-28 03:54:14,288 - INFO -     - accuracy: 0.2500
2025-07-28 03:54:14,288 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 03:54:14,288 - INFO -     - accuracy: 0.4500
2025-07-28 03:54:14,288 - INFO -   kmmlu_maritime_engineering:
2025-07-28 03:54:14,288 - INFO -     - accuracy: 0.3000
2025-07-28 03:54:14,288 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 03:54:14,288 - INFO -     - accuracy: 0.3500
2025-07-28 03:54:14,288 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 03:54:14,288 - INFO -     - accuracy: 0.3500
2025-07-28 03:54:14,288 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 03:54:14,288 - INFO -     - accuracy: 0.4000
2025-07-28 03:54:14,289 - INFO -   kmmlu_humss:
2025-07-28 03:54:14,289 - INFO -     - accuracy: 0.5000
2025-07-28 03:54:14,289 - INFO -   kmmlu_accounting:
2025-07-28 03:54:14,289 - INFO -     - accuracy: 0.5000
2025-07-28 03:54:14,289 - INFO -   kmmlu_criminal_law:
2025-07-28 03:54:14,289 - INFO -     - accuracy: 0.4000
2025-07-28 03:54:14,289 - INFO -   kmmlu_economics:
2025-07-28 03:54:14,289 - INFO -     - accuracy: 0.7500
2025-07-28 03:54:14,289 - INFO -   kmmlu_education:
2025-07-28 03:54:14,289 - INFO -     - accuracy: 0.7000
2025-07-28 03:54:14,290 - INFO -   kmmlu_korean_history:
2025-07-28 03:54:14,290 - INFO -     - accuracy: 0.4500
2025-07-28 03:54:14,290 - INFO -   kmmlu_law:
2025-07-28 03:54:14,290 - INFO -     - accuracy: 0.2000
2025-07-28 03:54:14,290 - INFO -   kmmlu_management:
2025-07-28 03:54:14,290 - INFO -     - accuracy: 0.6000
2025-07-28 03:54:14,290 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 03:54:14,290 - INFO -     - accuracy: 0.8500
2025-07-28 03:54:14,290 - INFO -   kmmlu_psychology:
2025-07-28 03:54:14,290 - INFO -     - accuracy: 0.3000
2025-07-28 03:54:14,290 - INFO -   kmmlu_social_welfare:
2025-07-28 03:54:14,291 - INFO -     - accuracy: 0.4000
2025-07-28 03:54:14,291 - INFO -   kmmlu_taxation:
2025-07-28 03:54:14,291 - INFO -     - accuracy: 0.3500
2025-07-28 03:54:14,291 - INFO -   kmmlu_other:
2025-07-28 03:54:14,291 - INFO -     - accuracy: 0.4455
2025-07-28 03:54:14,291 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 03:54:14,291 - INFO -     - accuracy: 0.3000
2025-07-28 03:54:14,291 - INFO -   kmmlu_construction:
2025-07-28 03:54:14,291 - INFO -     - accuracy: 0.4500
2025-07-28 03:54:14,291 - INFO -   kmmlu_fashion:
2025-07-28 03:54:14,292 - INFO -     - accuracy: 0.2500
2025-07-28 03:54:14,292 - INFO -   kmmlu_food_processing:
2025-07-28 03:54:14,292 - INFO -     - accuracy: 0.3500
2025-07-28 03:54:14,292 - INFO -   kmmlu_health:
2025-07-28 03:54:14,292 - INFO -     - accuracy: 0.6000
2025-07-28 03:54:14,292 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 03:54:14,292 - INFO -     - accuracy: 0.6500
2025-07-28 03:54:14,292 - INFO -   kmmlu_marketing:
2025-07-28 03:54:14,292 - INFO -     - accuracy: 0.6000
2025-07-28 03:54:14,292 - INFO -   kmmlu_patent:
2025-07-28 03:54:14,292 - INFO -     - accuracy: 0.4500
2025-07-28 03:54:14,293 - INFO -   kmmlu_public_safety:
2025-07-28 03:54:14,293 - INFO -     - accuracy: 0.5000
2025-07-28 03:54:14,293 - INFO -   kmmlu_real_estate:
2025-07-28 03:54:14,293 - INFO -     - accuracy: 0.3000
2025-07-28 03:54:14,293 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 03:54:14,293 - INFO -     - accuracy: 0.4500
2025-07-28 03:54:14,293 - INFO -   kmmlu_stem:
2025-07-28 03:54:14,293 - INFO -     - accuracy: 0.4455
2025-07-28 03:54:14,293 - INFO -   kmmlu_biology:
2025-07-28 03:54:14,293 - INFO -     - accuracy: 0.3000
2025-07-28 03:54:14,294 - INFO -   kmmlu_chemical_engineering:
2025-07-28 03:54:14,294 - INFO -     - accuracy: 0.5000
2025-07-28 03:54:14,294 - INFO -   kmmlu_chemistry:
2025-07-28 03:54:14,294 - INFO -     - accuracy: 0.3000
2025-07-28 03:54:14,294 - INFO -   kmmlu_civil_engineering:
2025-07-28 03:54:14,294 - INFO -     - accuracy: 0.2000
2025-07-28 03:54:14,294 - INFO -   kmmlu_computer_science:
2025-07-28 03:54:14,294 - INFO -     - accuracy: 0.9000
2025-07-28 03:54:14,294 - INFO -   kmmlu_ecology:
2025-07-28 03:54:14,294 - INFO -     - accuracy: 0.5000
2025-07-28 03:54:14,294 - INFO -   kmmlu_electrical_engineering:
2025-07-28 03:54:14,295 - INFO -     - accuracy: 0.4500
2025-07-28 03:54:14,295 - INFO -   kmmlu_information_technology:
2025-07-28 03:54:14,295 - INFO -     - accuracy: 0.5500
2025-07-28 03:54:14,295 - INFO -   kmmlu_materials_engineering:
2025-07-28 03:54:14,295 - INFO -     - accuracy: 0.4500
2025-07-28 03:54:14,295 - INFO -   kmmlu_math:
2025-07-28 03:54:14,295 - INFO -     - accuracy: 0.3500
2025-07-28 03:54:14,295 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 03:54:14,295 - INFO -     - accuracy: 0.4000
2025-07-28 03:54:14,295 - INFO - ============================================================

2025-07-28 03:54:14,337 - INFO - Qwen3-8B_harness_5: Processing task 2/10: kmmlu_hard
2025-07-28 03:54:14,339 - INFO - Qwen3-8B_harness_5: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 03:54:14,339 - INFO - Qwen3-8B_harness_5: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 03:54:14,340 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:55:29,910 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 03:55:29,911 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 03:55:29,911 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 03:55:29,911 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 03:55:29,911 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 03:55:29,912 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 03:55:29,921 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 03:55:29,921 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 03:55:29,921 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 03:55:29,921 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 03:55:29,921 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 03:55:29,922 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 03:55:29,922 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 03:55:29,922 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 03:55:29,922 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 03:55:29,922 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 03:55:29,922 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 03:55:29,923 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 03:55:29,923 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 03:55:29,923 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 03:55:29,923 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 03:55:29,923 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 03:55:29,923 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 03:55:29,923 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 03:55:29,924 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 03:55:29,924 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 03:55:29,924 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 03:55:29,924 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 03:55:29,924 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 03:55:29,924 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 03:55:29,924 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 03:55:29,925 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 03:55:29,925 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 03:55:29,925 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 03:55:29,925 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 03:55:29,925 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 03:55:29,925 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 03:55:29,926 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 03:55:29,926 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 03:55:29,926 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 03:55:29,926 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 03:55:29,926 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 03:55:29,926 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 03:55:29,926 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 03:55:29,927 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 03:56:12,882 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 03:56:12,883 - INFO - 
============================================================
2025-07-28 03:56:12,884 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 03:56:12,884 - INFO - ============================================================
2025-07-28 03:56:12,884 - INFO -   kmmlu_hard:
2025-07-28 03:56:12,885 - INFO -     - accuracy: 0.2700
2025-07-28 03:56:12,885 - INFO -   kmmlu_hard_applied_science:
2025-07-28 03:56:12,885 - INFO -     - accuracy: 0.2833
2025-07-28 03:56:12,885 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 03:56:12,885 - INFO -     - accuracy: 0.2500
2025-07-28 03:56:12,885 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 03:56:12,885 - INFO -     - accuracy: 0.3500
2025-07-28 03:56:12,886 - INFO -   kmmlu_hard_energy_management:
2025-07-28 03:56:12,886 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,886 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 03:56:12,886 - INFO -     - accuracy: 0.1500
2025-07-28 03:56:12,886 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 03:56:12,886 - INFO -     - accuracy: 0.1500
2025-07-28 03:56:12,886 - INFO -   kmmlu_hard_geomatics:
2025-07-28 03:56:12,886 - INFO -     - accuracy: 0.1500
2025-07-28 03:56:12,886 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 03:56:12,886 - INFO -     - accuracy: 0.4500
2025-07-28 03:56:12,887 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 03:56:12,887 - INFO -     - accuracy: 0.4000
2025-07-28 03:56:12,887 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 03:56:12,887 - INFO -     - accuracy: 0.0500
2025-07-28 03:56:12,887 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 03:56:12,887 - INFO -     - accuracy: 0.1500
2025-07-28 03:56:12,887 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 03:56:12,887 - INFO -     - accuracy: 0.5000
2025-07-28 03:56:12,887 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 03:56:12,887 - INFO -     - accuracy: 0.5000
2025-07-28 03:56:12,888 - INFO -   kmmlu_hard_humss:
2025-07-28 03:56:12,888 - INFO -     - accuracy: 0.2273
2025-07-28 03:56:12,888 - INFO -   kmmlu_hard_accounting:
2025-07-28 03:56:12,888 - INFO -     - accuracy: 0.2500
2025-07-28 03:56:12,888 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 03:56:12,888 - INFO -     - accuracy: 0.1500
2025-07-28 03:56:12,888 - INFO -   kmmlu_hard_economics:
2025-07-28 03:56:12,888 - INFO -     - accuracy: 0.1500
2025-07-28 03:56:12,888 - INFO -   kmmlu_hard_education:
2025-07-28 03:56:12,889 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,889 - INFO -   kmmlu_hard_korean_history:
2025-07-28 03:56:12,889 - INFO -     - accuracy: 0.1500
2025-07-28 03:56:12,889 - INFO -   kmmlu_hard_law:
2025-07-28 03:56:12,889 - INFO -     - accuracy: 0.1000
2025-07-28 03:56:12,889 - INFO -   kmmlu_hard_management:
2025-07-28 03:56:12,889 - INFO -     - accuracy: 0.4000
2025-07-28 03:56:12,889 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 03:56:12,889 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,890 - INFO -   kmmlu_hard_psychology:
2025-07-28 03:56:12,890 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,890 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 03:56:12,890 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,890 - INFO -   kmmlu_hard_taxation:
2025-07-28 03:56:12,890 - INFO -     - accuracy: 0.1000
2025-07-28 03:56:12,890 - INFO -   kmmlu_hard_other:
2025-07-28 03:56:12,890 - INFO -     - accuracy: 0.2818
2025-07-28 03:56:12,890 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 03:56:12,891 - INFO -     - accuracy: 0.1500
2025-07-28 03:56:12,891 - INFO -   kmmlu_hard_construction:
2025-07-28 03:56:12,891 - INFO -     - accuracy: 0.3500
2025-07-28 03:56:12,891 - INFO -   kmmlu_hard_fashion:
2025-07-28 03:56:12,891 - INFO -     - accuracy: 0.2000
2025-07-28 03:56:12,891 - INFO -   kmmlu_hard_food_processing:
2025-07-28 03:56:12,891 - INFO -     - accuracy: 0.3500
2025-07-28 03:56:12,891 - INFO -   kmmlu_hard_health:
2025-07-28 03:56:12,891 - INFO -     - accuracy: 0.1500
2025-07-28 03:56:12,892 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 03:56:12,892 - INFO -     - accuracy: 0.4000
2025-07-28 03:56:12,892 - INFO -   kmmlu_hard_marketing:
2025-07-28 03:56:12,892 - INFO -     - accuracy: 0.3500
2025-07-28 03:56:12,892 - INFO -   kmmlu_hard_patent:
2025-07-28 03:56:12,892 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,892 - INFO -   kmmlu_hard_public_safety:
2025-07-28 03:56:12,892 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,892 - INFO -   kmmlu_hard_real_estate:
2025-07-28 03:56:12,892 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,893 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 03:56:12,893 - INFO -     - accuracy: 0.2500
2025-07-28 03:56:12,893 - INFO -   kmmlu_hard_stem:
2025-07-28 03:56:12,893 - INFO -     - accuracy: 0.2864
2025-07-28 03:56:12,893 - INFO -   kmmlu_hard_biology:
2025-07-28 03:56:12,893 - INFO -     - accuracy: 0.1500
2025-07-28 03:56:12,893 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 03:56:12,893 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,893 - INFO -   kmmlu_hard_chemistry:
2025-07-28 03:56:12,894 - INFO -     - accuracy: 0.3500
2025-07-28 03:56:12,894 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 03:56:12,894 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,894 - INFO -   kmmlu_hard_computer_science:
2025-07-28 03:56:12,894 - INFO -     - accuracy: 0.4000
2025-07-28 03:56:12,894 - INFO -   kmmlu_hard_ecology:
2025-07-28 03:56:12,894 - INFO -     - accuracy: 0.3500
2025-07-28 03:56:12,894 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 03:56:12,894 - INFO -     - accuracy: 0.3000
2025-07-28 03:56:12,895 - INFO -   kmmlu_hard_information_technology:
2025-07-28 03:56:12,895 - INFO -     - accuracy: 0.4000
2025-07-28 03:56:12,895 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 03:56:12,895 - INFO -     - accuracy: 0.2000
2025-07-28 03:56:12,895 - INFO -   kmmlu_hard_math:
2025-07-28 03:56:12,895 - INFO -     - accuracy: 0.2000
2025-07-28 03:56:12,895 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 03:56:12,895 - INFO -     - accuracy: 0.2000
2025-07-28 03:56:12,896 - INFO - ============================================================

2025-07-28 03:56:12,934 - INFO - Qwen3-8B_harness_5: Processing task 3/10: haerae
2025-07-28 03:56:12,935 - INFO - Qwen3-8B_harness_5: Task 'haerae' will use num_fewshot=0
2025-07-28 03:56:12,936 - INFO - Qwen3-8B_harness_5: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 03:56:12,937 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:56:30,808 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 03:56:30,808 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 03:56:30,809 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 03:56:30,809 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 03:56:30,809 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 03:56:54,257 - INFO - Qwen3-8B_harness_5: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 03:56:54,259 - INFO - 
============================================================
2025-07-28 03:56:54,259 - INFO - Task 'haerae' Results:
2025-07-28 03:56:54,259 - INFO - ============================================================
2025-07-28 03:56:54,259 - INFO -   haerae:
2025-07-28 03:56:54,259 - INFO -     - accuracy: 0.6700
2025-07-28 03:56:54,259 - INFO -     - accuracy_norm: 0.6700
2025-07-28 03:56:54,260 - INFO -   haerae_general_knowledge:
2025-07-28 03:56:54,260 - INFO -     - accuracy: 0.8000
2025-07-28 03:56:54,260 - INFO -     - accuracy_norm: 0.8000
2025-07-28 03:56:54,260 - INFO -   haerae_history:
2025-07-28 03:56:54,260 - INFO -     - accuracy: 0.4500
2025-07-28 03:56:54,260 - INFO -     - accuracy_norm: 0.4500
2025-07-28 03:56:54,260 - INFO -   haerae_loan_word:
2025-07-28 03:56:54,260 - INFO -     - accuracy: 0.8500
2025-07-28 03:56:54,260 - INFO -     - accuracy_norm: 0.8500
2025-07-28 03:56:54,260 - INFO -   haerae_rare_word:
2025-07-28 03:56:54,261 - INFO -     - accuracy: 0.5500
2025-07-28 03:56:54,261 - INFO -     - accuracy_norm: 0.5500
2025-07-28 03:56:54,261 - INFO -   haerae_standard_nomenclature:
2025-07-28 03:56:54,261 - INFO -     - accuracy: 0.7000
2025-07-28 03:56:54,261 - INFO -     - accuracy_norm: 0.7000
2025-07-28 03:56:54,261 - INFO - ============================================================

2025-07-28 03:56:54,299 - INFO - Qwen3-8B_harness_5: Processing task 4/10: kobest
2025-07-28 03:56:54,300 - INFO - Qwen3-8B_harness_5: Task 'kobest' will use num_fewshot=0
2025-07-28 03:56:54,301 - INFO - Qwen3-8B_harness_5: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 03:56:54,301 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:57:15,905 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 03:57:15,905 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 03:57:15,905 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 03:57:15,906 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 03:57:15,906 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 03:57:28,585 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 03:57:28,586 - INFO - 
============================================================
2025-07-28 03:57:28,586 - INFO - Task 'kobest' Results:
2025-07-28 03:57:28,587 - INFO - ============================================================
2025-07-28 03:57:28,588 - INFO -   kobest:
2025-07-28 03:57:28,588 - INFO -     - accuracy: 0.6300
2025-07-28 03:57:28,588 - INFO -     - accuracy_norm: 0.5500
2025-07-28 03:57:28,589 - INFO -     - f1: 0.5957
2025-07-28 03:57:28,589 - INFO -   kobest_boolq:
2025-07-28 03:57:28,589 - INFO -     - accuracy: 0.6000
2025-07-28 03:57:28,589 - INFO -     - f1: 0.4667
2025-07-28 03:57:28,589 - INFO -   kobest_copa:
2025-07-28 03:57:28,589 - INFO -     - accuracy: 0.6500
2025-07-28 03:57:28,589 - INFO -     - f1: 0.6491
2025-07-28 03:57:28,589 - INFO -   kobest_hellaswag:
2025-07-28 03:57:28,590 - INFO -     - accuracy: 0.4000
2025-07-28 03:57:28,590 - INFO -     - accuracy_norm: 0.5500
2025-07-28 03:57:28,590 - INFO -     - f1: 0.3958
2025-07-28 03:57:28,590 - INFO -   kobest_sentineg:
2025-07-28 03:57:28,590 - INFO -     - accuracy: 0.8500
2025-07-28 03:57:28,590 - INFO -     - f1: 0.8400
2025-07-28 03:57:28,590 - INFO -   kobest_wic:
2025-07-28 03:57:28,590 - INFO -     - accuracy: 0.6500
2025-07-28 03:57:28,590 - INFO -     - f1: 0.6267
2025-07-28 03:57:28,591 - INFO - ============================================================

2025-07-28 03:57:28,629 - INFO - Qwen3-8B_harness_5: Processing task 5/10: csatqa
2025-07-28 03:57:28,630 - INFO - Qwen3-8B_harness_5: Task 'csatqa' detected as zero-shot task
2025-07-28 03:57:28,630 - INFO - Qwen3-8B_harness_5: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 03:57:28,631 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:57:43,770 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 03:57:43,771 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 03:57:43,771 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 03:57:43,771 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 03:57:43,771 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 03:57:43,771 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 03:59:11,753 - INFO - Qwen3-8B_harness_5: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 03:59:11,753 - INFO - 
============================================================
2025-07-28 03:59:11,755 - INFO - Task 'csatqa' Results:
2025-07-28 03:59:11,755 - INFO - ============================================================
2025-07-28 03:59:11,756 - INFO -   csatqa:
2025-07-28 03:59:11,756 - INFO -     - accuracy: 0.4685
2025-07-28 03:59:11,756 - INFO -     - accuracy_norm: 0.4685
2025-07-28 03:59:11,756 - INFO -   csatqa_gr:
2025-07-28 03:59:11,756 - INFO -     - accuracy: 0.2000
2025-07-28 03:59:11,756 - INFO -     - accuracy_norm: 0.2000
2025-07-28 03:59:11,757 - INFO -   csatqa_li:
2025-07-28 03:59:11,757 - INFO -     - accuracy: 0.5500
2025-07-28 03:59:11,757 - INFO -     - accuracy_norm: 0.5500
2025-07-28 03:59:11,757 - INFO -   csatqa_rch:
2025-07-28 03:59:11,757 - INFO -     - accuracy: 0.6000
2025-07-28 03:59:11,757 - INFO -     - accuracy_norm: 0.6000
2025-07-28 03:59:11,757 - INFO -   csatqa_rcs:
2025-07-28 03:59:11,757 - INFO -     - accuracy: 0.5500
2025-07-28 03:59:11,757 - INFO -     - accuracy_norm: 0.5500
2025-07-28 03:59:11,757 - INFO -   csatqa_rcss:
2025-07-28 03:59:11,758 - INFO -     - accuracy: 0.5000
2025-07-28 03:59:11,758 - INFO -     - accuracy_norm: 0.5000
2025-07-28 03:59:11,758 - INFO -   csatqa_wr:
2025-07-28 03:59:11,758 - INFO -     - accuracy: 0.3636
2025-07-28 03:59:11,758 - INFO -     - accuracy_norm: 0.3636
2025-07-28 03:59:11,758 - INFO - ============================================================

2025-07-28 03:59:11,804 - INFO - Qwen3-8B_harness_5: Processing task 6/10: kormedmcqa
2025-07-28 03:59:11,804 - INFO - Qwen3-8B_harness_5: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 03:59:11,806 - INFO - Qwen3-8B_harness_5: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 03:59:11,807 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 03:59:32,448 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 03:59:32,448 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 03:59:32,448 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 03:59:32,448 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 04:01:27,428 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 04:01:27,429 - INFO - 
============================================================
2025-07-28 04:01:27,430 - INFO - Task 'kormedmcqa' Results:
2025-07-28 04:01:27,430 - INFO - ============================================================
2025-07-28 04:01:27,430 - INFO -   kormedmcqa:
2025-07-28 04:01:27,430 - INFO -     - exact_match: 0.2500
2025-07-28 04:01:27,431 - INFO -   kormedmcqa_dentist:
2025-07-28 04:01:27,431 - INFO -     - exact_match: 0.1000
2025-07-28 04:01:27,431 - INFO -   kormedmcqa_doctor:
2025-07-28 04:01:27,431 - INFO -     - exact_match: 0.1000
2025-07-28 04:01:27,431 - INFO -   kormedmcqa_nurse:
2025-07-28 04:01:27,431 - INFO -     - exact_match: 0.2500
2025-07-28 04:01:27,431 - INFO -   kormedmcqa_pharm:
2025-07-28 04:01:27,431 - INFO -     - exact_match: 0.5500
2025-07-28 04:01:27,432 - INFO - ============================================================

2025-07-28 04:01:27,470 - INFO - Qwen3-8B_harness_5: Processing task 7/10: mmlu
2025-07-28 04:01:27,472 - INFO - Qwen3-8B_harness_5: Task 'mmlu' will use num_fewshot=0
2025-07-28 04:01:27,473 - INFO - Qwen3-8B_harness_5: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 04:01:27,474 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:04:13,658 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 04:04:13,659 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 04:04:13,659 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 04:04:13,659 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 04:04:13,659 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 04:04:13,659 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 04:04:13,659 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 04:04:13,659 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 04:04:13,660 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 04:04:13,661 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 04:04:13,662 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 04:04:13,663 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 04:04:13,664 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 04:04:13,664 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 04:04:13,664 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 04:05:07,554 - INFO - Qwen3-8B_harness_5: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 04:05:07,555 - INFO - 
============================================================
2025-07-28 04:05:07,556 - INFO - Task 'mmlu' Results:
2025-07-28 04:05:07,569 - INFO - ============================================================
2025-07-28 04:05:07,570 - INFO -   mmlu:
2025-07-28 04:05:07,570 - INFO -     - accuracy: 0.7614
2025-07-28 04:05:07,570 - INFO -   mmlu_humanities:
2025-07-28 04:05:07,570 - INFO -     - accuracy: 0.7692
2025-07-28 04:05:07,570 - INFO -   mmlu_formal_logic:
2025-07-28 04:05:07,570 - INFO -     - accuracy: 0.7000
2025-07-28 04:05:07,570 - INFO -   mmlu_high_school_european_history:
2025-07-28 04:05:07,571 - INFO -     - accuracy: 0.8500
2025-07-28 04:05:07,571 - INFO -   mmlu_high_school_us_history:
2025-07-28 04:05:07,571 - INFO -     - accuracy: 0.9000
2025-07-28 04:05:07,571 - INFO -   mmlu_high_school_world_history:
2025-07-28 04:05:07,571 - INFO -     - accuracy: 0.9000
2025-07-28 04:05:07,571 - INFO -   mmlu_international_law:
2025-07-28 04:05:07,571 - INFO -     - accuracy: 0.9000
2025-07-28 04:05:07,571 - INFO -   mmlu_jurisprudence:
2025-07-28 04:05:07,571 - INFO -     - accuracy: 0.8500
2025-07-28 04:05:07,572 - INFO -   mmlu_logical_fallacies:
2025-07-28 04:05:07,572 - INFO -     - accuracy: 0.8000
2025-07-28 04:05:07,572 - INFO -   mmlu_moral_disputes:
2025-07-28 04:05:07,572 - INFO -     - accuracy: 0.6500
2025-07-28 04:05:07,572 - INFO -   mmlu_moral_scenarios:
2025-07-28 04:05:07,572 - INFO -     - accuracy: 0.2500
2025-07-28 04:05:07,572 - INFO -   mmlu_philosophy:
2025-07-28 04:05:07,572 - INFO -     - accuracy: 0.7500
2025-07-28 04:05:07,572 - INFO -   mmlu_prehistory:
2025-07-28 04:05:07,572 - INFO -     - accuracy: 0.8000
2025-07-28 04:05:07,573 - INFO -   mmlu_professional_law:
2025-07-28 04:05:07,573 - INFO -     - accuracy: 0.6500
2025-07-28 04:05:07,573 - INFO -   mmlu_world_religions:
2025-07-28 04:05:07,573 - INFO -     - accuracy: 1.0000
2025-07-28 04:05:07,573 - INFO -   mmlu_other:
2025-07-28 04:05:07,573 - INFO -     - accuracy: 0.7500
2025-07-28 04:05:07,573 - INFO -   mmlu_business_ethics:
2025-07-28 04:05:07,573 - INFO -     - accuracy: 0.8500
2025-07-28 04:05:07,573 - INFO -   mmlu_clinical_knowledge:
2025-07-28 04:05:07,574 - INFO -     - accuracy: 0.8000
2025-07-28 04:05:07,574 - INFO -   mmlu_college_medicine:
2025-07-28 04:05:07,574 - INFO -     - accuracy: 0.7000
2025-07-28 04:05:07,574 - INFO -   mmlu_global_facts:
2025-07-28 04:05:07,574 - INFO -     - accuracy: 0.5500
2025-07-28 04:05:07,574 - INFO -   mmlu_human_aging:
2025-07-28 04:05:07,574 - INFO -     - accuracy: 0.8500
2025-07-28 04:05:07,574 - INFO -   mmlu_management:
2025-07-28 04:05:07,574 - INFO -     - accuracy: 0.8500
2025-07-28 04:05:07,575 - INFO -   mmlu_marketing:
2025-07-28 04:05:07,575 - INFO -     - accuracy: 0.8000
2025-07-28 04:05:07,575 - INFO -   mmlu_medical_genetics:
2025-07-28 04:05:07,575 - INFO -     - accuracy: 1.0000
2025-07-28 04:05:07,575 - INFO -   mmlu_miscellaneous:
2025-07-28 04:05:07,575 - INFO -     - accuracy: 0.7500
2025-07-28 04:05:07,575 - INFO -   mmlu_nutrition:
2025-07-28 04:05:07,575 - INFO -     - accuracy: 0.8000
2025-07-28 04:05:07,575 - INFO -   mmlu_professional_accounting:
2025-07-28 04:05:07,576 - INFO -     - accuracy: 0.4500
2025-07-28 04:05:07,576 - INFO -   mmlu_professional_medicine:
2025-07-28 04:05:07,576 - INFO -     - accuracy: 0.8000
2025-07-28 04:05:07,576 - INFO -   mmlu_virology:
2025-07-28 04:05:07,576 - INFO -     - accuracy: 0.5500
2025-07-28 04:05:07,576 - INFO -   mmlu_social_sciences:
2025-07-28 04:05:07,576 - INFO -     - accuracy: 0.8542
2025-07-28 04:05:07,576 - INFO -   mmlu_econometrics:
2025-07-28 04:05:07,576 - INFO -     - accuracy: 0.8000
2025-07-28 04:05:07,577 - INFO -   mmlu_high_school_geography:
2025-07-28 04:05:07,577 - INFO -     - accuracy: 0.8500
2025-07-28 04:05:07,577 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 04:05:07,577 - INFO -     - accuracy: 0.9500
2025-07-28 04:05:07,577 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 04:05:07,577 - INFO -     - accuracy: 0.8500
2025-07-28 04:05:07,577 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 04:05:07,577 - INFO -     - accuracy: 0.8500
2025-07-28 04:05:07,577 - INFO -   mmlu_high_school_psychology:
2025-07-28 04:05:07,577 - INFO -     - accuracy: 1.0000
2025-07-28 04:05:07,578 - INFO -   mmlu_human_sexuality:
2025-07-28 04:05:07,578 - INFO -     - accuracy: 0.8500
2025-07-28 04:05:07,578 - INFO -   mmlu_professional_psychology:
2025-07-28 04:05:07,578 - INFO -     - accuracy: 0.9000
2025-07-28 04:05:07,578 - INFO -   mmlu_public_relations:
2025-07-28 04:05:07,578 - INFO -     - accuracy: 0.6500
2025-07-28 04:05:07,578 - INFO -   mmlu_security_studies:
2025-07-28 04:05:07,578 - INFO -     - accuracy: 0.8500
2025-07-28 04:05:07,578 - INFO -   mmlu_sociology:
2025-07-28 04:05:07,579 - INFO -     - accuracy: 0.8000
2025-07-28 04:05:07,579 - INFO -   mmlu_us_foreign_policy:
2025-07-28 04:05:07,579 - INFO -     - accuracy: 0.9000
2025-07-28 04:05:07,579 - INFO -   mmlu_stem:
2025-07-28 04:05:07,579 - INFO -     - accuracy: 0.7053
2025-07-28 04:05:07,579 - INFO -   mmlu_abstract_algebra:
2025-07-28 04:05:07,579 - INFO -     - accuracy: 0.3500
2025-07-28 04:05:07,579 - INFO -   mmlu_anatomy:
2025-07-28 04:05:07,579 - INFO -     - accuracy: 0.7500
2025-07-28 04:05:07,580 - INFO -   mmlu_astronomy:
2025-07-28 04:05:07,580 - INFO -     - accuracy: 0.9500
2025-07-28 04:05:07,580 - INFO -   mmlu_college_biology:
2025-07-28 04:05:07,580 - INFO -     - accuracy: 0.9000
2025-07-28 04:05:07,580 - INFO -   mmlu_college_chemistry:
2025-07-28 04:05:07,580 - INFO -     - accuracy: 0.5500
2025-07-28 04:05:07,580 - INFO -   mmlu_college_computer_science:
2025-07-28 04:05:07,580 - INFO -     - accuracy: 0.7500
2025-07-28 04:05:07,580 - INFO -   mmlu_college_mathematics:
2025-07-28 04:05:07,580 - INFO -     - accuracy: 0.4500
2025-07-28 04:05:07,581 - INFO -   mmlu_college_physics:
2025-07-28 04:05:07,581 - INFO -     - accuracy: 0.7000
2025-07-28 04:05:07,581 - INFO -   mmlu_computer_security:
2025-07-28 04:05:07,581 - INFO -     - accuracy: 0.7500
2025-07-28 04:05:07,581 - INFO -   mmlu_conceptual_physics:
2025-07-28 04:05:07,581 - INFO -     - accuracy: 1.0000
2025-07-28 04:05:07,581 - INFO -   mmlu_electrical_engineering:
2025-07-28 04:05:07,581 - INFO -     - accuracy: 0.5500
2025-07-28 04:05:07,581 - INFO -   mmlu_elementary_mathematics:
2025-07-28 04:05:07,582 - INFO -     - accuracy: 0.6500
2025-07-28 04:05:07,582 - INFO -   mmlu_high_school_biology:
2025-07-28 04:05:07,582 - INFO -     - accuracy: 0.9500
2025-07-28 04:05:07,582 - INFO -   mmlu_high_school_chemistry:
2025-07-28 04:05:07,582 - INFO -     - accuracy: 0.7500
2025-07-28 04:05:07,582 - INFO -   mmlu_high_school_computer_science:
2025-07-28 04:05:07,582 - INFO -     - accuracy: 0.9000
2025-07-28 04:05:07,582 - INFO -   mmlu_high_school_mathematics:
2025-07-28 04:05:07,582 - INFO -     - accuracy: 0.5500
2025-07-28 04:05:07,583 - INFO -   mmlu_high_school_physics:
2025-07-28 04:05:07,583 - INFO -     - accuracy: 0.5500
2025-07-28 04:05:07,583 - INFO -   mmlu_high_school_statistics:
2025-07-28 04:05:07,583 - INFO -     - accuracy: 0.8000
2025-07-28 04:05:07,583 - INFO -   mmlu_machine_learning:
2025-07-28 04:05:07,583 - INFO -     - accuracy: 0.5500
2025-07-28 04:05:07,583 - INFO - ============================================================

2025-07-28 04:05:07,624 - INFO - Qwen3-8B_harness_5: Processing task 8/10: arc_challenge
2025-07-28 04:05:07,625 - INFO - Qwen3-8B_harness_5: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 04:05:07,626 - INFO - Qwen3-8B_harness_5: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 04:05:07,626 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:05:17,230 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 04:05:23,401 - INFO - Qwen3-8B_harness_5: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 04:05:23,403 - INFO - 
============================================================
2025-07-28 04:05:23,403 - INFO - Task 'arc_challenge' Results:
2025-07-28 04:05:23,403 - INFO - ============================================================
2025-07-28 04:05:23,403 - INFO -   arc_challenge:
2025-07-28 04:05:23,403 - INFO -     - accuracy: 0.4500
2025-07-28 04:05:23,403 - INFO -     - accuracy_norm: 0.5000
2025-07-28 04:05:23,404 - INFO - ============================================================

2025-07-28 04:05:23,441 - INFO - Qwen3-8B_harness_5: Processing task 9/10: arc_easy
2025-07-28 04:05:23,443 - INFO - Qwen3-8B_harness_5: Task 'arc_easy' will use num_fewshot=0
2025-07-28 04:05:23,443 - INFO - Qwen3-8B_harness_5: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 04:05:23,444 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:05:32,681 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 04:05:38,551 - INFO - Qwen3-8B_harness_5: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 04:05:38,552 - INFO - 
============================================================
2025-07-28 04:05:38,553 - INFO - Task 'arc_easy' Results:
2025-07-28 04:05:38,553 - INFO - ============================================================
2025-07-28 04:05:38,554 - INFO -   arc_easy:
2025-07-28 04:05:38,554 - INFO -     - accuracy: 0.7500
2025-07-28 04:05:38,554 - INFO -     - accuracy_norm: 0.7000
2025-07-28 04:05:38,554 - INFO - ============================================================

2025-07-28 04:05:38,591 - INFO - Qwen3-8B_harness_5: Processing task 10/10: hellaswag
2025-07-28 04:05:38,593 - INFO - Qwen3-8B_harness_5: Task 'hellaswag' will use num_fewshot=0
2025-07-28 04:05:38,593 - INFO - Qwen3-8B_harness_5: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 04:05:38,594 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:05:54,285 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 04:06:00,669 - INFO - Qwen3-8B_harness_5: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 04:06:00,671 - INFO - 
============================================================
2025-07-28 04:06:00,672 - INFO - Task 'hellaswag' Results:
2025-07-28 04:06:00,673 - INFO - ============================================================
2025-07-28 04:06:00,673 - INFO -   hellaswag:
2025-07-28 04:06:00,673 - INFO -     - accuracy: 0.4000
2025-07-28 04:06:00,673 - INFO -     - accuracy_norm: 0.5500
2025-07-28 04:06:00,673 - INFO - ============================================================

2025-07-28 04:06:00,710 - INFO - Qwen3-8B_harness_5: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 04:06:00,713 - INFO - [Process 1795506] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_032724/model_results/Qwen3-8B/Qwen3-8B_harness_5.json
2025-07-28 04:06:00,715 - INFO - [Process 1795506] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Qwen3-8B/Qwen3-8B_harness_5.json
2025-07-28 04:06:00,983 - INFO - Results uploaded to WandB as artifact
2025-07-28 04:06:00,992 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 04:06:00,994 - INFO - [Process 1795506] Successfully completed Qwen3-8B_harness_5
2025-07-28 04:06:03,040 - INFO - Run Qwen3-8B_harness_5 finished successfully
2025-07-28 04:06:03,041 - INFO - [Process 1795506] Llama-DNA-1.0-8B-Instruct_harness_6 assigned to cuda:0
2025-07-28 04:06:03,041 - INFO - [Process 1795506] Llama-DNA-1.0-8B-Instruct_harness_6 - using custom limit: 20
2025-07-28 04:06:04,480 - INFO - WandB run initialized: Llama-DNA-1.0-8B-Instruct_20250728_040603 (ID: 03094734)
2025-07-28 04:06:04,699 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Test mode (limit=2), setting num_fewshot=0
2025-07-28 04:06:04,699 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 1/10: kmmlu
2025-07-28 04:06:04,699 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kmmlu' will use num_fewshot=0
2025-07-28 04:06:04,699 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 04:06:04,700 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:07:18,820 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 04:07:18,820 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 04:07:18,820 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 04:07:18,820 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 04:07:18,820 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 04:07:18,820 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 04:07:18,820 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 04:07:18,821 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 04:07:18,822 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 04:07:18,822 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 04:07:18,822 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 04:07:18,822 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 04:07:18,822 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 04:07:18,822 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 04:07:18,822 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 04:07:18,822 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 04:07:18,822 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 04:07:18,822 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 04:07:18,823 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 04:07:18,824 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 04:07:18,824 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 04:07:18,824 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 04:07:18,824 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 04:07:52,581 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 04:07:52,582 - INFO - 
============================================================
2025-07-28 04:07:52,583 - INFO - Task 'kmmlu' Results:
2025-07-28 04:07:52,584 - INFO - ============================================================
2025-07-28 04:07:52,584 - INFO -   kmmlu:
2025-07-28 04:07:52,584 - INFO -     - accuracy: 0.4344
2025-07-28 04:07:52,584 - INFO -   kmmlu_applied_science:
2025-07-28 04:07:52,584 - INFO -     - accuracy: 0.3875
2025-07-28 04:07:52,585 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 04:07:52,585 - INFO -     - accuracy: 0.2500
2025-07-28 04:07:52,585 - INFO -   kmmlu_electronics_engineering:
2025-07-28 04:07:52,585 - INFO -     - accuracy: 0.5000
2025-07-28 04:07:52,585 - INFO -   kmmlu_energy_management:
2025-07-28 04:07:52,585 - INFO -     - accuracy: 0.3000
2025-07-28 04:07:52,585 - INFO -   kmmlu_environmental_science:
2025-07-28 04:07:52,585 - INFO -     - accuracy: 0.4500
2025-07-28 04:07:52,586 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 04:07:52,586 - INFO -     - accuracy: 0.4000
2025-07-28 04:07:52,586 - INFO -   kmmlu_geomatics:
2025-07-28 04:07:52,586 - INFO -     - accuracy: 0.4000
2025-07-28 04:07:52,586 - INFO -   kmmlu_industrial_engineer:
2025-07-28 04:07:52,586 - INFO -     - accuracy: 0.3500
2025-07-28 04:07:52,586 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 04:07:52,586 - INFO -     - accuracy: 0.4500
2025-07-28 04:07:52,586 - INFO -   kmmlu_maritime_engineering:
2025-07-28 04:07:52,586 - INFO -     - accuracy: 0.3500
2025-07-28 04:07:52,586 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 04:07:52,587 - INFO -     - accuracy: 0.3000
2025-07-28 04:07:52,587 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 04:07:52,587 - INFO -     - accuracy: 0.3000
2025-07-28 04:07:52,587 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 04:07:52,587 - INFO -     - accuracy: 0.6000
2025-07-28 04:07:52,587 - INFO -   kmmlu_humss:
2025-07-28 04:07:52,587 - INFO -     - accuracy: 0.4409
2025-07-28 04:07:52,587 - INFO -   kmmlu_accounting:
2025-07-28 04:07:52,587 - INFO -     - accuracy: 0.6000
2025-07-28 04:07:52,588 - INFO -   kmmlu_criminal_law:
2025-07-28 04:07:52,588 - INFO -     - accuracy: 0.2000
2025-07-28 04:07:52,588 - INFO -   kmmlu_economics:
2025-07-28 04:07:52,588 - INFO -     - accuracy: 0.7000
2025-07-28 04:07:52,588 - INFO -   kmmlu_education:
2025-07-28 04:07:52,588 - INFO -     - accuracy: 0.6000
2025-07-28 04:07:52,588 - INFO -   kmmlu_korean_history:
2025-07-28 04:07:52,588 - INFO -     - accuracy: 0.3500
2025-07-28 04:07:52,588 - INFO -   kmmlu_law:
2025-07-28 04:07:52,589 - INFO -     - accuracy: 0.2000
2025-07-28 04:07:52,589 - INFO -   kmmlu_management:
2025-07-28 04:07:52,589 - INFO -     - accuracy: 0.3500
2025-07-28 04:07:52,589 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 04:07:52,589 - INFO -     - accuracy: 0.7500
2025-07-28 04:07:52,589 - INFO -   kmmlu_psychology:
2025-07-28 04:07:52,589 - INFO -     - accuracy: 0.3500
2025-07-28 04:07:52,589 - INFO -   kmmlu_social_welfare:
2025-07-28 04:07:52,589 - INFO -     - accuracy: 0.4500
2025-07-28 04:07:52,590 - INFO -   kmmlu_taxation:
2025-07-28 04:07:52,590 - INFO -     - accuracy: 0.3000
2025-07-28 04:07:52,590 - INFO -   kmmlu_other:
2025-07-28 04:07:52,590 - INFO -     - accuracy: 0.4318
2025-07-28 04:07:52,590 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 04:07:52,590 - INFO -     - accuracy: 0.3500
2025-07-28 04:07:52,590 - INFO -   kmmlu_construction:
2025-07-28 04:07:52,590 - INFO -     - accuracy: 0.3000
2025-07-28 04:07:52,590 - INFO -   kmmlu_fashion:
2025-07-28 04:07:52,591 - INFO -     - accuracy: 0.1500
2025-07-28 04:07:52,591 - INFO -   kmmlu_food_processing:
2025-07-28 04:07:52,591 - INFO -     - accuracy: 0.4000
2025-07-28 04:07:52,591 - INFO -   kmmlu_health:
2025-07-28 04:07:52,591 - INFO -     - accuracy: 0.7500
2025-07-28 04:07:52,591 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 04:07:52,591 - INFO -     - accuracy: 0.7500
2025-07-28 04:07:52,591 - INFO -   kmmlu_marketing:
2025-07-28 04:07:52,591 - INFO -     - accuracy: 0.5500
2025-07-28 04:07:52,592 - INFO -   kmmlu_patent:
2025-07-28 04:07:52,592 - INFO -     - accuracy: 0.3000
2025-07-28 04:07:52,592 - INFO -   kmmlu_public_safety:
2025-07-28 04:07:52,592 - INFO -     - accuracy: 0.4500
2025-07-28 04:07:52,592 - INFO -   kmmlu_real_estate:
2025-07-28 04:07:52,592 - INFO -     - accuracy: 0.3500
2025-07-28 04:07:52,592 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 04:07:52,592 - INFO -     - accuracy: 0.4000
2025-07-28 04:07:52,592 - INFO -   kmmlu_stem:
2025-07-28 04:07:52,592 - INFO -     - accuracy: 0.4818
2025-07-28 04:07:52,593 - INFO -   kmmlu_biology:
2025-07-28 04:07:52,593 - INFO -     - accuracy: 0.3000
2025-07-28 04:07:52,593 - INFO -   kmmlu_chemical_engineering:
2025-07-28 04:07:52,593 - INFO -     - accuracy: 0.3500
2025-07-28 04:07:52,593 - INFO -   kmmlu_chemistry:
2025-07-28 04:07:52,593 - INFO -     - accuracy: 0.3000
2025-07-28 04:07:52,593 - INFO -   kmmlu_civil_engineering:
2025-07-28 04:07:52,593 - INFO -     - accuracy: 0.6500
2025-07-28 04:07:52,593 - INFO -   kmmlu_computer_science:
2025-07-28 04:07:52,594 - INFO -     - accuracy: 0.8500
2025-07-28 04:07:52,594 - INFO -   kmmlu_ecology:
2025-07-28 04:07:52,594 - INFO -     - accuracy: 0.5000
2025-07-28 04:07:52,594 - INFO -   kmmlu_electrical_engineering:
2025-07-28 04:07:52,594 - INFO -     - accuracy: 0.4000
2025-07-28 04:07:52,594 - INFO -   kmmlu_information_technology:
2025-07-28 04:07:52,594 - INFO -     - accuracy: 0.6500
2025-07-28 04:07:52,594 - INFO -   kmmlu_materials_engineering:
2025-07-28 04:07:52,594 - INFO -     - accuracy: 0.5000
2025-07-28 04:07:52,595 - INFO -   kmmlu_math:
2025-07-28 04:07:52,595 - INFO -     - accuracy: 0.3000
2025-07-28 04:07:52,595 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 04:07:52,595 - INFO -     - accuracy: 0.5000
2025-07-28 04:07:52,595 - INFO - ============================================================

2025-07-28 04:07:52,633 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 2/10: kmmlu_hard
2025-07-28 04:07:52,634 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 04:07:52,635 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 04:07:52,636 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:09:09,762 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 04:09:09,763 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 04:09:09,763 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 04:09:09,763 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 04:09:09,763 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 04:09:09,763 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 04:09:09,763 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 04:09:09,763 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 04:09:09,763 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 04:09:09,763 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 04:09:09,764 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 04:09:09,764 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 04:09:09,764 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 04:09:09,764 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 04:09:09,764 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 04:09:09,764 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 04:09:09,764 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 04:09:09,764 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 04:09:09,764 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 04:09:09,764 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 04:09:09,765 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 04:09:09,765 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 04:09:09,765 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 04:09:09,765 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 04:09:09,765 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 04:09:09,765 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 04:09:09,765 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 04:09:09,765 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 04:09:09,765 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 04:09:09,765 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 04:09:09,766 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 04:09:09,766 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 04:09:09,766 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 04:09:09,766 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 04:09:09,766 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 04:09:09,766 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 04:09:09,766 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 04:09:09,766 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 04:09:09,766 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 04:09:09,766 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 04:09:09,767 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 04:09:09,767 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 04:09:09,767 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 04:09:09,767 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 04:09:09,767 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 04:09:43,170 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 04:09:43,171 - INFO - 
============================================================
2025-07-28 04:09:43,172 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 04:09:43,172 - INFO - ============================================================
2025-07-28 04:09:43,173 - INFO -   kmmlu_hard:
2025-07-28 04:09:43,173 - INFO -     - accuracy: 0.2822
2025-07-28 04:09:43,173 - INFO -   kmmlu_hard_applied_science:
2025-07-28 04:09:43,173 - INFO -     - accuracy: 0.2875
2025-07-28 04:09:43,173 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 04:09:43,173 - INFO -     - accuracy: 0.2500
2025-07-28 04:09:43,173 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 04:09:43,173 - INFO -     - accuracy: 0.3000
2025-07-28 04:09:43,174 - INFO -   kmmlu_hard_energy_management:
2025-07-28 04:09:43,174 - INFO -     - accuracy: 0.2000
2025-07-28 04:09:43,174 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 04:09:43,174 - INFO -     - accuracy: 0.4000
2025-07-28 04:09:43,174 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 04:09:43,174 - INFO -     - accuracy: 0.1500
2025-07-28 04:09:43,174 - INFO -   kmmlu_hard_geomatics:
2025-07-28 04:09:43,174 - INFO -     - accuracy: 0.3000
2025-07-28 04:09:43,174 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 04:09:43,175 - INFO -     - accuracy: 0.2000
2025-07-28 04:09:43,175 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 04:09:43,175 - INFO -     - accuracy: 0.4000
2025-07-28 04:09:43,175 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 04:09:43,175 - INFO -     - accuracy: 0.3000
2025-07-28 04:09:43,175 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 04:09:43,175 - INFO -     - accuracy: 0.3500
2025-07-28 04:09:43,175 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 04:09:43,175 - INFO -     - accuracy: 0.1500
2025-07-28 04:09:43,176 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 04:09:43,176 - INFO -     - accuracy: 0.4500
2025-07-28 04:09:43,176 - INFO -   kmmlu_hard_humss:
2025-07-28 04:09:43,176 - INFO -     - accuracy: 0.2091
2025-07-28 04:09:43,176 - INFO -   kmmlu_hard_accounting:
2025-07-28 04:09:43,176 - INFO -     - accuracy: 0.1000
2025-07-28 04:09:43,176 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 04:09:43,176 - INFO -     - accuracy: 0.0500
2025-07-28 04:09:43,176 - INFO -   kmmlu_hard_economics:
2025-07-28 04:09:43,176 - INFO -     - accuracy: 0.3000
2025-07-28 04:09:43,176 - INFO -   kmmlu_hard_education:
2025-07-28 04:09:43,177 - INFO -     - accuracy: 0.2500
2025-07-28 04:09:43,177 - INFO -   kmmlu_hard_korean_history:
2025-07-28 04:09:43,177 - INFO -     - accuracy: 0.1500
2025-07-28 04:09:43,177 - INFO -   kmmlu_hard_law:
2025-07-28 04:09:43,177 - INFO -     - accuracy: 0.1500
2025-07-28 04:09:43,177 - INFO -   kmmlu_hard_management:
2025-07-28 04:09:43,177 - INFO -     - accuracy: 0.2500
2025-07-28 04:09:43,177 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 04:09:43,177 - INFO -     - accuracy: 0.2000
2025-07-28 04:09:43,178 - INFO -   kmmlu_hard_psychology:
2025-07-28 04:09:43,178 - INFO -     - accuracy: 0.5500
2025-07-28 04:09:43,178 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 04:09:43,178 - INFO -     - accuracy: 0.1500
2025-07-28 04:09:43,178 - INFO -   kmmlu_hard_taxation:
2025-07-28 04:09:43,178 - INFO -     - accuracy: 0.1500
2025-07-28 04:09:43,178 - INFO -   kmmlu_hard_other:
2025-07-28 04:09:43,178 - INFO -     - accuracy: 0.3091
2025-07-28 04:09:43,178 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 04:09:43,179 - INFO -     - accuracy: 0.1500
2025-07-28 04:09:43,179 - INFO -   kmmlu_hard_construction:
2025-07-28 04:09:43,179 - INFO -     - accuracy: 0.4500
2025-07-28 04:09:43,179 - INFO -   kmmlu_hard_fashion:
2025-07-28 04:09:43,179 - INFO -     - accuracy: 0.3500
2025-07-28 04:09:43,179 - INFO -   kmmlu_hard_food_processing:
2025-07-28 04:09:43,179 - INFO -     - accuracy: 0.4000
2025-07-28 04:09:43,179 - INFO -   kmmlu_hard_health:
2025-07-28 04:09:43,179 - INFO -     - accuracy: 0.1500
2025-07-28 04:09:43,180 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 04:09:43,180 - INFO -     - accuracy: 0.4500
2025-07-28 04:09:43,180 - INFO -   kmmlu_hard_marketing:
2025-07-28 04:09:43,180 - INFO -     - accuracy: 0.5500
2025-07-28 04:09:43,180 - INFO -   kmmlu_hard_patent:
2025-07-28 04:09:43,180 - INFO -     - accuracy: 0.1000
2025-07-28 04:09:43,180 - INFO -   kmmlu_hard_public_safety:
2025-07-28 04:09:43,180 - INFO -     - accuracy: 0.2000
2025-07-28 04:09:43,180 - INFO -   kmmlu_hard_real_estate:
2025-07-28 04:09:43,180 - INFO -     - accuracy: 0.3000
2025-07-28 04:09:43,181 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 04:09:43,181 - INFO -     - accuracy: 0.3000
2025-07-28 04:09:43,181 - INFO -   kmmlu_hard_stem:
2025-07-28 04:09:43,181 - INFO -     - accuracy: 0.3227
2025-07-28 04:09:43,181 - INFO -   kmmlu_hard_biology:
2025-07-28 04:09:43,181 - INFO -     - accuracy: 0.1500
2025-07-28 04:09:43,181 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 04:09:43,181 - INFO -     - accuracy: 0.2000
2025-07-28 04:09:43,200 - INFO -   kmmlu_hard_chemistry:
2025-07-28 04:09:43,200 - INFO -     - accuracy: 0.2500
2025-07-28 04:09:43,200 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 04:09:43,200 - INFO -     - accuracy: 0.3000
2025-07-28 04:09:43,200 - INFO -   kmmlu_hard_computer_science:
2025-07-28 04:09:43,200 - INFO -     - accuracy: 0.5500
2025-07-28 04:09:43,200 - INFO -   kmmlu_hard_ecology:
2025-07-28 04:09:43,201 - INFO -     - accuracy: 0.2000
2025-07-28 04:09:43,201 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 04:09:43,201 - INFO -     - accuracy: 0.3500
2025-07-28 04:09:43,201 - INFO -   kmmlu_hard_information_technology:
2025-07-28 04:09:43,201 - INFO -     - accuracy: 0.3500
2025-07-28 04:09:43,201 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 04:09:43,201 - INFO -     - accuracy: 0.5000
2025-07-28 04:09:43,201 - INFO -   kmmlu_hard_math:
2025-07-28 04:09:43,201 - INFO -     - accuracy: 0.4000
2025-07-28 04:09:43,202 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 04:09:43,202 - INFO -     - accuracy: 0.3000
2025-07-28 04:09:43,202 - INFO - ============================================================

2025-07-28 04:09:43,239 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 3/10: haerae
2025-07-28 04:09:43,241 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'haerae' will use num_fewshot=0
2025-07-28 04:09:43,242 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 04:09:43,242 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:10:02,246 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 04:10:02,247 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 04:10:02,247 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 04:10:02,247 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 04:10:02,247 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 04:10:20,155 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 04:10:20,156 - INFO - 
============================================================
2025-07-28 04:10:20,157 - INFO - Task 'haerae' Results:
2025-07-28 04:10:20,157 - INFO - ============================================================
2025-07-28 04:10:20,158 - INFO -   haerae:
2025-07-28 04:10:20,158 - INFO -     - accuracy: 0.6800
2025-07-28 04:10:20,158 - INFO -     - accuracy_norm: 0.6800
2025-07-28 04:10:20,158 - INFO -   haerae_general_knowledge:
2025-07-28 04:10:20,158 - INFO -     - accuracy: 0.7000
2025-07-28 04:10:20,158 - INFO -     - accuracy_norm: 0.7000
2025-07-28 04:10:20,158 - INFO -   haerae_history:
2025-07-28 04:10:20,159 - INFO -     - accuracy: 0.5000
2025-07-28 04:10:20,159 - INFO -     - accuracy_norm: 0.5000
2025-07-28 04:10:20,159 - INFO -   haerae_loan_word:
2025-07-28 04:10:20,159 - INFO -     - accuracy: 0.8500
2025-07-28 04:10:20,159 - INFO -     - accuracy_norm: 0.8500
2025-07-28 04:10:20,159 - INFO -   haerae_rare_word:
2025-07-28 04:10:20,159 - INFO -     - accuracy: 0.6500
2025-07-28 04:10:20,159 - INFO -     - accuracy_norm: 0.6500
2025-07-28 04:10:20,159 - INFO -   haerae_standard_nomenclature:
2025-07-28 04:10:20,159 - INFO -     - accuracy: 0.7000
2025-07-28 04:10:20,160 - INFO -     - accuracy_norm: 0.7000
2025-07-28 04:10:20,160 - INFO - ============================================================

2025-07-28 04:10:20,197 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 4/10: kobest
2025-07-28 04:10:20,198 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kobest' will use num_fewshot=0
2025-07-28 04:10:20,199 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 04:10:20,199 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:10:41,690 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 04:10:41,691 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 04:10:41,691 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 04:10:41,691 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 04:10:41,691 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 04:10:51,931 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 04:10:51,933 - INFO - 
============================================================
2025-07-28 04:10:51,933 - INFO - Task 'kobest' Results:
2025-07-28 04:10:51,934 - INFO - ============================================================
2025-07-28 04:10:51,935 - INFO -   kobest:
2025-07-28 04:10:51,935 - INFO -     - accuracy: 0.7500
2025-07-28 04:10:51,935 - INFO -     - accuracy_norm: 0.7000
2025-07-28 04:10:51,935 - INFO -     - f1: 0.7401
2025-07-28 04:10:51,935 - INFO -   kobest_boolq:
2025-07-28 04:10:51,935 - INFO -     - accuracy: 0.7000
2025-07-28 04:10:51,936 - INFO -     - f1: 0.6703
2025-07-28 04:10:51,936 - INFO -   kobest_copa:
2025-07-28 04:10:51,936 - INFO -     - accuracy: 0.8000
2025-07-28 04:10:51,936 - INFO -     - f1: 0.8000
2025-07-28 04:10:51,936 - INFO -   kobest_hellaswag:
2025-07-28 04:10:51,936 - INFO -     - accuracy: 0.5000
2025-07-28 04:10:51,936 - INFO -     - accuracy_norm: 0.7000
2025-07-28 04:10:51,936 - INFO -     - f1: 0.5000
2025-07-28 04:10:51,936 - INFO -   kobest_sentineg:
2025-07-28 04:10:51,937 - INFO -     - accuracy: 0.9500
2025-07-28 04:10:51,937 - INFO -     - f1: 0.9499
2025-07-28 04:10:51,937 - INFO -   kobest_wic:
2025-07-28 04:10:51,937 - INFO -     - accuracy: 0.8000
2025-07-28 04:10:51,937 - INFO -     - f1: 0.7802
2025-07-28 04:10:51,937 - INFO - ============================================================

2025-07-28 04:10:51,973 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 5/10: csatqa
2025-07-28 04:10:51,975 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'csatqa' detected as zero-shot task
2025-07-28 04:10:51,975 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 04:10:51,976 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:11:07,100 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 04:11:07,101 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 04:11:07,101 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 04:11:07,101 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 04:11:07,101 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 04:11:07,101 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 04:12:22,856 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 04:12:22,858 - INFO - 
============================================================
2025-07-28 04:12:22,859 - INFO - Task 'csatqa' Results:
2025-07-28 04:12:22,859 - INFO - ============================================================
2025-07-28 04:12:22,859 - INFO -   csatqa:
2025-07-28 04:12:22,860 - INFO -     - accuracy: 0.4054
2025-07-28 04:12:22,860 - INFO -     - accuracy_norm: 0.4054
2025-07-28 04:12:22,860 - INFO -   csatqa_gr:
2025-07-28 04:12:22,860 - INFO -     - accuracy: 0.2000
2025-07-28 04:12:22,860 - INFO -     - accuracy_norm: 0.2000
2025-07-28 04:12:22,860 - INFO -   csatqa_li:
2025-07-28 04:12:22,860 - INFO -     - accuracy: 0.4500
2025-07-28 04:12:22,860 - INFO -     - accuracy_norm: 0.4500
2025-07-28 04:12:22,861 - INFO -   csatqa_rch:
2025-07-28 04:12:22,861 - INFO -     - accuracy: 0.4500
2025-07-28 04:12:22,861 - INFO -     - accuracy_norm: 0.4500
2025-07-28 04:12:22,861 - INFO -   csatqa_rcs:
2025-07-28 04:12:22,861 - INFO -     - accuracy: 0.5000
2025-07-28 04:12:22,861 - INFO -     - accuracy_norm: 0.5000
2025-07-28 04:12:22,861 - INFO -   csatqa_rcss:
2025-07-28 04:12:22,861 - INFO -     - accuracy: 0.5000
2025-07-28 04:12:22,861 - INFO -     - accuracy_norm: 0.5000
2025-07-28 04:12:22,862 - INFO -   csatqa_wr:
2025-07-28 04:12:22,862 - INFO -     - accuracy: 0.2727
2025-07-28 04:12:22,862 - INFO -     - accuracy_norm: 0.2727
2025-07-28 04:12:22,862 - INFO - ============================================================

2025-07-28 04:12:22,904 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 6/10: kormedmcqa
2025-07-28 04:12:22,906 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 04:12:22,906 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 04:12:22,906 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:12:43,799 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 04:12:43,799 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 04:12:43,800 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 04:12:43,800 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 04:12:51,923 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 04:12:51,924 - INFO - 
============================================================
2025-07-28 04:12:51,925 - INFO - Task 'kormedmcqa' Results:
2025-07-28 04:12:51,926 - INFO - ============================================================
2025-07-28 04:12:51,926 - INFO -   kormedmcqa:
2025-07-28 04:12:51,926 - INFO -     - exact_match: 0.5750
2025-07-28 04:12:51,926 - INFO -   kormedmcqa_dentist:
2025-07-28 04:12:51,926 - INFO -     - exact_match: 0.4500
2025-07-28 04:12:51,926 - INFO -   kormedmcqa_doctor:
2025-07-28 04:12:51,927 - INFO -     - exact_match: 0.3500
2025-07-28 04:12:51,927 - INFO -   kormedmcqa_nurse:
2025-07-28 04:12:51,927 - INFO -     - exact_match: 0.7000
2025-07-28 04:12:51,927 - INFO -   kormedmcqa_pharm:
2025-07-28 04:12:51,927 - INFO -     - exact_match: 0.8000
2025-07-28 04:12:51,927 - INFO - ============================================================

2025-07-28 04:12:51,963 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 7/10: mmlu
2025-07-28 04:12:51,965 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'mmlu' will use num_fewshot=0
2025-07-28 04:12:51,965 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 04:12:51,965 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:15:38,032 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 04:15:38,032 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 04:15:38,032 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 04:15:38,032 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 04:15:38,032 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 04:15:38,032 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 04:15:38,032 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 04:15:38,033 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 04:15:38,034 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 04:15:38,035 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 04:15:38,036 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 04:15:38,037 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 04:15:38,037 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 04:15:38,037 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 04:15:38,037 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 04:15:38,037 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 04:16:19,619 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 04:16:19,621 - INFO - 
============================================================
2025-07-28 04:16:19,621 - INFO - Task 'mmlu' Results:
2025-07-28 04:16:19,621 - INFO - ============================================================
2025-07-28 04:16:19,621 - INFO -   mmlu:
2025-07-28 04:16:19,621 - INFO -     - accuracy: 0.6640
2025-07-28 04:16:19,622 - INFO -   mmlu_humanities:
2025-07-28 04:16:19,622 - INFO -     - accuracy: 0.7385
2025-07-28 04:16:19,622 - INFO -   mmlu_formal_logic:
2025-07-28 04:16:19,622 - INFO -     - accuracy: 0.5500
2025-07-28 04:16:19,622 - INFO -   mmlu_high_school_european_history:
2025-07-28 04:16:19,622 - INFO -     - accuracy: 0.7000
2025-07-28 04:16:19,622 - INFO -   mmlu_high_school_us_history:
2025-07-28 04:16:19,622 - INFO -     - accuracy: 0.8500
2025-07-28 04:16:19,623 - INFO -   mmlu_high_school_world_history:
2025-07-28 04:16:19,623 - INFO -     - accuracy: 0.9000
2025-07-28 04:16:19,623 - INFO -   mmlu_international_law:
2025-07-28 04:16:19,623 - INFO -     - accuracy: 0.8000
2025-07-28 04:16:19,623 - INFO -   mmlu_jurisprudence:
2025-07-28 04:16:19,623 - INFO -     - accuracy: 0.7500
2025-07-28 04:16:19,623 - INFO -   mmlu_logical_fallacies:
2025-07-28 04:16:19,623 - INFO -     - accuracy: 0.9000
2025-07-28 04:16:19,624 - INFO -   mmlu_moral_disputes:
2025-07-28 04:16:19,624 - INFO -     - accuracy: 0.6000
2025-07-28 04:16:19,624 - INFO -   mmlu_moral_scenarios:
2025-07-28 04:16:19,624 - INFO -     - accuracy: 0.3500
2025-07-28 04:16:19,624 - INFO -   mmlu_philosophy:
2025-07-28 04:16:19,624 - INFO -     - accuracy: 0.8500
2025-07-28 04:16:19,648 - INFO -   mmlu_prehistory:
2025-07-28 04:16:19,649 - INFO -     - accuracy: 0.8000
2025-07-28 04:16:19,649 - INFO -   mmlu_professional_law:
2025-07-28 04:16:19,649 - INFO -     - accuracy: 0.7000
2025-07-28 04:16:19,649 - INFO -   mmlu_world_religions:
2025-07-28 04:16:19,649 - INFO -     - accuracy: 0.8500
2025-07-28 04:16:19,649 - INFO -   mmlu_other:
2025-07-28 04:16:19,649 - INFO -     - accuracy: 0.7000
2025-07-28 04:16:19,649 - INFO -   mmlu_business_ethics:
2025-07-28 04:16:19,650 - INFO -     - accuracy: 0.8000
2025-07-28 04:16:19,650 - INFO -   mmlu_clinical_knowledge:
2025-07-28 04:16:19,650 - INFO -     - accuracy: 0.7500
2025-07-28 04:16:19,650 - INFO -   mmlu_college_medicine:
2025-07-28 04:16:19,650 - INFO -     - accuracy: 0.6500
2025-07-28 04:16:19,650 - INFO -   mmlu_global_facts:
2025-07-28 04:16:19,650 - INFO -     - accuracy: 0.4500
2025-07-28 04:16:19,650 - INFO -   mmlu_human_aging:
2025-07-28 04:16:19,650 - INFO -     - accuracy: 0.6000
2025-07-28 04:16:19,651 - INFO -   mmlu_management:
2025-07-28 04:16:19,651 - INFO -     - accuracy: 0.8500
2025-07-28 04:16:19,651 - INFO -   mmlu_marketing:
2025-07-28 04:16:19,651 - INFO -     - accuracy: 0.8000
2025-07-28 04:16:19,651 - INFO -   mmlu_medical_genetics:
2025-07-28 04:16:19,651 - INFO -     - accuracy: 0.8500
2025-07-28 04:16:19,651 - INFO -   mmlu_miscellaneous:
2025-07-28 04:16:19,651 - INFO -     - accuracy: 0.8000
2025-07-28 04:16:19,651 - INFO -   mmlu_nutrition:
2025-07-28 04:16:19,652 - INFO -     - accuracy: 0.7500
2025-07-28 04:16:19,652 - INFO -   mmlu_professional_accounting:
2025-07-28 04:16:19,652 - INFO -     - accuracy: 0.4500
2025-07-28 04:16:19,652 - INFO -   mmlu_professional_medicine:
2025-07-28 04:16:19,652 - INFO -     - accuracy: 0.7500
2025-07-28 04:16:19,652 - INFO -   mmlu_virology:
2025-07-28 04:16:19,652 - INFO -     - accuracy: 0.6000
2025-07-28 04:16:19,652 - INFO -   mmlu_social_sciences:
2025-07-28 04:16:19,652 - INFO -     - accuracy: 0.7542
2025-07-28 04:16:19,653 - INFO -   mmlu_econometrics:
2025-07-28 04:16:19,653 - INFO -     - accuracy: 0.6000
2025-07-28 04:16:19,653 - INFO -   mmlu_high_school_geography:
2025-07-28 04:16:19,653 - INFO -     - accuracy: 0.8500
2025-07-28 04:16:19,653 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 04:16:19,653 - INFO -     - accuracy: 0.9500
2025-07-28 04:16:19,653 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 04:16:19,653 - INFO -     - accuracy: 0.5500
2025-07-28 04:16:19,653 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 04:16:19,654 - INFO -     - accuracy: 0.6500
2025-07-28 04:16:19,654 - INFO -   mmlu_high_school_psychology:
2025-07-28 04:16:19,654 - INFO -     - accuracy: 0.9000
2025-07-28 04:16:19,654 - INFO -   mmlu_human_sexuality:
2025-07-28 04:16:19,654 - INFO -     - accuracy: 0.7500
2025-07-28 04:16:19,654 - INFO -   mmlu_professional_psychology:
2025-07-28 04:16:19,654 - INFO -     - accuracy: 0.8000
2025-07-28 04:16:19,654 - INFO -   mmlu_public_relations:
2025-07-28 04:16:19,654 - INFO -     - accuracy: 0.6000
2025-07-28 04:16:19,654 - INFO -   mmlu_security_studies:
2025-07-28 04:16:19,655 - INFO -     - accuracy: 0.7000
2025-07-28 04:16:19,655 - INFO -   mmlu_sociology:
2025-07-28 04:16:19,655 - INFO -     - accuracy: 0.8000
2025-07-28 04:16:19,655 - INFO -   mmlu_us_foreign_policy:
2025-07-28 04:16:19,655 - INFO -     - accuracy: 0.9000
2025-07-28 04:16:19,655 - INFO -   mmlu_stem:
2025-07-28 04:16:19,655 - INFO -     - accuracy: 0.5316
2025-07-28 04:16:19,655 - INFO -   mmlu_abstract_algebra:
2025-07-28 04:16:19,655 - INFO -     - accuracy: 0.2000
2025-07-28 04:16:19,655 - INFO -   mmlu_anatomy:
2025-07-28 04:16:19,655 - INFO -     - accuracy: 0.6500
2025-07-28 04:16:19,656 - INFO -   mmlu_astronomy:
2025-07-28 04:16:19,656 - INFO -     - accuracy: 0.9000
2025-07-28 04:16:19,656 - INFO -   mmlu_college_biology:
2025-07-28 04:16:19,656 - INFO -     - accuracy: 0.8000
2025-07-28 04:16:19,656 - INFO -   mmlu_college_chemistry:
2025-07-28 04:16:19,656 - INFO -     - accuracy: 0.3000
2025-07-28 04:16:19,656 - INFO -   mmlu_college_computer_science:
2025-07-28 04:16:19,656 - INFO -     - accuracy: 0.2500
2025-07-28 04:16:19,656 - INFO -   mmlu_college_mathematics:
2025-07-28 04:16:19,656 - INFO -     - accuracy: 0.3000
2025-07-28 04:16:19,657 - INFO -   mmlu_college_physics:
2025-07-28 04:16:19,657 - INFO -     - accuracy: 0.3500
2025-07-28 04:16:19,657 - INFO -   mmlu_computer_security:
2025-07-28 04:16:19,657 - INFO -     - accuracy: 0.7500
2025-07-28 04:16:19,657 - INFO -   mmlu_conceptual_physics:
2025-07-28 04:16:19,657 - INFO -     - accuracy: 0.6000
2025-07-28 04:16:19,657 - INFO -   mmlu_electrical_engineering:
2025-07-28 04:16:19,657 - INFO -     - accuracy: 0.6500
2025-07-28 04:16:19,657 - INFO -   mmlu_elementary_mathematics:
2025-07-28 04:16:19,657 - INFO -     - accuracy: 0.2000
2025-07-28 04:16:19,657 - INFO -   mmlu_high_school_biology:
2025-07-28 04:16:19,658 - INFO -     - accuracy: 0.8500
2025-07-28 04:16:19,658 - INFO -   mmlu_high_school_chemistry:
2025-07-28 04:16:19,658 - INFO -     - accuracy: 0.6000
2025-07-28 04:16:19,658 - INFO -   mmlu_high_school_computer_science:
2025-07-28 04:16:19,658 - INFO -     - accuracy: 0.8500
2025-07-28 04:16:19,658 - INFO -   mmlu_high_school_mathematics:
2025-07-28 04:16:19,658 - INFO -     - accuracy: 0.3500
2025-07-28 04:16:19,658 - INFO -   mmlu_high_school_physics:
2025-07-28 04:16:19,658 - INFO -     - accuracy: 0.3500
2025-07-28 04:16:19,658 - INFO -   mmlu_high_school_statistics:
2025-07-28 04:16:19,658 - INFO -     - accuracy: 0.6000
2025-07-28 04:16:19,659 - INFO -   mmlu_machine_learning:
2025-07-28 04:16:19,659 - INFO -     - accuracy: 0.5500
2025-07-28 04:16:19,659 - INFO - ============================================================

2025-07-28 04:16:19,697 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 8/10: arc_challenge
2025-07-28 04:16:19,698 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 04:16:19,699 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 04:16:19,699 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:16:29,333 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 04:16:34,636 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 04:16:34,638 - INFO - 
============================================================
2025-07-28 04:16:34,638 - INFO - Task 'arc_challenge' Results:
2025-07-28 04:16:34,638 - INFO - ============================================================
2025-07-28 04:16:34,638 - INFO -   arc_challenge:
2025-07-28 04:16:34,638 - INFO -     - accuracy: 0.5500
2025-07-28 04:16:34,639 - INFO -     - accuracy_norm: 0.6000
2025-07-28 04:16:34,639 - INFO - ============================================================

2025-07-28 04:16:34,675 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 9/10: arc_easy
2025-07-28 04:16:34,676 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'arc_easy' will use num_fewshot=0
2025-07-28 04:16:34,677 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 04:16:34,677 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:16:44,403 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 04:16:49,523 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 04:16:49,525 - INFO - 
============================================================
2025-07-28 04:16:49,525 - INFO - Task 'arc_easy' Results:
2025-07-28 04:16:49,525 - INFO - ============================================================
2025-07-28 04:16:49,525 - INFO -   arc_easy:
2025-07-28 04:16:49,525 - INFO -     - accuracy: 0.8000
2025-07-28 04:16:49,525 - INFO -     - accuracy_norm: 0.7000
2025-07-28 04:16:49,525 - INFO - ============================================================

2025-07-28 04:16:49,561 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 10/10: hellaswag
2025-07-28 04:16:49,563 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'hellaswag' will use num_fewshot=0
2025-07-28 04:16:49,563 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 04:16:49,564 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:17:05,911 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 04:17:11,294 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 04:17:11,296 - INFO - 
============================================================
2025-07-28 04:17:11,297 - INFO - Task 'hellaswag' Results:
2025-07-28 04:17:11,297 - INFO - ============================================================
2025-07-28 04:17:11,297 - INFO -   hellaswag:
2025-07-28 04:17:11,297 - INFO -     - accuracy: 0.4500
2025-07-28 04:17:11,297 - INFO -     - accuracy_norm: 0.6000
2025-07-28 04:17:11,298 - INFO - ============================================================

2025-07-28 04:17:11,334 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 04:17:11,336 - INFO - [Process 1795506] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_032724/model_results/Llama-DNA-1.0-8B-Instruct/Llama-DNA-1.0-8B-Instruct_harness_6.json
2025-07-28 04:17:11,338 - INFO - [Process 1795506] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Llama-DNA-1.0-8B-Instruct/Llama-DNA-1.0-8B-Instruct_harness_6.json
2025-07-28 04:17:11,619 - INFO - Results uploaded to WandB as artifact
2025-07-28 04:17:11,628 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 04:17:11,630 - INFO - [Process 1795506] Successfully completed Llama-DNA-1.0-8B-Instruct_harness_6
2025-07-28 04:17:14,285 - INFO - Run Llama-DNA-1.0-8B-Instruct_harness_6 finished successfully
2025-07-28 04:17:14,285 - INFO - Processing 6 small models in parallel
2025-07-28 04:17:19,218 - INFO - [Process 1811658] gemma-3-4b-it_harness_2 assigned to cuda:0
2025-07-28 04:17:19,218 - INFO - [Process 1811658] gemma-3-4b-it_harness_2 - using custom limit: 20
2025-07-28 04:17:20,901 - INFO - WandB run initialized: gemma-3-4b-it_20250728_041719 (ID: 03c308d0)
2025-07-28 04:17:22,685 - INFO - gemma-3-4b-it_harness_2: Gemma settings applied - max_gen_toks=256
2025-07-28 04:17:22,685 - INFO - gemma-3-4b-it_harness_2: Test mode (limit=2), setting num_fewshot=0
2025-07-28 04:17:22,685 - INFO - gemma-3-4b-it_harness_2: Gemma model detected, adjusting settings
2025-07-28 04:17:22,685 - INFO - gemma-3-4b-it_harness_2: Processing task 1/10: kmmlu
2025-07-28 04:17:22,685 - INFO - gemma-3-4b-it_harness_2: Task 'kmmlu' will use num_fewshot=0
2025-07-28 04:17:22,686 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 04:17:22,687 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:18:37,314 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 04:18:37,314 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 04:18:37,314 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 04:18:37,315 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 04:18:37,315 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 04:18:37,315 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 04:18:37,315 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 04:18:37,315 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 04:18:37,315 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 04:18:37,316 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 04:18:37,316 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 04:18:37,316 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 04:18:37,316 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 04:18:37,316 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 04:18:37,316 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 04:18:37,316 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 04:18:37,316 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 04:18:37,317 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 04:18:37,317 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 04:18:37,317 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 04:18:37,317 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 04:18:37,317 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 04:18:37,317 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 04:18:37,317 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 04:18:37,317 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 04:18:37,317 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 04:18:37,317 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 04:18:37,318 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 04:18:37,318 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 04:18:37,318 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 04:18:37,318 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 04:18:37,318 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 04:18:37,318 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 04:18:37,319 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 04:18:37,319 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 04:18:37,319 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 04:18:37,319 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 04:18:37,319 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 04:18:37,319 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 04:18:37,319 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 04:18:37,319 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 04:18:37,319 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 04:18:37,319 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 04:18:37,320 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 04:18:37,320 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 04:19:46,722 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 04:19:46,724 - INFO - 
============================================================
2025-07-28 04:19:46,725 - INFO - Task 'kmmlu' Results:
2025-07-28 04:19:46,726 - INFO - ============================================================
2025-07-28 04:19:46,727 - INFO -   kmmlu:
2025-07-28 04:19:46,727 - INFO -     - accuracy: 0.3056
2025-07-28 04:19:46,727 - INFO -   kmmlu_applied_science:
2025-07-28 04:19:46,727 - INFO -     - accuracy: 0.2167
2025-07-28 04:19:46,728 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 04:19:46,728 - INFO -     - accuracy: 0.2000
2025-07-28 04:19:46,728 - INFO -   kmmlu_electronics_engineering:
2025-07-28 04:19:46,728 - INFO -     - accuracy: 0.2500
2025-07-28 04:19:46,728 - INFO -   kmmlu_energy_management:
2025-07-28 04:19:46,728 - INFO -     - accuracy: 0.1000
2025-07-28 04:19:46,728 - INFO -   kmmlu_environmental_science:
2025-07-28 04:19:46,728 - INFO -     - accuracy: 0.2000
2025-07-28 04:19:46,728 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 04:19:46,728 - INFO -     - accuracy: 0.1000
2025-07-28 04:19:46,729 - INFO -   kmmlu_geomatics:
2025-07-28 04:19:46,729 - INFO -     - accuracy: 0.1000
2025-07-28 04:19:46,729 - INFO -   kmmlu_industrial_engineer:
2025-07-28 04:19:46,729 - INFO -     - accuracy: 0.2500
2025-07-28 04:19:46,729 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 04:19:46,729 - INFO -     - accuracy: 0.3000
2025-07-28 04:19:46,729 - INFO -   kmmlu_maritime_engineering:
2025-07-28 04:19:46,729 - INFO -     - accuracy: 0.3000
2025-07-28 04:19:46,729 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 04:19:46,729 - INFO -     - accuracy: 0.1500
2025-07-28 04:19:46,730 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 04:19:46,730 - INFO -     - accuracy: 0.2500
2025-07-28 04:19:46,730 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 04:19:46,730 - INFO -     - accuracy: 0.4000
2025-07-28 04:19:46,730 - INFO -   kmmlu_humss:
2025-07-28 04:19:46,730 - INFO -     - accuracy: 0.3409
2025-07-28 04:19:46,730 - INFO -   kmmlu_accounting:
2025-07-28 04:19:46,730 - INFO -     - accuracy: 0.2500
2025-07-28 04:19:46,730 - INFO -   kmmlu_criminal_law:
2025-07-28 04:19:46,730 - INFO -     - accuracy: 0.3000
2025-07-28 04:19:46,731 - INFO -   kmmlu_economics:
2025-07-28 04:19:46,731 - INFO -     - accuracy: 0.5500
2025-07-28 04:19:46,731 - INFO -   kmmlu_education:
2025-07-28 04:19:46,731 - INFO -     - accuracy: 0.4500
2025-07-28 04:19:46,731 - INFO -   kmmlu_korean_history:
2025-07-28 04:19:46,731 - INFO -     - accuracy: 0.2000
2025-07-28 04:19:46,731 - INFO -   kmmlu_law:
2025-07-28 04:19:46,731 - INFO -     - accuracy: 0.2500
2025-07-28 04:19:46,731 - INFO -   kmmlu_management:
2025-07-28 04:19:46,731 - INFO -     - accuracy: 0.5500
2025-07-28 04:19:46,732 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 04:19:46,732 - INFO -     - accuracy: 0.5000
2025-07-28 04:19:46,732 - INFO -   kmmlu_psychology:
2025-07-28 04:19:46,732 - INFO -     - accuracy: 0.1000
2025-07-28 04:19:46,732 - INFO -   kmmlu_social_welfare:
2025-07-28 04:19:46,732 - INFO -     - accuracy: 0.3000
2025-07-28 04:19:46,732 - INFO -   kmmlu_taxation:
2025-07-28 04:19:46,732 - INFO -     - accuracy: 0.3000
2025-07-28 04:19:46,732 - INFO -   kmmlu_other:
2025-07-28 04:19:46,732 - INFO -     - accuracy: 0.3636
2025-07-28 04:19:46,733 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 04:19:46,733 - INFO -     - accuracy: 0.3500
2025-07-28 04:19:46,741 - INFO -   kmmlu_construction:
2025-07-28 04:19:46,741 - INFO -     - accuracy: 0.4000
2025-07-28 04:19:46,741 - INFO -   kmmlu_fashion:
2025-07-28 04:19:46,741 - INFO -     - accuracy: 0.1500
2025-07-28 04:19:46,741 - INFO -   kmmlu_food_processing:
2025-07-28 04:19:46,741 - INFO -     - accuracy: 0.4000
2025-07-28 04:19:46,742 - INFO -   kmmlu_health:
2025-07-28 04:19:46,742 - INFO -     - accuracy: 0.7500
2025-07-28 04:19:46,742 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 04:19:46,742 - INFO -     - accuracy: 0.5000
2025-07-28 04:19:46,742 - INFO -   kmmlu_marketing:
2025-07-28 04:19:46,742 - INFO -     - accuracy: 0.4500
2025-07-28 04:19:46,742 - INFO -   kmmlu_patent:
2025-07-28 04:19:46,742 - INFO -     - accuracy: 0.2500
2025-07-28 04:19:46,743 - INFO -   kmmlu_public_safety:
2025-07-28 04:19:46,743 - INFO -     - accuracy: 0.2500
2025-07-28 04:19:46,743 - INFO -   kmmlu_real_estate:
2025-07-28 04:19:46,743 - INFO -     - accuracy: 0.3500
2025-07-28 04:19:46,743 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 04:19:46,743 - INFO -     - accuracy: 0.1500
2025-07-28 04:19:46,743 - INFO -   kmmlu_stem:
2025-07-28 04:19:46,743 - INFO -     - accuracy: 0.3091
2025-07-28 04:19:46,743 - INFO -   kmmlu_biology:
2025-07-28 04:19:46,743 - INFO -     - accuracy: 0.4500
2025-07-28 04:19:46,744 - INFO -   kmmlu_chemical_engineering:
2025-07-28 04:19:46,744 - INFO -     - accuracy: 0.1500
2025-07-28 04:19:46,744 - INFO -   kmmlu_chemistry:
2025-07-28 04:19:46,744 - INFO -     - accuracy: 0.2500
2025-07-28 04:19:46,744 - INFO -   kmmlu_civil_engineering:
2025-07-28 04:19:46,744 - INFO -     - accuracy: 0.2000
2025-07-28 04:19:46,744 - INFO -   kmmlu_computer_science:
2025-07-28 04:19:46,744 - INFO -     - accuracy: 0.5000
2025-07-28 04:19:46,744 - INFO -   kmmlu_ecology:
2025-07-28 04:19:46,745 - INFO -     - accuracy: 0.4500
2025-07-28 04:19:46,745 - INFO -   kmmlu_electrical_engineering:
2025-07-28 04:19:46,745 - INFO -     - accuracy: 0.1500
2025-07-28 04:19:46,745 - INFO -   kmmlu_information_technology:
2025-07-28 04:19:46,745 - INFO -     - accuracy: 0.3000
2025-07-28 04:19:46,745 - INFO -   kmmlu_materials_engineering:
2025-07-28 04:19:46,745 - INFO -     - accuracy: 0.4500
2025-07-28 04:19:46,745 - INFO -   kmmlu_math:
2025-07-28 04:19:46,745 - INFO -     - accuracy: 0.2500
2025-07-28 04:19:46,745 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 04:19:46,745 - INFO -     - accuracy: 0.2500
2025-07-28 04:19:46,746 - INFO - ============================================================

2025-07-28 04:19:46,768 - INFO - gemma-3-4b-it_harness_2: Processing task 2/10: kmmlu_hard
2025-07-28 04:19:46,769 - INFO - gemma-3-4b-it_harness_2: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 04:19:46,769 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 04:19:46,769 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:21:04,038 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 04:21:04,038 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 04:21:04,039 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 04:21:04,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 04:21:04,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 04:21:04,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 04:21:04,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 04:21:04,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 04:21:04,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 04:21:04,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 04:21:04,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 04:21:04,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 04:21:04,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 04:22:15,089 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 04:22:15,090 - INFO - 
============================================================
2025-07-28 04:22:15,091 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 04:22:15,092 - INFO - ============================================================
2025-07-28 04:22:15,094 - INFO -   kmmlu_hard:
2025-07-28 04:22:15,094 - INFO -     - accuracy: 0.2078
2025-07-28 04:22:15,094 - INFO -   kmmlu_hard_applied_science:
2025-07-28 04:22:15,094 - INFO -     - accuracy: 0.2250
2025-07-28 04:22:15,094 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 04:22:15,094 - INFO -     - accuracy: 0.0500
2025-07-28 04:22:15,095 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 04:22:15,095 - INFO -     - accuracy: 0.2500
2025-07-28 04:22:15,095 - INFO -   kmmlu_hard_energy_management:
2025-07-28 04:22:15,095 - INFO -     - accuracy: 0.3000
2025-07-28 04:22:15,095 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 04:22:15,095 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,095 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 04:22:15,095 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,096 - INFO -   kmmlu_hard_geomatics:
2025-07-28 04:22:15,096 - INFO -     - accuracy: 0.3000
2025-07-28 04:22:15,096 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 04:22:15,096 - INFO -     - accuracy: 0.3000
2025-07-28 04:22:15,096 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 04:22:15,096 - INFO -     - accuracy: 0.3500
2025-07-28 04:22:15,096 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 04:22:15,096 - INFO -     - accuracy: 0.1000
2025-07-28 04:22:15,096 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 04:22:15,097 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,097 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 04:22:15,097 - INFO -     - accuracy: 0.2500
2025-07-28 04:22:15,097 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 04:22:15,097 - INFO -     - accuracy: 0.2500
2025-07-28 04:22:15,097 - INFO -   kmmlu_hard_humss:
2025-07-28 04:22:15,097 - INFO -     - accuracy: 0.1818
2025-07-28 04:22:15,097 - INFO -   kmmlu_hard_accounting:
2025-07-28 04:22:15,097 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,098 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 04:22:15,098 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,098 - INFO -   kmmlu_hard_economics:
2025-07-28 04:22:15,098 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,098 - INFO -   kmmlu_hard_education:
2025-07-28 04:22:15,098 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,098 - INFO -   kmmlu_hard_korean_history:
2025-07-28 04:22:15,098 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,120 - INFO -   kmmlu_hard_law:
2025-07-28 04:22:15,120 - INFO -     - accuracy: 0.0000
2025-07-28 04:22:15,120 - INFO -   kmmlu_hard_management:
2025-07-28 04:22:15,121 - INFO -     - accuracy: 0.2500
2025-07-28 04:22:15,121 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 04:22:15,121 - INFO -     - accuracy: 0.4000
2025-07-28 04:22:15,121 - INFO -   kmmlu_hard_psychology:
2025-07-28 04:22:15,121 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,121 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 04:22:15,121 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,121 - INFO -   kmmlu_hard_taxation:
2025-07-28 04:22:15,122 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,122 - INFO -   kmmlu_hard_other:
2025-07-28 04:22:15,122 - INFO -     - accuracy: 0.2273
2025-07-28 04:22:15,122 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 04:22:15,122 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,122 - INFO -   kmmlu_hard_construction:
2025-07-28 04:22:15,122 - INFO -     - accuracy: 0.2500
2025-07-28 04:22:15,122 - INFO -   kmmlu_hard_fashion:
2025-07-28 04:22:15,122 - INFO -     - accuracy: 0.4000
2025-07-28 04:22:15,123 - INFO -   kmmlu_hard_food_processing:
2025-07-28 04:22:15,123 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,123 - INFO -   kmmlu_hard_health:
2025-07-28 04:22:15,123 - INFO -     - accuracy: 0.2500
2025-07-28 04:22:15,123 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 04:22:15,123 - INFO -     - accuracy: 0.4000
2025-07-28 04:22:15,123 - INFO -   kmmlu_hard_marketing:
2025-07-28 04:22:15,123 - INFO -     - accuracy: 0.2500
2025-07-28 04:22:15,124 - INFO -   kmmlu_hard_patent:
2025-07-28 04:22:15,124 - INFO -     - accuracy: 0.1000
2025-07-28 04:22:15,124 - INFO -   kmmlu_hard_public_safety:
2025-07-28 04:22:15,124 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,124 - INFO -   kmmlu_hard_real_estate:
2025-07-28 04:22:15,124 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,124 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 04:22:15,124 - INFO -     - accuracy: 0.1000
2025-07-28 04:22:15,124 - INFO -   kmmlu_hard_stem:
2025-07-28 04:22:15,125 - INFO -     - accuracy: 0.1955
2025-07-28 04:22:15,125 - INFO -   kmmlu_hard_biology:
2025-07-28 04:22:15,125 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,125 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 04:22:15,125 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,125 - INFO -   kmmlu_hard_chemistry:
2025-07-28 04:22:15,125 - INFO -     - accuracy: 0.3000
2025-07-28 04:22:15,125 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 04:22:15,125 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,126 - INFO -   kmmlu_hard_computer_science:
2025-07-28 04:22:15,126 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,126 - INFO -   kmmlu_hard_ecology:
2025-07-28 04:22:15,126 - INFO -     - accuracy: 0.0500
2025-07-28 04:22:15,126 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 04:22:15,126 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,126 - INFO -   kmmlu_hard_information_technology:
2025-07-28 04:22:15,126 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,127 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 04:22:15,127 - INFO -     - accuracy: 0.4000
2025-07-28 04:22:15,127 - INFO -   kmmlu_hard_math:
2025-07-28 04:22:15,127 - INFO -     - accuracy: 0.2000
2025-07-28 04:22:15,127 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 04:22:15,127 - INFO -     - accuracy: 0.1500
2025-07-28 04:22:15,127 - INFO - ============================================================

2025-07-28 04:22:15,152 - INFO - gemma-3-4b-it_harness_2: Processing task 3/10: haerae
2025-07-28 04:22:15,153 - INFO - gemma-3-4b-it_harness_2: Task 'haerae' will use num_fewshot=0
2025-07-28 04:22:15,153 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 04:22:15,154 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:22:34,543 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 04:22:34,544 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 04:22:34,544 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 04:22:34,544 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 04:22:34,544 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 04:23:11,868 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 04:23:11,869 - INFO - 
============================================================
2025-07-28 04:23:11,871 - INFO - Task 'haerae' Results:
2025-07-28 04:23:11,872 - INFO - ============================================================
2025-07-28 04:23:11,872 - INFO -   haerae:
2025-07-28 04:23:11,872 - INFO -     - accuracy: 0.5800
2025-07-28 04:23:11,872 - INFO -     - accuracy_norm: 0.5800
2025-07-28 04:23:11,872 - INFO -   haerae_general_knowledge:
2025-07-28 04:23:11,872 - INFO -     - accuracy: 0.7000
2025-07-28 04:23:11,872 - INFO -     - accuracy_norm: 0.7000
2025-07-28 04:23:11,873 - INFO -   haerae_history:
2025-07-28 04:23:11,873 - INFO -     - accuracy: 0.6000
2025-07-28 04:23:11,873 - INFO -     - accuracy_norm: 0.6000
2025-07-28 04:23:11,873 - INFO -   haerae_loan_word:
2025-07-28 04:23:11,873 - INFO -     - accuracy: 0.4000
2025-07-28 04:23:11,873 - INFO -     - accuracy_norm: 0.4000
2025-07-28 04:23:11,873 - INFO -   haerae_rare_word:
2025-07-28 04:23:11,873 - INFO -     - accuracy: 0.6000
2025-07-28 04:23:11,873 - INFO -     - accuracy_norm: 0.6000
2025-07-28 04:23:11,873 - INFO -   haerae_standard_nomenclature:
2025-07-28 04:23:11,873 - INFO -     - accuracy: 0.6000
2025-07-28 04:23:11,874 - INFO -     - accuracy_norm: 0.6000
2025-07-28 04:23:11,874 - INFO - ============================================================

2025-07-28 04:23:11,897 - INFO - gemma-3-4b-it_harness_2: Processing task 4/10: kobest
2025-07-28 04:23:11,898 - INFO - gemma-3-4b-it_harness_2: Task 'kobest' will use num_fewshot=0
2025-07-28 04:23:11,899 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 04:23:11,899 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:23:35,541 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 04:23:35,542 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 04:23:35,542 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 04:23:35,542 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 04:23:35,542 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 04:23:54,818 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 04:23:54,820 - INFO - 
============================================================
2025-07-28 04:23:54,821 - INFO - Task 'kobest' Results:
2025-07-28 04:23:54,823 - INFO - ============================================================
2025-07-28 04:23:54,823 - INFO -   kobest:
2025-07-28 04:23:54,823 - INFO -     - accuracy: 0.6500
2025-07-28 04:23:54,823 - INFO -     - accuracy_norm: 0.6000
2025-07-28 04:23:54,823 - INFO -     - f1: 0.5707
2025-07-28 04:23:54,823 - INFO -   kobest_boolq:
2025-07-28 04:23:54,823 - INFO -     - accuracy: 0.9000
2025-07-28 04:23:54,823 - INFO -     - f1: 0.8990
2025-07-28 04:23:54,824 - INFO -   kobest_copa:
2025-07-28 04:23:54,824 - INFO -     - accuracy: 0.8500
2025-07-28 04:23:54,824 - INFO -     - f1: 0.8496
2025-07-28 04:23:54,824 - INFO -   kobest_hellaswag:
2025-07-28 04:23:54,824 - INFO -     - accuracy: 0.4000
2025-07-28 04:23:54,824 - INFO -     - accuracy_norm: 0.6000
2025-07-28 04:23:54,824 - INFO -     - f1: 0.3951
2025-07-28 04:23:54,825 - INFO -   kobest_sentineg:
2025-07-28 04:23:54,825 - INFO -     - accuracy: 0.5500
2025-07-28 04:23:54,825 - INFO -     - f1: 0.3548
2025-07-28 04:23:54,826 - INFO -   kobest_wic:
2025-07-28 04:23:54,826 - INFO -     - accuracy: 0.5500
2025-07-28 04:23:54,826 - INFO -     - f1: 0.3548
2025-07-28 04:23:54,826 - INFO - ============================================================

2025-07-28 04:23:54,850 - INFO - gemma-3-4b-it_harness_2: Processing task 5/10: csatqa
2025-07-28 04:23:54,851 - INFO - gemma-3-4b-it_harness_2: Task 'csatqa' detected as zero-shot task
2025-07-28 04:23:54,851 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 04:23:54,852 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:24:10,728 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 04:24:10,728 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 04:24:10,728 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 04:24:10,729 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 04:24:10,729 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 04:24:10,729 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 04:25:19,572 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 04:25:19,574 - INFO - 
============================================================
2025-07-28 04:25:19,576 - INFO - Task 'csatqa' Results:
2025-07-28 04:25:19,577 - INFO - ============================================================
2025-07-28 04:25:19,577 - INFO -   csatqa:
2025-07-28 04:25:19,577 - INFO -     - accuracy: 0.3063
2025-07-28 04:25:19,577 - INFO -     - accuracy_norm: 0.3063
2025-07-28 04:25:19,577 - INFO -   csatqa_gr:
2025-07-28 04:25:19,578 - INFO -     - accuracy: 0.1500
2025-07-28 04:25:19,578 - INFO -     - accuracy_norm: 0.1500
2025-07-28 04:25:19,578 - INFO -   csatqa_li:
2025-07-28 04:25:19,578 - INFO -     - accuracy: 0.4500
2025-07-28 04:25:19,578 - INFO -     - accuracy_norm: 0.4500
2025-07-28 04:25:19,578 - INFO -   csatqa_rch:
2025-07-28 04:25:19,578 - INFO -     - accuracy: 0.2500
2025-07-28 04:25:19,578 - INFO -     - accuracy_norm: 0.2500
2025-07-28 04:25:19,578 - INFO -   csatqa_rcs:
2025-07-28 04:25:19,579 - INFO -     - accuracy: 0.3000
2025-07-28 04:25:19,579 - INFO -     - accuracy_norm: 0.3000
2025-07-28 04:25:19,579 - INFO -   csatqa_rcss:
2025-07-28 04:25:19,579 - INFO -     - accuracy: 0.4000
2025-07-28 04:25:19,579 - INFO -     - accuracy_norm: 0.4000
2025-07-28 04:25:19,579 - INFO -   csatqa_wr:
2025-07-28 04:25:19,579 - INFO -     - accuracy: 0.2727
2025-07-28 04:25:19,579 - INFO -     - accuracy_norm: 0.2727
2025-07-28 04:25:19,579 - INFO - ============================================================

2025-07-28 04:25:19,614 - INFO - gemma-3-4b-it_harness_2: Processing task 6/10: kormedmcqa
2025-07-28 04:25:19,616 - INFO - gemma-3-4b-it_harness_2: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 04:25:19,616 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 04:25:19,617 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:25:42,471 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 04:25:42,471 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 04:25:42,471 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 04:25:42,471 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 04:27:52,994 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 04:27:52,996 - INFO - 
============================================================
2025-07-28 04:27:52,997 - INFO - Task 'kormedmcqa' Results:
2025-07-28 04:27:52,998 - INFO - ============================================================
2025-07-28 04:27:52,998 - INFO -   kormedmcqa:
2025-07-28 04:27:52,998 - INFO -     - exact_match: 0.2250
2025-07-28 04:27:52,999 - INFO -   kormedmcqa_dentist:
2025-07-28 04:27:52,999 - INFO -     - exact_match: 0.0500
2025-07-28 04:27:52,999 - INFO -   kormedmcqa_doctor:
2025-07-28 04:27:52,999 - INFO -     - exact_match: 0.2000
2025-07-28 04:27:52,999 - INFO -   kormedmcqa_nurse:
2025-07-28 04:27:52,999 - INFO -     - exact_match: 0.4000
2025-07-28 04:27:52,999 - INFO -   kormedmcqa_pharm:
2025-07-28 04:27:52,999 - INFO -     - exact_match: 0.2500
2025-07-28 04:27:53,000 - INFO - ============================================================

2025-07-28 04:27:53,024 - INFO - gemma-3-4b-it_harness_2: Processing task 7/10: mmlu
2025-07-28 04:27:53,026 - INFO - gemma-3-4b-it_harness_2: Task 'mmlu' will use num_fewshot=0
2025-07-28 04:27:53,026 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 04:27:53,027 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:30:53,119 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 04:30:53,120 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 04:30:53,120 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 04:30:53,120 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 04:30:53,120 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 04:30:53,120 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 04:30:53,120 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 04:30:53,120 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 04:30:53,120 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 04:30:53,121 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 04:30:53,122 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 04:30:53,123 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 04:30:53,124 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 04:30:53,125 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 04:30:53,125 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 04:30:53,125 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 04:32:21,216 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 04:32:21,218 - INFO - 
============================================================
2025-07-28 04:32:21,219 - INFO - Task 'mmlu' Results:
2025-07-28 04:32:21,221 - INFO - ============================================================
2025-07-28 04:32:21,221 - INFO -   mmlu:
2025-07-28 04:32:21,221 - INFO -     - accuracy: 0.6070
2025-07-28 04:32:21,222 - INFO -   mmlu_humanities:
2025-07-28 04:32:21,222 - INFO -     - accuracy: 0.6308
2025-07-28 04:32:21,222 - INFO -   mmlu_formal_logic:
2025-07-28 04:32:21,222 - INFO -     - accuracy: 0.3000
2025-07-28 04:32:21,222 - INFO -   mmlu_high_school_european_history:
2025-07-28 04:32:21,222 - INFO -     - accuracy: 0.7500
2025-07-28 04:32:21,222 - INFO -   mmlu_high_school_us_history:
2025-07-28 04:32:21,222 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,223 - INFO -   mmlu_high_school_world_history:
2025-07-28 04:32:21,223 - INFO -     - accuracy: 0.8500
2025-07-28 04:32:21,223 - INFO -   mmlu_international_law:
2025-07-28 04:32:21,223 - INFO -     - accuracy: 0.8000
2025-07-28 04:32:21,223 - INFO -   mmlu_jurisprudence:
2025-07-28 04:32:21,223 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,223 - INFO -   mmlu_logical_fallacies:
2025-07-28 04:32:21,223 - INFO -     - accuracy: 0.7500
2025-07-28 04:32:21,223 - INFO -   mmlu_moral_disputes:
2025-07-28 04:32:21,223 - INFO -     - accuracy: 0.6500
2025-07-28 04:32:21,224 - INFO -   mmlu_moral_scenarios:
2025-07-28 04:32:21,224 - INFO -     - accuracy: 0.3000
2025-07-28 04:32:21,224 - INFO -   mmlu_philosophy:
2025-07-28 04:32:21,224 - INFO -     - accuracy: 0.6500
2025-07-28 04:32:21,224 - INFO -   mmlu_prehistory:
2025-07-28 04:32:21,224 - INFO -     - accuracy: 0.4500
2025-07-28 04:32:21,224 - INFO -   mmlu_professional_law:
2025-07-28 04:32:21,224 - INFO -     - accuracy: 0.4500
2025-07-28 04:32:21,224 - INFO -   mmlu_world_religions:
2025-07-28 04:32:21,224 - INFO -     - accuracy: 0.8500
2025-07-28 04:32:21,224 - INFO -   mmlu_other:
2025-07-28 04:32:21,225 - INFO -     - accuracy: 0.6269
2025-07-28 04:32:21,225 - INFO -   mmlu_business_ethics:
2025-07-28 04:32:21,225 - INFO -     - accuracy: 0.7500
2025-07-28 04:32:21,225 - INFO -   mmlu_clinical_knowledge:
2025-07-28 04:32:21,225 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,225 - INFO -   mmlu_college_medicine:
2025-07-28 04:32:21,225 - INFO -     - accuracy: 0.5500
2025-07-28 04:32:21,225 - INFO -   mmlu_global_facts:
2025-07-28 04:32:21,225 - INFO -     - accuracy: 0.3500
2025-07-28 04:32:21,225 - INFO -   mmlu_human_aging:
2025-07-28 04:32:21,226 - INFO -     - accuracy: 0.7500
2025-07-28 04:32:21,226 - INFO -   mmlu_management:
2025-07-28 04:32:21,226 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,226 - INFO -   mmlu_marketing:
2025-07-28 04:32:21,226 - INFO -     - accuracy: 0.7500
2025-07-28 04:32:21,226 - INFO -   mmlu_medical_genetics:
2025-07-28 04:32:21,226 - INFO -     - accuracy: 0.8000
2025-07-28 04:32:21,226 - INFO -   mmlu_miscellaneous:
2025-07-28 04:32:21,226 - INFO -     - accuracy: 0.7500
2025-07-28 04:32:21,226 - INFO -   mmlu_nutrition:
2025-07-28 04:32:21,226 - INFO -     - accuracy: 0.6500
2025-07-28 04:32:21,227 - INFO -   mmlu_professional_accounting:
2025-07-28 04:32:21,227 - INFO -     - accuracy: 0.3500
2025-07-28 04:32:21,227 - INFO -   mmlu_professional_medicine:
2025-07-28 04:32:21,227 - INFO -     - accuracy: 0.4500
2025-07-28 04:32:21,227 - INFO -   mmlu_virology:
2025-07-28 04:32:21,227 - INFO -     - accuracy: 0.6000
2025-07-28 04:32:21,227 - INFO -   mmlu_social_sciences:
2025-07-28 04:32:21,227 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,227 - INFO -   mmlu_econometrics:
2025-07-28 04:32:21,227 - INFO -     - accuracy: 0.5000
2025-07-28 04:32:21,228 - INFO -   mmlu_high_school_geography:
2025-07-28 04:32:21,228 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,228 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 04:32:21,228 - INFO -     - accuracy: 0.8500
2025-07-28 04:32:21,228 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 04:32:21,228 - INFO -     - accuracy: 0.5000
2025-07-28 04:32:21,228 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 04:32:21,228 - INFO -     - accuracy: 0.5000
2025-07-28 04:32:21,228 - INFO -   mmlu_high_school_psychology:
2025-07-28 04:32:21,228 - INFO -     - accuracy: 0.9000
2025-07-28 04:32:21,228 - INFO -   mmlu_human_sexuality:
2025-07-28 04:32:21,229 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,229 - INFO -   mmlu_professional_psychology:
2025-07-28 04:32:21,229 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,229 - INFO -   mmlu_public_relations:
2025-07-28 04:32:21,229 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,229 - INFO -   mmlu_security_studies:
2025-07-28 04:32:21,229 - INFO -     - accuracy: 0.8000
2025-07-28 04:32:21,229 - INFO -   mmlu_sociology:
2025-07-28 04:32:21,229 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,229 - INFO -   mmlu_us_foreign_policy:
2025-07-28 04:32:21,229 - INFO -     - accuracy: 0.8500
2025-07-28 04:32:21,230 - INFO -   mmlu_stem:
2025-07-28 04:32:21,230 - INFO -     - accuracy: 0.5184
2025-07-28 04:32:21,230 - INFO -   mmlu_abstract_algebra:
2025-07-28 04:32:21,230 - INFO -     - accuracy: 0.3500
2025-07-28 04:32:21,230 - INFO -   mmlu_anatomy:
2025-07-28 04:32:21,230 - INFO -     - accuracy: 0.6000
2025-07-28 04:32:21,230 - INFO -   mmlu_astronomy:
2025-07-28 04:32:21,230 - INFO -     - accuracy: 0.7500
2025-07-28 04:32:21,230 - INFO -   mmlu_college_biology:
2025-07-28 04:32:21,230 - INFO -     - accuracy: 0.7500
2025-07-28 04:32:21,231 - INFO -   mmlu_college_chemistry:
2025-07-28 04:32:21,231 - INFO -     - accuracy: 0.3500
2025-07-28 04:32:21,231 - INFO -   mmlu_college_computer_science:
2025-07-28 04:32:21,231 - INFO -     - accuracy: 0.3500
2025-07-28 04:32:21,231 - INFO -   mmlu_college_mathematics:
2025-07-28 04:32:21,231 - INFO -     - accuracy: 0.4000
2025-07-28 04:32:21,231 - INFO -   mmlu_college_physics:
2025-07-28 04:32:21,231 - INFO -     - accuracy: 0.4500
2025-07-28 04:32:21,231 - INFO -   mmlu_computer_security:
2025-07-28 04:32:21,231 - INFO -     - accuracy: 0.6500
2025-07-28 04:32:21,231 - INFO -   mmlu_conceptual_physics:
2025-07-28 04:32:21,232 - INFO -     - accuracy: 0.6500
2025-07-28 04:32:21,232 - INFO -   mmlu_electrical_engineering:
2025-07-28 04:32:21,232 - INFO -     - accuracy: 0.4000
2025-07-28 04:32:21,232 - INFO -   mmlu_elementary_mathematics:
2025-07-28 04:32:21,232 - INFO -     - accuracy: 0.4500
2025-07-28 04:32:21,232 - INFO -   mmlu_high_school_biology:
2025-07-28 04:32:21,232 - INFO -     - accuracy: 0.7000
2025-07-28 04:32:21,232 - INFO -   mmlu_high_school_chemistry:
2025-07-28 04:32:21,232 - INFO -     - accuracy: 0.5500
2025-07-28 04:32:21,232 - INFO -   mmlu_high_school_computer_science:
2025-07-28 04:32:21,233 - INFO -     - accuracy: 0.8500
2025-07-28 04:32:21,233 - INFO -   mmlu_high_school_mathematics:
2025-07-28 04:32:21,233 - INFO -     - accuracy: 0.3500
2025-07-28 04:32:21,233 - INFO -   mmlu_high_school_physics:
2025-07-28 04:32:21,233 - INFO -     - accuracy: 0.3000
2025-07-28 04:32:21,233 - INFO -   mmlu_high_school_statistics:
2025-07-28 04:32:21,233 - INFO -     - accuracy: 0.4500
2025-07-28 04:32:21,233 - INFO -   mmlu_machine_learning:
2025-07-28 04:32:21,233 - INFO -     - accuracy: 0.5000
2025-07-28 04:32:21,233 - INFO - ============================================================

2025-07-28 04:32:21,257 - INFO - gemma-3-4b-it_harness_2: Processing task 8/10: arc_challenge
2025-07-28 04:32:21,259 - INFO - gemma-3-4b-it_harness_2: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 04:32:21,260 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 04:32:21,260 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:32:32,347 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 04:32:41,524 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 04:32:41,525 - INFO - 
============================================================
2025-07-28 04:32:41,526 - INFO - Task 'arc_challenge' Results:
2025-07-28 04:32:41,528 - INFO - ============================================================
2025-07-28 04:32:41,528 - INFO -   arc_challenge:
2025-07-28 04:32:41,528 - INFO -     - accuracy: 0.5500
2025-07-28 04:32:41,528 - INFO -     - accuracy_norm: 0.5500
2025-07-28 04:32:41,528 - INFO - ============================================================

2025-07-28 04:32:41,551 - INFO - gemma-3-4b-it_harness_2: Processing task 9/10: arc_easy
2025-07-28 04:32:41,552 - INFO - gemma-3-4b-it_harness_2: Task 'arc_easy' will use num_fewshot=0
2025-07-28 04:32:41,552 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 04:32:41,553 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:32:51,287 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 04:32:58,589 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 04:32:58,590 - INFO - 
============================================================
2025-07-28 04:32:58,625 - INFO - Task 'arc_easy' Results:
2025-07-28 04:32:58,626 - INFO - ============================================================
2025-07-28 04:32:58,627 - INFO -   arc_easy:
2025-07-28 04:32:58,627 - INFO -     - accuracy: 0.8000
2025-07-28 04:32:58,627 - INFO -     - accuracy_norm: 0.6500
2025-07-28 04:32:58,627 - INFO - ============================================================

2025-07-28 04:32:58,650 - INFO - gemma-3-4b-it_harness_2: Processing task 10/10: hellaswag
2025-07-28 04:32:58,651 - INFO - gemma-3-4b-it_harness_2: Task 'hellaswag' will use num_fewshot=0
2025-07-28 04:32:58,652 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 04:32:58,652 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:33:16,114 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 04:33:25,292 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 04:33:25,295 - INFO - 
============================================================
2025-07-28 04:33:25,297 - INFO - Task 'hellaswag' Results:
2025-07-28 04:33:25,298 - INFO - ============================================================
2025-07-28 04:33:25,299 - INFO -   hellaswag:
2025-07-28 04:33:25,300 - INFO -     - accuracy: 0.5000
2025-07-28 04:33:25,300 - INFO -     - accuracy_norm: 0.7000
2025-07-28 04:33:25,301 - INFO - ============================================================

2025-07-28 04:33:25,324 - INFO - gemma-3-4b-it_harness_2: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 04:33:25,326 - INFO - [Process 1811658] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/gemma-3-4b-it/gemma-3-4b-it_harness_2.json
2025-07-28 04:33:25,629 - INFO - Results uploaded to WandB as artifact
2025-07-28 04:33:25,638 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 04:33:25,640 - INFO - [Process 1811658] Successfully completed gemma-3-4b-it_harness_2
2025-07-28 04:33:28,828 - INFO - Run gemma-3-4b-it_harness_2 finished successfully
2025-07-28 04:33:28,829 - INFO - [Process 1811658] EXAONE-3.5-2.4B-Instruct_harness_7 assigned to cuda:0
2025-07-28 04:33:28,829 - INFO - [Process 1811658] EXAONE-3.5-2.4B-Instruct_harness_7 - using custom limit: 20
2025-07-28 04:33:30,156 - INFO - WandB run initialized: EXAONE-3.5-2.4B-Instruct_20250728_043328 (ID: 9dadbb1c)
2025-07-28 04:33:30,366 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Test mode (limit=2), setting num_fewshot=0
2025-07-28 04:33:30,367 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 1/10: kmmlu
2025-07-28 04:33:30,367 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kmmlu' will use num_fewshot=0
2025-07-28 04:33:30,367 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 04:33:30,367 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:34:46,316 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 04:34:46,316 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 04:34:46,316 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 04:34:46,316 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 04:34:46,317 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 04:34:46,317 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 04:34:46,317 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 04:34:46,317 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 04:34:46,317 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 04:34:46,317 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 04:34:46,317 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 04:34:46,317 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 04:34:46,317 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 04:34:46,317 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 04:34:46,318 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 04:34:46,318 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 04:34:46,318 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 04:34:46,318 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 04:34:46,318 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 04:34:46,318 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 04:34:46,318 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 04:34:46,318 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 04:34:46,318 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 04:34:46,318 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 04:34:46,319 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 04:34:46,319 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 04:34:46,319 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 04:34:46,319 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 04:34:46,319 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 04:34:46,319 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 04:34:46,319 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 04:34:46,319 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 04:34:46,319 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 04:34:46,319 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 04:34:46,320 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 04:34:48,795 - WARNING - We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
2025-07-28 04:35:33,086 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 04:35:33,087 - INFO - 
============================================================
2025-07-28 04:35:33,088 - INFO - Task 'kmmlu' Results:
2025-07-28 04:35:33,089 - INFO - ============================================================
2025-07-28 04:35:33,090 - INFO -   kmmlu:
2025-07-28 04:35:33,090 - INFO -     - accuracy: 0.3756
2025-07-28 04:35:33,091 - INFO -   kmmlu_applied_science:
2025-07-28 04:35:33,091 - INFO -     - accuracy: 0.3500
2025-07-28 04:35:33,091 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 04:35:33,091 - INFO -     - accuracy: 0.2500
2025-07-28 04:35:33,091 - INFO -   kmmlu_electronics_engineering:
2025-07-28 04:35:33,091 - INFO -     - accuracy: 0.3500
2025-07-28 04:35:33,091 - INFO -   kmmlu_energy_management:
2025-07-28 04:35:33,091 - INFO -     - accuracy: 0.1500
2025-07-28 04:35:33,091 - INFO -   kmmlu_environmental_science:
2025-07-28 04:35:33,092 - INFO -     - accuracy: 0.2500
2025-07-28 04:35:33,092 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 04:35:33,092 - INFO -     - accuracy: 0.6000
2025-07-28 04:35:33,092 - INFO -   kmmlu_geomatics:
2025-07-28 04:35:33,092 - INFO -     - accuracy: 0.4000
2025-07-28 04:35:33,092 - INFO -   kmmlu_industrial_engineer:
2025-07-28 04:35:33,092 - INFO -     - accuracy: 0.3500
2025-07-28 04:35:33,092 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 04:35:33,092 - INFO -     - accuracy: 0.3500
2025-07-28 04:35:33,092 - INFO -   kmmlu_maritime_engineering:
2025-07-28 04:35:33,092 - INFO -     - accuracy: 0.4000
2025-07-28 04:35:33,093 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 04:35:33,093 - INFO -     - accuracy: 0.3000
2025-07-28 04:35:33,093 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 04:35:33,093 - INFO -     - accuracy: 0.5500
2025-07-28 04:35:33,093 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 04:35:33,093 - INFO -     - accuracy: 0.2500
2025-07-28 04:35:33,093 - INFO -   kmmlu_humss:
2025-07-28 04:35:33,093 - INFO -     - accuracy: 0.3909
2025-07-28 04:35:33,093 - INFO -   kmmlu_accounting:
2025-07-28 04:35:33,093 - INFO -     - accuracy: 0.5000
2025-07-28 04:35:33,094 - INFO -   kmmlu_criminal_law:
2025-07-28 04:35:33,094 - INFO -     - accuracy: 0.3000
2025-07-28 04:35:33,094 - INFO -   kmmlu_economics:
2025-07-28 04:35:33,094 - INFO -     - accuracy: 0.6000
2025-07-28 04:35:33,094 - INFO -   kmmlu_education:
2025-07-28 04:35:33,094 - INFO -     - accuracy: 0.4500
2025-07-28 04:35:33,094 - INFO -   kmmlu_korean_history:
2025-07-28 04:35:33,094 - INFO -     - accuracy: 0.2000
2025-07-28 04:35:33,094 - INFO -   kmmlu_law:
2025-07-28 04:35:33,094 - INFO -     - accuracy: 0.3500
2025-07-28 04:35:33,094 - INFO -   kmmlu_management:
2025-07-28 04:35:33,095 - INFO -     - accuracy: 0.4500
2025-07-28 04:35:33,095 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 04:35:33,095 - INFO -     - accuracy: 0.6000
2025-07-28 04:35:33,095 - INFO -   kmmlu_psychology:
2025-07-28 04:35:33,095 - INFO -     - accuracy: 0.2000
2025-07-28 04:35:33,095 - INFO -   kmmlu_social_welfare:
2025-07-28 04:35:33,095 - INFO -     - accuracy: 0.5000
2025-07-28 04:35:33,095 - INFO -   kmmlu_taxation:
2025-07-28 04:35:33,095 - INFO -     - accuracy: 0.1500
2025-07-28 04:35:33,095 - INFO -   kmmlu_other:
2025-07-28 04:35:33,095 - INFO -     - accuracy: 0.3727
2025-07-28 04:35:33,096 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 04:35:33,096 - INFO -     - accuracy: 0.4000
2025-07-28 04:35:33,096 - INFO -   kmmlu_construction:
2025-07-28 04:35:33,096 - INFO -     - accuracy: 0.3500
2025-07-28 04:35:33,096 - INFO -   kmmlu_fashion:
2025-07-28 04:35:33,096 - INFO -     - accuracy: 0.2500
2025-07-28 04:35:33,096 - INFO -   kmmlu_food_processing:
2025-07-28 04:35:33,096 - INFO -     - accuracy: 0.2500
2025-07-28 04:35:33,096 - INFO -   kmmlu_health:
2025-07-28 04:35:33,096 - INFO -     - accuracy: 0.5500
2025-07-28 04:35:33,097 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 04:35:33,097 - INFO -     - accuracy: 0.5500
2025-07-28 04:35:33,097 - INFO -   kmmlu_marketing:
2025-07-28 04:35:33,097 - INFO -     - accuracy: 0.5000
2025-07-28 04:35:33,097 - INFO -   kmmlu_patent:
2025-07-28 04:35:33,097 - INFO -     - accuracy: 0.3500
2025-07-28 04:35:33,097 - INFO -   kmmlu_public_safety:
2025-07-28 04:35:33,097 - INFO -     - accuracy: 0.3000
2025-07-28 04:35:33,097 - INFO -   kmmlu_real_estate:
2025-07-28 04:35:33,097 - INFO -     - accuracy: 0.3500
2025-07-28 04:35:33,097 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 04:35:33,097 - INFO -     - accuracy: 0.2500
2025-07-28 04:35:33,130 - INFO -   kmmlu_stem:
2025-07-28 04:35:33,130 - INFO -     - accuracy: 0.3909
2025-07-28 04:35:33,130 - INFO -   kmmlu_biology:
2025-07-28 04:35:33,131 - INFO -     - accuracy: 0.3500
2025-07-28 04:35:33,131 - INFO -   kmmlu_chemical_engineering:
2025-07-28 04:35:33,131 - INFO -     - accuracy: 0.4000
2025-07-28 04:35:33,131 - INFO -   kmmlu_chemistry:
2025-07-28 04:35:33,131 - INFO -     - accuracy: 0.4500
2025-07-28 04:35:33,131 - INFO -   kmmlu_civil_engineering:
2025-07-28 04:35:33,131 - INFO -     - accuracy: 0.5000
2025-07-28 04:35:33,131 - INFO -   kmmlu_computer_science:
2025-07-28 04:35:33,131 - INFO -     - accuracy: 0.6500
2025-07-28 04:35:33,132 - INFO -   kmmlu_ecology:
2025-07-28 04:35:33,132 - INFO -     - accuracy: 0.3500
2025-07-28 04:35:33,132 - INFO -   kmmlu_electrical_engineering:
2025-07-28 04:35:33,132 - INFO -     - accuracy: 0.3000
2025-07-28 04:35:33,132 - INFO -   kmmlu_information_technology:
2025-07-28 04:35:33,132 - INFO -     - accuracy: 0.5000
2025-07-28 04:35:33,132 - INFO -   kmmlu_materials_engineering:
2025-07-28 04:35:33,132 - INFO -     - accuracy: 0.2500
2025-07-28 04:35:33,132 - INFO -   kmmlu_math:
2025-07-28 04:35:33,132 - INFO -     - accuracy: 0.2500
2025-07-28 04:35:33,133 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 04:35:33,133 - INFO -     - accuracy: 0.3000
2025-07-28 04:35:33,133 - INFO - ============================================================

2025-07-28 04:35:33,158 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 2/10: kmmlu_hard
2025-07-28 04:35:33,158 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 04:35:33,159 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 04:35:33,159 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:36:44,684 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 04:36:44,684 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 04:36:44,684 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 04:36:44,685 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 04:36:44,686 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 04:36:44,687 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 04:36:44,688 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 04:36:44,688 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 04:36:44,688 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 04:36:44,688 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 04:36:44,688 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 04:36:44,688 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 04:36:44,688 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 04:36:44,688 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 04:37:31,994 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 04:37:31,996 - INFO - 
============================================================
2025-07-28 04:37:31,997 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 04:37:31,998 - INFO - ============================================================
2025-07-28 04:37:31,999 - INFO -   kmmlu_hard:
2025-07-28 04:37:31,999 - INFO -     - accuracy: 0.2300
2025-07-28 04:37:31,999 - INFO -   kmmlu_hard_applied_science:
2025-07-28 04:37:31,999 - INFO -     - accuracy: 0.2625
2025-07-28 04:37:31,999 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 04:37:31,999 - INFO -     - accuracy: 0.3000
2025-07-28 04:37:32,000 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 04:37:32,000 - INFO -     - accuracy: 0.2500
2025-07-28 04:37:32,000 - INFO -   kmmlu_hard_energy_management:
2025-07-28 04:37:32,000 - INFO -     - accuracy: 0.2000
2025-07-28 04:37:32,000 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 04:37:32,000 - INFO -     - accuracy: 0.3500
2025-07-28 04:37:32,000 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 04:37:32,000 - INFO -     - accuracy: 0.3000
2025-07-28 04:37:32,000 - INFO -   kmmlu_hard_geomatics:
2025-07-28 04:37:32,000 - INFO -     - accuracy: 0.3000
2025-07-28 04:37:32,001 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 04:37:32,001 - INFO -     - accuracy: 0.2500
2025-07-28 04:37:32,001 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 04:37:32,001 - INFO -     - accuracy: 0.2500
2025-07-28 04:37:32,001 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 04:37:32,001 - INFO -     - accuracy: 0.2000
2025-07-28 04:37:32,001 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 04:37:32,001 - INFO -     - accuracy: 0.1500
2025-07-28 04:37:32,001 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 04:37:32,001 - INFO -     - accuracy: 0.1500
2025-07-28 04:37:32,001 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 04:37:32,002 - INFO -     - accuracy: 0.4500
2025-07-28 04:37:32,002 - INFO -   kmmlu_hard_humss:
2025-07-28 04:37:32,002 - INFO -     - accuracy: 0.1636
2025-07-28 04:37:32,002 - INFO -   kmmlu_hard_accounting:
2025-07-28 04:37:32,002 - INFO -     - accuracy: 0.1500
2025-07-28 04:37:32,002 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 04:37:32,002 - INFO -     - accuracy: 0.1500
2025-07-28 04:37:32,002 - INFO -   kmmlu_hard_economics:
2025-07-28 04:37:32,002 - INFO -     - accuracy: 0.3000
2025-07-28 04:37:32,003 - INFO -   kmmlu_hard_education:
2025-07-28 04:37:32,004 - INFO -     - accuracy: 0.2500
2025-07-28 04:37:32,004 - INFO -   kmmlu_hard_korean_history:
2025-07-28 04:37:32,004 - INFO -     - accuracy: 0.1500
2025-07-28 04:37:32,004 - INFO -   kmmlu_hard_law:
2025-07-28 04:37:32,005 - INFO -     - accuracy: 0.1000
2025-07-28 04:37:32,005 - INFO -   kmmlu_hard_management:
2025-07-28 04:37:32,005 - INFO -     - accuracy: 0.1000
2025-07-28 04:37:32,005 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 04:37:32,005 - INFO -     - accuracy: 0.0500
2025-07-28 04:37:32,006 - INFO -   kmmlu_hard_psychology:
2025-07-28 04:37:32,006 - INFO -     - accuracy: 0.1000
2025-07-28 04:37:32,006 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 04:37:32,006 - INFO -     - accuracy: 0.2500
2025-07-28 04:37:32,007 - INFO -   kmmlu_hard_taxation:
2025-07-28 04:37:32,007 - INFO -     - accuracy: 0.2000
2025-07-28 04:37:32,007 - INFO -   kmmlu_hard_other:
2025-07-28 04:37:32,007 - INFO -     - accuracy: 0.2636
2025-07-28 04:37:32,007 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 04:37:32,007 - INFO -     - accuracy: 0.3000
2025-07-28 04:37:32,008 - INFO -   kmmlu_hard_construction:
2025-07-28 04:37:32,008 - INFO -     - accuracy: 0.3000
2025-07-28 04:37:32,008 - INFO -   kmmlu_hard_fashion:
2025-07-28 04:37:32,008 - INFO -     - accuracy: 0.3000
2025-07-28 04:37:32,008 - INFO -   kmmlu_hard_food_processing:
2025-07-28 04:37:32,009 - INFO -     - accuracy: 0.2500
2025-07-28 04:37:32,009 - INFO -   kmmlu_hard_health:
2025-07-28 04:37:32,009 - INFO -     - accuracy: 0.2000
2025-07-28 04:37:32,009 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 04:37:32,009 - INFO -     - accuracy: 0.3500
2025-07-28 04:37:32,010 - INFO -   kmmlu_hard_marketing:
2025-07-28 04:37:32,010 - INFO -     - accuracy: 0.3500
2025-07-28 04:37:32,010 - INFO -   kmmlu_hard_patent:
2025-07-28 04:37:32,010 - INFO -     - accuracy: 0.2000
2025-07-28 04:37:32,010 - INFO -   kmmlu_hard_public_safety:
2025-07-28 04:37:32,010 - INFO -     - accuracy: 0.1000
2025-07-28 04:37:32,011 - INFO -   kmmlu_hard_real_estate:
2025-07-28 04:37:32,011 - INFO -     - accuracy: 0.3000
2025-07-28 04:37:32,011 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 04:37:32,011 - INFO -     - accuracy: 0.2500
2025-07-28 04:37:32,012 - INFO -   kmmlu_hard_stem:
2025-07-28 04:37:32,012 - INFO -     - accuracy: 0.2273
2025-07-28 04:37:32,012 - INFO -   kmmlu_hard_biology:
2025-07-28 04:37:32,012 - INFO -     - accuracy: 0.0500
2025-07-28 04:37:32,012 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 04:37:32,013 - INFO -     - accuracy: 0.1000
2025-07-28 04:37:32,013 - INFO -   kmmlu_hard_chemistry:
2025-07-28 04:37:32,013 - INFO -     - accuracy: 0.2000
2025-07-28 04:37:32,013 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 04:37:32,013 - INFO -     - accuracy: 0.1000
2025-07-28 04:37:32,014 - INFO -   kmmlu_hard_computer_science:
2025-07-28 04:37:32,014 - INFO -     - accuracy: 0.4500
2025-07-28 04:37:32,014 - INFO -   kmmlu_hard_ecology:
2025-07-28 04:37:32,014 - INFO -     - accuracy: 0.3000
2025-07-28 04:37:32,014 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 04:37:32,015 - INFO -     - accuracy: 0.3500
2025-07-28 04:37:32,015 - INFO -   kmmlu_hard_information_technology:
2025-07-28 04:37:32,015 - INFO -     - accuracy: 0.3000
2025-07-28 04:37:32,015 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 04:37:32,015 - INFO -     - accuracy: 0.3500
2025-07-28 04:37:32,016 - INFO -   kmmlu_hard_math:
2025-07-28 04:37:32,016 - INFO -     - accuracy: 0.0500
2025-07-28 04:37:32,016 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 04:37:32,016 - INFO -     - accuracy: 0.2500
2025-07-28 04:37:32,017 - INFO - ============================================================

2025-07-28 04:37:32,042 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 3/10: haerae
2025-07-28 04:37:32,043 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'haerae' will use num_fewshot=0
2025-07-28 04:37:32,044 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 04:37:32,044 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:37:49,397 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 04:37:49,397 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 04:37:49,398 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 04:37:49,398 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 04:37:49,398 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 04:38:13,501 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 04:38:13,503 - INFO - 
============================================================
2025-07-28 04:38:13,504 - INFO - Task 'haerae' Results:
2025-07-28 04:38:13,506 - INFO - ============================================================
2025-07-28 04:38:13,506 - INFO -   haerae:
2025-07-28 04:38:13,506 - INFO -     - accuracy: 0.7400
2025-07-28 04:38:13,506 - INFO -     - accuracy_norm: 0.7400
2025-07-28 04:38:13,507 - INFO -   haerae_general_knowledge:
2025-07-28 04:38:13,507 - INFO -     - accuracy: 0.7500
2025-07-28 04:38:13,507 - INFO -     - accuracy_norm: 0.7500
2025-07-28 04:38:13,507 - INFO -   haerae_history:
2025-07-28 04:38:13,507 - INFO -     - accuracy: 0.8000
2025-07-28 04:38:13,507 - INFO -     - accuracy_norm: 0.8000
2025-07-28 04:38:13,507 - INFO -   haerae_loan_word:
2025-07-28 04:38:13,507 - INFO -     - accuracy: 0.9000
2025-07-28 04:38:13,507 - INFO -     - accuracy_norm: 0.9000
2025-07-28 04:38:13,508 - INFO -   haerae_rare_word:
2025-07-28 04:38:13,508 - INFO -     - accuracy: 0.5000
2025-07-28 04:38:13,508 - INFO -     - accuracy_norm: 0.5000
2025-07-28 04:38:13,508 - INFO -   haerae_standard_nomenclature:
2025-07-28 04:38:13,508 - INFO -     - accuracy: 0.7500
2025-07-28 04:38:13,508 - INFO -     - accuracy_norm: 0.7500
2025-07-28 04:38:13,508 - INFO - ============================================================

2025-07-28 04:38:13,532 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 4/10: kobest
2025-07-28 04:38:13,532 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kobest' will use num_fewshot=0
2025-07-28 04:38:13,533 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 04:38:13,534 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:38:33,505 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 04:38:33,505 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 04:38:33,506 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 04:38:33,506 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 04:38:33,506 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 04:38:44,459 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 04:38:44,460 - INFO - 
============================================================
2025-07-28 04:38:44,462 - INFO - Task 'kobest' Results:
2025-07-28 04:38:44,463 - INFO - ============================================================
2025-07-28 04:38:44,463 - INFO -   kobest:
2025-07-28 04:38:44,463 - INFO -     - accuracy: 0.6900
2025-07-28 04:38:44,464 - INFO -     - accuracy_norm: 0.6500
2025-07-28 04:38:44,464 - INFO -     - f1: 0.6724
2025-07-28 04:38:44,464 - INFO -   kobest_boolq:
2025-07-28 04:38:44,464 - INFO -     - accuracy: 0.8000
2025-07-28 04:38:44,464 - INFO -     - f1: 0.7917
2025-07-28 04:38:44,464 - INFO -   kobest_copa:
2025-07-28 04:38:44,464 - INFO -     - accuracy: 0.7000
2025-07-28 04:38:44,464 - INFO -     - f1: 0.6970
2025-07-28 04:38:44,465 - INFO -   kobest_hellaswag:
2025-07-28 04:38:44,465 - INFO -     - accuracy: 0.4500
2025-07-28 04:38:44,465 - INFO -     - accuracy_norm: 0.6500
2025-07-28 04:38:44,465 - INFO -     - f1: 0.4495
2025-07-28 04:38:44,465 - INFO -   kobest_sentineg:
2025-07-28 04:38:44,465 - INFO -     - accuracy: 0.9000
2025-07-28 04:38:44,465 - INFO -     - f1: 0.9000
2025-07-28 04:38:44,465 - INFO -   kobest_wic:
2025-07-28 04:38:44,465 - INFO -     - accuracy: 0.6000
2025-07-28 04:38:44,465 - INFO -     - f1: 0.5238
2025-07-28 04:38:44,466 - INFO - ============================================================

2025-07-28 04:38:44,489 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 5/10: csatqa
2025-07-28 04:38:44,491 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'csatqa' detected as zero-shot task
2025-07-28 04:38:44,491 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 04:38:44,492 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:38:57,172 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 04:38:57,173 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 04:38:57,173 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 04:38:57,173 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 04:38:57,173 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 04:38:57,173 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 04:42:27,252 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 04:42:27,254 - INFO - 
============================================================
2025-07-28 04:42:27,255 - INFO - Task 'csatqa' Results:
2025-07-28 04:42:27,256 - INFO - ============================================================
2025-07-28 04:42:27,256 - INFO -   csatqa:
2025-07-28 04:42:27,257 - INFO -     - accuracy: 0.3153
2025-07-28 04:42:27,257 - INFO -     - accuracy_norm: 0.3153
2025-07-28 04:42:27,257 - INFO -   csatqa_gr:
2025-07-28 04:42:27,258 - INFO -     - accuracy: 0.0500
2025-07-28 04:42:27,258 - INFO -     - accuracy_norm: 0.0500
2025-07-28 04:42:27,258 - INFO -   csatqa_li:
2025-07-28 04:42:27,258 - INFO -     - accuracy: 0.4000
2025-07-28 04:42:27,258 - INFO -     - accuracy_norm: 0.4000
2025-07-28 04:42:27,258 - INFO -   csatqa_rch:
2025-07-28 04:42:27,258 - INFO -     - accuracy: 0.4500
2025-07-28 04:42:27,258 - INFO -     - accuracy_norm: 0.4500
2025-07-28 04:42:27,258 - INFO -   csatqa_rcs:
2025-07-28 04:42:27,259 - INFO -     - accuracy: 0.3000
2025-07-28 04:42:27,259 - INFO -     - accuracy_norm: 0.3000
2025-07-28 04:42:27,259 - INFO -   csatqa_rcss:
2025-07-28 04:42:27,259 - INFO -     - accuracy: 0.4000
2025-07-28 04:42:27,259 - INFO -     - accuracy_norm: 0.4000
2025-07-28 04:42:27,259 - INFO -   csatqa_wr:
2025-07-28 04:42:27,259 - INFO -     - accuracy: 0.2727
2025-07-28 04:42:27,259 - INFO -     - accuracy_norm: 0.2727
2025-07-28 04:42:27,259 - INFO - ============================================================

2025-07-28 04:42:27,292 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 6/10: kormedmcqa
2025-07-28 04:42:27,294 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 04:42:27,295 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 04:42:27,295 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:42:45,784 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 04:42:45,784 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 04:42:45,784 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 04:42:45,784 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 04:42:54,705 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 04:42:54,706 - INFO - 
============================================================
2025-07-28 04:42:54,708 - INFO - Task 'kormedmcqa' Results:
2025-07-28 04:42:54,708 - INFO - ============================================================
2025-07-28 04:42:54,709 - INFO -   kormedmcqa:
2025-07-28 04:42:54,709 - INFO -     - exact_match: 0.5250
2025-07-28 04:42:54,710 - INFO -   kormedmcqa_dentist:
2025-07-28 04:42:54,710 - INFO -     - exact_match: 0.5000
2025-07-28 04:42:54,711 - INFO -   kormedmcqa_doctor:
2025-07-28 04:42:54,711 - INFO -     - exact_match: 0.5000
2025-07-28 04:42:54,711 - INFO -   kormedmcqa_nurse:
2025-07-28 04:42:54,711 - INFO -     - exact_match: 0.6500
2025-07-28 04:42:54,711 - INFO -   kormedmcqa_pharm:
2025-07-28 04:42:54,711 - INFO -     - exact_match: 0.4500
2025-07-28 04:42:54,711 - INFO - ============================================================

2025-07-28 04:42:54,736 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 7/10: mmlu
2025-07-28 04:42:54,737 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'mmlu' will use num_fewshot=0
2025-07-28 04:42:54,738 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 04:42:54,738 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:45:37,737 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 04:45:37,738 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 04:45:37,738 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 04:45:37,738 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 04:45:37,739 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 04:45:37,739 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 04:45:37,739 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 04:45:37,739 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 04:45:37,739 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 04:45:37,739 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 04:45:37,739 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 04:45:37,740 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 04:45:37,740 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 04:45:37,740 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 04:45:37,740 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 04:45:37,740 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 04:45:37,740 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 04:45:37,740 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 04:45:37,741 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 04:45:37,741 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 04:45:37,741 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 04:45:37,741 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 04:45:37,741 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 04:45:37,741 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 04:45:37,741 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 04:45:37,742 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 04:45:37,742 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 04:45:37,742 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 04:45:37,742 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 04:45:37,742 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 04:45:37,742 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 04:45:37,742 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 04:45:37,743 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 04:45:37,743 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 04:45:37,743 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 04:45:37,743 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 04:45:37,743 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 04:45:37,743 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 04:45:37,743 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 04:45:37,744 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 04:45:37,744 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 04:45:37,744 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 04:45:37,744 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 04:45:37,744 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 04:45:37,744 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 04:45:37,744 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 04:45:37,744 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 04:45:37,745 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 04:45:37,745 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 04:45:37,745 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 04:45:37,745 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 04:45:37,745 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 04:45:37,745 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 04:45:37,745 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 04:45:37,745 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 04:45:37,745 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 04:45:37,745 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 04:46:39,944 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 04:46:39,945 - INFO - 
============================================================
2025-07-28 04:46:39,947 - INFO - Task 'mmlu' Results:
2025-07-28 04:46:39,947 - INFO - ============================================================
2025-07-28 04:46:39,948 - INFO -   mmlu:
2025-07-28 04:46:39,949 - INFO -     - accuracy: 0.5991
2025-07-28 04:46:39,949 - INFO -   mmlu_humanities:
2025-07-28 04:46:39,949 - INFO -     - accuracy: 0.6038
2025-07-28 04:46:39,949 - INFO -   mmlu_formal_logic:
2025-07-28 04:46:39,949 - INFO -     - accuracy: 0.4000
2025-07-28 04:46:39,949 - INFO -   mmlu_high_school_european_history:
2025-07-28 04:46:39,949 - INFO -     - accuracy: 0.6500
2025-07-28 04:46:39,950 - INFO -   mmlu_high_school_us_history:
2025-07-28 04:46:39,950 - INFO -     - accuracy: 0.6500
2025-07-28 04:46:39,950 - INFO -   mmlu_high_school_world_history:
2025-07-28 04:46:39,950 - INFO -     - accuracy: 0.7500
2025-07-28 04:46:39,950 - INFO -   mmlu_international_law:
2025-07-28 04:46:39,950 - INFO -     - accuracy: 0.7500
2025-07-28 04:46:39,950 - INFO -   mmlu_jurisprudence:
2025-07-28 04:46:39,950 - INFO -     - accuracy: 0.7000
2025-07-28 04:46:39,950 - INFO -   mmlu_logical_fallacies:
2025-07-28 04:46:39,950 - INFO -     - accuracy: 0.6000
2025-07-28 04:46:39,951 - INFO -   mmlu_moral_disputes:
2025-07-28 04:46:39,951 - INFO -     - accuracy: 0.4500
2025-07-28 04:46:39,951 - INFO -   mmlu_moral_scenarios:
2025-07-28 04:46:39,951 - INFO -     - accuracy: 0.2500
2025-07-28 04:46:39,951 - INFO -   mmlu_philosophy:
2025-07-28 04:46:39,951 - INFO -     - accuracy: 0.7000
2025-07-28 04:46:39,951 - INFO -   mmlu_prehistory:
2025-07-28 04:46:39,951 - INFO -     - accuracy: 0.6500
2025-07-28 04:46:39,951 - INFO -   mmlu_professional_law:
2025-07-28 04:46:39,951 - INFO -     - accuracy: 0.6000
2025-07-28 04:46:39,952 - INFO -   mmlu_world_religions:
2025-07-28 04:46:39,952 - INFO -     - accuracy: 0.7000
2025-07-28 04:46:39,952 - INFO -   mmlu_other:
2025-07-28 04:46:39,952 - INFO -     - accuracy: 0.5962
2025-07-28 04:46:39,952 - INFO -   mmlu_business_ethics:
2025-07-28 04:46:39,952 - INFO -     - accuracy: 0.8000
2025-07-28 04:46:39,952 - INFO -   mmlu_clinical_knowledge:
2025-07-28 04:46:39,952 - INFO -     - accuracy: 0.6000
2025-07-28 04:46:39,952 - INFO -   mmlu_college_medicine:
2025-07-28 04:46:39,952 - INFO -     - accuracy: 0.6000
2025-07-28 04:46:39,952 - INFO -   mmlu_global_facts:
2025-07-28 04:46:39,953 - INFO -     - accuracy: 0.3000
2025-07-28 04:46:39,953 - INFO -   mmlu_human_aging:
2025-07-28 04:46:39,953 - INFO -     - accuracy: 0.6500
2025-07-28 04:46:39,953 - INFO -   mmlu_management:
2025-07-28 04:46:39,953 - INFO -     - accuracy: 0.7000
2025-07-28 04:46:39,953 - INFO -   mmlu_marketing:
2025-07-28 04:46:39,953 - INFO -     - accuracy: 0.7500
2025-07-28 04:46:39,953 - INFO -   mmlu_medical_genetics:
2025-07-28 04:46:39,953 - INFO -     - accuracy: 0.8000
2025-07-28 04:46:39,954 - INFO -   mmlu_miscellaneous:
2025-07-28 04:46:39,954 - INFO -     - accuracy: 0.6000
2025-07-28 04:46:39,954 - INFO -   mmlu_nutrition:
2025-07-28 04:46:39,954 - INFO -     - accuracy: 0.6500
2025-07-28 04:46:39,954 - INFO -   mmlu_professional_accounting:
2025-07-28 04:46:39,954 - INFO -     - accuracy: 0.2500
2025-07-28 04:46:39,954 - INFO -   mmlu_professional_medicine:
2025-07-28 04:46:39,954 - INFO -     - accuracy: 0.5000
2025-07-28 04:46:39,954 - INFO -   mmlu_virology:
2025-07-28 04:46:39,955 - INFO -     - accuracy: 0.5500
2025-07-28 04:46:39,955 - INFO -   mmlu_social_sciences:
2025-07-28 04:46:39,955 - INFO -     - accuracy: 0.6958
2025-07-28 04:46:39,955 - INFO -   mmlu_econometrics:
2025-07-28 04:46:39,955 - INFO -     - accuracy: 0.3500
2025-07-28 04:46:39,955 - INFO -   mmlu_high_school_geography:
2025-07-28 04:46:39,955 - INFO -     - accuracy: 0.8000
2025-07-28 04:46:39,955 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 04:46:39,955 - INFO -     - accuracy: 0.8500
2025-07-28 04:46:39,956 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 04:46:39,956 - INFO -     - accuracy: 0.6000
2025-07-28 04:46:39,956 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 04:46:39,956 - INFO -     - accuracy: 0.7500
2025-07-28 04:46:39,956 - INFO -   mmlu_high_school_psychology:
2025-07-28 04:46:39,956 - INFO -     - accuracy: 0.6500
2025-07-28 04:46:39,956 - INFO -   mmlu_human_sexuality:
2025-07-28 04:46:39,956 - INFO -     - accuracy: 0.9500
2025-07-28 04:46:39,956 - INFO -   mmlu_professional_psychology:
2025-07-28 04:46:39,957 - INFO -     - accuracy: 0.8000
2025-07-28 04:46:39,957 - INFO -   mmlu_public_relations:
2025-07-28 04:46:39,957 - INFO -     - accuracy: 0.3500
2025-07-28 04:46:39,957 - INFO -   mmlu_security_studies:
2025-07-28 04:46:39,957 - INFO -     - accuracy: 0.7500
2025-07-28 04:46:39,957 - INFO -   mmlu_sociology:
2025-07-28 04:46:39,957 - INFO -     - accuracy: 0.7000
2025-07-28 04:46:39,957 - INFO -   mmlu_us_foreign_policy:
2025-07-28 04:46:39,957 - INFO -     - accuracy: 0.8000
2025-07-28 04:46:39,958 - INFO -   mmlu_stem:
2025-07-28 04:46:39,958 - INFO -     - accuracy: 0.5368
2025-07-28 04:46:39,958 - INFO -   mmlu_abstract_algebra:
2025-07-28 04:46:39,958 - INFO -     - accuracy: 0.2500
2025-07-28 04:46:39,958 - INFO -   mmlu_anatomy:
2025-07-28 04:46:39,958 - INFO -     - accuracy: 0.4500
2025-07-28 04:46:39,958 - INFO -   mmlu_astronomy:
2025-07-28 04:46:39,958 - INFO -     - accuracy: 0.8000
2025-07-28 04:46:39,958 - INFO -   mmlu_college_biology:
2025-07-28 04:46:39,959 - INFO -     - accuracy: 0.9000
2025-07-28 04:46:39,959 - INFO -   mmlu_college_chemistry:
2025-07-28 04:46:39,959 - INFO -     - accuracy: 0.6000
2025-07-28 04:46:39,959 - INFO -   mmlu_college_computer_science:
2025-07-28 04:46:39,959 - INFO -     - accuracy: 0.4500
2025-07-28 04:46:39,959 - INFO -   mmlu_college_mathematics:
2025-07-28 04:46:39,959 - INFO -     - accuracy: 0.3500
2025-07-28 04:46:39,959 - INFO -   mmlu_college_physics:
2025-07-28 04:46:39,959 - INFO -     - accuracy: 0.5000
2025-07-28 04:46:39,960 - INFO -   mmlu_computer_security:
2025-07-28 04:46:39,960 - INFO -     - accuracy: 0.7000
2025-07-28 04:46:39,960 - INFO -   mmlu_conceptual_physics:
2025-07-28 04:46:39,960 - INFO -     - accuracy: 0.5500
2025-07-28 04:46:39,960 - INFO -   mmlu_electrical_engineering:
2025-07-28 04:46:39,960 - INFO -     - accuracy: 0.4500
2025-07-28 04:46:39,960 - INFO -   mmlu_elementary_mathematics:
2025-07-28 04:46:39,960 - INFO -     - accuracy: 0.4500
2025-07-28 04:46:39,960 - INFO -   mmlu_high_school_biology:
2025-07-28 04:46:39,960 - INFO -     - accuracy: 0.7500
2025-07-28 04:46:39,961 - INFO -   mmlu_high_school_chemistry:
2025-07-28 04:46:39,961 - INFO -     - accuracy: 0.6000
2025-07-28 04:46:39,961 - INFO -   mmlu_high_school_computer_science:
2025-07-28 04:46:39,961 - INFO -     - accuracy: 0.8500
2025-07-28 04:46:39,961 - INFO -   mmlu_high_school_mathematics:
2025-07-28 04:46:39,961 - INFO -     - accuracy: 0.3000
2025-07-28 04:46:39,961 - INFO -   mmlu_high_school_physics:
2025-07-28 04:46:39,961 - INFO -     - accuracy: 0.3500
2025-07-28 04:46:39,961 - INFO -   mmlu_high_school_statistics:
2025-07-28 04:46:39,962 - INFO -     - accuracy: 0.5000
2025-07-28 04:46:39,962 - INFO -   mmlu_machine_learning:
2025-07-28 04:46:39,962 - INFO -     - accuracy: 0.4000
2025-07-28 04:46:39,962 - INFO - ============================================================

2025-07-28 04:46:39,987 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 8/10: arc_challenge
2025-07-28 04:46:39,988 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 04:46:39,988 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 04:46:39,989 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:46:48,080 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 04:46:53,586 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 04:46:53,587 - INFO - 
============================================================
2025-07-28 04:46:53,589 - INFO - Task 'arc_challenge' Results:
2025-07-28 04:46:53,590 - INFO - ============================================================
2025-07-28 04:46:53,591 - INFO -   arc_challenge:
2025-07-28 04:46:53,591 - INFO -     - accuracy: 0.6000
2025-07-28 04:46:53,591 - INFO -     - accuracy_norm: 0.4500
2025-07-28 04:46:53,591 - INFO - ============================================================

2025-07-28 04:46:53,615 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 9/10: arc_easy
2025-07-28 04:46:53,616 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'arc_easy' will use num_fewshot=0
2025-07-28 04:46:53,617 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 04:46:53,617 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:47:01,899 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 04:47:06,768 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 04:47:06,770 - INFO - 
============================================================
2025-07-28 04:47:06,771 - INFO - Task 'arc_easy' Results:
2025-07-28 04:47:06,773 - INFO - ============================================================
2025-07-28 04:47:06,773 - INFO -   arc_easy:
2025-07-28 04:47:06,773 - INFO -     - accuracy: 0.8000
2025-07-28 04:47:06,773 - INFO -     - accuracy_norm: 0.7500
2025-07-28 04:47:06,773 - INFO - ============================================================

2025-07-28 04:47:06,797 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 10/10: hellaswag
2025-07-28 04:47:06,798 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'hellaswag' will use num_fewshot=0
2025-07-28 04:47:06,799 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 04:47:06,800 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:47:21,373 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 04:47:26,816 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 04:47:26,817 - INFO - 
============================================================
2025-07-28 04:47:26,819 - INFO - Task 'hellaswag' Results:
2025-07-28 04:47:26,820 - INFO - ============================================================
2025-07-28 04:47:26,820 - INFO -   hellaswag:
2025-07-28 04:47:26,821 - INFO -     - accuracy: 0.4000
2025-07-28 04:47:26,821 - INFO -     - accuracy_norm: 0.7000
2025-07-28 04:47:26,821 - INFO - ============================================================

2025-07-28 04:47:26,845 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 04:47:26,848 - INFO - [Process 1811658] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/EXAONE-3.5-2.4B-Instruct/EXAONE-3.5-2.4B-Instruct_harness_7.json
2025-07-28 04:47:27,114 - INFO - Results uploaded to WandB as artifact
2025-07-28 04:47:27,123 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 04:47:27,124 - INFO - [Process 1811658] Successfully completed EXAONE-3.5-2.4B-Instruct_harness_7
2025-07-28 04:47:29,931 - INFO - Run EXAONE-3.5-2.4B-Instruct_harness_7 finished successfully
2025-07-28 04:47:29,931 - INFO - [Process 1811658] HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9 assigned to cuda:0
2025-07-28 04:47:29,931 - INFO - [Process 1811658] HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9 - using custom limit: 20
2025-07-28 04:47:30,949 - INFO - WandB run initialized: HyperCLOVAX-SEED-Text-Instruct-1.5B_20250728_044729 (ID: 71bd7739)
2025-07-28 04:47:31,487 - ERROR - [Process 1811658] Error in HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9: 401 Client Error. (Request ID: Root=1-688700e3-3e83c47a214b75d70899841c;c4d0dc62-1f22-4292-9943-91d3bbf8c0d4)

Cannot access gated repo for url https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes.
Access to model naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B is restricted. You must have access to it and be authenticated to access it. Please log in.
Traceback (most recent call last):
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/gwlee/Benchmark/AIDE_Benchmark/code/core/evaluation_lm.py", line 630, in evaluate_single
    local_path = ensure_model_local(model_id)
  File "/home/gwlee/Benchmark/AIDE_Benchmark/code/core/evaluation_lm.py", line 149, in ensure_model_local
    local_path = snapshot_download(repo_id=repo_id, cache_dir=cache_dir, local_files_only=False)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py", line 296, in snapshot_download
    thread_map(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/tqdm/contrib/concurrent.py", line 69, in thread_map
    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/tqdm/contrib/concurrent.py", line 51, in _executor_map
    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 621, in result_iterator
    yield _result_or_cancel(fs.pop())
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 319, in _result_or_cancel
    return fut.result(timeout)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py", line 270, in _inner_hf_hub_download
    return hf_hub_download(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 426, in hf_raise_for_status
    raise _format(GatedRepoError, message, response) from e
huggingface_hub.errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-688700e3-3e83c47a214b75d70899841c;c4d0dc62-1f22-4292-9943-91d3bbf8c0d4)

Cannot access gated repo for url https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes.
Access to model naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-07-28 04:47:32,626 - ERROR - Run HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9 failed: 401 Client Error. (Request ID: Root=1-688700e3-3e83c47a214b75d70899841c;c4d0dc62-1f22-4292-9943-91d3bbf8c0d4)

Cannot access gated repo for url https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes.
Access to model naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-07-28 04:47:32,626 - INFO - [Process 1811658] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10 assigned to cuda:0
2025-07-28 04:47:32,627 - INFO - [Process 1811658] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10 - using custom limit: 20
2025-07-28 04:47:33,882 - INFO - WandB run initialized: HyperCLOVAX-SEED-Text-Instruct-0.5B_20250728_044732 (ID: f06132cd)
2025-07-28 04:47:34,088 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Test mode (limit=2), setting num_fewshot=0
2025-07-28 04:47:34,088 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 1/10: kmmlu
2025-07-28 04:47:34,088 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kmmlu' will use num_fewshot=0
2025-07-28 04:47:34,088 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 04:47:34,088 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:48:46,811 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 04:48:46,811 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 04:48:46,812 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 04:48:46,812 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 04:48:46,812 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 04:48:46,812 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 04:48:46,812 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 04:48:46,812 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 04:48:46,812 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 04:48:46,812 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 04:48:46,812 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 04:48:46,812 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 04:48:46,813 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 04:48:46,814 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 04:48:46,815 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 04:49:12,508 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 04:49:12,508 - INFO - 
============================================================
2025-07-28 04:49:12,509 - INFO - Task 'kmmlu' Results:
2025-07-28 04:49:12,510 - INFO - ============================================================
2025-07-28 04:49:12,511 - INFO -   kmmlu:
2025-07-28 04:49:12,511 - INFO -     - accuracy: 0.3400
2025-07-28 04:49:12,512 - INFO -   kmmlu_applied_science:
2025-07-28 04:49:12,512 - INFO -     - accuracy: 0.3167
2025-07-28 04:49:12,513 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 04:49:12,513 - INFO -     - accuracy: 0.2500
2025-07-28 04:49:12,513 - INFO -   kmmlu_electronics_engineering:
2025-07-28 04:49:12,513 - INFO -     - accuracy: 0.4000
2025-07-28 04:49:12,513 - INFO -   kmmlu_energy_management:
2025-07-28 04:49:12,513 - INFO -     - accuracy: 0.1500
2025-07-28 04:49:12,513 - INFO -   kmmlu_environmental_science:
2025-07-28 04:49:12,514 - INFO -     - accuracy: 0.2500
2025-07-28 04:49:12,514 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 04:49:12,514 - INFO -     - accuracy: 0.3000
2025-07-28 04:49:12,514 - INFO -   kmmlu_geomatics:
2025-07-28 04:49:12,514 - INFO -     - accuracy: 0.4500
2025-07-28 04:49:12,514 - INFO -   kmmlu_industrial_engineer:
2025-07-28 04:49:12,514 - INFO -     - accuracy: 0.4000
2025-07-28 04:49:12,514 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 04:49:12,514 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,515 - INFO -   kmmlu_maritime_engineering:
2025-07-28 04:49:12,515 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,515 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 04:49:12,515 - INFO -     - accuracy: 0.3000
2025-07-28 04:49:12,515 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 04:49:12,515 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,515 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 04:49:12,515 - INFO -     - accuracy: 0.2500
2025-07-28 04:49:12,516 - INFO -   kmmlu_humss:
2025-07-28 04:49:12,516 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,516 - INFO -   kmmlu_accounting:
2025-07-28 04:49:12,516 - INFO -     - accuracy: 0.5000
2025-07-28 04:49:12,516 - INFO -   kmmlu_criminal_law:
2025-07-28 04:49:12,516 - INFO -     - accuracy: 0.4000
2025-07-28 04:49:12,516 - INFO -   kmmlu_economics:
2025-07-28 04:49:12,516 - INFO -     - accuracy: 0.4000
2025-07-28 04:49:12,516 - INFO -   kmmlu_education:
2025-07-28 04:49:12,516 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,517 - INFO -   kmmlu_korean_history:
2025-07-28 04:49:12,517 - INFO -     - accuracy: 0.2500
2025-07-28 04:49:12,517 - INFO -   kmmlu_law:
2025-07-28 04:49:12,517 - INFO -     - accuracy: 0.2000
2025-07-28 04:49:12,517 - INFO -   kmmlu_management:
2025-07-28 04:49:12,517 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,517 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 04:49:12,517 - INFO -     - accuracy: 0.4000
2025-07-28 04:49:12,518 - INFO -   kmmlu_psychology:
2025-07-28 04:49:12,518 - INFO -     - accuracy: 0.3000
2025-07-28 04:49:12,518 - INFO -   kmmlu_social_welfare:
2025-07-28 04:49:12,518 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,518 - INFO -   kmmlu_taxation:
2025-07-28 04:49:12,518 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,518 - INFO -   kmmlu_other:
2025-07-28 04:49:12,518 - INFO -     - accuracy: 0.3409
2025-07-28 04:49:12,518 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 04:49:12,519 - INFO -     - accuracy: 0.1000
2025-07-28 04:49:12,519 - INFO -   kmmlu_construction:
2025-07-28 04:49:12,519 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,519 - INFO -   kmmlu_fashion:
2025-07-28 04:49:12,519 - INFO -     - accuracy: 0.2500
2025-07-28 04:49:12,519 - INFO -   kmmlu_food_processing:
2025-07-28 04:49:12,519 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,519 - INFO -   kmmlu_health:
2025-07-28 04:49:12,519 - INFO -     - accuracy: 0.5000
2025-07-28 04:49:12,519 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 04:49:12,520 - INFO -     - accuracy: 0.6000
2025-07-28 04:49:12,520 - INFO -   kmmlu_marketing:
2025-07-28 04:49:12,520 - INFO -     - accuracy: 0.4500
2025-07-28 04:49:12,520 - INFO -   kmmlu_patent:
2025-07-28 04:49:12,520 - INFO -     - accuracy: 0.2500
2025-07-28 04:49:12,520 - INFO -   kmmlu_public_safety:
2025-07-28 04:49:12,520 - INFO -     - accuracy: 0.2500
2025-07-28 04:49:12,520 - INFO -   kmmlu_real_estate:
2025-07-28 04:49:12,520 - INFO -     - accuracy: 0.2500
2025-07-28 04:49:12,520 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 04:49:12,521 - INFO -     - accuracy: 0.4000
2025-07-28 04:49:12,521 - INFO -   kmmlu_stem:
2025-07-28 04:49:12,521 - INFO -     - accuracy: 0.3545
2025-07-28 04:49:12,521 - INFO -   kmmlu_biology:
2025-07-28 04:49:12,521 - INFO -     - accuracy: 0.3000
2025-07-28 04:49:12,521 - INFO -   kmmlu_chemical_engineering:
2025-07-28 04:49:12,521 - INFO -     - accuracy: 0.2500
2025-07-28 04:49:12,521 - INFO -   kmmlu_chemistry:
2025-07-28 04:49:12,521 - INFO -     - accuracy: 0.2500
2025-07-28 04:49:12,522 - INFO -   kmmlu_civil_engineering:
2025-07-28 04:49:12,522 - INFO -     - accuracy: 0.3000
2025-07-28 04:49:12,522 - INFO -   kmmlu_computer_science:
2025-07-28 04:49:12,522 - INFO -     - accuracy: 0.3000
2025-07-28 04:49:12,522 - INFO -   kmmlu_ecology:
2025-07-28 04:49:12,522 - INFO -     - accuracy: 0.6000
2025-07-28 04:49:12,522 - INFO -   kmmlu_electrical_engineering:
2025-07-28 04:49:12,522 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,522 - INFO -   kmmlu_information_technology:
2025-07-28 04:49:12,523 - INFO -     - accuracy: 0.5000
2025-07-28 04:49:12,523 - INFO -   kmmlu_materials_engineering:
2025-07-28 04:49:12,523 - INFO -     - accuracy: 0.3000
2025-07-28 04:49:12,523 - INFO -   kmmlu_math:
2025-07-28 04:49:12,523 - INFO -     - accuracy: 0.3500
2025-07-28 04:49:12,523 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 04:49:12,523 - INFO -     - accuracy: 0.4000
2025-07-28 04:49:12,523 - INFO - ============================================================

2025-07-28 04:49:12,527 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 2/10: kmmlu_hard
2025-07-28 04:49:12,527 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 04:49:12,528 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 04:49:12,528 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:50:20,787 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 04:50:20,788 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 04:50:20,788 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 04:50:20,788 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 04:50:20,788 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 04:50:20,788 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 04:50:20,788 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 04:50:20,788 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 04:50:20,788 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 04:50:20,788 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 04:50:20,789 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 04:50:20,789 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 04:50:20,789 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 04:50:20,789 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 04:50:20,789 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 04:50:20,789 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 04:50:20,789 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 04:50:20,789 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 04:50:20,789 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 04:50:20,789 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 04:50:20,790 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 04:50:20,790 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 04:50:20,790 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 04:50:20,790 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 04:50:20,790 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 04:50:20,790 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 04:50:20,790 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 04:50:20,790 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 04:50:20,790 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 04:50:20,791 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 04:50:20,792 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 04:50:20,792 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 04:50:20,792 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 04:50:20,792 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 04:50:20,792 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 04:50:45,758 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 04:50:45,759 - INFO - 
============================================================
2025-07-28 04:50:45,760 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 04:50:45,761 - INFO - ============================================================
2025-07-28 04:50:45,762 - INFO -   kmmlu_hard:
2025-07-28 04:50:45,763 - INFO -     - accuracy: 0.2256
2025-07-28 04:50:45,763 - INFO -   kmmlu_hard_applied_science:
2025-07-28 04:50:45,763 - INFO -     - accuracy: 0.2417
2025-07-28 04:50:45,763 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 04:50:45,763 - INFO -     - accuracy: 0.1000
2025-07-28 04:50:45,763 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 04:50:45,763 - INFO -     - accuracy: 0.2000
2025-07-28 04:50:45,763 - INFO -   kmmlu_hard_energy_management:
2025-07-28 04:50:45,763 - INFO -     - accuracy: 0.2500
2025-07-28 04:50:45,764 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 04:50:45,764 - INFO -     - accuracy: 0.2000
2025-07-28 04:50:45,764 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 04:50:45,764 - INFO -     - accuracy: 0.3000
2025-07-28 04:50:45,764 - INFO -   kmmlu_hard_geomatics:
2025-07-28 04:50:45,764 - INFO -     - accuracy: 0.5000
2025-07-28 04:50:45,764 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 04:50:45,764 - INFO -     - accuracy: 0.0500
2025-07-28 04:50:45,764 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 04:50:45,764 - INFO -     - accuracy: 0.2500
2025-07-28 04:50:45,765 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 04:50:45,765 - INFO -     - accuracy: 0.3000
2025-07-28 04:50:45,765 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 04:50:45,765 - INFO -     - accuracy: 0.1000
2025-07-28 04:50:45,765 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 04:50:45,765 - INFO -     - accuracy: 0.3000
2025-07-28 04:50:45,765 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 04:50:45,765 - INFO -     - accuracy: 0.3500
2025-07-28 04:50:45,765 - INFO -   kmmlu_hard_humss:
2025-07-28 04:50:45,765 - INFO -     - accuracy: 0.1773
2025-07-28 04:50:45,765 - INFO -   kmmlu_hard_accounting:
2025-07-28 04:50:45,766 - INFO -     - accuracy: 0.1000
2025-07-28 04:50:45,766 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 04:50:45,766 - INFO -     - accuracy: 0.2000
2025-07-28 04:50:45,766 - INFO -   kmmlu_hard_economics:
2025-07-28 04:50:45,766 - INFO -     - accuracy: 0.1500
2025-07-28 04:50:45,766 - INFO -   kmmlu_hard_education:
2025-07-28 04:50:45,766 - INFO -     - accuracy: 0.1500
2025-07-28 04:50:45,766 - INFO -   kmmlu_hard_korean_history:
2025-07-28 04:50:45,766 - INFO -     - accuracy: 0.1000
2025-07-28 04:50:45,766 - INFO -   kmmlu_hard_law:
2025-07-28 04:50:45,767 - INFO -     - accuracy: 0.1000
2025-07-28 04:50:45,767 - INFO -   kmmlu_hard_management:
2025-07-28 04:50:45,767 - INFO -     - accuracy: 0.3000
2025-07-28 04:50:45,767 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 04:50:45,767 - INFO -     - accuracy: 0.2000
2025-07-28 04:50:45,767 - INFO -   kmmlu_hard_psychology:
2025-07-28 04:50:45,767 - INFO -     - accuracy: 0.2000
2025-07-28 04:50:45,767 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 04:50:45,767 - INFO -     - accuracy: 0.2500
2025-07-28 04:50:45,767 - INFO -   kmmlu_hard_taxation:
2025-07-28 04:50:45,767 - INFO -     - accuracy: 0.2000
2025-07-28 04:50:45,768 - INFO -   kmmlu_hard_other:
2025-07-28 04:50:45,768 - INFO -     - accuracy: 0.2545
2025-07-28 04:50:45,768 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 04:50:45,768 - INFO -     - accuracy: 0.1500
2025-07-28 04:50:45,768 - INFO -   kmmlu_hard_construction:
2025-07-28 04:50:45,768 - INFO -     - accuracy: 0.2000
2025-07-28 04:50:45,778 - INFO -   kmmlu_hard_fashion:
2025-07-28 04:50:45,779 - INFO -     - accuracy: 0.3500
2025-07-28 04:50:45,779 - INFO -   kmmlu_hard_food_processing:
2025-07-28 04:50:45,779 - INFO -     - accuracy: 0.0500
2025-07-28 04:50:45,779 - INFO -   kmmlu_hard_health:
2025-07-28 04:50:45,779 - INFO -     - accuracy: 0.0500
2025-07-28 04:50:45,779 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 04:50:45,779 - INFO -     - accuracy: 0.3500
2025-07-28 04:50:45,779 - INFO -   kmmlu_hard_marketing:
2025-07-28 04:50:45,779 - INFO -     - accuracy: 0.4500
2025-07-28 04:50:45,779 - INFO -   kmmlu_hard_patent:
2025-07-28 04:50:45,780 - INFO -     - accuracy: 0.1500
2025-07-28 04:50:45,780 - INFO -   kmmlu_hard_public_safety:
2025-07-28 04:50:45,780 - INFO -     - accuracy: 0.2500
2025-07-28 04:50:45,780 - INFO -   kmmlu_hard_real_estate:
2025-07-28 04:50:45,780 - INFO -     - accuracy: 0.4000
2025-07-28 04:50:45,780 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 04:50:45,780 - INFO -     - accuracy: 0.4000
2025-07-28 04:50:45,780 - INFO -   kmmlu_hard_stem:
2025-07-28 04:50:45,780 - INFO -     - accuracy: 0.2273
2025-07-28 04:50:45,780 - INFO -   kmmlu_hard_biology:
2025-07-28 04:50:45,780 - INFO -     - accuracy: 0.3000
2025-07-28 04:50:45,781 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 04:50:45,781 - INFO -     - accuracy: 0.0500
2025-07-28 04:50:45,781 - INFO -   kmmlu_hard_chemistry:
2025-07-28 04:50:45,781 - INFO -     - accuracy: 0.1000
2025-07-28 04:50:45,781 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 04:50:45,781 - INFO -     - accuracy: 0.2500
2025-07-28 04:50:45,781 - INFO -   kmmlu_hard_computer_science:
2025-07-28 04:50:45,781 - INFO -     - accuracy: 0.3500
2025-07-28 04:50:45,781 - INFO -   kmmlu_hard_ecology:
2025-07-28 04:50:45,781 - INFO -     - accuracy: 0.2500
2025-07-28 04:50:45,782 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 04:50:45,782 - INFO -     - accuracy: 0.4500
2025-07-28 04:50:45,782 - INFO -   kmmlu_hard_information_technology:
2025-07-28 04:50:45,782 - INFO -     - accuracy: 0.2500
2025-07-28 04:50:45,782 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 04:50:45,782 - INFO -     - accuracy: 0.0500
2025-07-28 04:50:45,782 - INFO -   kmmlu_hard_math:
2025-07-28 04:50:45,782 - INFO -     - accuracy: 0.2500
2025-07-28 04:50:45,782 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 04:50:45,782 - INFO -     - accuracy: 0.2000
2025-07-28 04:50:45,782 - INFO - ============================================================

2025-07-28 04:50:45,786 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 3/10: haerae
2025-07-28 04:50:45,786 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'haerae' will use num_fewshot=0
2025-07-28 04:50:45,787 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 04:50:45,787 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:51:01,420 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 04:51:01,422 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 04:51:01,422 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 04:51:01,422 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 04:51:01,422 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 04:51:15,139 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 04:51:15,140 - INFO - 
============================================================
2025-07-28 04:51:15,140 - INFO - Task 'haerae' Results:
2025-07-28 04:51:15,140 - INFO - ============================================================
2025-07-28 04:51:15,140 - INFO -   haerae:
2025-07-28 04:51:15,140 - INFO -     - accuracy: 0.6900
2025-07-28 04:51:15,142 - INFO -     - accuracy_norm: 0.6900
2025-07-28 04:51:15,143 - INFO -   haerae_general_knowledge:
2025-07-28 04:51:15,144 - INFO -     - accuracy: 0.7500
2025-07-28 04:51:15,144 - INFO -     - accuracy_norm: 0.7500
2025-07-28 04:51:15,144 - INFO -   haerae_history:
2025-07-28 04:51:15,144 - INFO -     - accuracy: 0.6000
2025-07-28 04:51:15,144 - INFO -     - accuracy_norm: 0.6000
2025-07-28 04:51:15,144 - INFO -   haerae_loan_word:
2025-07-28 04:51:15,144 - INFO -     - accuracy: 0.9000
2025-07-28 04:51:15,145 - INFO -     - accuracy_norm: 0.9000
2025-07-28 04:51:15,145 - INFO -   haerae_rare_word:
2025-07-28 04:51:15,145 - INFO -     - accuracy: 0.4500
2025-07-28 04:51:15,145 - INFO -     - accuracy_norm: 0.4500
2025-07-28 04:51:15,145 - INFO -   haerae_standard_nomenclature:
2025-07-28 04:51:15,145 - INFO -     - accuracy: 0.7500
2025-07-28 04:51:15,145 - INFO -     - accuracy_norm: 0.7500
2025-07-28 04:51:15,145 - INFO - ============================================================

2025-07-28 04:51:15,149 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 4/10: kobest
2025-07-28 04:51:15,149 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kobest' will use num_fewshot=0
2025-07-28 04:51:15,149 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 04:51:15,150 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:51:35,219 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 04:51:35,220 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 04:51:35,220 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 04:51:35,220 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 04:51:35,220 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 04:51:43,115 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 04:51:43,115 - INFO - 
============================================================
2025-07-28 04:51:43,115 - INFO - Task 'kobest' Results:
2025-07-28 04:51:43,116 - INFO - ============================================================
2025-07-28 04:51:43,116 - INFO -   kobest:
2025-07-28 04:51:43,116 - INFO -     - accuracy: 0.6300
2025-07-28 04:51:43,117 - INFO -     - accuracy_norm: 0.6000
2025-07-28 04:51:43,118 - INFO -     - f1: 0.5577
2025-07-28 04:51:43,120 - INFO -   kobest_boolq:
2025-07-28 04:51:43,120 - INFO -     - accuracy: 0.6000
2025-07-28 04:51:43,120 - INFO -     - f1: 0.4667
2025-07-28 04:51:43,120 - INFO -   kobest_copa:
2025-07-28 04:51:43,120 - INFO -     - accuracy: 0.8000
2025-07-28 04:51:43,120 - INFO -     - f1: 0.8000
2025-07-28 04:51:43,120 - INFO -   kobest_hellaswag:
2025-07-28 04:51:43,120 - INFO -     - accuracy: 0.4500
2025-07-28 04:51:43,120 - INFO -     - accuracy_norm: 0.6000
2025-07-28 04:51:43,121 - INFO -     - f1: 0.4520
2025-07-28 04:51:43,121 - INFO -   kobest_sentineg:
2025-07-28 04:51:43,121 - INFO -     - accuracy: 0.7500
2025-07-28 04:51:43,121 - INFO -     - f1: 0.7151
2025-07-28 04:51:43,121 - INFO -   kobest_wic:
2025-07-28 04:51:43,121 - INFO -     - accuracy: 0.5500
2025-07-28 04:51:43,121 - INFO -     - f1: 0.3548
2025-07-28 04:51:43,121 - INFO - ============================================================

2025-07-28 04:51:43,125 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 5/10: csatqa
2025-07-28 04:51:43,125 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'csatqa' detected as zero-shot task
2025-07-28 04:51:43,125 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 04:51:43,126 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:51:55,185 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 04:51:55,186 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 04:51:55,186 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 04:51:55,186 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 04:51:55,186 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 04:51:55,186 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 04:52:13,461 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 04:52:13,463 - INFO - 
============================================================
2025-07-28 04:52:13,465 - INFO - Task 'csatqa' Results:
2025-07-28 04:52:13,465 - INFO - ============================================================
2025-07-28 04:52:13,465 - INFO -   csatqa:
2025-07-28 04:52:13,465 - INFO -     - accuracy: 0.3243
2025-07-28 04:52:13,465 - INFO -     - accuracy_norm: 0.3243
2025-07-28 04:52:13,466 - INFO -   csatqa_gr:
2025-07-28 04:52:13,466 - INFO -     - accuracy: 0.2000
2025-07-28 04:52:13,466 - INFO -     - accuracy_norm: 0.2000
2025-07-28 04:52:13,466 - INFO -   csatqa_li:
2025-07-28 04:52:13,466 - INFO -     - accuracy: 0.5500
2025-07-28 04:52:13,466 - INFO -     - accuracy_norm: 0.5500
2025-07-28 04:52:13,466 - INFO -   csatqa_rch:
2025-07-28 04:52:13,466 - INFO -     - accuracy: 0.2000
2025-07-28 04:52:13,466 - INFO -     - accuracy_norm: 0.2000
2025-07-28 04:52:13,467 - INFO -   csatqa_rcs:
2025-07-28 04:52:13,467 - INFO -     - accuracy: 0.2000
2025-07-28 04:52:13,467 - INFO -     - accuracy_norm: 0.2000
2025-07-28 04:52:13,467 - INFO -   csatqa_rcss:
2025-07-28 04:52:13,467 - INFO -     - accuracy: 0.5000
2025-07-28 04:52:13,467 - INFO -     - accuracy_norm: 0.5000
2025-07-28 04:52:13,467 - INFO -   csatqa_wr:
2025-07-28 04:52:13,467 - INFO -     - accuracy: 0.2727
2025-07-28 04:52:13,467 - INFO -     - accuracy_norm: 0.2727
2025-07-28 04:52:13,468 - INFO - ============================================================

2025-07-28 04:52:13,474 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 6/10: kormedmcqa
2025-07-28 04:52:13,475 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 04:52:13,475 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 04:52:13,476 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:52:31,685 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 04:52:31,685 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 04:52:31,685 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 04:52:31,686 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 04:53:06,850 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 04:53:06,851 - INFO - 
============================================================
2025-07-28 04:53:06,851 - INFO - Task 'kormedmcqa' Results:
2025-07-28 04:53:06,851 - INFO - ============================================================
2025-07-28 04:53:06,851 - INFO -   kormedmcqa:
2025-07-28 04:53:06,851 - INFO -     - exact_match: 0.1250
2025-07-28 04:53:06,853 - INFO -   kormedmcqa_dentist:
2025-07-28 04:53:06,853 - INFO -     - exact_match: 0.2000
2025-07-28 04:53:06,855 - INFO -   kormedmcqa_doctor:
2025-07-28 04:53:06,856 - INFO -     - exact_match: 0.0500
2025-07-28 04:53:06,856 - INFO -   kormedmcqa_nurse:
2025-07-28 04:53:06,856 - INFO -     - exact_match: 0.2000
2025-07-28 04:53:06,856 - INFO -   kormedmcqa_pharm:
2025-07-28 04:53:06,856 - INFO -     - exact_match: 0.0500
2025-07-28 04:53:06,857 - INFO - ============================================================

2025-07-28 04:53:06,861 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 7/10: mmlu
2025-07-28 04:53:06,861 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'mmlu' will use num_fewshot=0
2025-07-28 04:53:06,861 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 04:53:06,862 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:55:45,445 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 04:55:45,446 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 04:55:45,446 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 04:55:45,446 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 04:55:45,446 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 04:55:45,446 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 04:55:45,446 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 04:55:45,446 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 04:55:45,446 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 04:55:45,446 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 04:55:45,447 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 04:55:45,448 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 04:55:45,449 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 04:55:45,450 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 04:55:45,451 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 04:55:45,451 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 04:56:16,273 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 04:56:16,274 - INFO - 
============================================================
2025-07-28 04:56:16,275 - INFO - Task 'mmlu' Results:
2025-07-28 04:56:16,277 - INFO - ============================================================
2025-07-28 04:56:16,277 - INFO -   mmlu:
2025-07-28 04:56:16,277 - INFO -     - accuracy: 0.4553
2025-07-28 04:56:16,277 - INFO -   mmlu_humanities:
2025-07-28 04:56:16,278 - INFO -     - accuracy: 0.4538
2025-07-28 04:56:16,278 - INFO -   mmlu_formal_logic:
2025-07-28 04:56:16,278 - INFO -     - accuracy: 0.2000
2025-07-28 04:56:16,278 - INFO -   mmlu_high_school_european_history:
2025-07-28 04:56:16,278 - INFO -     - accuracy: 0.6500
2025-07-28 04:56:16,278 - INFO -   mmlu_high_school_us_history:
2025-07-28 04:56:16,278 - INFO -     - accuracy: 0.5000
2025-07-28 04:56:16,278 - INFO -   mmlu_high_school_world_history:
2025-07-28 04:56:16,278 - INFO -     - accuracy: 0.5500
2025-07-28 04:56:16,279 - INFO -   mmlu_international_law:
2025-07-28 04:56:16,279 - INFO -     - accuracy: 0.6500
2025-07-28 04:56:16,279 - INFO -   mmlu_jurisprudence:
2025-07-28 04:56:16,279 - INFO -     - accuracy: 0.5500
2025-07-28 04:56:16,279 - INFO -   mmlu_logical_fallacies:
2025-07-28 04:56:16,279 - INFO -     - accuracy: 0.5000
2025-07-28 04:56:16,279 - INFO -   mmlu_moral_disputes:
2025-07-28 04:56:16,279 - INFO -     - accuracy: 0.3500
2025-07-28 04:56:16,279 - INFO -   mmlu_moral_scenarios:
2025-07-28 04:56:16,279 - INFO -     - accuracy: 0.2500
2025-07-28 04:56:16,280 - INFO -   mmlu_philosophy:
2025-07-28 04:56:16,280 - INFO -     - accuracy: 0.5000
2025-07-28 04:56:16,280 - INFO -   mmlu_prehistory:
2025-07-28 04:56:16,280 - INFO -     - accuracy: 0.3500
2025-07-28 04:56:16,280 - INFO -   mmlu_professional_law:
2025-07-28 04:56:16,280 - INFO -     - accuracy: 0.3500
2025-07-28 04:56:16,280 - INFO -   mmlu_world_religions:
2025-07-28 04:56:16,280 - INFO -     - accuracy: 0.5000
2025-07-28 04:56:16,280 - INFO -   mmlu_other:
2025-07-28 04:56:16,280 - INFO -     - accuracy: 0.5192
2025-07-28 04:56:16,280 - INFO -   mmlu_business_ethics:
2025-07-28 04:56:16,281 - INFO -     - accuracy: 0.5000
2025-07-28 04:56:16,281 - INFO -   mmlu_clinical_knowledge:
2025-07-28 04:56:16,281 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,281 - INFO -   mmlu_college_medicine:
2025-07-28 04:56:16,281 - INFO -     - accuracy: 0.6000
2025-07-28 04:56:16,281 - INFO -   mmlu_global_facts:
2025-07-28 04:56:16,281 - INFO -     - accuracy: 0.5500
2025-07-28 04:56:16,281 - INFO -   mmlu_human_aging:
2025-07-28 04:56:16,281 - INFO -     - accuracy: 0.6000
2025-07-28 04:56:16,281 - INFO -   mmlu_management:
2025-07-28 04:56:16,282 - INFO -     - accuracy: 0.5000
2025-07-28 04:56:16,282 - INFO -   mmlu_marketing:
2025-07-28 04:56:16,282 - INFO -     - accuracy: 0.5500
2025-07-28 04:56:16,282 - INFO -   mmlu_medical_genetics:
2025-07-28 04:56:16,282 - INFO -     - accuracy: 0.4500
2025-07-28 04:56:16,282 - INFO -   mmlu_miscellaneous:
2025-07-28 04:56:16,282 - INFO -     - accuracy: 0.6000
2025-07-28 04:56:16,282 - INFO -   mmlu_nutrition:
2025-07-28 04:56:16,282 - INFO -     - accuracy: 0.7500
2025-07-28 04:56:16,282 - INFO -   mmlu_professional_accounting:
2025-07-28 04:56:16,282 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,283 - INFO -   mmlu_professional_medicine:
2025-07-28 04:56:16,283 - INFO -     - accuracy: 0.4500
2025-07-28 04:56:16,283 - INFO -   mmlu_virology:
2025-07-28 04:56:16,283 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,283 - INFO -   mmlu_social_sciences:
2025-07-28 04:56:16,283 - INFO -     - accuracy: 0.5083
2025-07-28 04:56:16,283 - INFO -   mmlu_econometrics:
2025-07-28 04:56:16,283 - INFO -     - accuracy: 0.1500
2025-07-28 04:56:16,283 - INFO -   mmlu_high_school_geography:
2025-07-28 04:56:16,283 - INFO -     - accuracy: 0.5000
2025-07-28 04:56:16,284 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 04:56:16,284 - INFO -     - accuracy: 0.7000
2025-07-28 04:56:16,284 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 04:56:16,284 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,284 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 04:56:16,284 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,284 - INFO -   mmlu_high_school_psychology:
2025-07-28 04:56:16,284 - INFO -     - accuracy: 0.7000
2025-07-28 04:56:16,284 - INFO -   mmlu_human_sexuality:
2025-07-28 04:56:16,284 - INFO -     - accuracy: 0.6500
2025-07-28 04:56:16,284 - INFO -   mmlu_professional_psychology:
2025-07-28 04:56:16,285 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,285 - INFO -   mmlu_public_relations:
2025-07-28 04:56:16,285 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,285 - INFO -   mmlu_security_studies:
2025-07-28 04:56:16,285 - INFO -     - accuracy: 0.7000
2025-07-28 04:56:16,285 - INFO -   mmlu_sociology:
2025-07-28 04:56:16,285 - INFO -     - accuracy: 0.3500
2025-07-28 04:56:16,285 - INFO -   mmlu_us_foreign_policy:
2025-07-28 04:56:16,285 - INFO -     - accuracy: 0.7500
2025-07-28 04:56:16,285 - INFO -   mmlu_stem:
2025-07-28 04:56:16,286 - INFO -     - accuracy: 0.3789
2025-07-28 04:56:16,286 - INFO -   mmlu_abstract_algebra:
2025-07-28 04:56:16,286 - INFO -     - accuracy: 0.3500
2025-07-28 04:56:16,286 - INFO -   mmlu_anatomy:
2025-07-28 04:56:16,286 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,286 - INFO -   mmlu_astronomy:
2025-07-28 04:56:16,286 - INFO -     - accuracy: 0.4500
2025-07-28 04:56:16,286 - INFO -   mmlu_college_biology:
2025-07-28 04:56:16,286 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,286 - INFO -   mmlu_college_chemistry:
2025-07-28 04:56:16,286 - INFO -     - accuracy: 0.3500
2025-07-28 04:56:16,287 - INFO -   mmlu_college_computer_science:
2025-07-28 04:56:16,287 - INFO -     - accuracy: 0.3500
2025-07-28 04:56:16,287 - INFO -   mmlu_college_mathematics:
2025-07-28 04:56:16,287 - INFO -     - accuracy: 0.3000
2025-07-28 04:56:16,287 - INFO -   mmlu_college_physics:
2025-07-28 04:56:16,287 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,287 - INFO -   mmlu_computer_security:
2025-07-28 04:56:16,287 - INFO -     - accuracy: 0.5000
2025-07-28 04:56:16,287 - INFO -   mmlu_conceptual_physics:
2025-07-28 04:56:16,287 - INFO -     - accuracy: 0.5000
2025-07-28 04:56:16,288 - INFO -   mmlu_electrical_engineering:
2025-07-28 04:56:16,288 - INFO -     - accuracy: 0.2500
2025-07-28 04:56:16,288 - INFO -   mmlu_elementary_mathematics:
2025-07-28 04:56:16,288 - INFO -     - accuracy: 0.2500
2025-07-28 04:56:16,288 - INFO -   mmlu_high_school_biology:
2025-07-28 04:56:16,288 - INFO -     - accuracy: 0.4500
2025-07-28 04:56:16,288 - INFO -   mmlu_high_school_chemistry:
2025-07-28 04:56:16,288 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:16,288 - INFO -   mmlu_high_school_computer_science:
2025-07-28 04:56:16,288 - INFO -     - accuracy: 0.6000
2025-07-28 04:56:16,288 - INFO -   mmlu_high_school_mathematics:
2025-07-28 04:56:16,289 - INFO -     - accuracy: 0.2500
2025-07-28 04:56:16,289 - INFO -   mmlu_high_school_physics:
2025-07-28 04:56:16,289 - INFO -     - accuracy: 0.4500
2025-07-28 04:56:16,289 - INFO -   mmlu_high_school_statistics:
2025-07-28 04:56:16,289 - INFO -     - accuracy: 0.2000
2025-07-28 04:56:16,289 - INFO -   mmlu_machine_learning:
2025-07-28 04:56:16,289 - INFO -     - accuracy: 0.3500
2025-07-28 04:56:16,289 - INFO - ============================================================

2025-07-28 04:56:16,293 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 8/10: arc_challenge
2025-07-28 04:56:16,294 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 04:56:16,294 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 04:56:16,294 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:56:23,153 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 04:56:27,868 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 04:56:27,869 - INFO - 
============================================================
2025-07-28 04:56:27,869 - INFO - Task 'arc_challenge' Results:
2025-07-28 04:56:27,869 - INFO - ============================================================
2025-07-28 04:56:27,869 - INFO -   arc_challenge:
2025-07-28 04:56:27,869 - INFO -     - accuracy: 0.4000
2025-07-28 04:56:27,869 - INFO -     - accuracy_norm: 0.2500
2025-07-28 04:56:27,870 - INFO - ============================================================

2025-07-28 04:56:27,874 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 9/10: arc_easy
2025-07-28 04:56:27,876 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'arc_easy' will use num_fewshot=0
2025-07-28 04:56:27,876 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 04:56:27,877 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:56:34,546 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 04:56:39,137 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 04:56:39,138 - INFO - 
============================================================
2025-07-28 04:56:39,138 - INFO - Task 'arc_easy' Results:
2025-07-28 04:56:39,138 - INFO - ============================================================
2025-07-28 04:56:39,138 - INFO -   arc_easy:
2025-07-28 04:56:39,138 - INFO -     - accuracy: 0.6500
2025-07-28 04:56:39,138 - INFO -     - accuracy_norm: 0.5500
2025-07-28 04:56:39,139 - INFO - ============================================================

2025-07-28 04:56:39,143 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 10/10: hellaswag
2025-07-28 04:56:39,145 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'hellaswag' will use num_fewshot=0
2025-07-28 04:56:39,145 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 04:56:39,146 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:56:52,223 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 04:56:57,049 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 04:56:57,051 - INFO - 
============================================================
2025-07-28 04:56:57,052 - INFO - Task 'hellaswag' Results:
2025-07-28 04:56:57,053 - INFO - ============================================================
2025-07-28 04:56:57,053 - INFO -   hellaswag:
2025-07-28 04:56:57,054 - INFO -     - accuracy: 0.3500
2025-07-28 04:56:57,054 - INFO -     - accuracy_norm: 0.3000
2025-07-28 04:56:57,054 - INFO - ============================================================

2025-07-28 04:56:57,057 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 04:56:57,059 - INFO - [Process 1811658] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/HyperCLOVAX-SEED-Text-Instruct-0.5B/HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10.json
2025-07-28 04:56:57,327 - INFO - Results uploaded to WandB as artifact
2025-07-28 04:56:57,335 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 04:56:57,337 - INFO - [Process 1811658] Successfully completed HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10
2025-07-28 04:57:00,190 - INFO - Run HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10 finished successfully
2025-07-28 04:57:00,191 - INFO - [Process 1811658] kanana-1.5-2.1b-instruct-2505_harness_11 assigned to cuda:0
2025-07-28 04:57:00,191 - INFO - [Process 1811658] kanana-1.5-2.1b-instruct-2505_harness_11 - using custom limit: 20
2025-07-28 04:57:01,450 - INFO - WandB run initialized: kanana-1.5-2.1b-instruct-2505_20250728_045700 (ID: cf7b9a03)
2025-07-28 04:57:01,656 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Test mode (limit=2), setting num_fewshot=0
2025-07-28 04:57:01,656 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 1/10: kmmlu
2025-07-28 04:57:01,656 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kmmlu' will use num_fewshot=0
2025-07-28 04:57:01,656 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 04:57:01,656 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 04:57:01,657 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:58:13,790 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 04:58:13,790 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 04:58:13,790 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 04:58:13,790 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 04:58:13,790 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 04:58:13,790 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 04:58:13,791 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 04:58:13,792 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 04:58:13,793 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 04:58:13,794 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 04:58:13,794 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 04:58:13,794 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 04:58:13,794 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 04:58:45,992 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 04:58:45,993 - INFO - 
============================================================
2025-07-28 04:58:45,994 - INFO - Task 'kmmlu' Results:
2025-07-28 04:58:45,996 - INFO - ============================================================
2025-07-28 04:58:45,996 - INFO -   kmmlu:
2025-07-28 04:58:45,996 - INFO -     - accuracy: 0.3333
2025-07-28 04:58:45,997 - INFO -   kmmlu_applied_science:
2025-07-28 04:58:45,997 - INFO -     - accuracy: 0.2250
2025-07-28 04:58:45,997 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 04:58:45,997 - INFO -     - accuracy: 0.1500
2025-07-28 04:58:45,997 - INFO -   kmmlu_electronics_engineering:
2025-07-28 04:58:45,997 - INFO -     - accuracy: 0.1500
2025-07-28 04:58:45,997 - INFO -   kmmlu_energy_management:
2025-07-28 04:58:45,998 - INFO -     - accuracy: 0.1000
2025-07-28 04:58:45,998 - INFO -   kmmlu_environmental_science:
2025-07-28 04:58:45,998 - INFO -     - accuracy: 0.1500
2025-07-28 04:58:45,998 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 04:58:45,999 - INFO -     - accuracy: 0.3500
2025-07-28 04:58:45,999 - INFO -   kmmlu_geomatics:
2025-07-28 04:58:45,999 - INFO -     - accuracy: 0.2000
2025-07-28 04:58:45,999 - INFO -   kmmlu_industrial_engineer:
2025-07-28 04:58:45,999 - INFO -     - accuracy: 0.3500
2025-07-28 04:58:45,999 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 04:58:45,999 - INFO -     - accuracy: 0.3000
2025-07-28 04:58:46,000 - INFO -   kmmlu_maritime_engineering:
2025-07-28 04:58:46,000 - INFO -     - accuracy: 0.2500
2025-07-28 04:58:46,000 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 04:58:46,000 - INFO -     - accuracy: 0.2000
2025-07-28 04:58:46,000 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 04:58:46,000 - INFO -     - accuracy: 0.3500
2025-07-28 04:58:46,000 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 04:58:46,000 - INFO -     - accuracy: 0.1500
2025-07-28 04:58:46,001 - INFO -   kmmlu_humss:
2025-07-28 04:58:46,001 - INFO -     - accuracy: 0.4182
2025-07-28 04:58:46,001 - INFO -   kmmlu_accounting:
2025-07-28 04:58:46,001 - INFO -     - accuracy: 0.5500
2025-07-28 04:58:46,001 - INFO -   kmmlu_criminal_law:
2025-07-28 04:58:46,001 - INFO -     - accuracy: 0.4000
2025-07-28 04:58:46,001 - INFO -   kmmlu_economics:
2025-07-28 04:58:46,001 - INFO -     - accuracy: 0.5500
2025-07-28 04:58:46,001 - INFO -   kmmlu_education:
2025-07-28 04:58:46,002 - INFO -     - accuracy: 0.6500
2025-07-28 04:58:46,002 - INFO -   kmmlu_korean_history:
2025-07-28 04:58:46,002 - INFO -     - accuracy: 0.3000
2025-07-28 04:58:46,002 - INFO -   kmmlu_law:
2025-07-28 04:58:46,002 - INFO -     - accuracy: 0.2000
2025-07-28 04:58:46,002 - INFO -   kmmlu_management:
2025-07-28 04:58:46,002 - INFO -     - accuracy: 0.2000
2025-07-28 04:58:46,002 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 04:58:46,002 - INFO -     - accuracy: 0.6500
2025-07-28 04:58:46,003 - INFO -   kmmlu_psychology:
2025-07-28 04:58:46,003 - INFO -     - accuracy: 0.3500
2025-07-28 04:58:46,003 - INFO -   kmmlu_social_welfare:
2025-07-28 04:58:46,003 - INFO -     - accuracy: 0.3000
2025-07-28 04:58:46,003 - INFO -   kmmlu_taxation:
2025-07-28 04:58:46,003 - INFO -     - accuracy: 0.4500
2025-07-28 04:58:46,003 - INFO -   kmmlu_other:
2025-07-28 04:58:46,003 - INFO -     - accuracy: 0.3455
2025-07-28 04:58:46,004 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 04:58:46,004 - INFO -     - accuracy: 0.2500
2025-07-28 04:58:46,004 - INFO -   kmmlu_construction:
2025-07-28 04:58:46,004 - INFO -     - accuracy: 0.2500
2025-07-28 04:58:46,004 - INFO -   kmmlu_fashion:
2025-07-28 04:58:46,004 - INFO -     - accuracy: 0.4500
2025-07-28 04:58:46,004 - INFO -   kmmlu_food_processing:
2025-07-28 04:58:46,004 - INFO -     - accuracy: 0.4000
2025-07-28 04:58:46,004 - INFO -   kmmlu_health:
2025-07-28 04:58:46,004 - INFO -     - accuracy: 0.4500
2025-07-28 04:58:46,005 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 04:58:46,005 - INFO -     - accuracy: 0.4000
2025-07-28 04:58:46,005 - INFO -   kmmlu_marketing:
2025-07-28 04:58:46,005 - INFO -     - accuracy: 0.5000
2025-07-28 04:58:46,005 - INFO -   kmmlu_patent:
2025-07-28 04:58:46,005 - INFO -     - accuracy: 0.1500
2025-07-28 04:58:46,005 - INFO -   kmmlu_public_safety:
2025-07-28 04:58:46,005 - INFO -     - accuracy: 0.3000
2025-07-28 04:58:46,005 - INFO -   kmmlu_real_estate:
2025-07-28 04:58:46,006 - INFO -     - accuracy: 0.3000
2025-07-28 04:58:46,006 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 04:58:46,006 - INFO -     - accuracy: 0.3500
2025-07-28 04:58:46,006 - INFO -   kmmlu_stem:
2025-07-28 04:58:46,006 - INFO -     - accuracy: 0.3545
2025-07-28 04:58:46,006 - INFO -   kmmlu_biology:
2025-07-28 04:58:46,006 - INFO -     - accuracy: 0.3000
2025-07-28 04:58:46,006 - INFO -   kmmlu_chemical_engineering:
2025-07-28 04:58:46,006 - INFO -     - accuracy: 0.2000
2025-07-28 04:58:46,007 - INFO -   kmmlu_chemistry:
2025-07-28 04:58:46,007 - INFO -     - accuracy: 0.3000
2025-07-28 04:58:46,007 - INFO -   kmmlu_civil_engineering:
2025-07-28 04:58:46,007 - INFO -     - accuracy: 0.2500
2025-07-28 04:58:46,007 - INFO -   kmmlu_computer_science:
2025-07-28 04:58:46,007 - INFO -     - accuracy: 0.7500
2025-07-28 04:58:46,007 - INFO -   kmmlu_ecology:
2025-07-28 04:58:46,007 - INFO -     - accuracy: 0.2500
2025-07-28 04:58:46,008 - INFO -   kmmlu_electrical_engineering:
2025-07-28 04:58:46,008 - INFO -     - accuracy: 0.4500
2025-07-28 04:58:46,008 - INFO -   kmmlu_information_technology:
2025-07-28 04:58:46,008 - INFO -     - accuracy: 0.5500
2025-07-28 04:58:46,008 - INFO -   kmmlu_materials_engineering:
2025-07-28 04:58:46,008 - INFO -     - accuracy: 0.2500
2025-07-28 04:58:46,008 - INFO -   kmmlu_math:
2025-07-28 04:58:46,008 - INFO -     - accuracy: 0.3000
2025-07-28 04:58:46,008 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 04:58:46,008 - INFO -     - accuracy: 0.3000
2025-07-28 04:58:46,009 - INFO - ============================================================

2025-07-28 04:58:46,021 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 2/10: kmmlu_hard
2025-07-28 04:58:46,022 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 04:58:46,022 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 04:58:46,022 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 04:58:46,022 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 04:59:58,750 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 04:59:58,751 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 04:59:58,751 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 04:59:58,751 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 04:59:58,751 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 04:59:58,751 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 04:59:58,751 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 04:59:58,751 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 04:59:58,751 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 04:59:58,751 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 04:59:58,752 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 04:59:58,753 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 04:59:58,754 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 05:00:31,326 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 05:00:31,328 - INFO - 
============================================================
2025-07-28 05:00:31,329 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 05:00:31,330 - INFO - ============================================================
2025-07-28 05:00:31,331 - INFO -   kmmlu_hard:
2025-07-28 05:00:31,331 - INFO -     - accuracy: 0.2278
2025-07-28 05:00:31,331 - INFO -   kmmlu_hard_applied_science:
2025-07-28 05:00:31,331 - INFO -     - accuracy: 0.2417
2025-07-28 05:00:31,332 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 05:00:31,332 - INFO -     - accuracy: 0.1500
2025-07-28 05:00:31,332 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 05:00:31,332 - INFO -     - accuracy: 0.4500
2025-07-28 05:00:31,332 - INFO -   kmmlu_hard_energy_management:
2025-07-28 05:00:31,332 - INFO -     - accuracy: 0.2000
2025-07-28 05:00:31,332 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 05:00:31,332 - INFO -     - accuracy: 0.2500
2025-07-28 05:00:31,333 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 05:00:31,333 - INFO -     - accuracy: 0.0000
2025-07-28 05:00:31,333 - INFO -   kmmlu_hard_geomatics:
2025-07-28 05:00:31,333 - INFO -     - accuracy: 0.2500
2025-07-28 05:00:31,333 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 05:00:31,333 - INFO -     - accuracy: 0.2000
2025-07-28 05:00:31,333 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 05:00:31,333 - INFO -     - accuracy: 0.2500
2025-07-28 05:00:31,333 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 05:00:31,333 - INFO -     - accuracy: 0.1500
2025-07-28 05:00:31,334 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 05:00:31,334 - INFO -     - accuracy: 0.3000
2025-07-28 05:00:31,334 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 05:00:31,334 - INFO -     - accuracy: 0.3000
2025-07-28 05:00:31,334 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 05:00:31,334 - INFO -     - accuracy: 0.4000
2025-07-28 05:00:31,334 - INFO -   kmmlu_hard_humss:
2025-07-28 05:00:31,334 - INFO -     - accuracy: 0.2545
2025-07-28 05:00:31,334 - INFO -   kmmlu_hard_accounting:
2025-07-28 05:00:31,335 - INFO -     - accuracy: 0.2500
2025-07-28 05:00:31,335 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 05:00:31,335 - INFO -     - accuracy: 0.4000
2025-07-28 05:00:31,335 - INFO -   kmmlu_hard_economics:
2025-07-28 05:00:31,335 - INFO -     - accuracy: 0.1500
2025-07-28 05:00:31,335 - INFO -   kmmlu_hard_education:
2025-07-28 05:00:31,335 - INFO -     - accuracy: 0.2500
2025-07-28 05:00:31,335 - INFO -   kmmlu_hard_korean_history:
2025-07-28 05:00:31,335 - INFO -     - accuracy: 0.2000
2025-07-28 05:00:31,336 - INFO -   kmmlu_hard_law:
2025-07-28 05:00:31,336 - INFO -     - accuracy: 0.2500
2025-07-28 05:00:31,336 - INFO -   kmmlu_hard_management:
2025-07-28 05:00:31,336 - INFO -     - accuracy: 0.3000
2025-07-28 05:00:31,336 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 05:00:31,336 - INFO -     - accuracy: 0.6000
2025-07-28 05:00:31,336 - INFO -   kmmlu_hard_psychology:
2025-07-28 05:00:31,336 - INFO -     - accuracy: 0.1000
2025-07-28 05:00:31,336 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 05:00:31,337 - INFO -     - accuracy: 0.2000
2025-07-28 05:00:31,337 - INFO -   kmmlu_hard_taxation:
2025-07-28 05:00:31,337 - INFO -     - accuracy: 0.1000
2025-07-28 05:00:31,337 - INFO -   kmmlu_hard_other:
2025-07-28 05:00:31,337 - INFO -     - accuracy: 0.1909
2025-07-28 05:00:31,337 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 05:00:31,337 - INFO -     - accuracy: 0.1000
2025-07-28 05:00:31,337 - INFO -   kmmlu_hard_construction:
2025-07-28 05:00:31,337 - INFO -     - accuracy: 0.2500
2025-07-28 05:00:31,338 - INFO -   kmmlu_hard_fashion:
2025-07-28 05:00:31,338 - INFO -     - accuracy: 0.2500
2025-07-28 05:00:31,338 - INFO -   kmmlu_hard_food_processing:
2025-07-28 05:00:31,338 - INFO -     - accuracy: 0.1000
2025-07-28 05:00:31,338 - INFO -   kmmlu_hard_health:
2025-07-28 05:00:31,338 - INFO -     - accuracy: 0.0500
2025-07-28 05:00:31,338 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 05:00:31,338 - INFO -     - accuracy: 0.3500
2025-07-28 05:00:31,338 - INFO -   kmmlu_hard_marketing:
2025-07-28 05:00:31,339 - INFO -     - accuracy: 0.1500
2025-07-28 05:00:31,339 - INFO -   kmmlu_hard_patent:
2025-07-28 05:00:31,339 - INFO -     - accuracy: 0.0500
2025-07-28 05:00:31,339 - INFO -   kmmlu_hard_public_safety:
2025-07-28 05:00:31,339 - INFO -     - accuracy: 0.0500
2025-07-28 05:00:31,339 - INFO -   kmmlu_hard_real_estate:
2025-07-28 05:00:31,339 - INFO -     - accuracy: 0.4500
2025-07-28 05:00:31,339 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 05:00:31,339 - INFO -     - accuracy: 0.3000
2025-07-28 05:00:31,339 - INFO -   kmmlu_hard_stem:
2025-07-28 05:00:31,340 - INFO -     - accuracy: 0.2227
2025-07-28 05:00:31,340 - INFO -   kmmlu_hard_biology:
2025-07-28 05:00:31,340 - INFO -     - accuracy: 0.2000
2025-07-28 05:00:31,340 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 05:00:31,340 - INFO -     - accuracy: 0.2000
2025-07-28 05:00:31,340 - INFO -   kmmlu_hard_chemistry:
2025-07-28 05:00:31,340 - INFO -     - accuracy: 0.3000
2025-07-28 05:00:31,340 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 05:00:31,340 - INFO -     - accuracy: 0.1500
2025-07-28 05:00:31,341 - INFO -   kmmlu_hard_computer_science:
2025-07-28 05:00:31,341 - INFO -     - accuracy: 0.3500
2025-07-28 05:00:31,341 - INFO -   kmmlu_hard_ecology:
2025-07-28 05:00:31,341 - INFO -     - accuracy: 0.2000
2025-07-28 05:00:31,341 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 05:00:31,341 - INFO -     - accuracy: 0.2000
2025-07-28 05:00:31,341 - INFO -   kmmlu_hard_information_technology:
2025-07-28 05:00:31,341 - INFO -     - accuracy: 0.3500
2025-07-28 05:00:31,341 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 05:00:31,342 - INFO -     - accuracy: 0.1000
2025-07-28 05:00:31,342 - INFO -   kmmlu_hard_math:
2025-07-28 05:00:31,342 - INFO -     - accuracy: 0.1500
2025-07-28 05:00:31,342 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 05:00:31,342 - INFO -     - accuracy: 0.2500
2025-07-28 05:00:31,342 - INFO - ============================================================

2025-07-28 05:00:31,354 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 3/10: haerae
2025-07-28 05:00:31,354 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'haerae' will use num_fewshot=0
2025-07-28 05:00:31,355 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 05:00:31,355 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 05:00:31,356 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:00:47,647 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 05:00:47,647 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 05:00:47,647 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 05:00:47,647 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 05:00:47,647 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 05:01:05,137 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 05:01:05,139 - INFO - 
============================================================
2025-07-28 05:01:05,140 - INFO - Task 'haerae' Results:
2025-07-28 05:01:05,142 - INFO - ============================================================
2025-07-28 05:01:05,142 - INFO -   haerae:
2025-07-28 05:01:05,142 - INFO -     - accuracy: 0.8300
2025-07-28 05:01:05,142 - INFO -     - accuracy_norm: 0.8300
2025-07-28 05:01:05,143 - INFO -   haerae_general_knowledge:
2025-07-28 05:01:05,143 - INFO -     - accuracy: 0.8000
2025-07-28 05:01:05,143 - INFO -     - accuracy_norm: 0.8000
2025-07-28 05:01:05,143 - INFO -   haerae_history:
2025-07-28 05:01:05,143 - INFO -     - accuracy: 0.9000
2025-07-28 05:01:05,143 - INFO -     - accuracy_norm: 0.9000
2025-07-28 05:01:05,143 - INFO -   haerae_loan_word:
2025-07-28 05:01:05,143 - INFO -     - accuracy: 0.9000
2025-07-28 05:01:05,143 - INFO -     - accuracy_norm: 0.9000
2025-07-28 05:01:05,144 - INFO -   haerae_rare_word:
2025-07-28 05:01:05,144 - INFO -     - accuracy: 0.6000
2025-07-28 05:01:05,144 - INFO -     - accuracy_norm: 0.6000
2025-07-28 05:01:05,144 - INFO -   haerae_standard_nomenclature:
2025-07-28 05:01:05,144 - INFO -     - accuracy: 0.9500
2025-07-28 05:01:05,144 - INFO -     - accuracy_norm: 0.9500
2025-07-28 05:01:05,144 - INFO - ============================================================

2025-07-28 05:01:05,156 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 4/10: kobest
2025-07-28 05:01:05,157 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kobest' will use num_fewshot=0
2025-07-28 05:01:05,157 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 05:01:05,157 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 05:01:05,157 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:01:25,262 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 05:01:25,262 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 05:01:25,262 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 05:01:25,263 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 05:01:25,263 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 05:01:35,418 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 05:01:35,419 - INFO - 
============================================================
2025-07-28 05:01:35,421 - INFO - Task 'kobest' Results:
2025-07-28 05:01:35,422 - INFO - ============================================================
2025-07-28 05:01:35,423 - INFO -   kobest:
2025-07-28 05:01:35,424 - INFO -     - accuracy: 0.6700
2025-07-28 05:01:35,424 - INFO -     - accuracy_norm: 0.7500
2025-07-28 05:01:35,424 - INFO -     - f1: 0.6136
2025-07-28 05:01:35,424 - INFO -   kobest_boolq:
2025-07-28 05:01:35,424 - INFO -     - accuracy: 0.6000
2025-07-28 05:01:35,425 - INFO -     - f1: 0.5238
2025-07-28 05:01:35,425 - INFO -   kobest_copa:
2025-07-28 05:01:35,425 - INFO -     - accuracy: 0.8500
2025-07-28 05:01:35,425 - INFO -     - f1: 0.8496
2025-07-28 05:01:35,425 - INFO -   kobest_hellaswag:
2025-07-28 05:01:35,425 - INFO -     - accuracy: 0.4000
2025-07-28 05:01:35,426 - INFO -     - accuracy_norm: 0.7500
2025-07-28 05:01:35,426 - INFO -     - f1: 0.3909
2025-07-28 05:01:35,426 - INFO -   kobest_sentineg:
2025-07-28 05:01:35,426 - INFO -     - accuracy: 0.9500
2025-07-28 05:01:35,426 - INFO -     - f1: 0.9488
2025-07-28 05:01:35,427 - INFO -   kobest_wic:
2025-07-28 05:01:35,427 - INFO -     - accuracy: 0.5500
2025-07-28 05:01:35,427 - INFO -     - f1: 0.3548
2025-07-28 05:01:35,427 - INFO - ============================================================

2025-07-28 05:01:35,438 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 5/10: csatqa
2025-07-28 05:01:35,440 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'csatqa' detected as zero-shot task
2025-07-28 05:01:35,440 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 05:01:35,440 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 05:01:35,440 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:01:48,205 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 05:01:48,205 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 05:01:48,205 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 05:01:48,205 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 05:01:48,205 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 05:01:48,206 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 05:02:25,091 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 05:02:25,095 - INFO - 
============================================================
2025-07-28 05:02:25,096 - INFO - Task 'csatqa' Results:
2025-07-28 05:02:25,096 - INFO - ============================================================
2025-07-28 05:02:25,097 - INFO -   csatqa:
2025-07-28 05:02:25,097 - INFO -     - accuracy: 0.3423
2025-07-28 05:02:25,097 - INFO -     - accuracy_norm: 0.3423
2025-07-28 05:02:25,097 - INFO -   csatqa_gr:
2025-07-28 05:02:25,097 - INFO -     - accuracy: 0.1000
2025-07-28 05:02:25,097 - INFO -     - accuracy_norm: 0.1000
2025-07-28 05:02:25,097 - INFO -   csatqa_li:
2025-07-28 05:02:25,097 - INFO -     - accuracy: 0.5000
2025-07-28 05:02:25,097 - INFO -     - accuracy_norm: 0.5000
2025-07-28 05:02:25,098 - INFO -   csatqa_rch:
2025-07-28 05:02:25,098 - INFO -     - accuracy: 0.3000
2025-07-28 05:02:25,098 - INFO -     - accuracy_norm: 0.3000
2025-07-28 05:02:25,098 - INFO -   csatqa_rcs:
2025-07-28 05:02:25,098 - INFO -     - accuracy: 0.4000
2025-07-28 05:02:25,098 - INFO -     - accuracy_norm: 0.4000
2025-07-28 05:02:25,098 - INFO -   csatqa_rcss:
2025-07-28 05:02:25,098 - INFO -     - accuracy: 0.4500
2025-07-28 05:02:25,098 - INFO -     - accuracy_norm: 0.4500
2025-07-28 05:02:25,098 - INFO -   csatqa_wr:
2025-07-28 05:02:25,098 - INFO -     - accuracy: 0.2727
2025-07-28 05:02:25,098 - INFO -     - accuracy_norm: 0.2727
2025-07-28 05:02:25,099 - INFO - ============================================================

2025-07-28 05:02:25,115 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 6/10: kormedmcqa
2025-07-28 05:02:25,116 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 05:02:25,116 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 05:02:25,116 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 05:02:25,117 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:02:44,816 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 05:02:44,816 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 05:02:44,817 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 05:02:44,817 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 05:03:26,480 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 05:03:26,482 - INFO - 
============================================================
2025-07-28 05:03:26,483 - INFO - Task 'kormedmcqa' Results:
2025-07-28 05:03:26,485 - INFO - ============================================================
2025-07-28 05:03:26,485 - INFO -   kormedmcqa:
2025-07-28 05:03:26,486 - INFO -     - exact_match: 0.3125
2025-07-28 05:03:26,486 - INFO -   kormedmcqa_dentist:
2025-07-28 05:03:26,486 - INFO -     - exact_match: 0.2000
2025-07-28 05:03:26,486 - INFO -   kormedmcqa_doctor:
2025-07-28 05:03:26,487 - INFO -     - exact_match: 0.2500
2025-07-28 05:03:26,487 - INFO -   kormedmcqa_nurse:
2025-07-28 05:03:26,487 - INFO -     - exact_match: 0.5000
2025-07-28 05:03:26,487 - INFO -   kormedmcqa_pharm:
2025-07-28 05:03:26,487 - INFO -     - exact_match: 0.3000
2025-07-28 05:03:26,489 - INFO - ============================================================

2025-07-28 05:03:26,501 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 7/10: mmlu
2025-07-28 05:03:26,502 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'mmlu' will use num_fewshot=0
2025-07-28 05:03:26,502 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 05:03:26,502 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 05:03:26,503 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:06:12,219 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 05:06:12,220 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 05:06:12,220 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 05:06:12,220 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 05:06:12,220 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 05:06:12,220 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 05:06:12,220 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 05:06:12,220 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 05:06:12,220 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 05:06:12,220 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 05:06:12,220 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 05:06:12,221 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 05:06:12,222 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 05:06:12,223 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 05:06:12,224 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 05:06:51,879 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 05:06:51,881 - INFO - 
============================================================
2025-07-28 05:06:51,882 - INFO - Task 'mmlu' Results:
2025-07-28 05:06:51,883 - INFO - ============================================================
2025-07-28 05:06:51,884 - INFO -   mmlu:
2025-07-28 05:06:51,884 - INFO -     - accuracy: 0.5632
2025-07-28 05:06:51,884 - INFO -   mmlu_humanities:
2025-07-28 05:06:51,884 - INFO -     - accuracy: 0.5808
2025-07-28 05:06:51,885 - INFO -   mmlu_formal_logic:
2025-07-28 05:06:51,885 - INFO -     - accuracy: 0.3500
2025-07-28 05:06:51,885 - INFO -   mmlu_high_school_european_history:
2025-07-28 05:06:51,885 - INFO -     - accuracy: 0.6500
2025-07-28 05:06:51,885 - INFO -   mmlu_high_school_us_history:
2025-07-28 05:06:51,885 - INFO -     - accuracy: 0.6000
2025-07-28 05:06:51,885 - INFO -   mmlu_high_school_world_history:
2025-07-28 05:06:51,885 - INFO -     - accuracy: 0.8500
2025-07-28 05:06:51,886 - INFO -   mmlu_international_law:
2025-07-28 05:06:51,886 - INFO -     - accuracy: 0.7500
2025-07-28 05:06:51,886 - INFO -   mmlu_jurisprudence:
2025-07-28 05:06:51,886 - INFO -     - accuracy: 0.6500
2025-07-28 05:06:51,886 - INFO -   mmlu_logical_fallacies:
2025-07-28 05:06:51,886 - INFO -     - accuracy: 0.7000
2025-07-28 05:06:51,886 - INFO -   mmlu_moral_disputes:
2025-07-28 05:06:51,886 - INFO -     - accuracy: 0.5500
2025-07-28 05:06:51,886 - INFO -   mmlu_moral_scenarios:
2025-07-28 05:06:51,887 - INFO -     - accuracy: 0.2000
2025-07-28 05:06:51,887 - INFO -   mmlu_philosophy:
2025-07-28 05:06:51,887 - INFO -     - accuracy: 0.7500
2025-07-28 05:06:51,887 - INFO -   mmlu_prehistory:
2025-07-28 05:06:51,887 - INFO -     - accuracy: 0.5000
2025-07-28 05:06:51,887 - INFO -   mmlu_professional_law:
2025-07-28 05:06:51,887 - INFO -     - accuracy: 0.4000
2025-07-28 05:06:51,887 - INFO -   mmlu_world_religions:
2025-07-28 05:06:51,887 - INFO -     - accuracy: 0.6000
2025-07-28 05:06:51,888 - INFO -   mmlu_other:
2025-07-28 05:06:51,888 - INFO -     - accuracy: 0.5808
2025-07-28 05:06:51,888 - INFO -   mmlu_business_ethics:
2025-07-28 05:06:51,888 - INFO -     - accuracy: 0.7000
2025-07-28 05:06:51,888 - INFO -   mmlu_clinical_knowledge:
2025-07-28 05:06:51,888 - INFO -     - accuracy: 0.7500
2025-07-28 05:06:51,888 - INFO -   mmlu_college_medicine:
2025-07-28 05:06:51,888 - INFO -     - accuracy: 0.5500
2025-07-28 05:06:51,888 - INFO -   mmlu_global_facts:
2025-07-28 05:06:51,888 - INFO -     - accuracy: 0.4000
2025-07-28 05:06:51,910 - INFO -   mmlu_human_aging:
2025-07-28 05:06:51,911 - INFO -     - accuracy: 0.6500
2025-07-28 05:06:51,911 - INFO -   mmlu_management:
2025-07-28 05:06:51,911 - INFO -     - accuracy: 0.6000
2025-07-28 05:06:51,911 - INFO -   mmlu_marketing:
2025-07-28 05:06:51,911 - INFO -     - accuracy: 0.7000
2025-07-28 05:06:51,911 - INFO -   mmlu_medical_genetics:
2025-07-28 05:06:51,911 - INFO -     - accuracy: 0.9000
2025-07-28 05:06:51,911 - INFO -   mmlu_miscellaneous:
2025-07-28 05:06:51,912 - INFO -     - accuracy: 0.7000
2025-07-28 05:06:51,912 - INFO -   mmlu_nutrition:
2025-07-28 05:06:51,912 - INFO -     - accuracy: 0.6500
2025-07-28 05:06:51,912 - INFO -   mmlu_professional_accounting:
2025-07-28 05:06:51,912 - INFO -     - accuracy: 0.3500
2025-07-28 05:06:51,912 - INFO -   mmlu_professional_medicine:
2025-07-28 05:06:51,912 - INFO -     - accuracy: 0.3000
2025-07-28 05:06:51,912 - INFO -   mmlu_virology:
2025-07-28 05:06:51,912 - INFO -     - accuracy: 0.3000
2025-07-28 05:06:51,913 - INFO -   mmlu_social_sciences:
2025-07-28 05:06:51,913 - INFO -     - accuracy: 0.6208
2025-07-28 05:06:51,913 - INFO -   mmlu_econometrics:
2025-07-28 05:06:51,913 - INFO -     - accuracy: 0.4000
2025-07-28 05:06:51,913 - INFO -   mmlu_high_school_geography:
2025-07-28 05:06:51,913 - INFO -     - accuracy: 0.8000
2025-07-28 05:06:51,913 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 05:06:51,913 - INFO -     - accuracy: 0.7500
2025-07-28 05:06:51,913 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 05:06:51,914 - INFO -     - accuracy: 0.5000
2025-07-28 05:06:51,914 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 05:06:51,914 - INFO -     - accuracy: 0.5000
2025-07-28 05:06:51,914 - INFO -   mmlu_high_school_psychology:
2025-07-28 05:06:51,914 - INFO -     - accuracy: 0.8000
2025-07-28 05:06:51,914 - INFO -   mmlu_human_sexuality:
2025-07-28 05:06:51,914 - INFO -     - accuracy: 0.6500
2025-07-28 05:06:51,914 - INFO -   mmlu_professional_psychology:
2025-07-28 05:06:51,914 - INFO -     - accuracy: 0.6500
2025-07-28 05:06:51,915 - INFO -   mmlu_public_relations:
2025-07-28 05:06:51,915 - INFO -     - accuracy: 0.4000
2025-07-28 05:06:51,915 - INFO -   mmlu_security_studies:
2025-07-28 05:06:51,915 - INFO -     - accuracy: 0.6500
2025-07-28 05:06:51,915 - INFO -   mmlu_sociology:
2025-07-28 05:06:51,915 - INFO -     - accuracy: 0.6000
2025-07-28 05:06:51,915 - INFO -   mmlu_us_foreign_policy:
2025-07-28 05:06:51,915 - INFO -     - accuracy: 0.7500
2025-07-28 05:06:51,915 - INFO -   mmlu_stem:
2025-07-28 05:06:51,916 - INFO -     - accuracy: 0.5026
2025-07-28 05:06:51,916 - INFO -   mmlu_abstract_algebra:
2025-07-28 05:06:51,916 - INFO -     - accuracy: 0.2500
2025-07-28 05:06:51,916 - INFO -   mmlu_anatomy:
2025-07-28 05:06:51,916 - INFO -     - accuracy: 0.5500
2025-07-28 05:06:51,916 - INFO -   mmlu_astronomy:
2025-07-28 05:06:51,916 - INFO -     - accuracy: 0.7500
2025-07-28 05:06:51,916 - INFO -   mmlu_college_biology:
2025-07-28 05:06:51,916 - INFO -     - accuracy: 0.6500
2025-07-28 05:06:51,917 - INFO -   mmlu_college_chemistry:
2025-07-28 05:06:51,917 - INFO -     - accuracy: 0.4500
2025-07-28 05:06:51,917 - INFO -   mmlu_college_computer_science:
2025-07-28 05:06:51,917 - INFO -     - accuracy: 0.4500
2025-07-28 05:06:51,917 - INFO -   mmlu_college_mathematics:
2025-07-28 05:06:51,917 - INFO -     - accuracy: 0.4000
2025-07-28 05:06:51,917 - INFO -   mmlu_college_physics:
2025-07-28 05:06:51,917 - INFO -     - accuracy: 0.4500
2025-07-28 05:06:51,917 - INFO -   mmlu_computer_security:
2025-07-28 05:06:51,918 - INFO -     - accuracy: 0.6500
2025-07-28 05:06:51,918 - INFO -   mmlu_conceptual_physics:
2025-07-28 05:06:51,918 - INFO -     - accuracy: 0.6000
2025-07-28 05:06:51,918 - INFO -   mmlu_electrical_engineering:
2025-07-28 05:06:51,918 - INFO -     - accuracy: 0.4500
2025-07-28 05:06:51,918 - INFO -   mmlu_elementary_mathematics:
2025-07-28 05:06:51,918 - INFO -     - accuracy: 0.3000
2025-07-28 05:06:51,918 - INFO -   mmlu_high_school_biology:
2025-07-28 05:06:51,918 - INFO -     - accuracy: 0.8500
2025-07-28 05:06:51,919 - INFO -   mmlu_high_school_chemistry:
2025-07-28 05:06:51,919 - INFO -     - accuracy: 0.4000
2025-07-28 05:06:51,919 - INFO -   mmlu_high_school_computer_science:
2025-07-28 05:06:51,919 - INFO -     - accuracy: 0.6500
2025-07-28 05:06:51,919 - INFO -   mmlu_high_school_mathematics:
2025-07-28 05:06:51,919 - INFO -     - accuracy: 0.3500
2025-07-28 05:06:51,919 - INFO -   mmlu_high_school_physics:
2025-07-28 05:06:51,919 - INFO -     - accuracy: 0.6000
2025-07-28 05:06:51,919 - INFO -   mmlu_high_school_statistics:
2025-07-28 05:06:51,920 - INFO -     - accuracy: 0.4000
2025-07-28 05:06:51,920 - INFO -   mmlu_machine_learning:
2025-07-28 05:06:51,920 - INFO -     - accuracy: 0.3500
2025-07-28 05:06:51,920 - INFO - ============================================================

2025-07-28 05:06:51,932 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 8/10: arc_challenge
2025-07-28 05:06:51,934 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 05:06:51,934 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 05:06:51,934 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 05:06:51,934 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:06:59,972 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 05:07:05,314 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 05:07:05,316 - INFO - 
============================================================
2025-07-28 05:07:05,318 - INFO - Task 'arc_challenge' Results:
2025-07-28 05:07:05,320 - INFO - ============================================================
2025-07-28 05:07:05,320 - INFO -   arc_challenge:
2025-07-28 05:07:05,320 - INFO -     - accuracy: 0.5500
2025-07-28 05:07:05,320 - INFO -     - accuracy_norm: 0.5500
2025-07-28 05:07:05,321 - INFO - ============================================================

2025-07-28 05:07:05,332 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 9/10: arc_easy
2025-07-28 05:07:05,333 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'arc_easy' will use num_fewshot=0
2025-07-28 05:07:05,333 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 05:07:05,333 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 05:07:05,334 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:07:12,886 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 05:07:17,977 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 05:07:17,979 - INFO - 
============================================================
2025-07-28 05:07:17,980 - INFO - Task 'arc_easy' Results:
2025-07-28 05:07:17,982 - INFO - ============================================================
2025-07-28 05:07:17,982 - INFO -   arc_easy:
2025-07-28 05:07:17,982 - INFO -     - accuracy: 0.7000
2025-07-28 05:07:17,982 - INFO -     - accuracy_norm: 0.6500
2025-07-28 05:07:17,983 - INFO - ============================================================

2025-07-28 05:07:17,993 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 10/10: hellaswag
2025-07-28 05:07:17,994 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'hellaswag' will use num_fewshot=0
2025-07-28 05:07:17,994 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 05:07:17,994 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 05:07:17,995 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:07:31,420 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 05:07:36,888 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 05:07:36,890 - INFO - 
============================================================
2025-07-28 05:07:36,891 - INFO - Task 'hellaswag' Results:
2025-07-28 05:07:36,892 - INFO - ============================================================
2025-07-28 05:07:36,893 - INFO -   hellaswag:
2025-07-28 05:07:36,894 - INFO -     - accuracy: 0.4000
2025-07-28 05:07:36,894 - INFO -     - accuracy_norm: 0.4500
2025-07-28 05:07:36,894 - INFO - ============================================================

2025-07-28 05:07:36,905 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 05:07:36,907 - INFO - [Process 1811658] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/kanana-1.5-2.1b-instruct-2505/kanana-1.5-2.1b-instruct-2505_harness_11.json
2025-07-28 05:07:37,187 - INFO - Results uploaded to WandB as artifact
2025-07-28 05:07:37,196 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 05:07:37,198 - INFO - [Process 1811658] Successfully completed kanana-1.5-2.1b-instruct-2505_harness_11
2025-07-28 05:07:40,255 - INFO - Run kanana-1.5-2.1b-instruct-2505_harness_11 finished successfully
2025-07-28 05:07:40,256 - INFO - [Process 1811658] eagle-3b-preview_harness_12 assigned to cuda:0
2025-07-28 05:07:40,256 - INFO - [Process 1811658] eagle-3b-preview_harness_12 - using custom limit: 20
2025-07-28 05:07:41,527 - INFO - WandB run initialized: eagle-3b-preview_20250728_050740 (ID: f227ef58)
2025-07-28 05:07:41,738 - INFO - eagle-3b-preview_harness_12: Test mode (limit=2), setting num_fewshot=0
2025-07-28 05:07:41,738 - INFO - eagle-3b-preview_harness_12: Processing task 1/10: kmmlu
2025-07-28 05:07:41,739 - INFO - eagle-3b-preview_harness_12: Task 'kmmlu' will use num_fewshot=0
2025-07-28 05:07:41,739 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 05:07:41,739 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:08:55,046 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 05:08:55,046 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 05:08:55,046 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 05:08:55,046 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 05:08:55,046 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 05:08:55,047 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 05:08:55,048 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 05:08:55,049 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 05:08:55,050 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 05:08:55,050 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 05:08:55,050 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 05:08:55,050 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 05:08:55,050 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 05:08:55,050 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 05:09:13,123 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 05:09:13,124 - INFO - 
============================================================
2025-07-28 05:09:13,125 - INFO - Task 'kmmlu' Results:
2025-07-28 05:09:13,125 - INFO - ============================================================
2025-07-28 05:09:13,125 - INFO -   kmmlu:
2025-07-28 05:09:13,125 - INFO -     - accuracy: 0.1922
2025-07-28 05:09:13,125 - INFO -   kmmlu_applied_science:
2025-07-28 05:09:13,125 - INFO -     - accuracy: 0.1333
2025-07-28 05:09:13,125 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 05:09:13,125 - INFO -     - accuracy: 0.0000
2025-07-28 05:09:13,125 - INFO -   kmmlu_electronics_engineering:
2025-07-28 05:09:13,126 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,126 - INFO -   kmmlu_energy_management:
2025-07-28 05:09:13,126 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,126 - INFO -   kmmlu_environmental_science:
2025-07-28 05:09:13,126 - INFO -     - accuracy: 0.1500
2025-07-28 05:09:13,126 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 05:09:13,126 - INFO -     - accuracy: 0.3000
2025-07-28 05:09:13,126 - INFO -   kmmlu_geomatics:
2025-07-28 05:09:13,126 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,127 - INFO -   kmmlu_industrial_engineer:
2025-07-28 05:09:13,127 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,127 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 05:09:13,127 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,127 - INFO -   kmmlu_maritime_engineering:
2025-07-28 05:09:13,127 - INFO -     - accuracy: 0.1500
2025-07-28 05:09:13,127 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 05:09:13,127 - INFO -     - accuracy: 0.1500
2025-07-28 05:09:13,127 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 05:09:13,127 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,128 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 05:09:13,128 - INFO -     - accuracy: 0.2500
2025-07-28 05:09:13,128 - INFO -   kmmlu_humss:
2025-07-28 05:09:13,128 - INFO -     - accuracy: 0.2136
2025-07-28 05:09:13,128 - INFO -   kmmlu_accounting:
2025-07-28 05:09:13,128 - INFO -     - accuracy: 0.2000
2025-07-28 05:09:13,128 - INFO -   kmmlu_criminal_law:
2025-07-28 05:09:13,128 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,128 - INFO -   kmmlu_economics:
2025-07-28 05:09:13,128 - INFO -     - accuracy: 0.2000
2025-07-28 05:09:13,129 - INFO -   kmmlu_education:
2025-07-28 05:09:13,129 - INFO -     - accuracy: 0.1500
2025-07-28 05:09:13,129 - INFO -   kmmlu_korean_history:
2025-07-28 05:09:13,129 - INFO -     - accuracy: 0.2500
2025-07-28 05:09:13,129 - INFO -   kmmlu_law:
2025-07-28 05:09:13,129 - INFO -     - accuracy: 0.2500
2025-07-28 05:09:13,129 - INFO -   kmmlu_management:
2025-07-28 05:09:13,129 - INFO -     - accuracy: 0.4000
2025-07-28 05:09:13,129 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 05:09:13,129 - INFO -     - accuracy: 0.3000
2025-07-28 05:09:13,129 - INFO -   kmmlu_psychology:
2025-07-28 05:09:13,130 - INFO -     - accuracy: 0.2000
2025-07-28 05:09:13,130 - INFO -   kmmlu_social_welfare:
2025-07-28 05:09:13,130 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,130 - INFO -   kmmlu_taxation:
2025-07-28 05:09:13,130 - INFO -     - accuracy: 0.2000
2025-07-28 05:09:13,130 - INFO -   kmmlu_other:
2025-07-28 05:09:13,130 - INFO -     - accuracy: 0.2273
2025-07-28 05:09:13,130 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 05:09:13,130 - INFO -     - accuracy: 0.3500
2025-07-28 05:09:13,130 - INFO -   kmmlu_construction:
2025-07-28 05:09:13,131 - INFO -     - accuracy: 0.0500
2025-07-28 05:09:13,131 - INFO -   kmmlu_fashion:
2025-07-28 05:09:13,131 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,131 - INFO -   kmmlu_food_processing:
2025-07-28 05:09:13,131 - INFO -     - accuracy: 0.2000
2025-07-28 05:09:13,131 - INFO -   kmmlu_health:
2025-07-28 05:09:13,131 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,131 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 05:09:13,131 - INFO -     - accuracy: 0.1500
2025-07-28 05:09:13,131 - INFO -   kmmlu_marketing:
2025-07-28 05:09:13,132 - INFO -     - accuracy: 0.3500
2025-07-28 05:09:13,132 - INFO -   kmmlu_patent:
2025-07-28 05:09:13,132 - INFO -     - accuracy: 0.3000
2025-07-28 05:09:13,132 - INFO -   kmmlu_public_safety:
2025-07-28 05:09:13,132 - INFO -     - accuracy: 0.2500
2025-07-28 05:09:13,132 - INFO -   kmmlu_real_estate:
2025-07-28 05:09:13,132 - INFO -     - accuracy: 0.4000
2025-07-28 05:09:13,132 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 05:09:13,132 - INFO -     - accuracy: 0.2500
2025-07-28 05:09:13,132 - INFO -   kmmlu_stem:
2025-07-28 05:09:13,132 - INFO -     - accuracy: 0.2000
2025-07-28 05:09:13,133 - INFO -   kmmlu_biology:
2025-07-28 05:09:13,133 - INFO -     - accuracy: 0.2000
2025-07-28 05:09:13,133 - INFO -   kmmlu_chemical_engineering:
2025-07-28 05:09:13,133 - INFO -     - accuracy: 0.3500
2025-07-28 05:09:13,133 - INFO -   kmmlu_chemistry:
2025-07-28 05:09:13,133 - INFO -     - accuracy: 0.2000
2025-07-28 05:09:13,133 - INFO -   kmmlu_civil_engineering:
2025-07-28 05:09:13,133 - INFO -     - accuracy: 0.1500
2025-07-28 05:09:13,133 - INFO -   kmmlu_computer_science:
2025-07-28 05:09:13,133 - INFO -     - accuracy: 0.2500
2025-07-28 05:09:13,134 - INFO -   kmmlu_ecology:
2025-07-28 05:09:13,134 - INFO -     - accuracy: 0.2000
2025-07-28 05:09:13,134 - INFO -   kmmlu_electrical_engineering:
2025-07-28 05:09:13,134 - INFO -     - accuracy: 0.1000
2025-07-28 05:09:13,134 - INFO -   kmmlu_information_technology:
2025-07-28 05:09:13,134 - INFO -     - accuracy: 0.1500
2025-07-28 05:09:13,154 - INFO -   kmmlu_materials_engineering:
2025-07-28 05:09:13,154 - INFO -     - accuracy: 0.0500
2025-07-28 05:09:13,154 - INFO -   kmmlu_math:
2025-07-28 05:09:13,154 - INFO -     - accuracy: 0.2500
2025-07-28 05:09:13,154 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 05:09:13,154 - INFO -     - accuracy: 0.3000
2025-07-28 05:09:13,154 - INFO - ============================================================

2025-07-28 05:09:13,169 - INFO - eagle-3b-preview_harness_12: Processing task 2/10: kmmlu_hard
2025-07-28 05:09:13,171 - INFO - eagle-3b-preview_harness_12: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 05:09:13,171 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 05:09:13,171 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:10:27,084 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 05:10:27,084 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 05:10:27,085 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 05:10:27,085 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 05:10:27,085 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 05:10:27,085 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 05:10:27,085 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 05:10:27,085 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 05:10:27,086 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 05:10:27,086 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 05:10:27,086 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 05:10:27,086 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 05:10:27,086 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 05:10:27,086 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 05:10:27,086 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 05:10:27,087 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 05:10:27,087 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 05:10:27,087 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 05:10:27,087 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 05:10:27,087 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 05:10:27,087 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 05:10:27,087 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 05:10:27,087 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 05:10:27,088 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 05:10:27,088 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 05:10:27,088 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 05:10:27,088 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 05:10:27,088 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 05:10:27,088 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 05:10:27,088 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 05:10:27,088 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 05:10:27,089 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 05:10:27,089 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 05:10:27,089 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 05:10:27,089 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 05:10:27,089 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 05:10:27,089 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 05:10:27,089 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 05:10:27,089 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 05:10:27,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 05:10:27,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 05:10:27,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 05:10:27,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 05:10:27,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 05:10:27,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 05:10:45,652 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 05:10:45,653 - INFO - 
============================================================
2025-07-28 05:10:45,654 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 05:10:45,654 - INFO - ============================================================
2025-07-28 05:10:45,655 - INFO -   kmmlu_hard:
2025-07-28 05:10:45,655 - INFO -     - accuracy: 0.2056
2025-07-28 05:10:45,655 - INFO -   kmmlu_hard_applied_science:
2025-07-28 05:10:45,655 - INFO -     - accuracy: 0.1958
2025-07-28 05:10:45,655 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 05:10:45,655 - INFO -     - accuracy: 0.2500
2025-07-28 05:10:45,655 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 05:10:45,656 - INFO -     - accuracy: 0.1500
2025-07-28 05:10:45,656 - INFO -   kmmlu_hard_energy_management:
2025-07-28 05:10:45,656 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,656 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 05:10:45,656 - INFO -     - accuracy: 0.2500
2025-07-28 05:10:45,656 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 05:10:45,656 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,656 - INFO -   kmmlu_hard_geomatics:
2025-07-28 05:10:45,657 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,657 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 05:10:45,657 - INFO -     - accuracy: 0.1500
2025-07-28 05:10:45,657 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 05:10:45,657 - INFO -     - accuracy: 0.1500
2025-07-28 05:10:45,657 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 05:10:45,657 - INFO -     - accuracy: 0.3500
2025-07-28 05:10:45,657 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 05:10:45,657 - INFO -     - accuracy: 0.0500
2025-07-28 05:10:45,658 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 05:10:45,658 - INFO -     - accuracy: 0.1000
2025-07-28 05:10:45,658 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 05:10:45,658 - INFO -     - accuracy: 0.3000
2025-07-28 05:10:45,658 - INFO -   kmmlu_hard_humss:
2025-07-28 05:10:45,658 - INFO -     - accuracy: 0.1909
2025-07-28 05:10:45,658 - INFO -   kmmlu_hard_accounting:
2025-07-28 05:10:45,658 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,658 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 05:10:45,659 - INFO -     - accuracy: 0.1500
2025-07-28 05:10:45,659 - INFO -   kmmlu_hard_economics:
2025-07-28 05:10:45,659 - INFO -     - accuracy: 0.3000
2025-07-28 05:10:45,659 - INFO -   kmmlu_hard_education:
2025-07-28 05:10:45,659 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,659 - INFO -   kmmlu_hard_korean_history:
2025-07-28 05:10:45,659 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,659 - INFO -   kmmlu_hard_law:
2025-07-28 05:10:45,659 - INFO -     - accuracy: 0.2500
2025-07-28 05:10:45,659 - INFO -   kmmlu_hard_management:
2025-07-28 05:10:45,659 - INFO -     - accuracy: 0.0500
2025-07-28 05:10:45,660 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 05:10:45,660 - INFO -     - accuracy: 0.2500
2025-07-28 05:10:45,660 - INFO -   kmmlu_hard_psychology:
2025-07-28 05:10:45,660 - INFO -     - accuracy: 0.3500
2025-07-28 05:10:45,660 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 05:10:45,660 - INFO -     - accuracy: 0.0000
2025-07-28 05:10:45,660 - INFO -   kmmlu_hard_taxation:
2025-07-28 05:10:45,660 - INFO -     - accuracy: 0.1500
2025-07-28 05:10:45,660 - INFO -   kmmlu_hard_other:
2025-07-28 05:10:45,661 - INFO -     - accuracy: 0.2273
2025-07-28 05:10:45,661 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 05:10:45,661 - INFO -     - accuracy: 0.3500
2025-07-28 05:10:45,661 - INFO -   kmmlu_hard_construction:
2025-07-28 05:10:45,661 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,661 - INFO -   kmmlu_hard_fashion:
2025-07-28 05:10:45,661 - INFO -     - accuracy: 0.2500
2025-07-28 05:10:45,661 - INFO -   kmmlu_hard_food_processing:
2025-07-28 05:10:45,661 - INFO -     - accuracy: 0.3500
2025-07-28 05:10:45,662 - INFO -   kmmlu_hard_health:
2025-07-28 05:10:45,662 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,662 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 05:10:45,662 - INFO -     - accuracy: 0.1500
2025-07-28 05:10:45,662 - INFO -   kmmlu_hard_marketing:
2025-07-28 05:10:45,662 - INFO -     - accuracy: 0.3000
2025-07-28 05:10:45,662 - INFO -   kmmlu_hard_patent:
2025-07-28 05:10:45,662 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,662 - INFO -   kmmlu_hard_public_safety:
2025-07-28 05:10:45,663 - INFO -     - accuracy: 0.1500
2025-07-28 05:10:45,663 - INFO -   kmmlu_hard_real_estate:
2025-07-28 05:10:45,663 - INFO -     - accuracy: 0.1500
2025-07-28 05:10:45,663 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 05:10:45,663 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,663 - INFO -   kmmlu_hard_stem:
2025-07-28 05:10:45,663 - INFO -     - accuracy: 0.2091
2025-07-28 05:10:45,663 - INFO -   kmmlu_hard_biology:
2025-07-28 05:10:45,663 - INFO -     - accuracy: 0.3500
2025-07-28 05:10:45,664 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 05:10:45,664 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,664 - INFO -   kmmlu_hard_chemistry:
2025-07-28 05:10:45,664 - INFO -     - accuracy: 0.1000
2025-07-28 05:10:45,664 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 05:10:45,664 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,664 - INFO -   kmmlu_hard_computer_science:
2025-07-28 05:10:45,664 - INFO -     - accuracy: 0.1500
2025-07-28 05:10:45,664 - INFO -   kmmlu_hard_ecology:
2025-07-28 05:10:45,664 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,665 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 05:10:45,665 - INFO -     - accuracy: 0.1500
2025-07-28 05:10:45,665 - INFO -   kmmlu_hard_information_technology:
2025-07-28 05:10:45,665 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,665 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 05:10:45,665 - INFO -     - accuracy: 0.3000
2025-07-28 05:10:45,665 - INFO -   kmmlu_hard_math:
2025-07-28 05:10:45,665 - INFO -     - accuracy: 0.2500
2025-07-28 05:10:45,666 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 05:10:45,666 - INFO -     - accuracy: 0.2000
2025-07-28 05:10:45,666 - INFO - ============================================================

2025-07-28 05:10:45,682 - INFO - eagle-3b-preview_harness_12: Processing task 3/10: haerae
2025-07-28 05:10:45,683 - INFO - eagle-3b-preview_harness_12: Task 'haerae' will use num_fewshot=0
2025-07-28 05:10:45,683 - INFO - eagle-3b-preview_harness_12: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 05:10:45,684 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:11:03,180 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 05:11:03,180 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 05:11:03,180 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 05:11:03,181 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 05:11:03,181 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 05:11:13,374 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 05:11:13,376 - INFO - 
============================================================
2025-07-28 05:11:13,376 - INFO - Task 'haerae' Results:
2025-07-28 05:11:13,376 - INFO - ============================================================
2025-07-28 05:11:13,376 - INFO -   haerae:
2025-07-28 05:11:13,376 - INFO -     - accuracy: 0.1700
2025-07-28 05:11:13,376 - INFO -     - accuracy_norm: 0.1700
2025-07-28 05:11:13,377 - INFO -   haerae_general_knowledge:
2025-07-28 05:11:13,377 - INFO -     - accuracy: 0.2000
2025-07-28 05:11:13,377 - INFO -     - accuracy_norm: 0.2000
2025-07-28 05:11:13,377 - INFO -   haerae_history:
2025-07-28 05:11:13,377 - INFO -     - accuracy: 0.0000
2025-07-28 05:11:13,377 - INFO -     - accuracy_norm: 0.0000
2025-07-28 05:11:13,377 - INFO -   haerae_loan_word:
2025-07-28 05:11:13,377 - INFO -     - accuracy: 0.2500
2025-07-28 05:11:13,377 - INFO -     - accuracy_norm: 0.2500
2025-07-28 05:11:13,378 - INFO -   haerae_rare_word:
2025-07-28 05:11:13,378 - INFO -     - accuracy: 0.3000
2025-07-28 05:11:13,378 - INFO -     - accuracy_norm: 0.3000
2025-07-28 05:11:13,378 - INFO -   haerae_standard_nomenclature:
2025-07-28 05:11:13,378 - INFO -     - accuracy: 0.1000
2025-07-28 05:11:13,378 - INFO -     - accuracy_norm: 0.1000
2025-07-28 05:11:13,378 - INFO - ============================================================

2025-07-28 05:11:13,394 - INFO - eagle-3b-preview_harness_12: Processing task 4/10: kobest
2025-07-28 05:11:13,394 - INFO - eagle-3b-preview_harness_12: Task 'kobest' will use num_fewshot=0
2025-07-28 05:11:13,395 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 05:11:13,396 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:11:32,761 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 05:11:32,761 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 05:11:32,761 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 05:11:32,761 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 05:11:32,761 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 05:11:38,929 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 05:11:38,931 - INFO - 
============================================================
2025-07-28 05:11:38,931 - INFO - Task 'kobest' Results:
2025-07-28 05:11:38,931 - INFO - ============================================================
2025-07-28 05:11:38,932 - INFO -   kobest:
2025-07-28 05:11:38,932 - INFO -     - accuracy: 0.4700
2025-07-28 05:11:38,932 - INFO -     - accuracy_norm: 0.4500
2025-07-28 05:11:38,932 - INFO -     - f1: 0.3983
2025-07-28 05:11:38,932 - INFO -   kobest_boolq:
2025-07-28 05:11:38,933 - INFO -     - accuracy: 0.5000
2025-07-28 05:11:38,933 - INFO -     - f1: 0.3333
2025-07-28 05:11:38,933 - INFO -   kobest_copa:
2025-07-28 05:11:38,933 - INFO -     - accuracy: 0.5500
2025-07-28 05:11:38,933 - INFO -     - f1: 0.5489
2025-07-28 05:11:38,933 - INFO -   kobest_hellaswag:
2025-07-28 05:11:38,933 - INFO -     - accuracy: 0.3500
2025-07-28 05:11:38,934 - INFO -     - accuracy_norm: 0.4500
2025-07-28 05:11:38,934 - INFO -     - f1: 0.3547
2025-07-28 05:11:38,934 - INFO -   kobest_sentineg:
2025-07-28 05:11:38,934 - INFO -     - accuracy: 0.4000
2025-07-28 05:11:38,934 - INFO -     - f1: 0.4000
2025-07-28 05:11:38,934 - INFO -   kobest_wic:
2025-07-28 05:11:38,935 - INFO -     - accuracy: 0.5500
2025-07-28 05:11:38,935 - INFO -     - f1: 0.3548
2025-07-28 05:11:38,935 - INFO - ============================================================

2025-07-28 05:11:38,950 - INFO - eagle-3b-preview_harness_12: Processing task 5/10: csatqa
2025-07-28 05:11:38,951 - INFO - eagle-3b-preview_harness_12: Task 'csatqa' detected as zero-shot task
2025-07-28 05:11:38,951 - INFO - eagle-3b-preview_harness_12: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 05:11:38,952 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:11:51,403 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 05:11:51,403 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 05:11:51,403 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 05:11:51,403 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 05:11:51,403 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 05:11:51,403 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 05:12:23,780 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 05:12:23,782 - INFO - 
============================================================
2025-07-28 05:12:23,782 - INFO - Task 'csatqa' Results:
2025-07-28 05:12:23,782 - INFO - ============================================================
2025-07-28 05:12:23,782 - INFO -   csatqa:
2025-07-28 05:12:23,782 - INFO -     - accuracy: 0.1532
2025-07-28 05:12:23,782 - INFO -     - accuracy_norm: 0.1532
2025-07-28 05:12:23,783 - INFO -   csatqa_gr:
2025-07-28 05:12:23,783 - INFO -     - accuracy: 0.1000
2025-07-28 05:12:23,783 - INFO -     - accuracy_norm: 0.1000
2025-07-28 05:12:23,783 - INFO -   csatqa_li:
2025-07-28 05:12:23,783 - INFO -     - accuracy: 0.2000
2025-07-28 05:12:23,783 - INFO -     - accuracy_norm: 0.2000
2025-07-28 05:12:23,783 - INFO -   csatqa_rch:
2025-07-28 05:12:23,783 - INFO -     - accuracy: 0.1500
2025-07-28 05:12:23,783 - INFO -     - accuracy_norm: 0.1500
2025-07-28 05:12:23,783 - INFO -   csatqa_rcs:
2025-07-28 05:12:23,784 - INFO -     - accuracy: 0.2000
2025-07-28 05:12:23,784 - INFO -     - accuracy_norm: 0.2000
2025-07-28 05:12:23,784 - INFO -   csatqa_rcss:
2025-07-28 05:12:23,784 - INFO -     - accuracy: 0.1000
2025-07-28 05:12:23,784 - INFO -     - accuracy_norm: 0.1000
2025-07-28 05:12:23,784 - INFO -   csatqa_wr:
2025-07-28 05:12:23,784 - INFO -     - accuracy: 0.1818
2025-07-28 05:12:23,784 - INFO -     - accuracy_norm: 0.1818
2025-07-28 05:12:23,784 - INFO - ============================================================

2025-07-28 05:12:23,801 - INFO - eagle-3b-preview_harness_12: Processing task 6/10: kormedmcqa
2025-07-28 05:12:23,802 - INFO - eagle-3b-preview_harness_12: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 05:12:23,803 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 05:12:23,803 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:12:42,557 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 05:12:42,557 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 05:12:42,557 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 05:12:42,558 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 05:13:03,264 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 05:13:03,266 - INFO - 
============================================================
2025-07-28 05:13:03,266 - INFO - Task 'kormedmcqa' Results:
2025-07-28 05:13:03,266 - INFO - ============================================================
2025-07-28 05:13:03,267 - INFO -   kormedmcqa:
2025-07-28 05:13:03,267 - INFO -     - exact_match: 0.1875
2025-07-28 05:13:03,267 - INFO -   kormedmcqa_dentist:
2025-07-28 05:13:03,267 - INFO -     - exact_match: 0.1500
2025-07-28 05:13:03,267 - INFO -   kormedmcqa_doctor:
2025-07-28 05:13:03,267 - INFO -     - exact_match: 0.2000
2025-07-28 05:13:03,267 - INFO -   kormedmcqa_nurse:
2025-07-28 05:13:03,267 - INFO -     - exact_match: 0.1500
2025-07-28 05:13:03,268 - INFO -   kormedmcqa_pharm:
2025-07-28 05:13:03,268 - INFO -     - exact_match: 0.2500
2025-07-28 05:13:03,268 - INFO - ============================================================

2025-07-28 05:13:03,283 - INFO - eagle-3b-preview_harness_12: Processing task 7/10: mmlu
2025-07-28 05:13:03,284 - INFO - eagle-3b-preview_harness_12: Task 'mmlu' will use num_fewshot=0
2025-07-28 05:13:03,285 - INFO - eagle-3b-preview_harness_12: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 05:13:03,285 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:15:46,401 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 05:15:46,402 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 05:15:46,402 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 05:15:46,402 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 05:15:46,402 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 05:15:46,402 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 05:15:46,403 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 05:15:46,403 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 05:15:46,403 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 05:15:46,403 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 05:15:46,403 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 05:15:46,403 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 05:15:46,404 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 05:15:46,404 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 05:15:46,404 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 05:15:46,404 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 05:15:46,404 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 05:15:46,404 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 05:15:46,404 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 05:15:46,405 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 05:15:46,405 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 05:15:46,405 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 05:15:46,405 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 05:15:46,405 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 05:15:46,405 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 05:15:46,405 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 05:15:46,406 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 05:15:46,406 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 05:15:46,406 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 05:15:46,406 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 05:15:46,406 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 05:15:46,406 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 05:15:46,406 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 05:15:46,406 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 05:15:46,407 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 05:15:46,407 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 05:15:46,407 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 05:15:46,407 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 05:15:46,407 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 05:15:46,407 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 05:15:46,407 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 05:15:46,408 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 05:15:46,408 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 05:15:46,408 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 05:15:46,408 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 05:15:46,408 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 05:15:46,409 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 05:15:46,409 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 05:15:46,409 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 05:15:46,409 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 05:15:46,409 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 05:15:46,409 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 05:15:46,409 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 05:15:46,409 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 05:15:46,410 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 05:15:46,410 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 05:15:46,410 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 05:16:09,300 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 05:16:09,301 - INFO - 
============================================================
2025-07-28 05:16:09,301 - INFO - Task 'mmlu' Results:
2025-07-28 05:16:09,301 - INFO - ============================================================
2025-07-28 05:16:09,302 - INFO -   mmlu:
2025-07-28 05:16:09,302 - INFO -     - accuracy: 0.2368
2025-07-28 05:16:09,302 - INFO -   mmlu_humanities:
2025-07-28 05:16:09,302 - INFO -     - accuracy: 0.2269
2025-07-28 05:16:09,302 - INFO -   mmlu_formal_logic:
2025-07-28 05:16:09,303 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,303 - INFO -   mmlu_high_school_european_history:
2025-07-28 05:16:09,303 - INFO -     - accuracy: 0.2500
2025-07-28 05:16:09,303 - INFO -   mmlu_high_school_us_history:
2025-07-28 05:16:09,303 - INFO -     - accuracy: 0.1000
2025-07-28 05:16:09,304 - INFO -   mmlu_high_school_world_history:
2025-07-28 05:16:09,304 - INFO -     - accuracy: 0.2500
2025-07-28 05:16:09,304 - INFO -   mmlu_international_law:
2025-07-28 05:16:09,304 - INFO -     - accuracy: 0.1500
2025-07-28 05:16:09,305 - INFO -   mmlu_jurisprudence:
2025-07-28 05:16:09,305 - INFO -     - accuracy: 0.1500
2025-07-28 05:16:09,305 - INFO -   mmlu_logical_fallacies:
2025-07-28 05:16:09,305 - INFO -     - accuracy: 0.3500
2025-07-28 05:16:09,305 - INFO -   mmlu_moral_disputes:
2025-07-28 05:16:09,306 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,306 - INFO -   mmlu_moral_scenarios:
2025-07-28 05:16:09,306 - INFO -     - accuracy: 0.2500
2025-07-28 05:16:09,306 - INFO -   mmlu_philosophy:
2025-07-28 05:16:09,306 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,306 - INFO -   mmlu_prehistory:
2025-07-28 05:16:09,306 - INFO -     - accuracy: 0.3500
2025-07-28 05:16:09,306 - INFO -   mmlu_professional_law:
2025-07-28 05:16:09,306 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,307 - INFO -   mmlu_world_religions:
2025-07-28 05:16:09,307 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,307 - INFO -   mmlu_other:
2025-07-28 05:16:09,307 - INFO -     - accuracy: 0.2154
2025-07-28 05:16:09,307 - INFO -   mmlu_business_ethics:
2025-07-28 05:16:09,307 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,307 - INFO -   mmlu_clinical_knowledge:
2025-07-28 05:16:09,307 - INFO -     - accuracy: 0.1000
2025-07-28 05:16:09,307 - INFO -   mmlu_college_medicine:
2025-07-28 05:16:09,308 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,316 - INFO -   mmlu_global_facts:
2025-07-28 05:16:09,316 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,316 - INFO -   mmlu_human_aging:
2025-07-28 05:16:09,316 - INFO -     - accuracy: 0.0500
2025-07-28 05:16:09,317 - INFO -   mmlu_management:
2025-07-28 05:16:09,317 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,317 - INFO -   mmlu_marketing:
2025-07-28 05:16:09,317 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,317 - INFO -   mmlu_medical_genetics:
2025-07-28 05:16:09,317 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,317 - INFO -   mmlu_miscellaneous:
2025-07-28 05:16:09,317 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,317 - INFO -   mmlu_nutrition:
2025-07-28 05:16:09,318 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,318 - INFO -   mmlu_professional_accounting:
2025-07-28 05:16:09,318 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,318 - INFO -   mmlu_professional_medicine:
2025-07-28 05:16:09,318 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,318 - INFO -   mmlu_virology:
2025-07-28 05:16:09,318 - INFO -     - accuracy: 0.1500
2025-07-28 05:16:09,318 - INFO -   mmlu_social_sciences:
2025-07-28 05:16:09,318 - INFO -     - accuracy: 0.1917
2025-07-28 05:16:09,319 - INFO -   mmlu_econometrics:
2025-07-28 05:16:09,319 - INFO -     - accuracy: 0.1000
2025-07-28 05:16:09,319 - INFO -   mmlu_high_school_geography:
2025-07-28 05:16:09,319 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,319 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 05:16:09,319 - INFO -     - accuracy: 0.1500
2025-07-28 05:16:09,319 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 05:16:09,319 - INFO -     - accuracy: 0.1000
2025-07-28 05:16:09,320 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 05:16:09,320 - INFO -     - accuracy: 0.1000
2025-07-28 05:16:09,320 - INFO -   mmlu_high_school_psychology:
2025-07-28 05:16:09,320 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,320 - INFO -   mmlu_human_sexuality:
2025-07-28 05:16:09,320 - INFO -     - accuracy: 0.2500
2025-07-28 05:16:09,320 - INFO -   mmlu_professional_psychology:
2025-07-28 05:16:09,320 - INFO -     - accuracy: 0.1500
2025-07-28 05:16:09,320 - INFO -   mmlu_public_relations:
2025-07-28 05:16:09,320 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,321 - INFO -   mmlu_security_studies:
2025-07-28 05:16:09,321 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,321 - INFO -   mmlu_sociology:
2025-07-28 05:16:09,321 - INFO -     - accuracy: 0.3500
2025-07-28 05:16:09,321 - INFO -   mmlu_us_foreign_policy:
2025-07-28 05:16:09,321 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,321 - INFO -   mmlu_stem:
2025-07-28 05:16:09,321 - INFO -     - accuracy: 0.2868
2025-07-28 05:16:09,322 - INFO -   mmlu_abstract_algebra:
2025-07-28 05:16:09,322 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,322 - INFO -   mmlu_anatomy:
2025-07-28 05:16:09,322 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,322 - INFO -   mmlu_astronomy:
2025-07-28 05:16:09,322 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,322 - INFO -   mmlu_college_biology:
2025-07-28 05:16:09,322 - INFO -     - accuracy: 0.2500
2025-07-28 05:16:09,322 - INFO -   mmlu_college_chemistry:
2025-07-28 05:16:09,323 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,323 - INFO -   mmlu_college_computer_science:
2025-07-28 05:16:09,323 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,323 - INFO -   mmlu_college_mathematics:
2025-07-28 05:16:09,323 - INFO -     - accuracy: 0.4000
2025-07-28 05:16:09,323 - INFO -   mmlu_college_physics:
2025-07-28 05:16:09,323 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,323 - INFO -   mmlu_computer_security:
2025-07-28 05:16:09,323 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,324 - INFO -   mmlu_conceptual_physics:
2025-07-28 05:16:09,324 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,324 - INFO -   mmlu_electrical_engineering:
2025-07-28 05:16:09,324 - INFO -     - accuracy: 0.2500
2025-07-28 05:16:09,324 - INFO -   mmlu_elementary_mathematics:
2025-07-28 05:16:09,324 - INFO -     - accuracy: 0.2500
2025-07-28 05:16:09,324 - INFO -   mmlu_high_school_biology:
2025-07-28 05:16:09,324 - INFO -     - accuracy: 0.2500
2025-07-28 05:16:09,324 - INFO -   mmlu_high_school_chemistry:
2025-07-28 05:16:09,325 - INFO -     - accuracy: 0.4500
2025-07-28 05:16:09,325 - INFO -   mmlu_high_school_computer_science:
2025-07-28 05:16:09,325 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:09,325 - INFO -   mmlu_high_school_mathematics:
2025-07-28 05:16:09,325 - INFO -     - accuracy: 0.2500
2025-07-28 05:16:09,325 - INFO -   mmlu_high_school_physics:
2025-07-28 05:16:09,325 - INFO -     - accuracy: 0.3500
2025-07-28 05:16:09,325 - INFO -   mmlu_high_school_statistics:
2025-07-28 05:16:09,325 - INFO -     - accuracy: 0.3000
2025-07-28 05:16:09,326 - INFO -   mmlu_machine_learning:
2025-07-28 05:16:09,326 - INFO -     - accuracy: 0.4000
2025-07-28 05:16:09,326 - INFO - ============================================================

2025-07-28 05:16:09,341 - INFO - eagle-3b-preview_harness_12: Processing task 8/10: arc_challenge
2025-07-28 05:16:09,343 - INFO - eagle-3b-preview_harness_12: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 05:16:09,343 - INFO - eagle-3b-preview_harness_12: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 05:16:09,343 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:16:17,211 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 05:16:21,367 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 05:16:21,371 - INFO - 
============================================================
2025-07-28 05:16:21,371 - INFO - Task 'arc_challenge' Results:
2025-07-28 05:16:21,371 - INFO - ============================================================
2025-07-28 05:16:21,371 - INFO -   arc_challenge:
2025-07-28 05:16:21,371 - INFO -     - accuracy: 0.2000
2025-07-28 05:16:21,371 - INFO -     - accuracy_norm: 0.1500
2025-07-28 05:16:21,372 - INFO - ============================================================

2025-07-28 05:16:21,387 - INFO - eagle-3b-preview_harness_12: Processing task 9/10: arc_easy
2025-07-28 05:16:21,388 - INFO - eagle-3b-preview_harness_12: Task 'arc_easy' will use num_fewshot=0
2025-07-28 05:16:21,388 - INFO - eagle-3b-preview_harness_12: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 05:16:21,389 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:16:29,614 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 05:16:33,726 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 05:16:33,728 - INFO - 
============================================================
2025-07-28 05:16:33,728 - INFO - Task 'arc_easy' Results:
2025-07-28 05:16:33,728 - INFO - ============================================================
2025-07-28 05:16:33,728 - INFO -   arc_easy:
2025-07-28 05:16:33,728 - INFO -     - accuracy: 0.5500
2025-07-28 05:16:33,728 - INFO -     - accuracy_norm: 0.4000
2025-07-28 05:16:33,729 - INFO - ============================================================

2025-07-28 05:16:33,744 - INFO - eagle-3b-preview_harness_12: Processing task 10/10: hellaswag
2025-07-28 05:16:33,744 - INFO - eagle-3b-preview_harness_12: Task 'hellaswag' will use num_fewshot=0
2025-07-28 05:16:33,745 - INFO - eagle-3b-preview_harness_12: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 05:16:33,746 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:16:47,729 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 05:16:51,944 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 05:16:51,946 - INFO - 
============================================================
2025-07-28 05:16:51,946 - INFO - Task 'hellaswag' Results:
2025-07-28 05:16:51,946 - INFO - ============================================================
2025-07-28 05:16:51,946 - INFO -   hellaswag:
2025-07-28 05:16:51,947 - INFO -     - accuracy: 0.3500
2025-07-28 05:16:51,947 - INFO -     - accuracy_norm: 0.4000
2025-07-28 05:16:51,947 - INFO - ============================================================

2025-07-28 05:16:51,962 - INFO - eagle-3b-preview_harness_12: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 05:16:51,964 - INFO - [Process 1811658] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/eagle-3b-preview/eagle-3b-preview_harness_12.json
2025-07-28 05:16:52,236 - INFO - Results uploaded to WandB as artifact
2025-07-28 05:16:52,247 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 05:16:52,249 - INFO - [Process 1811658] Successfully completed eagle-3b-preview_harness_12
2025-07-28 05:16:55,112 - INFO - Run eagle-3b-preview_harness_12 finished successfully
2025-07-28 05:16:56,490 - INFO - Processing 3 large models with single GPU
2025-07-28 05:16:56,491 - INFO - [Process 1795506] gemma-3-12b-it_harness_3 assigned to cuda:0
2025-07-28 05:16:56,492 - INFO - [Process 1795506] gemma-3-12b-it_harness_3 - using custom limit: 20
2025-07-28 05:16:57,747 - INFO - WandB run initialized: gemma-3-12b-it_20250728_051656 (ID: 8a9e3e52)
2025-07-28 05:16:59,453 - INFO - gemma-3-12b-it_harness_3: Gemma settings applied - max_gen_toks=256
2025-07-28 05:16:59,454 - INFO - gemma-3-12b-it_harness_3: Test mode (limit=2), setting num_fewshot=0
2025-07-28 05:16:59,454 - INFO - GPU memory available: 79.3GB
2025-07-28 05:16:59,454 - INFO - gemma-3-12b-it_harness_3: Using 8bit=True, batch_size=1
2025-07-28 05:16:59,455 - INFO - gemma-3-12b-it_harness_3: Gemma model detected, will handle cache settings after loading
2025-07-28 05:17:23,130 - INFO - gemma-3-12b-it_harness_3: Processing task 1/10: kmmlu
2025-07-28 05:17:23,131 - INFO - gemma-3-12b-it_harness_3: Task 'kmmlu' will use num_fewshot=0
2025-07-28 05:17:23,131 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 05:17:23,131 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:18:33,273 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 05:18:33,274 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 05:18:33,274 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 05:18:33,274 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 05:18:33,274 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 05:18:33,274 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 05:18:33,274 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 05:18:33,274 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 05:18:33,275 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 05:18:33,276 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 05:18:33,277 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 05:18:33,278 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 05:18:33,278 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 05:18:33,278 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 05:23:56,689 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 05:23:56,691 - INFO - 
============================================================
2025-07-28 05:23:56,692 - INFO - Task 'kmmlu' Results:
2025-07-28 05:23:56,693 - INFO - ============================================================
2025-07-28 05:23:56,693 - INFO -   kmmlu:
2025-07-28 05:23:56,694 - INFO -     - accuracy: 0.3733
2025-07-28 05:23:56,694 - INFO -   kmmlu_applied_science:
2025-07-28 05:23:56,694 - INFO -     - accuracy: 0.3250
2025-07-28 05:23:56,694 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 05:23:56,695 - INFO -     - accuracy: 0.3500
2025-07-28 05:23:56,695 - INFO -   kmmlu_electronics_engineering:
2025-07-28 05:23:56,695 - INFO -     - accuracy: 0.6500
2025-07-28 05:23:56,695 - INFO -   kmmlu_energy_management:
2025-07-28 05:23:56,695 - INFO -     - accuracy: 0.1000
2025-07-28 05:23:56,696 - INFO -   kmmlu_environmental_science:
2025-07-28 05:23:56,696 - INFO -     - accuracy: 0.3000
2025-07-28 05:23:56,696 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 05:23:56,697 - INFO -     - accuracy: 0.3000
2025-07-28 05:23:56,697 - INFO -   kmmlu_geomatics:
2025-07-28 05:23:56,697 - INFO -     - accuracy: 0.3000
2025-07-28 05:23:56,698 - INFO -   kmmlu_industrial_engineer:
2025-07-28 05:23:56,698 - INFO -     - accuracy: 0.3000
2025-07-28 05:23:56,698 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 05:23:56,698 - INFO -     - accuracy: 0.3000
2025-07-28 05:23:56,698 - INFO -   kmmlu_maritime_engineering:
2025-07-28 05:23:56,698 - INFO -     - accuracy: 0.3000
2025-07-28 05:23:56,698 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 05:23:56,698 - INFO -     - accuracy: 0.3500
2025-07-28 05:23:56,699 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 05:23:56,699 - INFO -     - accuracy: 0.2500
2025-07-28 05:23:56,699 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 05:23:56,699 - INFO -     - accuracy: 0.4000
2025-07-28 05:23:56,699 - INFO -   kmmlu_humss:
2025-07-28 05:23:56,699 - INFO -     - accuracy: 0.4682
2025-07-28 05:23:56,699 - INFO -   kmmlu_accounting:
2025-07-28 05:23:56,699 - INFO -     - accuracy: 0.5000
2025-07-28 05:23:56,699 - INFO -   kmmlu_criminal_law:
2025-07-28 05:23:56,700 - INFO -     - accuracy: 0.2500
2025-07-28 05:23:56,700 - INFO -   kmmlu_economics:
2025-07-28 05:23:56,700 - INFO -     - accuracy: 0.7500
2025-07-28 05:23:56,700 - INFO -   kmmlu_education:
2025-07-28 05:23:56,700 - INFO -     - accuracy: 0.5500
2025-07-28 05:23:56,700 - INFO -   kmmlu_korean_history:
2025-07-28 05:23:56,700 - INFO -     - accuracy: 0.2500
2025-07-28 05:23:56,700 - INFO -   kmmlu_law:
2025-07-28 05:23:56,700 - INFO -     - accuracy: 0.1000
2025-07-28 05:23:56,701 - INFO -   kmmlu_management:
2025-07-28 05:23:56,701 - INFO -     - accuracy: 0.6000
2025-07-28 05:23:56,701 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 05:23:56,701 - INFO -     - accuracy: 0.9000
2025-07-28 05:23:56,701 - INFO -   kmmlu_psychology:
2025-07-28 05:23:56,701 - INFO -     - accuracy: 0.3000
2025-07-28 05:23:56,701 - INFO -   kmmlu_social_welfare:
2025-07-28 05:23:56,701 - INFO -     - accuracy: 0.4500
2025-07-28 05:23:56,715 - INFO -   kmmlu_taxation:
2025-07-28 05:23:56,715 - INFO -     - accuracy: 0.5000
2025-07-28 05:23:56,715 - INFO -   kmmlu_other:
2025-07-28 05:23:56,715 - INFO -     - accuracy: 0.3409
2025-07-28 05:23:56,716 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 05:23:56,716 - INFO -     - accuracy: 0.1000
2025-07-28 05:23:56,716 - INFO -   kmmlu_construction:
2025-07-28 05:23:56,716 - INFO -     - accuracy: 0.3500
2025-07-28 05:23:56,716 - INFO -   kmmlu_fashion:
2025-07-28 05:23:56,716 - INFO -     - accuracy: 0.1000
2025-07-28 05:23:56,716 - INFO -   kmmlu_food_processing:
2025-07-28 05:23:56,716 - INFO -     - accuracy: 0.4500
2025-07-28 05:23:56,717 - INFO -   kmmlu_health:
2025-07-28 05:23:56,717 - INFO -     - accuracy: 0.6500
2025-07-28 05:23:56,717 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 05:23:56,717 - INFO -     - accuracy: 0.7000
2025-07-28 05:23:56,717 - INFO -   kmmlu_marketing:
2025-07-28 05:23:56,717 - INFO -     - accuracy: 0.5000
2025-07-28 05:23:56,717 - INFO -   kmmlu_patent:
2025-07-28 05:23:56,717 - INFO -     - accuracy: 0.1500
2025-07-28 05:23:56,717 - INFO -   kmmlu_public_safety:
2025-07-28 05:23:56,718 - INFO -     - accuracy: 0.3000
2025-07-28 05:23:56,718 - INFO -   kmmlu_real_estate:
2025-07-28 05:23:56,718 - INFO -     - accuracy: 0.2500
2025-07-28 05:23:56,718 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 05:23:56,718 - INFO -     - accuracy: 0.2000
2025-07-28 05:23:56,718 - INFO -   kmmlu_stem:
2025-07-28 05:23:56,718 - INFO -     - accuracy: 0.3636
2025-07-28 05:23:56,718 - INFO -   kmmlu_biology:
2025-07-28 05:23:56,718 - INFO -     - accuracy: 0.2500
2025-07-28 05:23:56,719 - INFO -   kmmlu_chemical_engineering:
2025-07-28 05:23:56,719 - INFO -     - accuracy: 0.2500
2025-07-28 05:23:56,719 - INFO -   kmmlu_chemistry:
2025-07-28 05:23:56,719 - INFO -     - accuracy: 0.4500
2025-07-28 05:23:56,719 - INFO -   kmmlu_civil_engineering:
2025-07-28 05:23:56,719 - INFO -     - accuracy: 0.3500
2025-07-28 05:23:56,719 - INFO -   kmmlu_computer_science:
2025-07-28 05:23:56,719 - INFO -     - accuracy: 0.6000
2025-07-28 05:23:56,720 - INFO -   kmmlu_ecology:
2025-07-28 05:23:56,720 - INFO -     - accuracy: 0.4000
2025-07-28 05:23:56,720 - INFO -   kmmlu_electrical_engineering:
2025-07-28 05:23:56,720 - INFO -     - accuracy: 0.2000
2025-07-28 05:23:56,720 - INFO -   kmmlu_information_technology:
2025-07-28 05:23:56,720 - INFO -     - accuracy: 0.5500
2025-07-28 05:23:56,720 - INFO -   kmmlu_materials_engineering:
2025-07-28 05:23:56,720 - INFO -     - accuracy: 0.4000
2025-07-28 05:23:56,720 - INFO -   kmmlu_math:
2025-07-28 05:23:56,721 - INFO -     - accuracy: 0.2000
2025-07-28 05:23:56,721 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 05:23:56,721 - INFO -     - accuracy: 0.3500
2025-07-28 05:23:56,721 - INFO - ============================================================

2025-07-28 05:23:56,726 - INFO - gemma-3-12b-it_harness_3: Processing task 2/10: kmmlu_hard
2025-07-28 05:23:56,726 - INFO - gemma-3-12b-it_harness_3: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 05:23:56,726 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 05:23:56,727 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:25:10,495 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 05:25:10,495 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 05:25:10,495 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 05:25:10,495 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 05:25:10,495 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 05:25:10,496 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 05:25:10,497 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 05:25:10,498 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 05:25:10,499 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 05:25:10,499 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 05:25:10,499 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 05:25:10,499 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 05:25:10,499 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 05:25:10,499 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 05:30:32,092 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 05:30:32,094 - INFO - 
============================================================
2025-07-28 05:30:32,095 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 05:30:32,096 - INFO - ============================================================
2025-07-28 05:30:32,096 - INFO -   kmmlu_hard:
2025-07-28 05:30:32,096 - INFO -     - accuracy: 0.2567
2025-07-28 05:30:32,097 - INFO -   kmmlu_hard_applied_science:
2025-07-28 05:30:32,097 - INFO -     - accuracy: 0.2542
2025-07-28 05:30:32,097 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 05:30:32,097 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,097 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 05:30:32,097 - INFO -     - accuracy: 0.2000
2025-07-28 05:30:32,097 - INFO -   kmmlu_hard_energy_management:
2025-07-28 05:30:32,097 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,098 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 05:30:32,098 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,098 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 05:30:32,098 - INFO -     - accuracy: 0.1000
2025-07-28 05:30:32,098 - INFO -   kmmlu_hard_geomatics:
2025-07-28 05:30:32,098 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,098 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 05:30:32,098 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,099 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 05:30:32,099 - INFO -     - accuracy: 0.3000
2025-07-28 05:30:32,099 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 05:30:32,099 - INFO -     - accuracy: 0.4000
2025-07-28 05:30:32,099 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 05:30:32,099 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,099 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 05:30:32,099 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,099 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 05:30:32,099 - INFO -     - accuracy: 0.3000
2025-07-28 05:30:32,100 - INFO -   kmmlu_hard_humss:
2025-07-28 05:30:32,100 - INFO -     - accuracy: 0.2364
2025-07-28 05:30:32,100 - INFO -   kmmlu_hard_accounting:
2025-07-28 05:30:32,100 - INFO -     - accuracy: 0.3000
2025-07-28 05:30:32,100 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 05:30:32,100 - INFO -     - accuracy: 0.1500
2025-07-28 05:30:32,100 - INFO -   kmmlu_hard_economics:
2025-07-28 05:30:32,100 - INFO -     - accuracy: 0.2000
2025-07-28 05:30:32,100 - INFO -   kmmlu_hard_education:
2025-07-28 05:30:32,100 - INFO -     - accuracy: 0.2000
2025-07-28 05:30:32,100 - INFO -   kmmlu_hard_korean_history:
2025-07-28 05:30:32,101 - INFO -     - accuracy: 0.1000
2025-07-28 05:30:32,101 - INFO -   kmmlu_hard_law:
2025-07-28 05:30:32,101 - INFO -     - accuracy: 0.2000
2025-07-28 05:30:32,101 - INFO -   kmmlu_hard_management:
2025-07-28 05:30:32,101 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,101 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 05:30:32,101 - INFO -     - accuracy: 0.3500
2025-07-28 05:30:32,101 - INFO -   kmmlu_hard_psychology:
2025-07-28 05:30:32,101 - INFO -     - accuracy: 0.1500
2025-07-28 05:30:32,102 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 05:30:32,102 - INFO -     - accuracy: 0.3500
2025-07-28 05:30:32,102 - INFO -   kmmlu_hard_taxation:
2025-07-28 05:30:32,102 - INFO -     - accuracy: 0.3500
2025-07-28 05:30:32,102 - INFO -   kmmlu_hard_other:
2025-07-28 05:30:32,102 - INFO -     - accuracy: 0.2636
2025-07-28 05:30:32,102 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 05:30:32,102 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,103 - INFO -   kmmlu_hard_construction:
2025-07-28 05:30:32,103 - INFO -     - accuracy: 0.3000
2025-07-28 05:30:32,103 - INFO -   kmmlu_hard_fashion:
2025-07-28 05:30:32,103 - INFO -     - accuracy: 0.3000
2025-07-28 05:30:32,103 - INFO -   kmmlu_hard_food_processing:
2025-07-28 05:30:32,103 - INFO -     - accuracy: 0.2000
2025-07-28 05:30:32,103 - INFO -   kmmlu_hard_health:
2025-07-28 05:30:32,103 - INFO -     - accuracy: 0.1000
2025-07-28 05:30:32,103 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 05:30:32,103 - INFO -     - accuracy: 0.3500
2025-07-28 05:30:32,104 - INFO -   kmmlu_hard_marketing:
2025-07-28 05:30:32,104 - INFO -     - accuracy: 0.5000
2025-07-28 05:30:32,104 - INFO -   kmmlu_hard_patent:
2025-07-28 05:30:32,104 - INFO -     - accuracy: 0.1500
2025-07-28 05:30:32,104 - INFO -   kmmlu_hard_public_safety:
2025-07-28 05:30:32,104 - INFO -     - accuracy: 0.2000
2025-07-28 05:30:32,104 - INFO -   kmmlu_hard_real_estate:
2025-07-28 05:30:32,104 - INFO -     - accuracy: 0.4000
2025-07-28 05:30:32,104 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 05:30:32,105 - INFO -     - accuracy: 0.1500
2025-07-28 05:30:32,105 - INFO -   kmmlu_hard_stem:
2025-07-28 05:30:32,105 - INFO -     - accuracy: 0.2727
2025-07-28 05:30:32,105 - INFO -   kmmlu_hard_biology:
2025-07-28 05:30:32,105 - INFO -     - accuracy: 0.3000
2025-07-28 05:30:32,105 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 05:30:32,105 - INFO -     - accuracy: 0.1000
2025-07-28 05:30:32,105 - INFO -   kmmlu_hard_chemistry:
2025-07-28 05:30:32,105 - INFO -     - accuracy: 0.5000
2025-07-28 05:30:32,106 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 05:30:32,106 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,106 - INFO -   kmmlu_hard_computer_science:
2025-07-28 05:30:32,106 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,106 - INFO -   kmmlu_hard_ecology:
2025-07-28 05:30:32,106 - INFO -     - accuracy: 0.2000
2025-07-28 05:30:32,106 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 05:30:32,106 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,106 - INFO -   kmmlu_hard_information_technology:
2025-07-28 05:30:32,107 - INFO -     - accuracy: 0.4500
2025-07-28 05:30:32,107 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 05:30:32,107 - INFO -     - accuracy: 0.1500
2025-07-28 05:30:32,107 - INFO -   kmmlu_hard_math:
2025-07-28 05:30:32,107 - INFO -     - accuracy: 0.3000
2025-07-28 05:30:32,107 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 05:30:32,107 - INFO -     - accuracy: 0.2500
2025-07-28 05:30:32,107 - INFO - ============================================================

2025-07-28 05:30:32,112 - INFO - gemma-3-12b-it_harness_3: Processing task 3/10: haerae
2025-07-28 05:30:32,112 - INFO - gemma-3-12b-it_harness_3: Task 'haerae' will use num_fewshot=0
2025-07-28 05:30:32,112 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 05:30:32,113 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:30:47,789 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 05:30:47,789 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 05:30:47,789 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 05:30:47,789 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 05:30:47,789 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 05:33:44,817 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 05:33:44,818 - INFO - 
============================================================
2025-07-28 05:33:44,819 - INFO - Task 'haerae' Results:
2025-07-28 05:33:44,821 - INFO - ============================================================
2025-07-28 05:33:44,821 - INFO -   haerae:
2025-07-28 05:33:44,821 - INFO -     - accuracy: 0.8100
2025-07-28 05:33:44,821 - INFO -     - accuracy_norm: 0.8100
2025-07-28 05:33:44,822 - INFO -   haerae_general_knowledge:
2025-07-28 05:33:44,822 - INFO -     - accuracy: 0.8500
2025-07-28 05:33:44,822 - INFO -     - accuracy_norm: 0.8500
2025-07-28 05:33:44,822 - INFO -   haerae_history:
2025-07-28 05:33:44,822 - INFO -     - accuracy: 0.7500
2025-07-28 05:33:44,822 - INFO -     - accuracy_norm: 0.7500
2025-07-28 05:33:44,823 - INFO -   haerae_loan_word:
2025-07-28 05:33:44,823 - INFO -     - accuracy: 0.9000
2025-07-28 05:33:44,823 - INFO -     - accuracy_norm: 0.9000
2025-07-28 05:33:44,823 - INFO -   haerae_rare_word:
2025-07-28 05:33:44,823 - INFO -     - accuracy: 0.7500
2025-07-28 05:33:44,823 - INFO -     - accuracy_norm: 0.7500
2025-07-28 05:33:44,823 - INFO -   haerae_standard_nomenclature:
2025-07-28 05:33:44,823 - INFO -     - accuracy: 0.8000
2025-07-28 05:33:44,823 - INFO -     - accuracy_norm: 0.8000
2025-07-28 05:33:44,824 - INFO - ============================================================

2025-07-28 05:33:44,827 - INFO - gemma-3-12b-it_harness_3: Processing task 4/10: kobest
2025-07-28 05:33:44,827 - INFO - gemma-3-12b-it_harness_3: Task 'kobest' will use num_fewshot=0
2025-07-28 05:33:44,827 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 05:33:44,828 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:34:02,936 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 05:34:02,937 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 05:34:02,937 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 05:34:02,937 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 05:34:02,937 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 05:35:25,382 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 05:35:25,384 - INFO - 
============================================================
2025-07-28 05:35:25,385 - INFO - Task 'kobest' Results:
2025-07-28 05:35:25,386 - INFO - ============================================================
2025-07-28 05:35:25,386 - INFO -   kobest:
2025-07-28 05:35:25,387 - INFO -     - accuracy: 0.7200
2025-07-28 05:35:25,387 - INFO -     - accuracy_norm: 0.7000
2025-07-28 05:35:25,387 - INFO -     - f1: 0.6822
2025-07-28 05:35:25,387 - INFO -   kobest_boolq:
2025-07-28 05:35:25,387 - INFO -     - accuracy: 0.9000
2025-07-28 05:35:25,387 - INFO -     - f1: 0.8958
2025-07-28 05:35:25,387 - INFO -   kobest_copa:
2025-07-28 05:35:25,387 - INFO -     - accuracy: 0.7500
2025-07-28 05:35:25,387 - INFO -     - f1: 0.7494
2025-07-28 05:35:25,388 - INFO -   kobest_hellaswag:
2025-07-28 05:35:25,388 - INFO -     - accuracy: 0.4500
2025-07-28 05:35:25,388 - INFO -     - accuracy_norm: 0.7000
2025-07-28 05:35:25,388 - INFO -     - f1: 0.4623
2025-07-28 05:35:25,388 - INFO -   kobest_sentineg:
2025-07-28 05:35:25,388 - INFO -     - accuracy: 0.9500
2025-07-28 05:35:25,388 - INFO -     - f1: 0.9488
2025-07-28 05:35:25,388 - INFO -   kobest_wic:
2025-07-28 05:35:25,388 - INFO -     - accuracy: 0.5500
2025-07-28 05:35:25,389 - INFO -     - f1: 0.3548
2025-07-28 05:35:25,389 - INFO - ============================================================

2025-07-28 05:35:25,392 - INFO - gemma-3-12b-it_harness_3: Processing task 5/10: csatqa
2025-07-28 05:35:25,392 - INFO - gemma-3-12b-it_harness_3: Task 'csatqa' detected as zero-shot task
2025-07-28 05:35:25,392 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 05:35:25,393 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:35:37,024 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 05:35:37,024 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 05:35:37,025 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 05:35:37,025 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 05:35:37,025 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 05:35:37,025 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 05:40:14,835 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 05:40:14,839 - INFO - 
============================================================
2025-07-28 05:40:14,840 - INFO - Task 'csatqa' Results:
2025-07-28 05:40:14,840 - INFO - ============================================================
2025-07-28 05:40:14,840 - INFO -   csatqa:
2025-07-28 05:40:14,840 - INFO -     - accuracy: 0.4775
2025-07-28 05:40:14,840 - INFO -     - accuracy_norm: 0.4775
2025-07-28 05:40:14,841 - INFO -   csatqa_gr:
2025-07-28 05:40:14,841 - INFO -     - accuracy: 0.2500
2025-07-28 05:40:14,841 - INFO -     - accuracy_norm: 0.2500
2025-07-28 05:40:14,841 - INFO -   csatqa_li:
2025-07-28 05:40:14,841 - INFO -     - accuracy: 0.4500
2025-07-28 05:40:14,841 - INFO -     - accuracy_norm: 0.4500
2025-07-28 05:40:14,842 - INFO -   csatqa_rch:
2025-07-28 05:40:14,842 - INFO -     - accuracy: 0.6000
2025-07-28 05:40:14,842 - INFO -     - accuracy_norm: 0.6000
2025-07-28 05:40:14,843 - INFO -   csatqa_rcs:
2025-07-28 05:40:14,843 - INFO -     - accuracy: 0.5500
2025-07-28 05:40:14,843 - INFO -     - accuracy_norm: 0.5500
2025-07-28 05:40:14,843 - INFO -   csatqa_rcss:
2025-07-28 05:40:14,843 - INFO -     - accuracy: 0.5500
2025-07-28 05:40:14,843 - INFO -     - accuracy_norm: 0.5500
2025-07-28 05:40:14,843 - INFO -   csatqa_wr:
2025-07-28 05:40:14,843 - INFO -     - accuracy: 0.4545
2025-07-28 05:40:14,843 - INFO -     - accuracy_norm: 0.4545
2025-07-28 05:40:14,844 - INFO - ============================================================

2025-07-28 05:40:14,858 - INFO - gemma-3-12b-it_harness_3: Processing task 6/10: kormedmcqa
2025-07-28 05:40:14,858 - INFO - gemma-3-12b-it_harness_3: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 05:40:14,858 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 05:40:14,859 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:40:32,644 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 05:40:32,645 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 05:40:32,645 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 05:40:32,645 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 05:42:26,093 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 05:42:26,096 - INFO - 
============================================================
2025-07-28 05:42:26,097 - INFO - Task 'kormedmcqa' Results:
2025-07-28 05:42:26,099 - INFO - ============================================================
2025-07-28 05:42:26,099 - INFO -   kormedmcqa:
2025-07-28 05:42:26,099 - INFO -     - exact_match: 0.5875
2025-07-28 05:42:26,100 - INFO -   kormedmcqa_dentist:
2025-07-28 05:42:26,101 - INFO -     - exact_match: 0.5000
2025-07-28 05:42:26,101 - INFO -   kormedmcqa_doctor:
2025-07-28 05:42:26,101 - INFO -     - exact_match: 0.5000
2025-07-28 05:42:26,102 - INFO -   kormedmcqa_nurse:
2025-07-28 05:42:26,102 - INFO -     - exact_match: 0.9500
2025-07-28 05:42:26,102 - INFO -   kormedmcqa_pharm:
2025-07-28 05:42:26,103 - INFO -     - exact_match: 0.4000
2025-07-28 05:42:26,103 - INFO - ============================================================

2025-07-28 05:42:26,105 - INFO - gemma-3-12b-it_harness_3: Processing task 7/10: mmlu
2025-07-28 05:42:26,105 - INFO - gemma-3-12b-it_harness_3: Task 'mmlu' will use num_fewshot=0
2025-07-28 05:42:26,105 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 05:42:26,106 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:45:10,119 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 05:45:10,120 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 05:45:10,120 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 05:45:10,120 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 05:45:10,120 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 05:45:10,120 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 05:45:10,120 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 05:45:10,120 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 05:45:10,120 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 05:45:10,120 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 05:45:10,120 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 05:45:10,121 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 05:45:10,122 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 05:45:10,123 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 05:45:10,124 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 05:45:10,125 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 05:51:42,498 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 05:51:42,499 - INFO - 
============================================================
2025-07-28 05:51:42,501 - INFO - Task 'mmlu' Results:
2025-07-28 05:51:42,502 - INFO - ============================================================
2025-07-28 05:51:42,502 - INFO -   mmlu:
2025-07-28 05:51:42,502 - INFO -     - accuracy: 0.7386
2025-07-28 05:51:42,503 - INFO -   mmlu_humanities:
2025-07-28 05:51:42,503 - INFO -     - accuracy: 0.7577
2025-07-28 05:51:42,503 - INFO -   mmlu_formal_logic:
2025-07-28 05:51:42,503 - INFO -     - accuracy: 0.6500
2025-07-28 05:51:42,503 - INFO -   mmlu_high_school_european_history:
2025-07-28 05:51:42,503 - INFO -     - accuracy: 0.8000
2025-07-28 05:51:42,503 - INFO -   mmlu_high_school_us_history:
2025-07-28 05:51:42,503 - INFO -     - accuracy: 0.8000
2025-07-28 05:51:42,504 - INFO -   mmlu_high_school_world_history:
2025-07-28 05:51:42,504 - INFO -     - accuracy: 0.9500
2025-07-28 05:51:42,504 - INFO -   mmlu_international_law:
2025-07-28 05:51:42,504 - INFO -     - accuracy: 0.8500
2025-07-28 05:51:42,504 - INFO -   mmlu_jurisprudence:
2025-07-28 05:51:42,504 - INFO -     - accuracy: 0.8000
2025-07-28 05:51:42,504 - INFO -   mmlu_logical_fallacies:
2025-07-28 05:51:42,504 - INFO -     - accuracy: 0.9000
2025-07-28 05:51:42,504 - INFO -   mmlu_moral_disputes:
2025-07-28 05:51:42,505 - INFO -     - accuracy: 0.7500
2025-07-28 05:51:42,505 - INFO -   mmlu_moral_scenarios:
2025-07-28 05:51:42,505 - INFO -     - accuracy: 0.2000
2025-07-28 05:51:42,505 - INFO -   mmlu_philosophy:
2025-07-28 05:51:42,505 - INFO -     - accuracy: 0.9000
2025-07-28 05:51:42,506 - INFO -   mmlu_prehistory:
2025-07-28 05:51:42,506 - INFO -     - accuracy: 0.7000
2025-07-28 05:51:42,507 - INFO -   mmlu_professional_law:
2025-07-28 05:51:42,507 - INFO -     - accuracy: 0.7500
2025-07-28 05:51:42,507 - INFO -   mmlu_world_religions:
2025-07-28 05:51:42,507 - INFO -     - accuracy: 0.8000
2025-07-28 05:51:42,507 - INFO -   mmlu_other:
2025-07-28 05:51:42,507 - INFO -     - accuracy: 0.7462
2025-07-28 05:51:42,508 - INFO -   mmlu_business_ethics:
2025-07-28 05:51:42,508 - INFO -     - accuracy: 0.7500
2025-07-28 05:51:42,508 - INFO -   mmlu_clinical_knowledge:
2025-07-28 05:51:42,508 - INFO -     - accuracy: 0.8500
2025-07-28 05:51:42,508 - INFO -   mmlu_college_medicine:
2025-07-28 05:51:42,508 - INFO -     - accuracy: 0.8000
2025-07-28 05:51:42,508 - INFO -   mmlu_global_facts:
2025-07-28 05:51:42,508 - INFO -     - accuracy: 0.4500
2025-07-28 05:51:42,509 - INFO -   mmlu_human_aging:
2025-07-28 05:51:42,509 - INFO -     - accuracy: 0.7000
2025-07-28 05:51:42,509 - INFO -   mmlu_management:
2025-07-28 05:51:42,509 - INFO -     - accuracy: 0.8000
2025-07-28 05:51:42,509 - INFO -   mmlu_marketing:
2025-07-28 05:51:42,509 - INFO -     - accuracy: 0.9500
2025-07-28 05:51:42,509 - INFO -   mmlu_medical_genetics:
2025-07-28 05:51:42,509 - INFO -     - accuracy: 0.9500
2025-07-28 05:51:42,509 - INFO -   mmlu_miscellaneous:
2025-07-28 05:51:42,510 - INFO -     - accuracy: 0.8500
2025-07-28 05:51:42,510 - INFO -   mmlu_nutrition:
2025-07-28 05:51:42,510 - INFO -     - accuracy: 0.7500
2025-07-28 05:51:42,510 - INFO -   mmlu_professional_accounting:
2025-07-28 05:51:42,510 - INFO -     - accuracy: 0.4500
2025-07-28 05:51:42,510 - INFO -   mmlu_professional_medicine:
2025-07-28 05:51:42,510 - INFO -     - accuracy: 0.8000
2025-07-28 05:51:42,510 - INFO -   mmlu_virology:
2025-07-28 05:51:42,510 - INFO -     - accuracy: 0.6000
2025-07-28 05:51:42,511 - INFO -   mmlu_social_sciences:
2025-07-28 05:51:42,511 - INFO -     - accuracy: 0.8000
2025-07-28 05:51:42,511 - INFO -   mmlu_econometrics:
2025-07-28 05:51:42,511 - INFO -     - accuracy: 0.5000
2025-07-28 05:51:42,511 - INFO -   mmlu_high_school_geography:
2025-07-28 05:51:42,511 - INFO -     - accuracy: 0.9500
2025-07-28 05:51:42,511 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 05:51:42,511 - INFO -     - accuracy: 0.8500
2025-07-28 05:51:42,511 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 05:51:42,512 - INFO -     - accuracy: 0.8500
2025-07-28 05:51:42,512 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 05:51:42,512 - INFO -     - accuracy: 0.6500
2025-07-28 05:51:42,512 - INFO -   mmlu_high_school_psychology:
2025-07-28 05:51:42,512 - INFO -     - accuracy: 0.9500
2025-07-28 05:51:42,512 - INFO -   mmlu_human_sexuality:
2025-07-28 05:51:42,512 - INFO -     - accuracy: 0.8500
2025-07-28 05:51:42,512 - INFO -   mmlu_professional_psychology:
2025-07-28 05:51:42,512 - INFO -     - accuracy: 0.9000
2025-07-28 05:51:42,513 - INFO -   mmlu_public_relations:
2025-07-28 05:51:42,513 - INFO -     - accuracy: 0.6000
2025-07-28 05:51:42,513 - INFO -   mmlu_security_studies:
2025-07-28 05:51:42,513 - INFO -     - accuracy: 0.8000
2025-07-28 05:51:42,513 - INFO -   mmlu_sociology:
2025-07-28 05:51:42,513 - INFO -     - accuracy: 0.7500
2025-07-28 05:51:42,513 - INFO -   mmlu_us_foreign_policy:
2025-07-28 05:51:42,513 - INFO -     - accuracy: 0.9500
2025-07-28 05:51:42,513 - INFO -   mmlu_stem:
2025-07-28 05:51:42,514 - INFO -     - accuracy: 0.6816
2025-07-28 05:51:42,514 - INFO -   mmlu_abstract_algebra:
2025-07-28 05:51:42,514 - INFO -     - accuracy: 0.3500
2025-07-28 05:51:42,514 - INFO -   mmlu_anatomy:
2025-07-28 05:51:42,514 - INFO -     - accuracy: 0.8500
2025-07-28 05:51:42,514 - INFO -   mmlu_astronomy:
2025-07-28 05:51:42,514 - INFO -     - accuracy: 0.9000
2025-07-28 05:51:42,514 - INFO -   mmlu_college_biology:
2025-07-28 05:51:42,514 - INFO -     - accuracy: 0.9500
2025-07-28 05:51:42,515 - INFO -   mmlu_college_chemistry:
2025-07-28 05:51:42,515 - INFO -     - accuracy: 0.3500
2025-07-28 05:51:42,515 - INFO -   mmlu_college_computer_science:
2025-07-28 05:51:42,515 - INFO -     - accuracy: 0.5500
2025-07-28 05:51:42,515 - INFO -   mmlu_college_mathematics:
2025-07-28 05:51:42,515 - INFO -     - accuracy: 0.4500
2025-07-28 05:51:42,515 - INFO -   mmlu_college_physics:
2025-07-28 05:51:42,515 - INFO -     - accuracy: 0.7000
2025-07-28 05:51:42,515 - INFO -   mmlu_computer_security:
2025-07-28 05:51:42,516 - INFO -     - accuracy: 0.8000
2025-07-28 05:51:42,516 - INFO -   mmlu_conceptual_physics:
2025-07-28 05:51:42,516 - INFO -     - accuracy: 0.9500
2025-07-28 05:51:42,516 - INFO -   mmlu_electrical_engineering:
2025-07-28 05:51:42,516 - INFO -     - accuracy: 0.6500
2025-07-28 05:51:42,516 - INFO -   mmlu_elementary_mathematics:
2025-07-28 05:51:42,516 - INFO -     - accuracy: 0.7500
2025-07-28 05:51:42,516 - INFO -   mmlu_high_school_biology:
2025-07-28 05:51:42,516 - INFO -     - accuracy: 0.9000
2025-07-28 05:51:42,517 - INFO -   mmlu_high_school_chemistry:
2025-07-28 05:51:42,517 - INFO -     - accuracy: 0.9000
2025-07-28 05:51:42,517 - INFO -   mmlu_high_school_computer_science:
2025-07-28 05:51:42,517 - INFO -     - accuracy: 0.8500
2025-07-28 05:51:42,517 - INFO -   mmlu_high_school_mathematics:
2025-07-28 05:51:42,517 - INFO -     - accuracy: 0.4000
2025-07-28 05:51:42,517 - INFO -   mmlu_high_school_physics:
2025-07-28 05:51:42,517 - INFO -     - accuracy: 0.5000
2025-07-28 05:51:42,517 - INFO -   mmlu_high_school_statistics:
2025-07-28 05:51:42,518 - INFO -     - accuracy: 0.7000
2025-07-28 05:51:42,518 - INFO -   mmlu_machine_learning:
2025-07-28 05:51:42,518 - INFO -     - accuracy: 0.4500
2025-07-28 05:51:42,518 - INFO - ============================================================

2025-07-28 05:51:42,524 - INFO - gemma-3-12b-it_harness_3: Processing task 8/10: arc_challenge
2025-07-28 05:51:42,524 - INFO - gemma-3-12b-it_harness_3: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 05:51:42,524 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 05:51:42,525 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:51:49,205 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 05:52:15,818 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 05:52:15,820 - INFO - 
============================================================
2025-07-28 05:52:15,821 - INFO - Task 'arc_challenge' Results:
2025-07-28 05:52:15,823 - INFO - ============================================================
2025-07-28 05:52:15,824 - INFO -   arc_challenge:
2025-07-28 05:52:15,824 - INFO -     - accuracy: 0.6500
2025-07-28 05:52:15,824 - INFO -     - accuracy_norm: 0.7000
2025-07-28 05:52:15,824 - INFO - ============================================================

2025-07-28 05:52:15,826 - INFO - gemma-3-12b-it_harness_3: Processing task 9/10: arc_easy
2025-07-28 05:52:15,826 - INFO - gemma-3-12b-it_harness_3: Task 'arc_easy' will use num_fewshot=0
2025-07-28 05:52:15,826 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 05:52:15,827 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:52:21,974 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 05:52:48,684 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 05:52:48,686 - INFO - 
============================================================
2025-07-28 05:52:48,687 - INFO - Task 'arc_easy' Results:
2025-07-28 05:52:48,689 - INFO - ============================================================
2025-07-28 05:52:48,689 - INFO -   arc_easy:
2025-07-28 05:52:48,689 - INFO -     - accuracy: 0.8000
2025-07-28 05:52:48,690 - INFO -     - accuracy_norm: 0.5500
2025-07-28 05:52:48,690 - INFO - ============================================================

2025-07-28 05:52:48,691 - INFO - gemma-3-12b-it_harness_3: Processing task 10/10: hellaswag
2025-07-28 05:52:48,691 - INFO - gemma-3-12b-it_harness_3: Task 'hellaswag' will use num_fewshot=0
2025-07-28 05:52:48,692 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 05:52:48,692 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:53:02,034 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 05:53:31,335 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 05:53:31,337 - INFO - 
============================================================
2025-07-28 05:53:31,338 - INFO - Task 'hellaswag' Results:
2025-07-28 05:53:31,340 - INFO - ============================================================
2025-07-28 05:53:31,342 - INFO -   hellaswag:
2025-07-28 05:53:31,342 - INFO -     - accuracy: 0.6000
2025-07-28 05:53:31,342 - INFO -     - accuracy_norm: 0.8000
2025-07-28 05:53:31,343 - INFO - ============================================================

2025-07-28 05:53:31,344 - INFO - gemma-3-12b-it_harness_3: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 05:53:31,346 - INFO - [Process 1795506] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_032724/model_results/gemma-3-12b-it/gemma-3-12b-it_harness_3.json
2025-07-28 05:53:31,347 - INFO - [Process 1795506] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/gemma-3-12b-it/gemma-3-12b-it_harness_3.json
2025-07-28 05:53:31,622 - INFO - Results uploaded to WandB as artifact
2025-07-28 05:53:31,631 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 05:53:31,633 - INFO - [Process 1795506] Successfully completed gemma-3-12b-it_harness_3
2025-07-28 05:53:33,646 - INFO - Run gemma-3-12b-it_harness_3 finished successfully
2025-07-28 05:53:33,648 - INFO - [Process 1795506] EXAONE-3.5-32B-Instruct_harness_8 assigned to cuda:0
2025-07-28 05:53:33,649 - INFO - [Process 1795506] EXAONE-3.5-32B-Instruct_harness_8 - using custom limit: 20
2025-07-28 05:53:34,941 - INFO - WandB run initialized: EXAONE-3.5-32B-Instruct_20250728_055333 (ID: 36f11146)
2025-07-28 05:53:35,163 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Test mode (limit=2), setting num_fewshot=0
2025-07-28 05:53:35,195 - INFO - GPU memory available: 79.3GB
2025-07-28 05:53:35,195 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Using 8bit=True, batch_size=1
2025-07-28 05:55:26,215 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 1/10: kmmlu
2025-07-28 05:55:26,216 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kmmlu' will use num_fewshot=0
2025-07-28 05:55:26,216 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 05:55:26,216 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 05:56:38,663 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 05:56:38,663 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 05:56:38,664 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 05:56:38,665 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 05:56:38,666 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 05:56:38,667 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 05:56:38,667 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 05:56:38,667 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 05:56:38,667 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 05:56:38,667 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 05:56:38,667 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 05:56:38,667 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 05:56:38,667 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 05:56:38,667 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 05:56:41,213 - WARNING - We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
2025-07-28 06:01:18,130 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 06:01:18,130 - INFO - 
============================================================
2025-07-28 06:01:18,130 - INFO - Task 'kmmlu' Results:
2025-07-28 06:01:18,130 - INFO - ============================================================
2025-07-28 06:01:18,130 - INFO -   kmmlu:
2025-07-28 06:01:18,130 - INFO -     - accuracy: 0.4211
2025-07-28 06:01:18,131 - INFO -   kmmlu_applied_science:
2025-07-28 06:01:18,131 - INFO -     - accuracy: 0.3292
2025-07-28 06:01:18,131 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 06:01:18,131 - INFO -     - accuracy: 0.3000
2025-07-28 06:01:18,131 - INFO -   kmmlu_electronics_engineering:
2025-07-28 06:01:18,131 - INFO -     - accuracy: 0.5000
2025-07-28 06:01:18,131 - INFO -   kmmlu_energy_management:
2025-07-28 06:01:18,131 - INFO -     - accuracy: 0.2500
2025-07-28 06:01:18,131 - INFO -   kmmlu_environmental_science:
2025-07-28 06:01:18,131 - INFO -     - accuracy: 0.2000
2025-07-28 06:01:18,132 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 06:01:18,132 - INFO -     - accuracy: 0.3500
2025-07-28 06:01:18,132 - INFO -   kmmlu_geomatics:
2025-07-28 06:01:18,132 - INFO -     - accuracy: 0.3000
2025-07-28 06:01:18,132 - INFO -   kmmlu_industrial_engineer:
2025-07-28 06:01:18,132 - INFO -     - accuracy: 0.4000
2025-07-28 06:01:18,132 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 06:01:18,132 - INFO -     - accuracy: 0.5000
2025-07-28 06:01:18,132 - INFO -   kmmlu_maritime_engineering:
2025-07-28 06:01:18,132 - INFO -     - accuracy: 0.1000
2025-07-28 06:01:18,133 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 06:01:18,133 - INFO -     - accuracy: 0.3000
2025-07-28 06:01:18,133 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 06:01:18,133 - INFO -     - accuracy: 0.4000
2025-07-28 06:01:18,133 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 06:01:18,133 - INFO -     - accuracy: 0.3500
2025-07-28 06:01:18,133 - INFO -   kmmlu_humss:
2025-07-28 06:01:18,133 - INFO -     - accuracy: 0.5227
2025-07-28 06:01:18,133 - INFO -   kmmlu_accounting:
2025-07-28 06:01:18,133 - INFO -     - accuracy: 0.6500
2025-07-28 06:01:18,134 - INFO -   kmmlu_criminal_law:
2025-07-28 06:01:18,134 - INFO -     - accuracy: 0.3000
2025-07-28 06:01:18,134 - INFO -   kmmlu_economics:
2025-07-28 06:01:18,134 - INFO -     - accuracy: 0.8000
2025-07-28 06:01:18,134 - INFO -   kmmlu_education:
2025-07-28 06:01:18,134 - INFO -     - accuracy: 0.8000
2025-07-28 06:01:18,134 - INFO -   kmmlu_korean_history:
2025-07-28 06:01:18,134 - INFO -     - accuracy: 0.4500
2025-07-28 06:01:18,134 - INFO -   kmmlu_law:
2025-07-28 06:01:18,134 - INFO -     - accuracy: 0.1500
2025-07-28 06:01:18,134 - INFO -   kmmlu_management:
2025-07-28 06:01:18,135 - INFO -     - accuracy: 0.6000
2025-07-28 06:01:18,135 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 06:01:18,135 - INFO -     - accuracy: 0.8000
2025-07-28 06:01:18,135 - INFO -   kmmlu_psychology:
2025-07-28 06:01:18,135 - INFO -     - accuracy: 0.3500
2025-07-28 06:01:18,135 - INFO -   kmmlu_social_welfare:
2025-07-28 06:01:18,135 - INFO -     - accuracy: 0.4500
2025-07-28 06:01:18,135 - INFO -   kmmlu_taxation:
2025-07-28 06:01:18,135 - INFO -     - accuracy: 0.4000
2025-07-28 06:01:18,135 - INFO -   kmmlu_other:
2025-07-28 06:01:18,136 - INFO -     - accuracy: 0.4318
2025-07-28 06:01:18,136 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 06:01:18,136 - INFO -     - accuracy: 0.4000
2025-07-28 06:01:18,136 - INFO -   kmmlu_construction:
2025-07-28 06:01:18,136 - INFO -     - accuracy: 0.5000
2025-07-28 06:01:18,136 - INFO -   kmmlu_fashion:
2025-07-28 06:01:18,136 - INFO -     - accuracy: 0.2500
2025-07-28 06:01:18,136 - INFO -   kmmlu_food_processing:
2025-07-28 06:01:18,136 - INFO -     - accuracy: 0.3500
2025-07-28 06:01:18,136 - INFO -   kmmlu_health:
2025-07-28 06:01:18,136 - INFO -     - accuracy: 0.6000
2025-07-28 06:01:18,137 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 06:01:18,137 - INFO -     - accuracy: 0.8500
2025-07-28 06:01:18,137 - INFO -   kmmlu_marketing:
2025-07-28 06:01:18,137 - INFO -     - accuracy: 0.4000
2025-07-28 06:01:18,137 - INFO -   kmmlu_patent:
2025-07-28 06:01:18,137 - INFO -     - accuracy: 0.4500
2025-07-28 06:01:18,137 - INFO -   kmmlu_public_safety:
2025-07-28 06:01:18,137 - INFO -     - accuracy: 0.1500
2025-07-28 06:01:18,137 - INFO -   kmmlu_real_estate:
2025-07-28 06:01:18,137 - INFO -     - accuracy: 0.5000
2025-07-28 06:01:18,138 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 06:01:18,138 - INFO -     - accuracy: 0.3000
2025-07-28 06:01:18,138 - INFO -   kmmlu_stem:
2025-07-28 06:01:18,138 - INFO -     - accuracy: 0.4091
2025-07-28 06:01:18,138 - INFO -   kmmlu_biology:
2025-07-28 06:01:18,138 - INFO -     - accuracy: 0.4000
2025-07-28 06:01:18,138 - INFO -   kmmlu_chemical_engineering:
2025-07-28 06:01:18,138 - INFO -     - accuracy: 0.4500
2025-07-28 06:01:18,138 - INFO -   kmmlu_chemistry:
2025-07-28 06:01:18,138 - INFO -     - accuracy: 0.4000
2025-07-28 06:01:18,139 - INFO -   kmmlu_civil_engineering:
2025-07-28 06:01:18,139 - INFO -     - accuracy: 0.2500
2025-07-28 06:01:18,139 - INFO -   kmmlu_computer_science:
2025-07-28 06:01:18,139 - INFO -     - accuracy: 0.6500
2025-07-28 06:01:18,139 - INFO -   kmmlu_ecology:
2025-07-28 06:01:18,139 - INFO -     - accuracy: 0.2500
2025-07-28 06:01:18,139 - INFO -   kmmlu_electrical_engineering:
2025-07-28 06:01:18,139 - INFO -     - accuracy: 0.2500
2025-07-28 06:01:18,139 - INFO -   kmmlu_information_technology:
2025-07-28 06:01:18,139 - INFO -     - accuracy: 0.6500
2025-07-28 06:01:18,139 - INFO -   kmmlu_materials_engineering:
2025-07-28 06:01:18,140 - INFO -     - accuracy: 0.5500
2025-07-28 06:01:18,140 - INFO -   kmmlu_math:
2025-07-28 06:01:18,140 - INFO -     - accuracy: 0.3000
2025-07-28 06:01:18,140 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 06:01:18,140 - INFO -     - accuracy: 0.3500
2025-07-28 06:01:18,140 - INFO - ============================================================

2025-07-28 06:01:18,152 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 2/10: kmmlu_hard
2025-07-28 06:01:18,153 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 06:01:18,153 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 06:01:18,153 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:02:28,344 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 06:02:28,344 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 06:02:28,344 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 06:02:28,344 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 06:02:28,345 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 06:02:28,346 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 06:02:28,347 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 06:02:28,348 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 06:02:28,348 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 06:02:28,348 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 06:02:28,348 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 06:02:28,348 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 06:02:28,348 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 06:02:28,348 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 06:02:28,348 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 06:07:09,895 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 06:07:09,895 - INFO - 
============================================================
2025-07-28 06:07:09,895 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 06:07:09,896 - INFO - ============================================================
2025-07-28 06:07:09,896 - INFO -   kmmlu_hard:
2025-07-28 06:07:09,896 - INFO -     - accuracy: 0.2400
2025-07-28 06:07:09,896 - INFO -   kmmlu_hard_applied_science:
2025-07-28 06:07:09,897 - INFO -     - accuracy: 0.2583
2025-07-28 06:07:09,897 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 06:07:09,897 - INFO -     - accuracy: 0.3000
2025-07-28 06:07:09,897 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 06:07:09,897 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,897 - INFO -   kmmlu_hard_energy_management:
2025-07-28 06:07:09,897 - INFO -     - accuracy: 0.1500
2025-07-28 06:07:09,897 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 06:07:09,898 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,898 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 06:07:09,898 - INFO -     - accuracy: 0.1000
2025-07-28 06:07:09,898 - INFO -   kmmlu_hard_geomatics:
2025-07-28 06:07:09,898 - INFO -     - accuracy: 0.3000
2025-07-28 06:07:09,898 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 06:07:09,898 - INFO -     - accuracy: 0.4000
2025-07-28 06:07:09,898 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 06:07:09,898 - INFO -     - accuracy: 0.3500
2025-07-28 06:07:09,899 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 06:07:09,899 - INFO -     - accuracy: 0.1500
2025-07-28 06:07:09,899 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 06:07:09,899 - INFO -     - accuracy: 0.3500
2025-07-28 06:07:09,899 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 06:07:09,899 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,899 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 06:07:09,899 - INFO -     - accuracy: 0.4000
2025-07-28 06:07:09,899 - INFO -   kmmlu_hard_humss:
2025-07-28 06:07:09,900 - INFO -     - accuracy: 0.2273
2025-07-28 06:07:09,900 - INFO -   kmmlu_hard_accounting:
2025-07-28 06:07:09,900 - INFO -     - accuracy: 0.3000
2025-07-28 06:07:09,900 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 06:07:09,900 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,900 - INFO -   kmmlu_hard_economics:
2025-07-28 06:07:09,900 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,900 - INFO -   kmmlu_hard_education:
2025-07-28 06:07:09,900 - INFO -     - accuracy: 0.4000
2025-07-28 06:07:09,900 - INFO -   kmmlu_hard_korean_history:
2025-07-28 06:07:09,900 - INFO -     - accuracy: 0.1500
2025-07-28 06:07:09,901 - INFO -   kmmlu_hard_law:
2025-07-28 06:07:09,901 - INFO -     - accuracy: 0.1000
2025-07-28 06:07:09,901 - INFO -   kmmlu_hard_management:
2025-07-28 06:07:09,901 - INFO -     - accuracy: 0.4000
2025-07-28 06:07:09,901 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 06:07:09,901 - INFO -     - accuracy: 0.1500
2025-07-28 06:07:09,901 - INFO -   kmmlu_hard_psychology:
2025-07-28 06:07:09,901 - INFO -     - accuracy: 0.1500
2025-07-28 06:07:09,901 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 06:07:09,902 - INFO -     - accuracy: 0.2500
2025-07-28 06:07:09,902 - INFO -   kmmlu_hard_taxation:
2025-07-28 06:07:09,902 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,902 - INFO -   kmmlu_hard_other:
2025-07-28 06:07:09,902 - INFO -     - accuracy: 0.2727
2025-07-28 06:07:09,902 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 06:07:09,902 - INFO -     - accuracy: 0.3000
2025-07-28 06:07:09,902 - INFO -   kmmlu_hard_construction:
2025-07-28 06:07:09,902 - INFO -     - accuracy: 0.1000
2025-07-28 06:07:09,903 - INFO -   kmmlu_hard_fashion:
2025-07-28 06:07:09,903 - INFO -     - accuracy: 0.4000
2025-07-28 06:07:09,903 - INFO -   kmmlu_hard_food_processing:
2025-07-28 06:07:09,903 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,903 - INFO -   kmmlu_hard_health:
2025-07-28 06:07:09,903 - INFO -     - accuracy: 0.3000
2025-07-28 06:07:09,903 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 06:07:09,903 - INFO -     - accuracy: 0.4000
2025-07-28 06:07:09,904 - INFO -   kmmlu_hard_marketing:
2025-07-28 06:07:09,904 - INFO -     - accuracy: 0.4000
2025-07-28 06:07:09,904 - INFO -   kmmlu_hard_patent:
2025-07-28 06:07:09,904 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,904 - INFO -   kmmlu_hard_public_safety:
2025-07-28 06:07:09,904 - INFO -     - accuracy: 0.3000
2025-07-28 06:07:09,904 - INFO -   kmmlu_hard_real_estate:
2025-07-28 06:07:09,904 - INFO -     - accuracy: 0.3000
2025-07-28 06:07:09,904 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 06:07:09,905 - INFO -     - accuracy: 0.1000
2025-07-28 06:07:09,905 - INFO -   kmmlu_hard_stem:
2025-07-28 06:07:09,905 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,905 - INFO -   kmmlu_hard_biology:
2025-07-28 06:07:09,905 - INFO -     - accuracy: 0.2500
2025-07-28 06:07:09,905 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 06:07:09,905 - INFO -     - accuracy: 0.1500
2025-07-28 06:07:09,905 - INFO -   kmmlu_hard_chemistry:
2025-07-28 06:07:09,905 - INFO -     - accuracy: 0.3500
2025-07-28 06:07:09,906 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 06:07:09,906 - INFO -     - accuracy: 0.0500
2025-07-28 06:07:09,906 - INFO -   kmmlu_hard_computer_science:
2025-07-28 06:07:09,906 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,906 - INFO -   kmmlu_hard_ecology:
2025-07-28 06:07:09,906 - INFO -     - accuracy: 0.1500
2025-07-28 06:07:09,906 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 06:07:09,906 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,906 - INFO -   kmmlu_hard_information_technology:
2025-07-28 06:07:09,907 - INFO -     - accuracy: 0.4000
2025-07-28 06:07:09,907 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 06:07:09,907 - INFO -     - accuracy: 0.2000
2025-07-28 06:07:09,907 - INFO -   kmmlu_hard_math:
2025-07-28 06:07:09,907 - INFO -     - accuracy: 0.2500
2025-07-28 06:07:09,907 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 06:07:09,907 - INFO -     - accuracy: 0.0000
2025-07-28 06:07:09,907 - INFO - ============================================================

2025-07-28 06:07:09,911 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 3/10: haerae
2025-07-28 06:07:09,912 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'haerae' will use num_fewshot=0
2025-07-28 06:07:09,912 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 06:07:09,912 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:07:26,221 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 06:07:26,221 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 06:07:26,222 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 06:07:26,222 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 06:07:26,222 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 06:10:00,287 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 06:10:00,288 - INFO - 
============================================================
2025-07-28 06:10:00,289 - INFO - Task 'haerae' Results:
2025-07-28 06:10:00,289 - INFO - ============================================================
2025-07-28 06:10:00,289 - INFO -   haerae:
2025-07-28 06:10:00,289 - INFO -     - accuracy: 0.8700
2025-07-28 06:10:00,289 - INFO -     - accuracy_norm: 0.8700
2025-07-28 06:10:00,289 - INFO -   haerae_general_knowledge:
2025-07-28 06:10:00,289 - INFO -     - accuracy: 0.8500
2025-07-28 06:10:00,289 - INFO -     - accuracy_norm: 0.8500
2025-07-28 06:10:00,290 - INFO -   haerae_history:
2025-07-28 06:10:00,290 - INFO -     - accuracy: 0.9500
2025-07-28 06:10:00,290 - INFO -     - accuracy_norm: 0.9500
2025-07-28 06:10:00,290 - INFO -   haerae_loan_word:
2025-07-28 06:10:00,290 - INFO -     - accuracy: 0.9000
2025-07-28 06:10:00,290 - INFO -     - accuracy_norm: 0.9000
2025-07-28 06:10:00,290 - INFO -   haerae_rare_word:
2025-07-28 06:10:00,290 - INFO -     - accuracy: 0.7500
2025-07-28 06:10:00,291 - INFO -     - accuracy_norm: 0.7500
2025-07-28 06:10:00,291 - INFO -   haerae_standard_nomenclature:
2025-07-28 06:10:00,291 - INFO -     - accuracy: 0.9000
2025-07-28 06:10:00,291 - INFO -     - accuracy_norm: 0.9000
2025-07-28 06:10:00,291 - INFO - ============================================================

2025-07-28 06:10:00,294 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 4/10: kobest
2025-07-28 06:10:00,294 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kobest' will use num_fewshot=0
2025-07-28 06:10:00,294 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 06:10:00,294 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:10:18,313 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 06:10:18,314 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 06:10:18,314 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 06:10:18,315 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 06:10:18,315 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 06:11:28,407 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 06:11:28,408 - INFO - 
============================================================
2025-07-28 06:11:28,408 - INFO - Task 'kobest' Results:
2025-07-28 06:11:28,408 - INFO - ============================================================
2025-07-28 06:11:28,408 - INFO -   kobest:
2025-07-28 06:11:28,409 - INFO -     - accuracy: 0.7600
2025-07-28 06:11:28,409 - INFO -     - accuracy_norm: 0.8500
2025-07-28 06:11:28,409 - INFO -     - f1: 0.7597
2025-07-28 06:11:28,410 - INFO -   kobest_boolq:
2025-07-28 06:11:28,411 - INFO -     - accuracy: 0.8500
2025-07-28 06:11:28,411 - INFO -     - f1: 0.8496
2025-07-28 06:11:28,411 - INFO -   kobest_copa:
2025-07-28 06:11:28,411 - INFO -     - accuracy: 0.9000
2025-07-28 06:11:28,411 - INFO -     - f1: 0.9000
2025-07-28 06:11:28,411 - INFO -   kobest_hellaswag:
2025-07-28 06:11:28,411 - INFO -     - accuracy: 0.5500
2025-07-28 06:11:28,411 - INFO -     - accuracy_norm: 0.8500
2025-07-28 06:11:28,412 - INFO -     - f1: 0.5530
2025-07-28 06:11:28,412 - INFO -   kobest_sentineg:
2025-07-28 06:11:28,412 - INFO -     - accuracy: 0.9000
2025-07-28 06:11:28,412 - INFO -     - f1: 0.8958
2025-07-28 06:11:28,412 - INFO -   kobest_wic:
2025-07-28 06:11:28,412 - INFO -     - accuracy: 0.6000
2025-07-28 06:11:28,412 - INFO -     - f1: 0.6000
2025-07-28 06:11:28,412 - INFO - ============================================================

2025-07-28 06:11:28,415 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 5/10: csatqa
2025-07-28 06:11:28,415 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'csatqa' detected as zero-shot task
2025-07-28 06:11:28,415 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 06:11:28,416 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:11:40,065 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 06:11:40,066 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 06:11:40,066 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 06:11:40,066 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 06:11:40,066 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 06:11:40,066 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 06:17:51,589 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 06:17:51,590 - INFO - 
============================================================
2025-07-28 06:17:51,590 - INFO - Task 'csatqa' Results:
2025-07-28 06:17:51,590 - INFO - ============================================================
2025-07-28 06:17:51,590 - INFO -   csatqa:
2025-07-28 06:17:51,590 - INFO -     - accuracy: 0.4865
2025-07-28 06:17:51,591 - INFO -     - accuracy_norm: 0.4865
2025-07-28 06:17:51,591 - INFO -   csatqa_gr:
2025-07-28 06:17:51,591 - INFO -     - accuracy: 0.1500
2025-07-28 06:17:51,591 - INFO -     - accuracy_norm: 0.1500
2025-07-28 06:17:51,591 - INFO -   csatqa_li:
2025-07-28 06:17:51,591 - INFO -     - accuracy: 0.7000
2025-07-28 06:17:51,591 - INFO -     - accuracy_norm: 0.7000
2025-07-28 06:17:51,591 - INFO -   csatqa_rch:
2025-07-28 06:17:51,592 - INFO -     - accuracy: 0.6000
2025-07-28 06:17:51,592 - INFO -     - accuracy_norm: 0.6000
2025-07-28 06:17:51,592 - INFO -   csatqa_rcs:
2025-07-28 06:17:51,592 - INFO -     - accuracy: 0.4000
2025-07-28 06:17:51,592 - INFO -     - accuracy_norm: 0.4000
2025-07-28 06:17:51,592 - INFO -   csatqa_rcss:
2025-07-28 06:17:51,592 - INFO -     - accuracy: 0.7000
2025-07-28 06:17:51,592 - INFO -     - accuracy_norm: 0.7000
2025-07-28 06:17:51,592 - INFO -   csatqa_wr:
2025-07-28 06:17:51,592 - INFO -     - accuracy: 0.2727
2025-07-28 06:17:51,592 - INFO -     - accuracy_norm: 0.2727
2025-07-28 06:17:51,593 - INFO - ============================================================

2025-07-28 06:17:51,603 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 6/10: kormedmcqa
2025-07-28 06:17:51,604 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 06:17:51,604 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 06:17:51,605 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:18:08,626 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 06:18:08,626 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 06:18:08,627 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 06:18:08,627 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 06:19:21,738 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 06:19:21,739 - INFO - 
============================================================
2025-07-28 06:19:21,740 - INFO - Task 'kormedmcqa' Results:
2025-07-28 06:19:21,740 - INFO - ============================================================
2025-07-28 06:19:21,740 - INFO -   kormedmcqa:
2025-07-28 06:19:21,740 - INFO -     - exact_match: 0.6125
2025-07-28 06:19:21,740 - INFO -   kormedmcqa_dentist:
2025-07-28 06:19:21,740 - INFO -     - exact_match: 0.4000
2025-07-28 06:19:21,741 - INFO -   kormedmcqa_doctor:
2025-07-28 06:19:21,741 - INFO -     - exact_match: 0.5000
2025-07-28 06:19:21,741 - INFO -   kormedmcqa_nurse:
2025-07-28 06:19:21,741 - INFO -     - exact_match: 0.9000
2025-07-28 06:19:21,741 - INFO -   kormedmcqa_pharm:
2025-07-28 06:19:21,741 - INFO -     - exact_match: 0.6500
2025-07-28 06:19:21,741 - INFO - ============================================================

2025-07-28 06:19:21,745 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 7/10: mmlu
2025-07-28 06:19:21,745 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'mmlu' will use num_fewshot=0
2025-07-28 06:19:21,745 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 06:19:21,746 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:22:13,400 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 06:22:13,401 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 06:22:13,401 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 06:22:13,401 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 06:22:13,401 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 06:22:13,401 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 06:22:13,401 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 06:22:13,401 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 06:22:13,401 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 06:22:13,402 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 06:22:13,403 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 06:22:13,404 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 06:22:13,405 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 06:22:13,406 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 06:22:13,406 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 06:22:13,406 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 06:28:07,614 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 06:28:07,614 - INFO - 
============================================================
2025-07-28 06:28:07,615 - INFO - Task 'mmlu' Results:
2025-07-28 06:28:07,615 - INFO - ============================================================
2025-07-28 06:28:07,615 - INFO -   mmlu:
2025-07-28 06:28:07,615 - INFO -     - accuracy: 0.7070
2025-07-28 06:28:07,615 - INFO -   mmlu_humanities:
2025-07-28 06:28:07,615 - INFO -     - accuracy: 0.7462
2025-07-28 06:28:07,615 - INFO -   mmlu_formal_logic:
2025-07-28 06:28:07,615 - INFO -     - accuracy: 0.6500
2025-07-28 06:28:07,615 - INFO -   mmlu_high_school_european_history:
2025-07-28 06:28:07,616 - INFO -     - accuracy: 0.6500
2025-07-28 06:28:07,616 - INFO -   mmlu_high_school_us_history:
2025-07-28 06:28:07,616 - INFO -     - accuracy: 0.8500
2025-07-28 06:28:07,616 - INFO -   mmlu_high_school_world_history:
2025-07-28 06:28:07,616 - INFO -     - accuracy: 0.9500
2025-07-28 06:28:07,616 - INFO -   mmlu_international_law:
2025-07-28 06:28:07,616 - INFO -     - accuracy: 0.8000
2025-07-28 06:28:07,616 - INFO -   mmlu_jurisprudence:
2025-07-28 06:28:07,616 - INFO -     - accuracy: 0.8000
2025-07-28 06:28:07,616 - INFO -   mmlu_logical_fallacies:
2025-07-28 06:28:07,617 - INFO -     - accuracy: 0.9000
2025-07-28 06:28:07,617 - INFO -   mmlu_moral_disputes:
2025-07-28 06:28:07,617 - INFO -     - accuracy: 0.7000
2025-07-28 06:28:07,617 - INFO -   mmlu_moral_scenarios:
2025-07-28 06:28:07,617 - INFO -     - accuracy: 0.3000
2025-07-28 06:28:07,617 - INFO -   mmlu_philosophy:
2025-07-28 06:28:07,617 - INFO -     - accuracy: 0.9500
2025-07-28 06:28:07,617 - INFO -   mmlu_prehistory:
2025-07-28 06:28:07,617 - INFO -     - accuracy: 0.7000
2025-07-28 06:28:07,617 - INFO -   mmlu_professional_law:
2025-07-28 06:28:07,617 - INFO -     - accuracy: 0.7000
2025-07-28 06:28:07,618 - INFO -   mmlu_world_religions:
2025-07-28 06:28:07,618 - INFO -     - accuracy: 0.7500
2025-07-28 06:28:07,618 - INFO -   mmlu_other:
2025-07-28 06:28:07,618 - INFO -     - accuracy: 0.6846
2025-07-28 06:28:07,618 - INFO -   mmlu_business_ethics:
2025-07-28 06:28:07,618 - INFO -     - accuracy: 0.9000
2025-07-28 06:28:07,618 - INFO -   mmlu_clinical_knowledge:
2025-07-28 06:28:07,618 - INFO -     - accuracy: 0.7000
2025-07-28 06:28:07,618 - INFO -   mmlu_college_medicine:
2025-07-28 06:28:07,618 - INFO -     - accuracy: 0.8500
2025-07-28 06:28:07,618 - INFO -   mmlu_global_facts:
2025-07-28 06:28:07,619 - INFO -     - accuracy: 0.3500
2025-07-28 06:28:07,619 - INFO -   mmlu_human_aging:
2025-07-28 06:28:07,619 - INFO -     - accuracy: 0.7000
2025-07-28 06:28:07,619 - INFO -   mmlu_management:
2025-07-28 06:28:07,619 - INFO -     - accuracy: 0.7500
2025-07-28 06:28:07,619 - INFO -   mmlu_marketing:
2025-07-28 06:28:07,619 - INFO -     - accuracy: 0.8500
2025-07-28 06:28:07,619 - INFO -   mmlu_medical_genetics:
2025-07-28 06:28:07,619 - INFO -     - accuracy: 0.7000
2025-07-28 06:28:07,619 - INFO -   mmlu_miscellaneous:
2025-07-28 06:28:07,619 - INFO -     - accuracy: 0.7500
2025-07-28 06:28:07,620 - INFO -   mmlu_nutrition:
2025-07-28 06:28:07,620 - INFO -     - accuracy: 0.7500
2025-07-28 06:28:07,620 - INFO -   mmlu_professional_accounting:
2025-07-28 06:28:07,620 - INFO -     - accuracy: 0.3500
2025-07-28 06:28:07,620 - INFO -   mmlu_professional_medicine:
2025-07-28 06:28:07,620 - INFO -     - accuracy: 0.7000
2025-07-28 06:28:07,620 - INFO -   mmlu_virology:
2025-07-28 06:28:07,620 - INFO -     - accuracy: 0.5500
2025-07-28 06:28:07,620 - INFO -   mmlu_social_sciences:
2025-07-28 06:28:07,620 - INFO -     - accuracy: 0.8125
2025-07-28 06:28:07,620 - INFO -   mmlu_econometrics:
2025-07-28 06:28:07,621 - INFO -     - accuracy: 0.6000
2025-07-28 06:28:07,621 - INFO -   mmlu_high_school_geography:
2025-07-28 06:28:07,621 - INFO -     - accuracy: 0.8500
2025-07-28 06:28:07,621 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 06:28:07,621 - INFO -     - accuracy: 1.0000
2025-07-28 06:28:07,621 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 06:28:07,621 - INFO -     - accuracy: 0.7500
2025-07-28 06:28:07,621 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 06:28:07,621 - INFO -     - accuracy: 0.7500
2025-07-28 06:28:07,621 - INFO -   mmlu_high_school_psychology:
2025-07-28 06:28:07,621 - INFO -     - accuracy: 1.0000
2025-07-28 06:28:07,622 - INFO -   mmlu_human_sexuality:
2025-07-28 06:28:07,622 - INFO -     - accuracy: 0.9000
2025-07-28 06:28:07,622 - INFO -   mmlu_professional_psychology:
2025-07-28 06:28:07,622 - INFO -     - accuracy: 0.8500
2025-07-28 06:28:07,622 - INFO -   mmlu_public_relations:
2025-07-28 06:28:07,622 - INFO -     - accuracy: 0.5000
2025-07-28 06:28:07,622 - INFO -   mmlu_security_studies:
2025-07-28 06:28:07,622 - INFO -     - accuracy: 0.9000
2025-07-28 06:28:07,622 - INFO -   mmlu_sociology:
2025-07-28 06:28:07,622 - INFO -     - accuracy: 0.6500
2025-07-28 06:28:07,623 - INFO -   mmlu_us_foreign_policy:
2025-07-28 06:28:07,623 - INFO -     - accuracy: 1.0000
2025-07-28 06:28:07,623 - INFO -   mmlu_stem:
2025-07-28 06:28:07,623 - INFO -     - accuracy: 0.6289
2025-07-28 06:28:07,623 - INFO -   mmlu_abstract_algebra:
2025-07-28 06:28:07,623 - INFO -     - accuracy: 0.2000
2025-07-28 06:28:07,623 - INFO -   mmlu_anatomy:
2025-07-28 06:28:07,623 - INFO -     - accuracy: 0.7500
2025-07-28 06:28:07,623 - INFO -   mmlu_astronomy:
2025-07-28 06:28:07,623 - INFO -     - accuracy: 0.9000
2025-07-28 06:28:07,623 - INFO -   mmlu_college_biology:
2025-07-28 06:28:07,624 - INFO -     - accuracy: 0.7000
2025-07-28 06:28:07,624 - INFO -   mmlu_college_chemistry:
2025-07-28 06:28:07,624 - INFO -     - accuracy: 0.4000
2025-07-28 06:28:07,624 - INFO -   mmlu_college_computer_science:
2025-07-28 06:28:07,624 - INFO -     - accuracy: 0.6500
2025-07-28 06:28:07,624 - INFO -   mmlu_college_mathematics:
2025-07-28 06:28:07,624 - INFO -     - accuracy: 0.3500
2025-07-28 06:28:07,624 - INFO -   mmlu_college_physics:
2025-07-28 06:28:07,624 - INFO -     - accuracy: 0.6000
2025-07-28 06:28:07,624 - INFO -   mmlu_computer_security:
2025-07-28 06:28:07,624 - INFO -     - accuracy: 0.7500
2025-07-28 06:28:07,625 - INFO -   mmlu_conceptual_physics:
2025-07-28 06:28:07,625 - INFO -     - accuracy: 0.9000
2025-07-28 06:28:07,625 - INFO -   mmlu_electrical_engineering:
2025-07-28 06:28:07,625 - INFO -     - accuracy: 0.6500
2025-07-28 06:28:07,625 - INFO -   mmlu_elementary_mathematics:
2025-07-28 06:28:07,625 - INFO -     - accuracy: 0.5500
2025-07-28 06:28:07,625 - INFO -   mmlu_high_school_biology:
2025-07-28 06:28:07,625 - INFO -     - accuracy: 0.9000
2025-07-28 06:28:07,625 - INFO -   mmlu_high_school_chemistry:
2025-07-28 06:28:07,625 - INFO -     - accuracy: 0.6500
2025-07-28 06:28:07,625 - INFO -   mmlu_high_school_computer_science:
2025-07-28 06:28:07,626 - INFO -     - accuracy: 0.9500
2025-07-28 06:28:07,626 - INFO -   mmlu_high_school_mathematics:
2025-07-28 06:28:07,626 - INFO -     - accuracy: 0.3000
2025-07-28 06:28:07,626 - INFO -   mmlu_high_school_physics:
2025-07-28 06:28:07,626 - INFO -     - accuracy: 0.4000
2025-07-28 06:28:07,626 - INFO -   mmlu_high_school_statistics:
2025-07-28 06:28:07,626 - INFO -     - accuracy: 0.8500
2025-07-28 06:28:07,626 - INFO -   mmlu_machine_learning:
2025-07-28 06:28:07,626 - INFO -     - accuracy: 0.5000
2025-07-28 06:28:07,627 - INFO - ============================================================

2025-07-28 06:28:07,632 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 8/10: arc_challenge
2025-07-28 06:28:07,632 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 06:28:07,632 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 06:28:07,633 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:28:14,538 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 06:28:39,655 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 06:28:39,656 - INFO - 
============================================================
2025-07-28 06:28:39,656 - INFO - Task 'arc_challenge' Results:
2025-07-28 06:28:39,656 - INFO - ============================================================
2025-07-28 06:28:39,656 - INFO -   arc_challenge:
2025-07-28 06:28:39,656 - INFO -     - accuracy: 0.6000
2025-07-28 06:28:39,656 - INFO -     - accuracy_norm: 0.6000
2025-07-28 06:28:39,657 - INFO - ============================================================

2025-07-28 06:28:39,658 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 9/10: arc_easy
2025-07-28 06:28:39,658 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'arc_easy' will use num_fewshot=0
2025-07-28 06:28:39,659 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 06:28:39,659 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:28:45,767 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 06:29:07,630 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 06:29:07,631 - INFO - 
============================================================
2025-07-28 06:29:07,632 - INFO - Task 'arc_easy' Results:
2025-07-28 06:29:07,632 - INFO - ============================================================
2025-07-28 06:29:07,632 - INFO -   arc_easy:
2025-07-28 06:29:07,632 - INFO -     - accuracy: 0.8500
2025-07-28 06:29:07,632 - INFO -     - accuracy_norm: 0.7500
2025-07-28 06:29:07,632 - INFO - ============================================================

2025-07-28 06:29:07,633 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 10/10: hellaswag
2025-07-28 06:29:07,634 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'hellaswag' will use num_fewshot=0
2025-07-28 06:29:07,634 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 06:29:07,634 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:29:20,929 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 06:29:47,593 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 06:29:47,594 - INFO - 
============================================================
2025-07-28 06:29:47,594 - INFO - Task 'hellaswag' Results:
2025-07-28 06:29:47,595 - INFO - ============================================================
2025-07-28 06:29:47,595 - INFO -   hellaswag:
2025-07-28 06:29:47,595 - INFO -     - accuracy: 0.5000
2025-07-28 06:29:47,595 - INFO -     - accuracy_norm: 0.6500
2025-07-28 06:29:47,595 - INFO - ============================================================

2025-07-28 06:29:47,597 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 06:29:47,599 - INFO - [Process 1795506] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_032724/model_results/EXAONE-3.5-32B-Instruct/EXAONE-3.5-32B-Instruct_harness_8.json
2025-07-28 06:29:47,600 - INFO - [Process 1795506] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/EXAONE-3.5-32B-Instruct/EXAONE-3.5-32B-Instruct_harness_8.json
2025-07-28 06:29:47,898 - INFO - Results uploaded to WandB as artifact
2025-07-28 06:29:47,908 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 06:29:47,910 - INFO - [Process 1795506] Successfully completed EXAONE-3.5-32B-Instruct_harness_8
2025-07-28 06:29:50,044 - INFO - Run EXAONE-3.5-32B-Instruct_harness_8 finished successfully
2025-07-28 06:29:50,046 - INFO - [Process 1795506] luxia-21.4b-alignment-v1.2_harness_13 assigned to cuda:0
2025-07-28 06:29:50,047 - INFO - [Process 1795506] luxia-21.4b-alignment-v1.2_harness_13 - using custom limit: 20
2025-07-28 06:29:51,295 - INFO - WandB run initialized: luxia-21.4b-alignment-v1.2_20250728_062950 (ID: 229a0d36)
2025-07-28 06:29:51,513 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Test mode (limit=2), setting num_fewshot=0
2025-07-28 06:29:51,593 - INFO - GPU memory available: 79.3GB
2025-07-28 06:29:51,593 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Using 8bit=True, batch_size=1
2025-07-28 06:30:31,837 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 1/10: kmmlu
2025-07-28 06:30:31,838 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'kmmlu' will use num_fewshot=0
2025-07-28 06:30:31,838 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 06:30:31,838 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:31:44,529 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 06:31:44,529 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 06:31:44,530 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 06:31:44,531 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 06:31:44,532 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 06:31:44,533 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 06:31:44,533 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 06:31:44,533 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 06:31:44,533 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 06:31:44,533 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 06:31:44,533 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 06:31:44,533 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 06:31:44,533 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 06:31:44,533 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 06:35:43,911 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 06:35:43,912 - INFO - 
============================================================
2025-07-28 06:35:43,912 - INFO - Task 'kmmlu' Results:
2025-07-28 06:35:43,912 - INFO - ============================================================
2025-07-28 06:35:43,912 - INFO -   kmmlu:
2025-07-28 06:35:43,912 - INFO -     - accuracy: 0.2344
2025-07-28 06:35:43,912 - INFO -   kmmlu_applied_science:
2025-07-28 06:35:43,912 - INFO -     - accuracy: 0.1958
2025-07-28 06:35:43,912 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 06:35:43,912 - INFO -     - accuracy: 0.2500
2025-07-28 06:35:43,913 - INFO -   kmmlu_electronics_engineering:
2025-07-28 06:35:43,913 - INFO -     - accuracy: 0.2500
2025-07-28 06:35:43,913 - INFO -   kmmlu_energy_management:
2025-07-28 06:35:43,913 - INFO -     - accuracy: 0.0500
2025-07-28 06:35:43,913 - INFO -   kmmlu_environmental_science:
2025-07-28 06:35:43,913 - INFO -     - accuracy: 0.0500
2025-07-28 06:35:43,913 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 06:35:43,913 - INFO -     - accuracy: 0.1500
2025-07-28 06:35:43,913 - INFO -   kmmlu_geomatics:
2025-07-28 06:35:43,913 - INFO -     - accuracy: 0.2500
2025-07-28 06:35:43,914 - INFO -   kmmlu_industrial_engineer:
2025-07-28 06:35:43,914 - INFO -     - accuracy: 0.3000
2025-07-28 06:35:43,914 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 06:35:43,914 - INFO -     - accuracy: 0.1500
2025-07-28 06:35:43,914 - INFO -   kmmlu_maritime_engineering:
2025-07-28 06:35:43,914 - INFO -     - accuracy: 0.1000
2025-07-28 06:35:43,914 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 06:35:43,914 - INFO -     - accuracy: 0.2500
2025-07-28 06:35:43,914 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 06:35:43,914 - INFO -     - accuracy: 0.1500
2025-07-28 06:35:43,914 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 06:35:43,915 - INFO -     - accuracy: 0.4000
2025-07-28 06:35:43,915 - INFO -   kmmlu_humss:
2025-07-28 06:35:43,915 - INFO -     - accuracy: 0.3045
2025-07-28 06:35:43,915 - INFO -   kmmlu_accounting:
2025-07-28 06:35:43,915 - INFO -     - accuracy: 0.5000
2025-07-28 06:35:43,915 - INFO -   kmmlu_criminal_law:
2025-07-28 06:35:43,915 - INFO -     - accuracy: 0.2000
2025-07-28 06:35:43,915 - INFO -   kmmlu_economics:
2025-07-28 06:35:43,915 - INFO -     - accuracy: 0.3500
2025-07-28 06:35:43,915 - INFO -   kmmlu_education:
2025-07-28 06:35:43,916 - INFO -     - accuracy: 0.4500
2025-07-28 06:35:43,916 - INFO -   kmmlu_korean_history:
2025-07-28 06:35:43,916 - INFO -     - accuracy: 0.2500
2025-07-28 06:35:43,916 - INFO -   kmmlu_law:
2025-07-28 06:35:43,916 - INFO -     - accuracy: 0.2000
2025-07-28 06:35:43,916 - INFO -   kmmlu_management:
2025-07-28 06:35:43,916 - INFO -     - accuracy: 0.2000
2025-07-28 06:35:43,916 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 06:35:43,916 - INFO -     - accuracy: 0.3500
2025-07-28 06:35:43,916 - INFO -   kmmlu_psychology:
2025-07-28 06:35:43,916 - INFO -     - accuracy: 0.1500
2025-07-28 06:35:43,917 - INFO -   kmmlu_social_welfare:
2025-07-28 06:35:43,917 - INFO -     - accuracy: 0.3000
2025-07-28 06:35:43,917 - INFO -   kmmlu_taxation:
2025-07-28 06:35:43,917 - INFO -     - accuracy: 0.4000
2025-07-28 06:35:43,917 - INFO -   kmmlu_other:
2025-07-28 06:35:43,917 - INFO -     - accuracy: 0.2182
2025-07-28 06:35:43,917 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 06:35:43,917 - INFO -     - accuracy: 0.1000
2025-07-28 06:35:43,917 - INFO -   kmmlu_construction:
2025-07-28 06:35:43,917 - INFO -     - accuracy: 0.2000
2025-07-28 06:35:43,918 - INFO -   kmmlu_fashion:
2025-07-28 06:35:43,918 - INFO -     - accuracy: 0.2000
2025-07-28 06:35:43,918 - INFO -   kmmlu_food_processing:
2025-07-28 06:35:43,918 - INFO -     - accuracy: 0.2500
2025-07-28 06:35:43,918 - INFO -   kmmlu_health:
2025-07-28 06:35:43,918 - INFO -     - accuracy: 0.5500
2025-07-28 06:35:43,918 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 06:35:43,918 - INFO -     - accuracy: 0.2500
2025-07-28 06:35:43,918 - INFO -   kmmlu_marketing:
2025-07-28 06:35:43,918 - INFO -     - accuracy: 0.3000
2025-07-28 06:35:43,918 - INFO -   kmmlu_patent:
2025-07-28 06:35:43,919 - INFO -     - accuracy: 0.1500
2025-07-28 06:35:43,919 - INFO -   kmmlu_public_safety:
2025-07-28 06:35:43,919 - INFO -     - accuracy: 0.1500
2025-07-28 06:35:43,919 - INFO -   kmmlu_real_estate:
2025-07-28 06:35:43,919 - INFO -     - accuracy: 0.1000
2025-07-28 06:35:43,919 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 06:35:43,919 - INFO -     - accuracy: 0.1500
2025-07-28 06:35:43,919 - INFO -   kmmlu_stem:
2025-07-28 06:35:43,919 - INFO -     - accuracy: 0.2227
2025-07-28 06:35:43,919 - INFO -   kmmlu_biology:
2025-07-28 06:35:43,919 - INFO -     - accuracy: 0.3000
2025-07-28 06:35:43,920 - INFO -   kmmlu_chemical_engineering:
2025-07-28 06:35:43,920 - INFO -     - accuracy: 0.2000
2025-07-28 06:35:43,920 - INFO -   kmmlu_chemistry:
2025-07-28 06:35:43,920 - INFO -     - accuracy: 0.1500
2025-07-28 06:35:43,920 - INFO -   kmmlu_civil_engineering:
2025-07-28 06:35:43,920 - INFO -     - accuracy: 0.1000
2025-07-28 06:35:43,920 - INFO -   kmmlu_computer_science:
2025-07-28 06:35:43,920 - INFO -     - accuracy: 0.3500
2025-07-28 06:35:43,920 - INFO -   kmmlu_ecology:
2025-07-28 06:35:43,920 - INFO -     - accuracy: 0.1000
2025-07-28 06:35:43,920 - INFO -   kmmlu_electrical_engineering:
2025-07-28 06:35:43,921 - INFO -     - accuracy: 0.2500
2025-07-28 06:35:43,921 - INFO -   kmmlu_information_technology:
2025-07-28 06:35:43,921 - INFO -     - accuracy: 0.2500
2025-07-28 06:35:43,921 - INFO -   kmmlu_materials_engineering:
2025-07-28 06:35:43,921 - INFO -     - accuracy: 0.2000
2025-07-28 06:35:43,921 - INFO -   kmmlu_math:
2025-07-28 06:35:43,921 - INFO -     - accuracy: 0.3500
2025-07-28 06:35:43,921 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 06:35:43,921 - INFO -     - accuracy: 0.2000
2025-07-28 06:35:43,921 - INFO - ============================================================

2025-07-28 06:35:43,924 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 2/10: kmmlu_hard
2025-07-28 06:35:43,925 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 06:35:43,925 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 06:35:43,925 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:36:58,519 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 06:36:58,520 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 06:36:58,520 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 06:36:58,520 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 06:36:58,520 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 06:36:58,520 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 06:36:58,521 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 06:36:58,521 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 06:36:58,521 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 06:36:58,521 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 06:36:58,521 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 06:36:58,521 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 06:36:58,521 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 06:36:58,521 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 06:36:58,522 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 06:36:58,522 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 06:36:58,522 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 06:36:58,522 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 06:36:58,522 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 06:36:58,522 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 06:36:58,522 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 06:36:58,522 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 06:36:58,522 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 06:36:58,523 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 06:36:58,523 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 06:36:58,523 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 06:36:58,523 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 06:36:58,523 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 06:36:58,523 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 06:36:58,523 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 06:36:58,523 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 06:36:58,523 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 06:36:58,524 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 06:36:58,524 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 06:36:58,524 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 06:36:58,524 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 06:36:58,524 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 06:36:58,524 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 06:36:58,524 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 06:36:58,524 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 06:36:58,524 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 06:36:58,525 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 06:36:58,525 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 06:36:58,525 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 06:36:58,525 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 06:40:57,631 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 06:40:57,632 - INFO - 
============================================================
2025-07-28 06:40:57,632 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 06:40:57,632 - INFO - ============================================================
2025-07-28 06:40:57,632 - INFO -   kmmlu_hard:
2025-07-28 06:40:57,632 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,633 - INFO -   kmmlu_hard_applied_science:
2025-07-28 06:40:57,633 - INFO -     - accuracy: 0.1667
2025-07-28 06:40:57,633 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 06:40:57,633 - INFO -     - accuracy: 0.0500
2025-07-28 06:40:57,633 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 06:40:57,633 - INFO -     - accuracy: 0.0000
2025-07-28 06:40:57,633 - INFO -   kmmlu_hard_energy_management:
2025-07-28 06:40:57,634 - INFO -     - accuracy: 0.3500
2025-07-28 06:40:57,634 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 06:40:57,634 - INFO -     - accuracy: 0.0000
2025-07-28 06:40:57,634 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 06:40:57,634 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,634 - INFO -   kmmlu_hard_geomatics:
2025-07-28 06:40:57,634 - INFO -     - accuracy: 0.0500
2025-07-28 06:40:57,634 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 06:40:57,634 - INFO -     - accuracy: 0.2500
2025-07-28 06:40:57,635 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 06:40:57,635 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,635 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 06:40:57,635 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,635 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 06:40:57,635 - INFO -     - accuracy: 0.1500
2025-07-28 06:40:57,635 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 06:40:57,635 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,635 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 06:40:57,635 - INFO -     - accuracy: 0.3500
2025-07-28 06:40:57,636 - INFO -   kmmlu_hard_humss:
2025-07-28 06:40:57,636 - INFO -     - accuracy: 0.2545
2025-07-28 06:40:57,636 - INFO -   kmmlu_hard_accounting:
2025-07-28 06:40:57,636 - INFO -     - accuracy: 0.3500
2025-07-28 06:40:57,636 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 06:40:57,636 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,636 - INFO -   kmmlu_hard_economics:
2025-07-28 06:40:57,636 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,636 - INFO -   kmmlu_hard_education:
2025-07-28 06:40:57,636 - INFO -     - accuracy: 0.1000
2025-07-28 06:40:57,637 - INFO -   kmmlu_hard_korean_history:
2025-07-28 06:40:57,637 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,637 - INFO -   kmmlu_hard_law:
2025-07-28 06:40:57,637 - INFO -     - accuracy: 0.2500
2025-07-28 06:40:57,637 - INFO -   kmmlu_hard_management:
2025-07-28 06:40:57,637 - INFO -     - accuracy: 0.2500
2025-07-28 06:40:57,637 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 06:40:57,637 - INFO -     - accuracy: 0.4000
2025-07-28 06:40:57,637 - INFO -   kmmlu_hard_psychology:
2025-07-28 06:40:57,637 - INFO -     - accuracy: 0.3000
2025-07-28 06:40:57,637 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 06:40:57,638 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,638 - INFO -   kmmlu_hard_taxation:
2025-07-28 06:40:57,638 - INFO -     - accuracy: 0.3500
2025-07-28 06:40:57,638 - INFO -   kmmlu_hard_other:
2025-07-28 06:40:57,638 - INFO -     - accuracy: 0.1864
2025-07-28 06:40:57,638 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 06:40:57,638 - INFO -     - accuracy: 0.1000
2025-07-28 06:40:57,638 - INFO -   kmmlu_hard_construction:
2025-07-28 06:40:57,638 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,639 - INFO -   kmmlu_hard_fashion:
2025-07-28 06:40:57,639 - INFO -     - accuracy: 0.3500
2025-07-28 06:40:57,639 - INFO -   kmmlu_hard_food_processing:
2025-07-28 06:40:57,639 - INFO -     - accuracy: 0.1500
2025-07-28 06:40:57,639 - INFO -   kmmlu_hard_health:
2025-07-28 06:40:57,639 - INFO -     - accuracy: 0.1500
2025-07-28 06:40:57,639 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 06:40:57,639 - INFO -     - accuracy: 0.1000
2025-07-28 06:40:57,639 - INFO -   kmmlu_hard_marketing:
2025-07-28 06:40:57,639 - INFO -     - accuracy: 0.3500
2025-07-28 06:40:57,640 - INFO -   kmmlu_hard_patent:
2025-07-28 06:40:57,640 - INFO -     - accuracy: 0.1500
2025-07-28 06:40:57,640 - INFO -   kmmlu_hard_public_safety:
2025-07-28 06:40:57,640 - INFO -     - accuracy: 0.2500
2025-07-28 06:40:57,640 - INFO -   kmmlu_hard_real_estate:
2025-07-28 06:40:57,640 - INFO -     - accuracy: 0.1000
2025-07-28 06:40:57,640 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 06:40:57,640 - INFO -     - accuracy: 0.1500
2025-07-28 06:40:57,641 - INFO -   kmmlu_hard_stem:
2025-07-28 06:40:57,641 - INFO -     - accuracy: 0.1955
2025-07-28 06:40:57,641 - INFO -   kmmlu_hard_biology:
2025-07-28 06:40:57,641 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,641 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 06:40:57,641 - INFO -     - accuracy: 0.1000
2025-07-28 06:40:57,641 - INFO -   kmmlu_hard_chemistry:
2025-07-28 06:40:57,641 - INFO -     - accuracy: 0.2500
2025-07-28 06:40:57,641 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 06:40:57,641 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,642 - INFO -   kmmlu_hard_computer_science:
2025-07-28 06:40:57,642 - INFO -     - accuracy: 0.1500
2025-07-28 06:40:57,642 - INFO -   kmmlu_hard_ecology:
2025-07-28 06:40:57,642 - INFO -     - accuracy: 0.1000
2025-07-28 06:40:57,642 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 06:40:57,642 - INFO -     - accuracy: 0.3000
2025-07-28 06:40:57,642 - INFO -   kmmlu_hard_information_technology:
2025-07-28 06:40:57,642 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,642 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 06:40:57,643 - INFO -     - accuracy: 0.2500
2025-07-28 06:40:57,643 - INFO -   kmmlu_hard_math:
2025-07-28 06:40:57,643 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,643 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 06:40:57,643 - INFO -     - accuracy: 0.2000
2025-07-28 06:40:57,643 - INFO - ============================================================

2025-07-28 06:40:57,645 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 3/10: haerae
2025-07-28 06:40:57,646 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'haerae' will use num_fewshot=0
2025-07-28 06:40:57,646 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 06:40:57,646 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:41:12,680 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 06:41:12,680 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 06:41:12,681 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 06:41:12,681 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 06:41:12,681 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 06:43:22,954 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 06:43:22,955 - INFO - 
============================================================
2025-07-28 06:43:22,955 - INFO - Task 'haerae' Results:
2025-07-28 06:43:22,955 - INFO - ============================================================
2025-07-28 06:43:22,955 - INFO -   haerae:
2025-07-28 06:43:22,955 - INFO -     - accuracy: 0.3900
2025-07-28 06:43:22,956 - INFO -     - accuracy_norm: 0.3900
2025-07-28 06:43:22,956 - INFO -   haerae_general_knowledge:
2025-07-28 06:43:22,956 - INFO -     - accuracy: 0.5000
2025-07-28 06:43:22,956 - INFO -     - accuracy_norm: 0.5000
2025-07-28 06:43:22,956 - INFO -   haerae_history:
2025-07-28 06:43:22,956 - INFO -     - accuracy: 0.2000
2025-07-28 06:43:22,956 - INFO -     - accuracy_norm: 0.2000
2025-07-28 06:43:22,956 - INFO -   haerae_loan_word:
2025-07-28 06:43:22,956 - INFO -     - accuracy: 0.4500
2025-07-28 06:43:22,956 - INFO -     - accuracy_norm: 0.4500
2025-07-28 06:43:22,957 - INFO -   haerae_rare_word:
2025-07-28 06:43:22,957 - INFO -     - accuracy: 0.5000
2025-07-28 06:43:22,957 - INFO -     - accuracy_norm: 0.5000
2025-07-28 06:43:22,957 - INFO -   haerae_standard_nomenclature:
2025-07-28 06:43:22,957 - INFO -     - accuracy: 0.3000
2025-07-28 06:43:22,957 - INFO -     - accuracy_norm: 0.3000
2025-07-28 06:43:22,957 - INFO - ============================================================

2025-07-28 06:43:22,958 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 4/10: kobest
2025-07-28 06:43:22,958 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'kobest' will use num_fewshot=0
2025-07-28 06:43:22,959 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 06:43:22,959 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:43:40,527 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 06:43:40,527 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 06:43:40,527 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 06:43:40,527 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 06:43:40,527 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 06:44:43,387 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 06:44:43,389 - INFO - 
============================================================
2025-07-28 06:44:43,389 - INFO - Task 'kobest' Results:
2025-07-28 06:44:43,389 - INFO - ============================================================
2025-07-28 06:44:43,389 - INFO -   kobest:
2025-07-28 06:44:43,389 - INFO -     - accuracy: 0.5400
2025-07-28 06:44:43,389 - INFO -     - accuracy_norm: 0.6000
2025-07-28 06:44:43,389 - INFO -     - f1: 0.4449
2025-07-28 06:44:43,389 - INFO -   kobest_boolq:
2025-07-28 06:44:43,389 - INFO -     - accuracy: 0.6000
2025-07-28 06:44:43,389 - INFO -     - f1: 0.5238
2025-07-28 06:44:43,390 - INFO -   kobest_copa:
2025-07-28 06:44:43,390 - INFO -     - accuracy: 0.6000
2025-07-28 06:44:43,390 - INFO -     - f1: 0.6000
2025-07-28 06:44:43,390 - INFO -   kobest_hellaswag:
2025-07-28 06:44:43,390 - INFO -     - accuracy: 0.4000
2025-07-28 06:44:43,390 - INFO -     - accuracy_norm: 0.6000
2025-07-28 06:44:43,390 - INFO -     - f1: 0.3909
2025-07-28 06:44:43,390 - INFO -   kobest_sentineg:
2025-07-28 06:44:43,390 - INFO -     - accuracy: 0.5500
2025-07-28 06:44:43,390 - INFO -     - f1: 0.3548
2025-07-28 06:44:43,390 - INFO -   kobest_wic:
2025-07-28 06:44:43,391 - INFO -     - accuracy: 0.5500
2025-07-28 06:44:43,391 - INFO -     - f1: 0.3548
2025-07-28 06:44:43,391 - INFO - ============================================================

2025-07-28 06:44:43,392 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 5/10: csatqa
2025-07-28 06:44:43,392 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'csatqa' detected as zero-shot task
2025-07-28 06:44:43,392 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 06:44:43,393 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:44:53,923 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 06:44:53,923 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 06:44:53,923 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 06:44:53,923 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 06:44:53,923 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 06:44:53,924 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 06:53:04,044 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 06:53:04,045 - INFO - 
============================================================
2025-07-28 06:53:04,045 - INFO - Task 'csatqa' Results:
2025-07-28 06:53:04,045 - INFO - ============================================================
2025-07-28 06:53:04,045 - INFO -   csatqa:
2025-07-28 06:53:04,046 - INFO -     - accuracy: 0.2523
2025-07-28 06:53:04,046 - INFO -     - accuracy_norm: 0.2523
2025-07-28 06:53:04,046 - INFO -   csatqa_gr:
2025-07-28 06:53:04,046 - INFO -     - accuracy: 0.1500
2025-07-28 06:53:04,046 - INFO -     - accuracy_norm: 0.1500
2025-07-28 06:53:04,046 - INFO -   csatqa_li:
2025-07-28 06:53:04,046 - INFO -     - accuracy: 0.2500
2025-07-28 06:53:04,046 - INFO -     - accuracy_norm: 0.2500
2025-07-28 06:53:04,046 - INFO -   csatqa_rch:
2025-07-28 06:53:04,047 - INFO -     - accuracy: 0.3000
2025-07-28 06:53:04,047 - INFO -     - accuracy_norm: 0.3000
2025-07-28 06:53:04,047 - INFO -   csatqa_rcs:
2025-07-28 06:53:04,047 - INFO -     - accuracy: 0.2500
2025-07-28 06:53:04,047 - INFO -     - accuracy_norm: 0.2500
2025-07-28 06:53:04,047 - INFO -   csatqa_rcss:
2025-07-28 06:53:04,047 - INFO -     - accuracy: 0.3000
2025-07-28 06:53:04,047 - INFO -     - accuracy_norm: 0.3000
2025-07-28 06:53:04,047 - INFO -   csatqa_wr:
2025-07-28 06:53:04,047 - INFO -     - accuracy: 0.2727
2025-07-28 06:53:04,047 - INFO -     - accuracy_norm: 0.2727
2025-07-28 06:53:04,048 - INFO - ============================================================

2025-07-28 06:53:04,057 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 6/10: kormedmcqa
2025-07-28 06:53:04,058 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 06:53:04,058 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 06:53:04,058 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:53:22,798 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 06:53:22,798 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 06:53:22,799 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 06:53:22,799 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 06:54:29,559 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 06:54:29,561 - INFO - 
============================================================
2025-07-28 06:54:29,561 - INFO - Task 'kormedmcqa' Results:
2025-07-28 06:54:29,561 - INFO - ============================================================
2025-07-28 06:54:29,561 - INFO -   kormedmcqa:
2025-07-28 06:54:29,561 - INFO -     - exact_match: 0.4375
2025-07-28 06:54:29,561 - INFO -   kormedmcqa_dentist:
2025-07-28 06:54:29,562 - INFO -     - exact_match: 0.6000
2025-07-28 06:54:29,562 - INFO -   kormedmcqa_doctor:
2025-07-28 06:54:29,562 - INFO -     - exact_match: 0.3000
2025-07-28 06:54:29,562 - INFO -   kormedmcqa_nurse:
2025-07-28 06:54:29,562 - INFO -     - exact_match: 0.4000
2025-07-28 06:54:29,562 - INFO -   kormedmcqa_pharm:
2025-07-28 06:54:29,562 - INFO -     - exact_match: 0.4500
2025-07-28 06:54:29,563 - INFO - ============================================================

2025-07-28 06:54:29,565 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 7/10: mmlu
2025-07-28 06:54:29,566 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'mmlu' will use num_fewshot=0
2025-07-28 06:54:29,566 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 06:54:29,566 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 06:57:18,274 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 06:57:18,274 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 06:57:18,274 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 06:57:18,274 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 06:57:18,275 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 06:57:18,275 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 06:57:18,275 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 06:57:18,275 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 06:57:18,275 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 06:57:18,275 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 06:57:18,275 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 06:57:18,275 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 06:57:18,275 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 06:57:18,275 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 06:57:18,276 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 06:57:18,277 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 06:57:18,278 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 06:57:18,279 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 06:57:18,279 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 06:57:18,279 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 06:57:18,279 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 06:57:18,279 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 06:57:18,279 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 06:57:18,279 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 06:57:18,279 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 06:57:18,279 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 07:02:11,067 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 07:02:11,067 - INFO - 
============================================================
2025-07-28 07:02:11,067 - INFO - Task 'mmlu' Results:
2025-07-28 07:02:11,067 - INFO - ============================================================
2025-07-28 07:02:11,067 - INFO -   mmlu:
2025-07-28 07:02:11,068 - INFO -     - accuracy: 0.6482
2025-07-28 07:02:11,068 - INFO -   mmlu_humanities:
2025-07-28 07:02:11,068 - INFO -     - accuracy: 0.6846
2025-07-28 07:02:11,068 - INFO -   mmlu_formal_logic:
2025-07-28 07:02:11,068 - INFO -     - accuracy: 0.5500
2025-07-28 07:02:11,068 - INFO -   mmlu_high_school_european_history:
2025-07-28 07:02:11,068 - INFO -     - accuracy: 0.7500
2025-07-28 07:02:11,069 - INFO -   mmlu_high_school_us_history:
2025-07-28 07:02:11,069 - INFO -     - accuracy: 0.9000
2025-07-28 07:02:11,069 - INFO -   mmlu_high_school_world_history:
2025-07-28 07:02:11,069 - INFO -     - accuracy: 0.8500
2025-07-28 07:02:11,069 - INFO -   mmlu_international_law:
2025-07-28 07:02:11,069 - INFO -     - accuracy: 0.8000
2025-07-28 07:02:11,069 - INFO -   mmlu_jurisprudence:
2025-07-28 07:02:11,069 - INFO -     - accuracy: 0.8000
2025-07-28 07:02:11,069 - INFO -   mmlu_logical_fallacies:
2025-07-28 07:02:11,070 - INFO -     - accuracy: 0.7000
2025-07-28 07:02:11,070 - INFO -   mmlu_moral_disputes:
2025-07-28 07:02:11,070 - INFO -     - accuracy: 0.5500
2025-07-28 07:02:11,070 - INFO -   mmlu_moral_scenarios:
2025-07-28 07:02:11,070 - INFO -     - accuracy: 0.3500
2025-07-28 07:02:11,070 - INFO -   mmlu_philosophy:
2025-07-28 07:02:11,070 - INFO -     - accuracy: 0.7000
2025-07-28 07:02:11,070 - INFO -   mmlu_prehistory:
2025-07-28 07:02:11,070 - INFO -     - accuracy: 0.7000
2025-07-28 07:02:11,070 - INFO -   mmlu_professional_law:
2025-07-28 07:02:11,071 - INFO -     - accuracy: 0.5500
2025-07-28 07:02:11,071 - INFO -   mmlu_world_religions:
2025-07-28 07:02:11,071 - INFO -     - accuracy: 0.7000
2025-07-28 07:02:11,071 - INFO -   mmlu_other:
2025-07-28 07:02:11,071 - INFO -     - accuracy: 0.6423
2025-07-28 07:02:11,071 - INFO -   mmlu_business_ethics:
2025-07-28 07:02:11,071 - INFO -     - accuracy: 0.8500
2025-07-28 07:02:11,071 - INFO -   mmlu_clinical_knowledge:
2025-07-28 07:02:11,071 - INFO -     - accuracy: 0.7000
2025-07-28 07:02:11,072 - INFO -   mmlu_college_medicine:
2025-07-28 07:02:11,072 - INFO -     - accuracy: 0.7000
2025-07-28 07:02:11,072 - INFO -   mmlu_global_facts:
2025-07-28 07:02:11,072 - INFO -     - accuracy: 0.3000
2025-07-28 07:02:11,072 - INFO -   mmlu_human_aging:
2025-07-28 07:02:11,072 - INFO -     - accuracy: 0.8500
2025-07-28 07:02:11,072 - INFO -   mmlu_management:
2025-07-28 07:02:11,072 - INFO -     - accuracy: 0.7000
2025-07-28 07:02:11,072 - INFO -   mmlu_marketing:
2025-07-28 07:02:11,073 - INFO -     - accuracy: 0.7000
2025-07-28 07:02:11,073 - INFO -   mmlu_medical_genetics:
2025-07-28 07:02:11,073 - INFO -     - accuracy: 0.6500
2025-07-28 07:02:11,073 - INFO -   mmlu_miscellaneous:
2025-07-28 07:02:11,073 - INFO -     - accuracy: 0.7500
2025-07-28 07:02:11,073 - INFO -   mmlu_nutrition:
2025-07-28 07:02:11,073 - INFO -     - accuracy: 0.7500
2025-07-28 07:02:11,073 - INFO -   mmlu_professional_accounting:
2025-07-28 07:02:11,073 - INFO -     - accuracy: 0.4000
2025-07-28 07:02:11,074 - INFO -   mmlu_professional_medicine:
2025-07-28 07:02:11,074 - INFO -     - accuracy: 0.4500
2025-07-28 07:02:11,074 - INFO -   mmlu_virology:
2025-07-28 07:02:11,074 - INFO -     - accuracy: 0.5500
2025-07-28 07:02:11,074 - INFO -   mmlu_social_sciences:
2025-07-28 07:02:11,074 - INFO -     - accuracy: 0.7333
2025-07-28 07:02:11,074 - INFO -   mmlu_econometrics:
2025-07-28 07:02:11,074 - INFO -     - accuracy: 0.5500
2025-07-28 07:02:11,074 - INFO -   mmlu_high_school_geography:
2025-07-28 07:02:11,075 - INFO -     - accuracy: 0.9500
2025-07-28 07:02:11,075 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 07:02:11,075 - INFO -     - accuracy: 0.8500
2025-07-28 07:02:11,075 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 07:02:11,075 - INFO -     - accuracy: 0.5000
2025-07-28 07:02:11,075 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 07:02:11,075 - INFO -     - accuracy: 0.6500
2025-07-28 07:02:11,075 - INFO -   mmlu_high_school_psychology:
2025-07-28 07:02:11,075 - INFO -     - accuracy: 0.9000
2025-07-28 07:02:11,076 - INFO -   mmlu_human_sexuality:
2025-07-28 07:02:11,076 - INFO -     - accuracy: 0.7500
2025-07-28 07:02:11,076 - INFO -   mmlu_professional_psychology:
2025-07-28 07:02:11,076 - INFO -     - accuracy: 0.8000
2025-07-28 07:02:11,076 - INFO -   mmlu_public_relations:
2025-07-28 07:02:11,076 - INFO -     - accuracy: 0.3500
2025-07-28 07:02:11,076 - INFO -   mmlu_security_studies:
2025-07-28 07:02:11,076 - INFO -     - accuracy: 0.8500
2025-07-28 07:02:11,077 - INFO -   mmlu_sociology:
2025-07-28 07:02:11,077 - INFO -     - accuracy: 0.8000
2025-07-28 07:02:11,077 - INFO -   mmlu_us_foreign_policy:
2025-07-28 07:02:11,077 - INFO -     - accuracy: 0.8500
2025-07-28 07:02:11,077 - INFO -   mmlu_stem:
2025-07-28 07:02:11,077 - INFO -     - accuracy: 0.5737
2025-07-28 07:02:11,077 - INFO -   mmlu_abstract_algebra:
2025-07-28 07:02:11,077 - INFO -     - accuracy: 0.3000
2025-07-28 07:02:11,077 - INFO -   mmlu_anatomy:
2025-07-28 07:02:11,078 - INFO -     - accuracy: 0.7500
2025-07-28 07:02:11,078 - INFO -   mmlu_astronomy:
2025-07-28 07:02:11,078 - INFO -     - accuracy: 0.8500
2025-07-28 07:02:11,078 - INFO -   mmlu_college_biology:
2025-07-28 07:02:11,078 - INFO -     - accuracy: 0.8500
2025-07-28 07:02:11,078 - INFO -   mmlu_college_chemistry:
2025-07-28 07:02:11,078 - INFO -     - accuracy: 0.5000
2025-07-28 07:02:11,078 - INFO -   mmlu_college_computer_science:
2025-07-28 07:02:11,079 - INFO -     - accuracy: 0.4000
2025-07-28 07:02:11,079 - INFO -   mmlu_college_mathematics:
2025-07-28 07:02:11,079 - INFO -     - accuracy: 0.4500
2025-07-28 07:02:11,079 - INFO -   mmlu_college_physics:
2025-07-28 07:02:11,079 - INFO -     - accuracy: 0.5000
2025-07-28 07:02:11,079 - INFO -   mmlu_computer_security:
2025-07-28 07:02:11,079 - INFO -     - accuracy: 0.8000
2025-07-28 07:02:11,079 - INFO -   mmlu_conceptual_physics:
2025-07-28 07:02:11,079 - INFO -     - accuracy: 0.7500
2025-07-28 07:02:11,080 - INFO -   mmlu_electrical_engineering:
2025-07-28 07:02:11,080 - INFO -     - accuracy: 0.3500
2025-07-28 07:02:11,080 - INFO -   mmlu_elementary_mathematics:
2025-07-28 07:02:11,080 - INFO -     - accuracy: 0.5000
2025-07-28 07:02:11,080 - INFO -   mmlu_high_school_biology:
2025-07-28 07:02:11,080 - INFO -     - accuracy: 0.8500
2025-07-28 07:02:11,080 - INFO -   mmlu_high_school_chemistry:
2025-07-28 07:02:11,080 - INFO -     - accuracy: 0.5500
2025-07-28 07:02:11,080 - INFO -   mmlu_high_school_computer_science:
2025-07-28 07:02:11,081 - INFO -     - accuracy: 0.8000
2025-07-28 07:02:11,081 - INFO -   mmlu_high_school_mathematics:
2025-07-28 07:02:11,081 - INFO -     - accuracy: 0.2500
2025-07-28 07:02:11,081 - INFO -   mmlu_high_school_physics:
2025-07-28 07:02:11,081 - INFO -     - accuracy: 0.4500
2025-07-28 07:02:11,081 - INFO -   mmlu_high_school_statistics:
2025-07-28 07:02:11,081 - INFO -     - accuracy: 0.4000
2025-07-28 07:02:11,081 - INFO -   mmlu_machine_learning:
2025-07-28 07:02:11,081 - INFO -     - accuracy: 0.6000
2025-07-28 07:02:11,082 - INFO - ============================================================

2025-07-28 07:02:11,083 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 8/10: arc_challenge
2025-07-28 07:02:11,084 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 07:02:11,084 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 07:02:11,084 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:02:18,391 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 07:02:40,752 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 07:02:40,753 - INFO - 
============================================================
2025-07-28 07:02:40,753 - INFO - Task 'arc_challenge' Results:
2025-07-28 07:02:40,753 - INFO - ============================================================
2025-07-28 07:02:40,754 - INFO -   arc_challenge:
2025-07-28 07:02:40,754 - INFO -     - accuracy: 0.6000
2025-07-28 07:02:40,754 - INFO -     - accuracy_norm: 0.6000
2025-07-28 07:02:40,754 - INFO - ============================================================

2025-07-28 07:02:40,755 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 9/10: arc_easy
2025-07-28 07:02:40,755 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'arc_easy' will use num_fewshot=0
2025-07-28 07:02:40,755 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 07:02:40,756 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:02:47,100 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 07:03:07,361 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 07:03:07,363 - INFO - 
============================================================
2025-07-28 07:03:07,363 - INFO - Task 'arc_easy' Results:
2025-07-28 07:03:07,363 - INFO - ============================================================
2025-07-28 07:03:07,363 - INFO -   arc_easy:
2025-07-28 07:03:07,363 - INFO -     - accuracy: 0.8000
2025-07-28 07:03:07,363 - INFO -     - accuracy_norm: 0.8000
2025-07-28 07:03:07,364 - INFO - ============================================================

2025-07-28 07:03:07,365 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 10/10: hellaswag
2025-07-28 07:03:07,365 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'hellaswag' will use num_fewshot=0
2025-07-28 07:03:07,365 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 07:03:07,365 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:03:21,585 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 07:03:44,535 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 07:03:44,536 - INFO - 
============================================================
2025-07-28 07:03:44,536 - INFO - Task 'hellaswag' Results:
2025-07-28 07:03:44,536 - INFO - ============================================================
2025-07-28 07:03:44,536 - INFO -   hellaswag:
2025-07-28 07:03:44,537 - INFO -     - accuracy: 0.6000
2025-07-28 07:03:44,537 - INFO -     - accuracy_norm: 0.6500
2025-07-28 07:03:44,537 - INFO - ============================================================

2025-07-28 07:03:44,538 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 07:03:44,540 - INFO - [Process 1795506] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_032724/model_results/luxia-21.4b-alignment-v1.2/luxia-21.4b-alignment-v1.2_harness_13.json
2025-07-28 07:03:44,542 - INFO - [Process 1795506] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/luxia-21.4b-alignment-v1.2/luxia-21.4b-alignment-v1.2_harness_13.json
2025-07-28 07:03:44,818 - INFO - Results uploaded to WandB as artifact
2025-07-28 07:03:44,828 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 07:03:44,830 - INFO - [Process 1795506] Successfully completed luxia-21.4b-alignment-v1.2_harness_13
2025-07-28 07:03:46,871 - INFO - Run luxia-21.4b-alignment-v1.2_harness_13 finished successfully
2025-07-28 07:03:46,874 - WARNING - No results directory found for model gemma-3-4b-it
2025-07-28 07:03:46,875 - WARNING - No results directory found for model EXAONE-3.5-2.4B-Instruct
2025-07-28 07:03:46,876 - WARNING - No results directory found for model HyperCLOVAX-SEED-Text-Instruct-1.5B
2025-07-28 07:03:46,876 - WARNING - No results directory found for model HyperCLOVAX-SEED-Text-Instruct-0.5B
2025-07-28 07:03:46,876 - WARNING - No results directory found for model kanana-1.5-2.1b-instruct-2505
2025-07-28 07:03:46,876 - WARNING - No results directory found for model eagle-3b-preview
2025-07-28 07:03:46,877 - ERROR - Phase 2 threshold optimization failed: keys must be str, int, float, bool or None, not tuple
2025-07-28 07:39:25,067 - INFO - Using experiment directory: /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_073925
2025-07-28 07:39:25,067 - INFO - ============================================================
2025-07-28 07:39:25,067 - INFO - BASELINE MODE - Traditional Execution
2025-07-28 07:39:25,067 - INFO - ============================================================
2025-07-28 07:39:25,067 - INFO - Processing 4 medium models sequentially
2025-07-28 07:39:25,094 - INFO - [Process 1865749] Llama-3.1-8B_harness_1 assigned to cuda:0
2025-07-28 07:39:25,094 - INFO - [Process 1865749] Llama-3.1-8B_harness_1 - using custom limit: 20
2025-07-28 07:39:27,041 - INFO - WandB run initialized: Llama-3.1-8B_20250728_073925 (ID: fea3999e)
2025-07-28 07:39:27,352 - INFO - Llama-3.1-8B_harness_1: Test mode (limit=2), setting num_fewshot=0
2025-07-28 07:39:27,352 - INFO - Llama-3.1-8B_harness_1: Processing task 1/10: kmmlu
2025-07-28 07:39:27,353 - INFO - Llama-3.1-8B_harness_1: Task 'kmmlu' will use num_fewshot=0
2025-07-28 07:39:27,353 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 07:39:27,354 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:40:43,453 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 07:40:43,454 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 07:40:43,454 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 07:40:43,454 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 07:40:43,454 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 07:40:43,454 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 07:40:43,454 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 07:40:43,454 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 07:40:43,454 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 07:40:43,454 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 07:40:43,454 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 07:40:43,455 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 07:40:43,455 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 07:40:43,455 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 07:40:43,455 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 07:40:43,455 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 07:40:43,455 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 07:40:43,455 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 07:40:43,455 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 07:40:43,455 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 07:40:43,455 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 07:40:43,456 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 07:40:43,456 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 07:40:43,456 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 07:40:43,456 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 07:40:43,456 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 07:40:43,456 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 07:40:43,456 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 07:40:43,456 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 07:40:43,456 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 07:40:43,456 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 07:40:43,457 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 07:40:43,457 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 07:40:43,457 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 07:40:43,457 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 07:40:43,457 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 07:40:43,457 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 07:40:43,457 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 07:40:43,457 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 07:40:43,457 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 07:40:43,457 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 07:40:43,458 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 07:40:43,458 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 07:40:43,458 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 07:40:43,458 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 07:41:15,405 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 07:41:15,406 - INFO - 
============================================================
2025-07-28 07:41:15,406 - INFO - Task 'kmmlu' Results:
2025-07-28 07:41:15,406 - INFO - ============================================================
2025-07-28 07:41:15,406 - INFO -   kmmlu:
2025-07-28 07:41:15,406 - INFO -     - accuracy: 0.3289
2025-07-28 07:41:15,406 - INFO -   kmmlu_applied_science:
2025-07-28 07:41:15,407 - INFO -     - accuracy: 0.2667
2025-07-28 07:41:15,407 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 07:41:15,407 - INFO -     - accuracy: 0.2000
2025-07-28 07:41:15,407 - INFO -   kmmlu_electronics_engineering:
2025-07-28 07:41:15,407 - INFO -     - accuracy: 0.1000
2025-07-28 07:41:15,407 - INFO -   kmmlu_energy_management:
2025-07-28 07:41:15,407 - INFO -     - accuracy: 0.1000
2025-07-28 07:41:15,407 - INFO -   kmmlu_environmental_science:
2025-07-28 07:41:15,408 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,408 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 07:41:15,408 - INFO -     - accuracy: 0.3500
2025-07-28 07:41:15,408 - INFO -   kmmlu_geomatics:
2025-07-28 07:41:15,408 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,408 - INFO -   kmmlu_industrial_engineer:
2025-07-28 07:41:15,408 - INFO -     - accuracy: 0.3500
2025-07-28 07:41:15,408 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 07:41:15,408 - INFO -     - accuracy: 0.4500
2025-07-28 07:41:15,409 - INFO -   kmmlu_maritime_engineering:
2025-07-28 07:41:15,409 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,409 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 07:41:15,409 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,409 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 07:41:15,409 - INFO -     - accuracy: 0.3000
2025-07-28 07:41:15,409 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 07:41:15,409 - INFO -     - accuracy: 0.3500
2025-07-28 07:41:15,409 - INFO -   kmmlu_humss:
2025-07-28 07:41:15,410 - INFO -     - accuracy: 0.3591
2025-07-28 07:41:15,410 - INFO -   kmmlu_accounting:
2025-07-28 07:41:15,410 - INFO -     - accuracy: 0.4500
2025-07-28 07:41:15,410 - INFO -   kmmlu_criminal_law:
2025-07-28 07:41:15,410 - INFO -     - accuracy: 0.3000
2025-07-28 07:41:15,410 - INFO -   kmmlu_economics:
2025-07-28 07:41:15,410 - INFO -     - accuracy: 0.5000
2025-07-28 07:41:15,410 - INFO -   kmmlu_education:
2025-07-28 07:41:15,410 - INFO -     - accuracy: 0.3000
2025-07-28 07:41:15,411 - INFO -   kmmlu_korean_history:
2025-07-28 07:41:15,411 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,411 - INFO -   kmmlu_law:
2025-07-28 07:41:15,411 - INFO -     - accuracy: 0.3500
2025-07-28 07:41:15,411 - INFO -   kmmlu_management:
2025-07-28 07:41:15,411 - INFO -     - accuracy: 0.3000
2025-07-28 07:41:15,411 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 07:41:15,411 - INFO -     - accuracy: 0.5500
2025-07-28 07:41:15,411 - INFO -   kmmlu_psychology:
2025-07-28 07:41:15,411 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,412 - INFO -   kmmlu_social_welfare:
2025-07-28 07:41:15,412 - INFO -     - accuracy: 0.5000
2025-07-28 07:41:15,412 - INFO -   kmmlu_taxation:
2025-07-28 07:41:15,412 - INFO -     - accuracy: 0.2000
2025-07-28 07:41:15,412 - INFO -   kmmlu_other:
2025-07-28 07:41:15,412 - INFO -     - accuracy: 0.2955
2025-07-28 07:41:15,412 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 07:41:15,412 - INFO -     - accuracy: 0.1500
2025-07-28 07:41:15,412 - INFO -   kmmlu_construction:
2025-07-28 07:41:15,413 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,413 - INFO -   kmmlu_fashion:
2025-07-28 07:41:15,413 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,413 - INFO -   kmmlu_food_processing:
2025-07-28 07:41:15,413 - INFO -     - accuracy: 0.3500
2025-07-28 07:41:15,413 - INFO -   kmmlu_health:
2025-07-28 07:41:15,413 - INFO -     - accuracy: 0.5000
2025-07-28 07:41:15,413 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 07:41:15,413 - INFO -     - accuracy: 0.3500
2025-07-28 07:41:15,413 - INFO -   kmmlu_marketing:
2025-07-28 07:41:15,414 - INFO -     - accuracy: 0.4500
2025-07-28 07:41:15,414 - INFO -   kmmlu_patent:
2025-07-28 07:41:15,414 - INFO -     - accuracy: 0.2000
2025-07-28 07:41:15,414 - INFO -   kmmlu_public_safety:
2025-07-28 07:41:15,414 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,414 - INFO -   kmmlu_real_estate:
2025-07-28 07:41:15,414 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,414 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 07:41:15,414 - INFO -     - accuracy: 0.2500
2025-07-28 07:41:15,414 - INFO -   kmmlu_stem:
2025-07-28 07:41:15,415 - INFO -     - accuracy: 0.4000
2025-07-28 07:41:15,415 - INFO -   kmmlu_biology:
2025-07-28 07:41:15,415 - INFO -     - accuracy: 0.3000
2025-07-28 07:41:15,415 - INFO -   kmmlu_chemical_engineering:
2025-07-28 07:41:15,415 - INFO -     - accuracy: 0.3500
2025-07-28 07:41:15,415 - INFO -   kmmlu_chemistry:
2025-07-28 07:41:15,415 - INFO -     - accuracy: 0.3500
2025-07-28 07:41:15,415 - INFO -   kmmlu_civil_engineering:
2025-07-28 07:41:15,415 - INFO -     - accuracy: 0.4000
2025-07-28 07:41:15,416 - INFO -   kmmlu_computer_science:
2025-07-28 07:41:15,416 - INFO -     - accuracy: 0.6500
2025-07-28 07:41:15,416 - INFO -   kmmlu_ecology:
2025-07-28 07:41:15,416 - INFO -     - accuracy: 0.4500
2025-07-28 07:41:15,416 - INFO -   kmmlu_electrical_engineering:
2025-07-28 07:41:15,416 - INFO -     - accuracy: 0.4000
2025-07-28 07:41:15,416 - INFO -   kmmlu_information_technology:
2025-07-28 07:41:15,416 - INFO -     - accuracy: 0.5000
2025-07-28 07:41:15,416 - INFO -   kmmlu_materials_engineering:
2025-07-28 07:41:15,416 - INFO -     - accuracy: 0.3000
2025-07-28 07:41:15,417 - INFO -   kmmlu_math:
2025-07-28 07:41:15,417 - INFO -     - accuracy: 0.3500
2025-07-28 07:41:15,417 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 07:41:15,417 - INFO -     - accuracy: 0.3500
2025-07-28 07:41:15,417 - INFO - ============================================================

2025-07-28 07:41:15,451 - INFO - Llama-3.1-8B_harness_1: Processing task 2/10: kmmlu_hard
2025-07-28 07:41:15,451 - INFO - Llama-3.1-8B_harness_1: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 07:41:15,451 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 07:41:15,452 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:42:32,126 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 07:42:32,127 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 07:42:32,127 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 07:42:32,127 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 07:42:32,127 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 07:42:32,127 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 07:42:32,127 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 07:42:32,127 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 07:42:32,128 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 07:42:32,128 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 07:42:32,128 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 07:42:32,128 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 07:42:32,128 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 07:42:32,128 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 07:42:32,128 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 07:42:32,128 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 07:42:32,128 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 07:42:32,128 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 07:42:32,129 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 07:42:32,129 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 07:42:32,129 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 07:42:32,129 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 07:42:32,129 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 07:42:32,129 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 07:42:32,129 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 07:42:32,129 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 07:42:32,129 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 07:42:32,129 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 07:42:32,130 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 07:42:32,130 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 07:42:32,130 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 07:42:32,130 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 07:42:32,130 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 07:42:32,130 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 07:42:32,130 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 07:42:32,130 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 07:42:32,130 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 07:42:32,130 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 07:42:32,131 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 07:42:32,131 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 07:42:32,131 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 07:42:32,131 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 07:42:32,131 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 07:42:32,131 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 07:42:32,131 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 07:43:03,964 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 07:43:03,964 - INFO - 
============================================================
2025-07-28 07:43:03,965 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 07:43:03,965 - INFO - ============================================================
2025-07-28 07:43:03,966 - INFO -   kmmlu_hard:
2025-07-28 07:43:03,966 - INFO -     - accuracy: 0.2600
2025-07-28 07:43:03,966 - INFO -   kmmlu_hard_applied_science:
2025-07-28 07:43:03,966 - INFO -     - accuracy: 0.3083
2025-07-28 07:43:03,966 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 07:43:03,966 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,966 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 07:43:03,967 - INFO -     - accuracy: 0.3000
2025-07-28 07:43:03,967 - INFO -   kmmlu_hard_energy_management:
2025-07-28 07:43:03,967 - INFO -     - accuracy: 0.3500
2025-07-28 07:43:03,967 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 07:43:03,967 - INFO -     - accuracy: 0.4500
2025-07-28 07:43:03,967 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 07:43:03,967 - INFO -     - accuracy: 0.2500
2025-07-28 07:43:03,967 - INFO -   kmmlu_hard_geomatics:
2025-07-28 07:43:03,967 - INFO -     - accuracy: 0.5500
2025-07-28 07:43:03,968 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 07:43:03,968 - INFO -     - accuracy: 0.4500
2025-07-28 07:43:03,968 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 07:43:03,968 - INFO -     - accuracy: 0.1500
2025-07-28 07:43:03,968 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 07:43:03,968 - INFO -     - accuracy: 0.1500
2025-07-28 07:43:03,968 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 07:43:03,968 - INFO -     - accuracy: 0.2500
2025-07-28 07:43:03,968 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 07:43:03,969 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,969 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 07:43:03,969 - INFO -     - accuracy: 0.4000
2025-07-28 07:43:03,969 - INFO -   kmmlu_hard_humss:
2025-07-28 07:43:03,969 - INFO -     - accuracy: 0.2182
2025-07-28 07:43:03,969 - INFO -   kmmlu_hard_accounting:
2025-07-28 07:43:03,969 - INFO -     - accuracy: 0.1500
2025-07-28 07:43:03,969 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 07:43:03,969 - INFO -     - accuracy: 0.1000
2025-07-28 07:43:03,969 - INFO -   kmmlu_hard_economics:
2025-07-28 07:43:03,969 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,970 - INFO -   kmmlu_hard_education:
2025-07-28 07:43:03,970 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,970 - INFO -   kmmlu_hard_korean_history:
2025-07-28 07:43:03,970 - INFO -     - accuracy: 0.3000
2025-07-28 07:43:03,970 - INFO -   kmmlu_hard_law:
2025-07-28 07:43:03,970 - INFO -     - accuracy: 0.2500
2025-07-28 07:43:03,970 - INFO -   kmmlu_hard_management:
2025-07-28 07:43:03,970 - INFO -     - accuracy: 0.3000
2025-07-28 07:43:03,970 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 07:43:03,970 - INFO -     - accuracy: 0.4000
2025-07-28 07:43:03,971 - INFO -   kmmlu_hard_psychology:
2025-07-28 07:43:03,971 - INFO -     - accuracy: 0.1500
2025-07-28 07:43:03,971 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 07:43:03,971 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,971 - INFO -   kmmlu_hard_taxation:
2025-07-28 07:43:03,971 - INFO -     - accuracy: 0.1500
2025-07-28 07:43:03,971 - INFO -   kmmlu_hard_other:
2025-07-28 07:43:03,971 - INFO -     - accuracy: 0.2727
2025-07-28 07:43:03,971 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 07:43:03,971 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,972 - INFO -   kmmlu_hard_construction:
2025-07-28 07:43:03,972 - INFO -     - accuracy: 0.4000
2025-07-28 07:43:03,972 - INFO -   kmmlu_hard_fashion:
2025-07-28 07:43:03,972 - INFO -     - accuracy: 0.3000
2025-07-28 07:43:03,972 - INFO -   kmmlu_hard_food_processing:
2025-07-28 07:43:03,972 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,972 - INFO -   kmmlu_hard_health:
2025-07-28 07:43:03,972 - INFO -     - accuracy: 0.2500
2025-07-28 07:43:03,972 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 07:43:03,973 - INFO -     - accuracy: 0.3000
2025-07-28 07:43:03,973 - INFO -   kmmlu_hard_marketing:
2025-07-28 07:43:03,973 - INFO -     - accuracy: 0.4500
2025-07-28 07:43:03,973 - INFO -   kmmlu_hard_patent:
2025-07-28 07:43:03,973 - INFO -     - accuracy: 0.0500
2025-07-28 07:43:03,973 - INFO -   kmmlu_hard_public_safety:
2025-07-28 07:43:03,973 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,973 - INFO -   kmmlu_hard_real_estate:
2025-07-28 07:43:03,973 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,974 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 07:43:03,974 - INFO -     - accuracy: 0.4500
2025-07-28 07:43:03,974 - INFO -   kmmlu_hard_stem:
2025-07-28 07:43:03,974 - INFO -     - accuracy: 0.2364
2025-07-28 07:43:03,974 - INFO -   kmmlu_hard_biology:
2025-07-28 07:43:03,974 - INFO -     - accuracy: 0.2500
2025-07-28 07:43:03,974 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 07:43:03,974 - INFO -     - accuracy: 0.1500
2025-07-28 07:43:03,974 - INFO -   kmmlu_hard_chemistry:
2025-07-28 07:43:03,975 - INFO -     - accuracy: 0.3000
2025-07-28 07:43:03,975 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 07:43:03,975 - INFO -     - accuracy: 0.1500
2025-07-28 07:43:03,975 - INFO -   kmmlu_hard_computer_science:
2025-07-28 07:43:03,975 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,975 - INFO -   kmmlu_hard_ecology:
2025-07-28 07:43:03,975 - INFO -     - accuracy: 0.3500
2025-07-28 07:43:03,975 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 07:43:03,975 - INFO -     - accuracy: 0.3000
2025-07-28 07:43:03,975 - INFO -   kmmlu_hard_information_technology:
2025-07-28 07:43:03,976 - INFO -     - accuracy: 0.3000
2025-07-28 07:43:03,976 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 07:43:03,976 - INFO -     - accuracy: 0.2000
2025-07-28 07:43:03,976 - INFO -   kmmlu_hard_math:
2025-07-28 07:43:03,976 - INFO -     - accuracy: 0.1500
2025-07-28 07:43:03,976 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 07:43:03,976 - INFO -     - accuracy: 0.2500
2025-07-28 07:43:03,976 - INFO - ============================================================

2025-07-28 07:43:04,011 - INFO - Llama-3.1-8B_harness_1: Processing task 3/10: haerae
2025-07-28 07:43:04,012 - INFO - Llama-3.1-8B_harness_1: Task 'haerae' will use num_fewshot=0
2025-07-28 07:43:04,012 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 07:43:04,013 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:43:23,498 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 07:43:23,499 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 07:43:23,499 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 07:43:23,499 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 07:43:23,499 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 07:43:40,549 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 07:43:40,550 - INFO - 
============================================================
2025-07-28 07:43:40,550 - INFO - Task 'haerae' Results:
2025-07-28 07:43:40,551 - INFO - ============================================================
2025-07-28 07:43:40,551 - INFO -   haerae:
2025-07-28 07:43:40,551 - INFO -     - accuracy: 0.4800
2025-07-28 07:43:40,551 - INFO -     - accuracy_norm: 0.4800
2025-07-28 07:43:40,551 - INFO -   haerae_general_knowledge:
2025-07-28 07:43:40,551 - INFO -     - accuracy: 0.6000
2025-07-28 07:43:40,551 - INFO -     - accuracy_norm: 0.6000
2025-07-28 07:43:40,552 - INFO -   haerae_history:
2025-07-28 07:43:40,552 - INFO -     - accuracy: 0.3000
2025-07-28 07:43:40,552 - INFO -     - accuracy_norm: 0.3000
2025-07-28 07:43:40,552 - INFO -   haerae_loan_word:
2025-07-28 07:43:40,552 - INFO -     - accuracy: 0.5500
2025-07-28 07:43:40,552 - INFO -     - accuracy_norm: 0.5500
2025-07-28 07:43:40,552 - INFO -   haerae_rare_word:
2025-07-28 07:43:40,552 - INFO -     - accuracy: 0.2500
2025-07-28 07:43:40,552 - INFO -     - accuracy_norm: 0.2500
2025-07-28 07:43:40,553 - INFO -   haerae_standard_nomenclature:
2025-07-28 07:43:40,553 - INFO -     - accuracy: 0.7000
2025-07-28 07:43:40,553 - INFO -     - accuracy_norm: 0.7000
2025-07-28 07:43:40,553 - INFO - ============================================================

2025-07-28 07:43:40,588 - INFO - Llama-3.1-8B_harness_1: Processing task 4/10: kobest
2025-07-28 07:43:40,589 - INFO - Llama-3.1-8B_harness_1: Task 'kobest' will use num_fewshot=0
2025-07-28 07:43:40,589 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 07:43:40,590 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:44:03,866 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 07:44:03,867 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 07:44:03,867 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 07:44:03,867 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 07:44:03,867 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 07:44:13,669 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 07:44:13,670 - INFO - 
============================================================
2025-07-28 07:44:13,671 - INFO - Task 'kobest' Results:
2025-07-28 07:44:13,671 - INFO - ============================================================
2025-07-28 07:44:13,671 - INFO -   kobest:
2025-07-28 07:44:13,671 - INFO -     - accuracy: 0.6000
2025-07-28 07:44:13,671 - INFO -     - accuracy_norm: 0.7500
2025-07-28 07:44:13,671 - INFO -     - f1: 0.5294
2025-07-28 07:44:13,671 - INFO -   kobest_boolq:
2025-07-28 07:44:13,671 - INFO -     - accuracy: 0.6500
2025-07-28 07:44:13,672 - INFO -     - f1: 0.5611
2025-07-28 07:44:13,672 - INFO -   kobest_copa:
2025-07-28 07:44:13,672 - INFO -     - accuracy: 0.7500
2025-07-28 07:44:13,672 - INFO -     - f1: 0.7494
2025-07-28 07:44:13,672 - INFO -   kobest_hellaswag:
2025-07-28 07:44:13,672 - INFO -     - accuracy: 0.3500
2025-07-28 07:44:13,672 - INFO -     - accuracy_norm: 0.7500
2025-07-28 07:44:13,672 - INFO -     - f1: 0.3388
2025-07-28 07:44:13,672 - INFO -   kobest_sentineg:
2025-07-28 07:44:13,673 - INFO -     - accuracy: 0.7000
2025-07-28 07:44:13,673 - INFO -     - f1: 0.6429
2025-07-28 07:44:13,673 - INFO -   kobest_wic:
2025-07-28 07:44:13,673 - INFO -     - accuracy: 0.5500
2025-07-28 07:44:13,673 - INFO -     - f1: 0.3548
2025-07-28 07:44:13,673 - INFO - ============================================================

2025-07-28 07:44:13,708 - INFO - Llama-3.1-8B_harness_1: Processing task 5/10: csatqa
2025-07-28 07:44:13,709 - INFO - Llama-3.1-8B_harness_1: Task 'csatqa' detected as zero-shot task
2025-07-28 07:44:13,709 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 07:44:13,710 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:44:29,205 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 07:44:29,205 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 07:44:29,205 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 07:44:29,205 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 07:44:29,205 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 07:44:29,205 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 07:45:44,768 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 07:45:44,770 - INFO - 
============================================================
2025-07-28 07:45:44,770 - INFO - Task 'csatqa' Results:
2025-07-28 07:45:44,771 - INFO - ============================================================
2025-07-28 07:45:44,771 - INFO -   csatqa:
2025-07-28 07:45:44,771 - INFO -     - accuracy: 0.2703
2025-07-28 07:45:44,771 - INFO -     - accuracy_norm: 0.2703
2025-07-28 07:45:44,771 - INFO -   csatqa_gr:
2025-07-28 07:45:44,772 - INFO -     - accuracy: 0.1000
2025-07-28 07:45:44,772 - INFO -     - accuracy_norm: 0.1000
2025-07-28 07:45:44,772 - INFO -   csatqa_li:
2025-07-28 07:45:44,772 - INFO -     - accuracy: 0.2000
2025-07-28 07:45:44,772 - INFO -     - accuracy_norm: 0.2000
2025-07-28 07:45:44,772 - INFO -   csatqa_rch:
2025-07-28 07:45:44,772 - INFO -     - accuracy: 0.3500
2025-07-28 07:45:44,772 - INFO -     - accuracy_norm: 0.3500
2025-07-28 07:45:44,772 - INFO -   csatqa_rcs:
2025-07-28 07:45:44,772 - INFO -     - accuracy: 0.3000
2025-07-28 07:45:44,773 - INFO -     - accuracy_norm: 0.3000
2025-07-28 07:45:44,773 - INFO -   csatqa_rcss:
2025-07-28 07:45:44,773 - INFO -     - accuracy: 0.4000
2025-07-28 07:45:44,773 - INFO -     - accuracy_norm: 0.4000
2025-07-28 07:45:44,773 - INFO -   csatqa_wr:
2025-07-28 07:45:44,773 - INFO -     - accuracy: 0.2727
2025-07-28 07:45:44,773 - INFO -     - accuracy_norm: 0.2727
2025-07-28 07:45:44,773 - INFO - ============================================================

2025-07-28 07:45:44,815 - INFO - Llama-3.1-8B_harness_1: Processing task 6/10: kormedmcqa
2025-07-28 07:45:44,816 - INFO - Llama-3.1-8B_harness_1: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 07:45:44,817 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 07:45:44,817 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:46:06,591 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 07:46:06,592 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 07:46:06,592 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 07:46:06,592 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 07:47:49,006 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 07:47:49,007 - INFO - 
============================================================
2025-07-28 07:47:49,007 - INFO - Task 'kormedmcqa' Results:
2025-07-28 07:47:49,008 - INFO - ============================================================
2025-07-28 07:47:49,008 - INFO -   kormedmcqa:
2025-07-28 07:47:49,008 - INFO -     - exact_match: 0.0875
2025-07-28 07:47:49,008 - INFO -   kormedmcqa_dentist:
2025-07-28 07:47:49,008 - INFO -     - exact_match: 0.0000
2025-07-28 07:47:49,008 - INFO -   kormedmcqa_doctor:
2025-07-28 07:47:49,008 - INFO -     - exact_match: 0.0500
2025-07-28 07:47:49,008 - INFO -   kormedmcqa_nurse:
2025-07-28 07:47:49,009 - INFO -     - exact_match: 0.2500
2025-07-28 07:47:49,009 - INFO -   kormedmcqa_pharm:
2025-07-28 07:47:49,009 - INFO -     - exact_match: 0.0500
2025-07-28 07:47:49,009 - INFO - ============================================================

2025-07-28 07:47:49,045 - INFO - Llama-3.1-8B_harness_1: Processing task 7/10: mmlu
2025-07-28 07:47:49,045 - INFO - Llama-3.1-8B_harness_1: Task 'mmlu' will use num_fewshot=0
2025-07-28 07:47:49,046 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 07:47:49,047 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:51:07,973 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 07:51:07,973 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 07:51:07,973 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 07:51:07,973 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 07:51:07,973 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 07:51:07,973 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 07:51:07,973 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 07:51:07,973 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 07:51:07,974 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 07:51:07,975 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 07:51:07,976 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 07:51:07,977 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 07:51:07,978 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 07:51:07,978 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 07:51:47,432 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 07:51:47,433 - INFO - 
============================================================
2025-07-28 07:51:47,433 - INFO - Task 'mmlu' Results:
2025-07-28 07:51:47,433 - INFO - ============================================================
2025-07-28 07:51:47,434 - INFO -   mmlu:
2025-07-28 07:51:47,434 - INFO -     - accuracy: 0.6623
2025-07-28 07:51:47,434 - INFO -   mmlu_humanities:
2025-07-28 07:51:47,434 - INFO -     - accuracy: 0.7000
2025-07-28 07:51:47,434 - INFO -   mmlu_formal_logic:
2025-07-28 07:51:47,434 - INFO -     - accuracy: 0.4500
2025-07-28 07:51:47,434 - INFO -   mmlu_high_school_european_history:
2025-07-28 07:51:47,434 - INFO -     - accuracy: 0.7000
2025-07-28 07:51:47,435 - INFO -   mmlu_high_school_us_history:
2025-07-28 07:51:47,435 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,435 - INFO -   mmlu_high_school_world_history:
2025-07-28 07:51:47,435 - INFO -     - accuracy: 0.9500
2025-07-28 07:51:47,435 - INFO -   mmlu_international_law:
2025-07-28 07:51:47,435 - INFO -     - accuracy: 0.8500
2025-07-28 07:51:47,435 - INFO -   mmlu_jurisprudence:
2025-07-28 07:51:47,435 - INFO -     - accuracy: 0.7500
2025-07-28 07:51:47,435 - INFO -   mmlu_logical_fallacies:
2025-07-28 07:51:47,435 - INFO -     - accuracy: 0.7500
2025-07-28 07:51:47,435 - INFO -   mmlu_moral_disputes:
2025-07-28 07:51:47,436 - INFO -     - accuracy: 0.5500
2025-07-28 07:51:47,436 - INFO -   mmlu_moral_scenarios:
2025-07-28 07:51:47,436 - INFO -     - accuracy: 0.3500
2025-07-28 07:51:47,436 - INFO -   mmlu_philosophy:
2025-07-28 07:51:47,436 - INFO -     - accuracy: 0.6500
2025-07-28 07:51:47,436 - INFO -   mmlu_prehistory:
2025-07-28 07:51:47,436 - INFO -     - accuracy: 0.8500
2025-07-28 07:51:47,436 - INFO -   mmlu_professional_law:
2025-07-28 07:51:47,436 - INFO -     - accuracy: 0.6000
2025-07-28 07:51:47,436 - INFO -   mmlu_world_religions:
2025-07-28 07:51:47,436 - INFO -     - accuracy: 0.8500
2025-07-28 07:51:47,437 - INFO -   mmlu_other:
2025-07-28 07:51:47,437 - INFO -     - accuracy: 0.6385
2025-07-28 07:51:47,437 - INFO -   mmlu_business_ethics:
2025-07-28 07:51:47,437 - INFO -     - accuracy: 0.6500
2025-07-28 07:51:47,437 - INFO -   mmlu_clinical_knowledge:
2025-07-28 07:51:47,437 - INFO -     - accuracy: 0.6500
2025-07-28 07:51:47,437 - INFO -   mmlu_college_medicine:
2025-07-28 07:51:47,437 - INFO -     - accuracy: 0.7000
2025-07-28 07:51:47,437 - INFO -   mmlu_global_facts:
2025-07-28 07:51:47,437 - INFO -     - accuracy: 0.3500
2025-07-28 07:51:47,437 - INFO -   mmlu_human_aging:
2025-07-28 07:51:47,438 - INFO -     - accuracy: 0.4000
2025-07-28 07:51:47,438 - INFO -   mmlu_management:
2025-07-28 07:51:47,438 - INFO -     - accuracy: 0.8500
2025-07-28 07:51:47,438 - INFO -   mmlu_marketing:
2025-07-28 07:51:47,438 - INFO -     - accuracy: 0.7500
2025-07-28 07:51:47,438 - INFO -   mmlu_medical_genetics:
2025-07-28 07:51:47,438 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,438 - INFO -   mmlu_miscellaneous:
2025-07-28 07:51:47,438 - INFO -     - accuracy: 0.8500
2025-07-28 07:51:47,438 - INFO -   mmlu_nutrition:
2025-07-28 07:51:47,438 - INFO -     - accuracy: 0.7500
2025-07-28 07:51:47,439 - INFO -   mmlu_professional_accounting:
2025-07-28 07:51:47,439 - INFO -     - accuracy: 0.2500
2025-07-28 07:51:47,439 - INFO -   mmlu_professional_medicine:
2025-07-28 07:51:47,439 - INFO -     - accuracy: 0.7000
2025-07-28 07:51:47,439 - INFO -   mmlu_virology:
2025-07-28 07:51:47,439 - INFO -     - accuracy: 0.6000
2025-07-28 07:51:47,439 - INFO -   mmlu_social_sciences:
2025-07-28 07:51:47,439 - INFO -     - accuracy: 0.7667
2025-07-28 07:51:47,439 - INFO -   mmlu_econometrics:
2025-07-28 07:51:47,439 - INFO -     - accuracy: 0.4500
2025-07-28 07:51:47,440 - INFO -   mmlu_high_school_geography:
2025-07-28 07:51:47,440 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,440 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 07:51:47,440 - INFO -     - accuracy: 0.9000
2025-07-28 07:51:47,440 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 07:51:47,440 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,440 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 07:51:47,440 - INFO -     - accuracy: 0.6500
2025-07-28 07:51:47,440 - INFO -   mmlu_high_school_psychology:
2025-07-28 07:51:47,440 - INFO -     - accuracy: 0.9000
2025-07-28 07:51:47,440 - INFO -   mmlu_human_sexuality:
2025-07-28 07:51:47,441 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,441 - INFO -   mmlu_professional_psychology:
2025-07-28 07:51:47,441 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,441 - INFO -   mmlu_public_relations:
2025-07-28 07:51:47,441 - INFO -     - accuracy: 0.6000
2025-07-28 07:51:47,441 - INFO -   mmlu_security_studies:
2025-07-28 07:51:47,441 - INFO -     - accuracy: 0.7500
2025-07-28 07:51:47,441 - INFO -   mmlu_sociology:
2025-07-28 07:51:47,441 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,441 - INFO -   mmlu_us_foreign_policy:
2025-07-28 07:51:47,441 - INFO -     - accuracy: 0.9500
2025-07-28 07:51:47,442 - INFO -   mmlu_stem:
2025-07-28 07:51:47,442 - INFO -     - accuracy: 0.5868
2025-07-28 07:51:47,442 - INFO -   mmlu_abstract_algebra:
2025-07-28 07:51:47,442 - INFO -     - accuracy: 0.3000
2025-07-28 07:51:47,442 - INFO -   mmlu_anatomy:
2025-07-28 07:51:47,442 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,442 - INFO -   mmlu_astronomy:
2025-07-28 07:51:47,442 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,442 - INFO -   mmlu_college_biology:
2025-07-28 07:51:47,442 - INFO -     - accuracy: 0.8500
2025-07-28 07:51:47,442 - INFO -   mmlu_college_chemistry:
2025-07-28 07:51:47,443 - INFO -     - accuracy: 0.4000
2025-07-28 07:51:47,443 - INFO -   mmlu_college_computer_science:
2025-07-28 07:51:47,443 - INFO -     - accuracy: 0.4500
2025-07-28 07:51:47,443 - INFO -   mmlu_college_mathematics:
2025-07-28 07:51:47,443 - INFO -     - accuracy: 0.4000
2025-07-28 07:51:47,443 - INFO -   mmlu_college_physics:
2025-07-28 07:51:47,443 - INFO -     - accuracy: 0.5500
2025-07-28 07:51:47,443 - INFO -   mmlu_computer_security:
2025-07-28 07:51:47,443 - INFO -     - accuracy: 0.7500
2025-07-28 07:51:47,443 - INFO -   mmlu_conceptual_physics:
2025-07-28 07:51:47,443 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,444 - INFO -   mmlu_electrical_engineering:
2025-07-28 07:51:47,444 - INFO -     - accuracy: 0.5500
2025-07-28 07:51:47,444 - INFO -   mmlu_elementary_mathematics:
2025-07-28 07:51:47,444 - INFO -     - accuracy: 0.5000
2025-07-28 07:51:47,444 - INFO -   mmlu_high_school_biology:
2025-07-28 07:51:47,444 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,444 - INFO -   mmlu_high_school_chemistry:
2025-07-28 07:51:47,444 - INFO -     - accuracy: 0.6000
2025-07-28 07:51:47,444 - INFO -   mmlu_high_school_computer_science:
2025-07-28 07:51:47,444 - INFO -     - accuracy: 0.8000
2025-07-28 07:51:47,444 - INFO -   mmlu_high_school_mathematics:
2025-07-28 07:51:47,445 - INFO -     - accuracy: 0.3000
2025-07-28 07:51:47,445 - INFO -   mmlu_high_school_physics:
2025-07-28 07:51:47,445 - INFO -     - accuracy: 0.5500
2025-07-28 07:51:47,445 - INFO -   mmlu_high_school_statistics:
2025-07-28 07:51:47,445 - INFO -     - accuracy: 0.6000
2025-07-28 07:51:47,445 - INFO -   mmlu_machine_learning:
2025-07-28 07:51:47,445 - INFO -     - accuracy: 0.3500
2025-07-28 07:51:47,445 - INFO - ============================================================

2025-07-28 07:51:47,482 - INFO - Llama-3.1-8B_harness_1: Processing task 8/10: arc_challenge
2025-07-28 07:51:47,483 - INFO - Llama-3.1-8B_harness_1: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 07:51:47,483 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 07:51:47,484 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:51:57,825 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 07:52:02,980 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 07:52:02,981 - INFO - 
============================================================
2025-07-28 07:52:02,982 - INFO - Task 'arc_challenge' Results:
2025-07-28 07:52:02,982 - INFO - ============================================================
2025-07-28 07:52:02,983 - INFO -   arc_challenge:
2025-07-28 07:52:02,983 - INFO -     - accuracy: 0.4000
2025-07-28 07:52:02,983 - INFO -     - accuracy_norm: 0.3500
2025-07-28 07:52:02,983 - INFO - ============================================================

2025-07-28 07:52:03,018 - INFO - Llama-3.1-8B_harness_1: Processing task 9/10: arc_easy
2025-07-28 07:52:03,019 - INFO - Llama-3.1-8B_harness_1: Task 'arc_easy' will use num_fewshot=0
2025-07-28 07:52:03,019 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 07:52:03,020 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:52:12,540 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 07:52:17,560 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 07:52:17,561 - INFO - 
============================================================
2025-07-28 07:52:17,562 - INFO - Task 'arc_easy' Results:
2025-07-28 07:52:17,562 - INFO - ============================================================
2025-07-28 07:52:17,562 - INFO -   arc_easy:
2025-07-28 07:52:17,562 - INFO -     - accuracy: 0.8500
2025-07-28 07:52:17,562 - INFO -     - accuracy_norm: 0.7500
2025-07-28 07:52:17,563 - INFO - ============================================================

2025-07-28 07:52:17,598 - INFO - Llama-3.1-8B_harness_1: Processing task 10/10: hellaswag
2025-07-28 07:52:17,598 - INFO - Llama-3.1-8B_harness_1: Task 'hellaswag' will use num_fewshot=0
2025-07-28 07:52:17,599 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 07:52:17,599 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:52:35,333 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 07:52:40,663 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 07:52:40,665 - INFO - 
============================================================
2025-07-28 07:52:40,666 - INFO - Task 'hellaswag' Results:
2025-07-28 07:52:40,666 - INFO - ============================================================
2025-07-28 07:52:40,666 - INFO -   hellaswag:
2025-07-28 07:52:40,666 - INFO -     - accuracy: 0.4500
2025-07-28 07:52:40,667 - INFO -     - accuracy_norm: 0.6500
2025-07-28 07:52:40,667 - INFO - ============================================================

2025-07-28 07:52:40,702 - INFO - Llama-3.1-8B_harness_1: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 07:52:40,705 - INFO - [Process 1865749] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_073925/model_results/Llama-3.1-8B/Llama-3.1-8B_harness_1.json
2025-07-28 07:52:40,707 - INFO - [Process 1865749] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Llama-3.1-8B/Llama-3.1-8B_harness_1.json
2025-07-28 07:52:41,018 - INFO - Results uploaded to WandB as artifact
2025-07-28 07:52:41,027 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 07:52:41,029 - INFO - [Process 1865749] Successfully completed Llama-3.1-8B_harness_1
2025-07-28 07:52:44,359 - INFO - Run Llama-3.1-8B_harness_1 finished successfully
2025-07-28 07:52:44,360 - INFO - [Process 1865749] Mistral-7B-v0.3_harness_4 assigned to cuda:0
2025-07-28 07:52:44,360 - INFO - [Process 1865749] Mistral-7B-v0.3_harness_4 - using custom limit: 20
2025-07-28 07:52:45,672 - INFO - WandB run initialized: Mistral-7B-v0.3_20250728_075244 (ID: 8881a0b4)
2025-07-28 07:52:45,890 - INFO - Mistral-7B-v0.3_harness_4: Test mode (limit=2), setting num_fewshot=0
2025-07-28 07:52:45,890 - INFO - Mistral-7B-v0.3_harness_4: Processing task 1/10: kmmlu
2025-07-28 07:52:45,890 - INFO - Mistral-7B-v0.3_harness_4: Task 'kmmlu' will use num_fewshot=0
2025-07-28 07:52:45,890 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 07:52:45,890 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:53:59,186 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 07:53:59,186 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 07:53:59,186 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 07:53:59,186 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 07:53:59,186 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 07:53:59,186 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 07:53:59,186 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 07:53:59,186 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 07:53:59,187 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 07:53:59,188 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 07:53:59,189 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 07:53:59,190 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 07:53:59,190 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 07:53:59,190 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 07:53:59,190 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 07:54:33,611 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 07:54:33,611 - INFO - 
============================================================
2025-07-28 07:54:33,612 - INFO - Task 'kmmlu' Results:
2025-07-28 07:54:33,612 - INFO - ============================================================
2025-07-28 07:54:33,612 - INFO -   kmmlu:
2025-07-28 07:54:33,612 - INFO -     - accuracy: 0.3044
2025-07-28 07:54:33,612 - INFO -   kmmlu_applied_science:
2025-07-28 07:54:33,612 - INFO -     - accuracy: 0.2458
2025-07-28 07:54:33,612 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 07:54:33,612 - INFO -     - accuracy: 0.1000
2025-07-28 07:54:33,613 - INFO -   kmmlu_electronics_engineering:
2025-07-28 07:54:33,613 - INFO -     - accuracy: 0.1000
2025-07-28 07:54:33,613 - INFO -   kmmlu_energy_management:
2025-07-28 07:54:33,613 - INFO -     - accuracy: 0.2500
2025-07-28 07:54:33,613 - INFO -   kmmlu_environmental_science:
2025-07-28 07:54:33,613 - INFO -     - accuracy: 0.1000
2025-07-28 07:54:33,613 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 07:54:33,613 - INFO -     - accuracy: 0.5000
2025-07-28 07:54:33,613 - INFO -   kmmlu_geomatics:
2025-07-28 07:54:33,613 - INFO -     - accuracy: 0.2000
2025-07-28 07:54:33,614 - INFO -   kmmlu_industrial_engineer:
2025-07-28 07:54:33,614 - INFO -     - accuracy: 0.2500
2025-07-28 07:54:33,614 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 07:54:33,614 - INFO -     - accuracy: 0.3000
2025-07-28 07:54:33,614 - INFO -   kmmlu_maritime_engineering:
2025-07-28 07:54:33,614 - INFO -     - accuracy: 0.2000
2025-07-28 07:54:33,614 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 07:54:33,614 - INFO -     - accuracy: 0.4500
2025-07-28 07:54:33,614 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 07:54:33,615 - INFO -     - accuracy: 0.2500
2025-07-28 07:54:33,615 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 07:54:33,615 - INFO -     - accuracy: 0.2500
2025-07-28 07:54:33,615 - INFO -   kmmlu_humss:
2025-07-28 07:54:33,615 - INFO -     - accuracy: 0.3000
2025-07-28 07:54:33,615 - INFO -   kmmlu_accounting:
2025-07-28 07:54:33,615 - INFO -     - accuracy: 0.2500
2025-07-28 07:54:33,615 - INFO -   kmmlu_criminal_law:
2025-07-28 07:54:33,615 - INFO -     - accuracy: 0.1500
2025-07-28 07:54:33,615 - INFO -   kmmlu_economics:
2025-07-28 07:54:33,615 - INFO -     - accuracy: 0.3000
2025-07-28 07:54:33,616 - INFO -   kmmlu_education:
2025-07-28 07:54:33,616 - INFO -     - accuracy: 0.2500
2025-07-28 07:54:33,616 - INFO -   kmmlu_korean_history:
2025-07-28 07:54:33,616 - INFO -     - accuracy: 0.5500
2025-07-28 07:54:33,616 - INFO -   kmmlu_law:
2025-07-28 07:54:33,616 - INFO -     - accuracy: 0.4000
2025-07-28 07:54:33,616 - INFO -   kmmlu_management:
2025-07-28 07:54:33,616 - INFO -     - accuracy: 0.4000
2025-07-28 07:54:33,616 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 07:54:33,616 - INFO -     - accuracy: 0.2500
2025-07-28 07:54:33,617 - INFO -   kmmlu_psychology:
2025-07-28 07:54:33,617 - INFO -     - accuracy: 0.1500
2025-07-28 07:54:33,617 - INFO -   kmmlu_social_welfare:
2025-07-28 07:54:33,617 - INFO -     - accuracy: 0.3000
2025-07-28 07:54:33,617 - INFO -   kmmlu_taxation:
2025-07-28 07:54:33,617 - INFO -     - accuracy: 0.3000
2025-07-28 07:54:33,617 - INFO -   kmmlu_other:
2025-07-28 07:54:33,617 - INFO -     - accuracy: 0.3091
2025-07-28 07:54:33,617 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 07:54:33,618 - INFO -     - accuracy: 0.3500
2025-07-28 07:54:33,618 - INFO -   kmmlu_construction:
2025-07-28 07:54:33,618 - INFO -     - accuracy: 0.1500
2025-07-28 07:54:33,618 - INFO -   kmmlu_fashion:
2025-07-28 07:54:33,618 - INFO -     - accuracy: 0.2000
2025-07-28 07:54:33,618 - INFO -   kmmlu_food_processing:
2025-07-28 07:54:33,618 - INFO -     - accuracy: 0.3500
2025-07-28 07:54:33,618 - INFO -   kmmlu_health:
2025-07-28 07:54:33,618 - INFO -     - accuracy: 0.1000
2025-07-28 07:54:33,619 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 07:54:33,619 - INFO -     - accuracy: 0.3000
2025-07-28 07:54:33,619 - INFO -   kmmlu_marketing:
2025-07-28 07:54:33,619 - INFO -     - accuracy: 0.3500
2025-07-28 07:54:33,619 - INFO -   kmmlu_patent:
2025-07-28 07:54:33,619 - INFO -     - accuracy: 0.3500
2025-07-28 07:54:33,619 - INFO -   kmmlu_public_safety:
2025-07-28 07:54:33,619 - INFO -     - accuracy: 0.3500
2025-07-28 07:54:33,619 - INFO -   kmmlu_real_estate:
2025-07-28 07:54:33,620 - INFO -     - accuracy: 0.4500
2025-07-28 07:54:33,620 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 07:54:33,620 - INFO -     - accuracy: 0.4500
2025-07-28 07:54:33,620 - INFO -   kmmlu_stem:
2025-07-28 07:54:33,620 - INFO -     - accuracy: 0.3682
2025-07-28 07:54:33,620 - INFO -   kmmlu_biology:
2025-07-28 07:54:33,620 - INFO -     - accuracy: 0.3000
2025-07-28 07:54:33,620 - INFO -   kmmlu_chemical_engineering:
2025-07-28 07:54:33,620 - INFO -     - accuracy: 0.6000
2025-07-28 07:54:33,621 - INFO -   kmmlu_chemistry:
2025-07-28 07:54:33,621 - INFO -     - accuracy: 0.2500
2025-07-28 07:54:33,621 - INFO -   kmmlu_civil_engineering:
2025-07-28 07:54:33,621 - INFO -     - accuracy: 0.2000
2025-07-28 07:54:33,621 - INFO -   kmmlu_computer_science:
2025-07-28 07:54:33,621 - INFO -     - accuracy: 0.5500
2025-07-28 07:54:33,621 - INFO -   kmmlu_ecology:
2025-07-28 07:54:33,621 - INFO -     - accuracy: 0.5000
2025-07-28 07:54:33,621 - INFO -   kmmlu_electrical_engineering:
2025-07-28 07:54:33,621 - INFO -     - accuracy: 0.2000
2025-07-28 07:54:33,622 - INFO -   kmmlu_information_technology:
2025-07-28 07:54:33,622 - INFO -     - accuracy: 0.4000
2025-07-28 07:54:33,622 - INFO -   kmmlu_materials_engineering:
2025-07-28 07:54:33,622 - INFO -     - accuracy: 0.3000
2025-07-28 07:54:33,622 - INFO -   kmmlu_math:
2025-07-28 07:54:33,622 - INFO -     - accuracy: 0.3000
2025-07-28 07:54:33,622 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 07:54:33,622 - INFO -     - accuracy: 0.4500
2025-07-28 07:54:33,623 - INFO - ============================================================

2025-07-28 07:54:33,656 - INFO - Mistral-7B-v0.3_harness_4: Processing task 2/10: kmmlu_hard
2025-07-28 07:54:33,657 - INFO - Mistral-7B-v0.3_harness_4: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 07:54:33,657 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 07:54:33,658 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:55:49,359 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 07:55:49,360 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 07:55:49,360 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 07:55:49,360 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 07:55:49,360 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 07:55:49,360 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 07:55:49,360 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 07:55:49,360 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 07:55:49,361 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 07:55:49,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 07:55:49,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 07:55:49,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 07:55:49,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 07:56:24,012 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 07:56:24,012 - INFO - 
============================================================
2025-07-28 07:56:24,012 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 07:56:24,012 - INFO - ============================================================
2025-07-28 07:56:24,013 - INFO -   kmmlu_hard:
2025-07-28 07:56:24,013 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,013 - INFO -   kmmlu_hard_applied_science:
2025-07-28 07:56:24,014 - INFO -     - accuracy: 0.2958
2025-07-28 07:56:24,014 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 07:56:24,014 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,014 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 07:56:24,014 - INFO -     - accuracy: 0.3500
2025-07-28 07:56:24,014 - INFO -   kmmlu_hard_energy_management:
2025-07-28 07:56:24,014 - INFO -     - accuracy: 0.3500
2025-07-28 07:56:24,015 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 07:56:24,015 - INFO -     - accuracy: 0.3500
2025-07-28 07:56:24,015 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 07:56:24,015 - INFO -     - accuracy: 0.3000
2025-07-28 07:56:24,015 - INFO -   kmmlu_hard_geomatics:
2025-07-28 07:56:24,015 - INFO -     - accuracy: 0.3000
2025-07-28 07:56:24,015 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 07:56:24,015 - INFO -     - accuracy: 0.5500
2025-07-28 07:56:24,015 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 07:56:24,016 - INFO -     - accuracy: 0.1500
2025-07-28 07:56:24,016 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 07:56:24,016 - INFO -     - accuracy: 0.2000
2025-07-28 07:56:24,016 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 07:56:24,016 - INFO -     - accuracy: 0.3000
2025-07-28 07:56:24,016 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 07:56:24,016 - INFO -     - accuracy: 0.2000
2025-07-28 07:56:24,016 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 07:56:24,016 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,017 - INFO -   kmmlu_hard_humss:
2025-07-28 07:56:24,017 - INFO -     - accuracy: 0.1909
2025-07-28 07:56:24,017 - INFO -   kmmlu_hard_accounting:
2025-07-28 07:56:24,017 - INFO -     - accuracy: 0.1000
2025-07-28 07:56:24,017 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 07:56:24,017 - INFO -     - accuracy: 0.1500
2025-07-28 07:56:24,017 - INFO -   kmmlu_hard_economics:
2025-07-28 07:56:24,017 - INFO -     - accuracy: 0.1500
2025-07-28 07:56:24,017 - INFO -   kmmlu_hard_education:
2025-07-28 07:56:24,018 - INFO -     - accuracy: 0.3000
2025-07-28 07:56:24,018 - INFO -   kmmlu_hard_korean_history:
2025-07-28 07:56:24,018 - INFO -     - accuracy: 0.4000
2025-07-28 07:56:24,018 - INFO -   kmmlu_hard_law:
2025-07-28 07:56:24,018 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,018 - INFO -   kmmlu_hard_management:
2025-07-28 07:56:24,018 - INFO -     - accuracy: 0.0500
2025-07-28 07:56:24,018 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 07:56:24,018 - INFO -     - accuracy: 0.1500
2025-07-28 07:56:24,019 - INFO -   kmmlu_hard_psychology:
2025-07-28 07:56:24,019 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,019 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 07:56:24,019 - INFO -     - accuracy: 0.1500
2025-07-28 07:56:24,019 - INFO -   kmmlu_hard_taxation:
2025-07-28 07:56:24,019 - INFO -     - accuracy: 0.1500
2025-07-28 07:56:24,019 - INFO -   kmmlu_hard_other:
2025-07-28 07:56:24,019 - INFO -     - accuracy: 0.2409
2025-07-28 07:56:24,019 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 07:56:24,019 - INFO -     - accuracy: 0.1500
2025-07-28 07:56:24,019 - INFO -   kmmlu_hard_construction:
2025-07-28 07:56:24,020 - INFO -     - accuracy: 0.2000
2025-07-28 07:56:24,020 - INFO -   kmmlu_hard_fashion:
2025-07-28 07:56:24,020 - INFO -     - accuracy: 0.2000
2025-07-28 07:56:24,020 - INFO -   kmmlu_hard_food_processing:
2025-07-28 07:56:24,020 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,020 - INFO -   kmmlu_hard_health:
2025-07-28 07:56:24,020 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,020 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 07:56:24,020 - INFO -     - accuracy: 0.4000
2025-07-28 07:56:24,021 - INFO -   kmmlu_hard_marketing:
2025-07-28 07:56:24,021 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,021 - INFO -   kmmlu_hard_patent:
2025-07-28 07:56:24,021 - INFO -     - accuracy: 0.3500
2025-07-28 07:56:24,021 - INFO -   kmmlu_hard_public_safety:
2025-07-28 07:56:24,021 - INFO -     - accuracy: 0.1000
2025-07-28 07:56:24,021 - INFO -   kmmlu_hard_real_estate:
2025-07-28 07:56:24,021 - INFO -     - accuracy: 0.3500
2025-07-28 07:56:24,021 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 07:56:24,022 - INFO -     - accuracy: 0.1500
2025-07-28 07:56:24,022 - INFO -   kmmlu_hard_stem:
2025-07-28 07:56:24,022 - INFO -     - accuracy: 0.2682
2025-07-28 07:56:24,022 - INFO -   kmmlu_hard_biology:
2025-07-28 07:56:24,022 - INFO -     - accuracy: 0.3000
2025-07-28 07:56:24,022 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 07:56:24,022 - INFO -     - accuracy: 0.3500
2025-07-28 07:56:24,022 - INFO -   kmmlu_hard_chemistry:
2025-07-28 07:56:24,022 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,023 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 07:56:24,023 - INFO -     - accuracy: 0.3000
2025-07-28 07:56:24,023 - INFO -   kmmlu_hard_computer_science:
2025-07-28 07:56:24,023 - INFO -     - accuracy: 0.2000
2025-07-28 07:56:24,023 - INFO -   kmmlu_hard_ecology:
2025-07-28 07:56:24,023 - INFO -     - accuracy: 0.2000
2025-07-28 07:56:24,023 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 07:56:24,023 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,023 - INFO -   kmmlu_hard_information_technology:
2025-07-28 07:56:24,024 - INFO -     - accuracy: 0.2500
2025-07-28 07:56:24,024 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 07:56:24,024 - INFO -     - accuracy: 0.3000
2025-07-28 07:56:24,024 - INFO -   kmmlu_hard_math:
2025-07-28 07:56:24,024 - INFO -     - accuracy: 0.4000
2025-07-28 07:56:24,024 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 07:56:24,024 - INFO -     - accuracy: 0.1500
2025-07-28 07:56:24,024 - INFO - ============================================================

2025-07-28 07:56:24,058 - INFO - Mistral-7B-v0.3_harness_4: Processing task 3/10: haerae
2025-07-28 07:56:24,059 - INFO - Mistral-7B-v0.3_harness_4: Task 'haerae' will use num_fewshot=0
2025-07-28 07:56:24,059 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 07:56:24,060 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:56:42,946 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 07:56:42,946 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 07:56:42,946 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 07:56:42,946 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 07:56:42,947 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 07:57:01,370 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 07:57:01,371 - INFO - 
============================================================
2025-07-28 07:57:01,371 - INFO - Task 'haerae' Results:
2025-07-28 07:57:01,371 - INFO - ============================================================
2025-07-28 07:57:01,371 - INFO -   haerae:
2025-07-28 07:57:01,371 - INFO -     - accuracy: 0.4400
2025-07-28 07:57:01,371 - INFO -     - accuracy_norm: 0.4400
2025-07-28 07:57:01,371 - INFO -   haerae_general_knowledge:
2025-07-28 07:57:01,372 - INFO -     - accuracy: 0.7500
2025-07-28 07:57:01,372 - INFO -     - accuracy_norm: 0.7500
2025-07-28 07:57:01,372 - INFO -   haerae_history:
2025-07-28 07:57:01,372 - INFO -     - accuracy: 0.3000
2025-07-28 07:57:01,372 - INFO -     - accuracy_norm: 0.3000
2025-07-28 07:57:01,372 - INFO -   haerae_loan_word:
2025-07-28 07:57:01,372 - INFO -     - accuracy: 0.5000
2025-07-28 07:57:01,372 - INFO -     - accuracy_norm: 0.5000
2025-07-28 07:57:01,372 - INFO -   haerae_rare_word:
2025-07-28 07:57:01,373 - INFO -     - accuracy: 0.3000
2025-07-28 07:57:01,373 - INFO -     - accuracy_norm: 0.3000
2025-07-28 07:57:01,373 - INFO -   haerae_standard_nomenclature:
2025-07-28 07:57:01,373 - INFO -     - accuracy: 0.3500
2025-07-28 07:57:01,373 - INFO -     - accuracy_norm: 0.3500
2025-07-28 07:57:01,373 - INFO - ============================================================

2025-07-28 07:57:01,406 - INFO - Mistral-7B-v0.3_harness_4: Processing task 4/10: kobest
2025-07-28 07:57:01,408 - INFO - Mistral-7B-v0.3_harness_4: Task 'kobest' will use num_fewshot=0
2025-07-28 07:57:01,408 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 07:57:01,408 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:57:23,421 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 07:57:23,422 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 07:57:23,422 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 07:57:23,422 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 07:57:23,422 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 07:57:33,965 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 07:57:33,966 - INFO - 
============================================================
2025-07-28 07:57:33,967 - INFO - Task 'kobest' Results:
2025-07-28 07:57:33,967 - INFO - ============================================================
2025-07-28 07:57:33,967 - INFO -   kobest:
2025-07-28 07:57:33,967 - INFO -     - accuracy: 0.5300
2025-07-28 07:57:33,967 - INFO -     - accuracy_norm: 0.5500
2025-07-28 07:57:33,967 - INFO -     - f1: 0.4254
2025-07-28 07:57:33,968 - INFO -   kobest_boolq:
2025-07-28 07:57:33,968 - INFO -     - accuracy: 0.5500
2025-07-28 07:57:33,972 - INFO -     - f1: 0.4357
2025-07-28 07:57:33,973 - INFO -   kobest_copa:
2025-07-28 07:57:33,973 - INFO -     - accuracy: 0.6500
2025-07-28 07:57:33,973 - INFO -     - f1: 0.6491
2025-07-28 07:57:33,973 - INFO -   kobest_hellaswag:
2025-07-28 07:57:33,973 - INFO -     - accuracy: 0.3500
2025-07-28 07:57:33,973 - INFO -     - accuracy_norm: 0.5500
2025-07-28 07:57:33,973 - INFO -     - f1: 0.3326
2025-07-28 07:57:33,973 - INFO -   kobest_sentineg:
2025-07-28 07:57:33,974 - INFO -     - accuracy: 0.5500
2025-07-28 07:57:33,974 - INFO -     - f1: 0.3548
2025-07-28 07:57:33,974 - INFO -   kobest_wic:
2025-07-28 07:57:33,974 - INFO -     - accuracy: 0.5500
2025-07-28 07:57:33,974 - INFO -     - f1: 0.3548
2025-07-28 07:57:33,974 - INFO - ============================================================

2025-07-28 07:57:34,009 - INFO - Mistral-7B-v0.3_harness_4: Processing task 5/10: csatqa
2025-07-28 07:57:34,010 - INFO - Mistral-7B-v0.3_harness_4: Task 'csatqa' detected as zero-shot task
2025-07-28 07:57:34,011 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 07:57:34,011 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 07:57:48,163 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 07:57:48,164 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 07:57:48,164 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 07:57:48,164 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 07:57:48,164 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 07:57:48,164 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 07:59:44,301 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 07:59:44,302 - INFO - 
============================================================
2025-07-28 07:59:44,302 - INFO - Task 'csatqa' Results:
2025-07-28 07:59:44,302 - INFO - ============================================================
2025-07-28 07:59:44,302 - INFO -   csatqa:
2025-07-28 07:59:44,303 - INFO -     - accuracy: 0.2252
2025-07-28 07:59:44,303 - INFO -     - accuracy_norm: 0.2252
2025-07-28 07:59:44,303 - INFO -   csatqa_gr:
2025-07-28 07:59:44,303 - INFO -     - accuracy: 0.1000
2025-07-28 07:59:44,303 - INFO -     - accuracy_norm: 0.1000
2025-07-28 07:59:44,303 - INFO -   csatqa_li:
2025-07-28 07:59:44,303 - INFO -     - accuracy: 0.4000
2025-07-28 07:59:44,303 - INFO -     - accuracy_norm: 0.4000
2025-07-28 07:59:44,304 - INFO -   csatqa_rch:
2025-07-28 07:59:44,304 - INFO -     - accuracy: 0.2500
2025-07-28 07:59:44,304 - INFO -     - accuracy_norm: 0.2500
2025-07-28 07:59:44,304 - INFO -   csatqa_rcs:
2025-07-28 07:59:44,304 - INFO -     - accuracy: 0.2000
2025-07-28 07:59:44,304 - INFO -     - accuracy_norm: 0.2000
2025-07-28 07:59:44,304 - INFO -   csatqa_rcss:
2025-07-28 07:59:44,304 - INFO -     - accuracy: 0.2000
2025-07-28 07:59:44,304 - INFO -     - accuracy_norm: 0.2000
2025-07-28 07:59:44,305 - INFO -   csatqa_wr:
2025-07-28 07:59:44,305 - INFO -     - accuracy: 0.1818
2025-07-28 07:59:44,305 - INFO -     - accuracy_norm: 0.1818
2025-07-28 07:59:44,305 - INFO - ============================================================

2025-07-28 07:59:44,343 - INFO - Mistral-7B-v0.3_harness_4: Processing task 6/10: kormedmcqa
2025-07-28 07:59:44,345 - INFO - Mistral-7B-v0.3_harness_4: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 07:59:44,345 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 07:59:44,345 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:00:04,741 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 08:00:04,741 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 08:00:04,742 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 08:00:04,742 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 08:00:15,170 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 08:00:15,172 - INFO - 
============================================================
2025-07-28 08:00:15,172 - INFO - Task 'kormedmcqa' Results:
2025-07-28 08:00:15,172 - INFO - ============================================================
2025-07-28 08:00:15,172 - INFO -   kormedmcqa:
2025-07-28 08:00:15,172 - INFO -     - exact_match: 0.4375
2025-07-28 08:00:15,173 - INFO -   kormedmcqa_dentist:
2025-07-28 08:00:15,173 - INFO -     - exact_match: 0.3500
2025-07-28 08:00:15,173 - INFO -   kormedmcqa_doctor:
2025-07-28 08:00:15,173 - INFO -     - exact_match: 0.3500
2025-07-28 08:00:15,174 - INFO -   kormedmcqa_nurse:
2025-07-28 08:00:15,174 - INFO -     - exact_match: 0.4000
2025-07-28 08:00:15,174 - INFO -   kormedmcqa_pharm:
2025-07-28 08:00:15,174 - INFO -     - exact_match: 0.6500
2025-07-28 08:00:15,174 - INFO - ============================================================

2025-07-28 08:00:15,209 - INFO - Mistral-7B-v0.3_harness_4: Processing task 7/10: mmlu
2025-07-28 08:00:15,211 - INFO - Mistral-7B-v0.3_harness_4: Task 'mmlu' will use num_fewshot=0
2025-07-28 08:00:15,211 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 08:00:15,211 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:03:08,957 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 08:03:08,958 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 08:03:08,958 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 08:03:08,958 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 08:03:08,958 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 08:03:08,958 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 08:03:08,958 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 08:03:08,958 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 08:03:08,958 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 08:03:08,958 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 08:03:08,958 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 08:03:08,959 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 08:03:08,960 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 08:03:08,961 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 08:03:08,962 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 08:03:49,284 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 08:03:49,284 - INFO - 
============================================================
2025-07-28 08:03:49,285 - INFO - Task 'mmlu' Results:
2025-07-28 08:03:49,285 - INFO - ============================================================
2025-07-28 08:03:49,285 - INFO -   mmlu:
2025-07-28 08:03:49,285 - INFO -     - accuracy: 0.6088
2025-07-28 08:03:49,285 - INFO -   mmlu_humanities:
2025-07-28 08:03:49,286 - INFO -     - accuracy: 0.6423
2025-07-28 08:03:49,286 - INFO -   mmlu_formal_logic:
2025-07-28 08:03:49,286 - INFO -     - accuracy: 0.3500
2025-07-28 08:03:49,286 - INFO -   mmlu_high_school_european_history:
2025-07-28 08:03:49,287 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,287 - INFO -   mmlu_high_school_us_history:
2025-07-28 08:03:49,287 - INFO -     - accuracy: 0.7500
2025-07-28 08:03:49,287 - INFO -   mmlu_high_school_world_history:
2025-07-28 08:03:49,287 - INFO -     - accuracy: 0.8500
2025-07-28 08:03:49,288 - INFO -   mmlu_international_law:
2025-07-28 08:03:49,288 - INFO -     - accuracy: 0.8500
2025-07-28 08:03:49,288 - INFO -   mmlu_jurisprudence:
2025-07-28 08:03:49,288 - INFO -     - accuracy: 0.6500
2025-07-28 08:03:49,290 - INFO -   mmlu_logical_fallacies:
2025-07-28 08:03:49,290 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,290 - INFO -   mmlu_moral_disputes:
2025-07-28 08:03:49,290 - INFO -     - accuracy: 0.5500
2025-07-28 08:03:49,290 - INFO -   mmlu_moral_scenarios:
2025-07-28 08:03:49,291 - INFO -     - accuracy: 0.2500
2025-07-28 08:03:49,291 - INFO -   mmlu_philosophy:
2025-07-28 08:03:49,291 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,291 - INFO -   mmlu_prehistory:
2025-07-28 08:03:49,291 - INFO -     - accuracy: 0.5500
2025-07-28 08:03:49,291 - INFO -   mmlu_professional_law:
2025-07-28 08:03:49,291 - INFO -     - accuracy: 0.5500
2025-07-28 08:03:49,291 - INFO -   mmlu_world_religions:
2025-07-28 08:03:49,292 - INFO -     - accuracy: 0.9000
2025-07-28 08:03:49,292 - INFO -   mmlu_other:
2025-07-28 08:03:49,292 - INFO -     - accuracy: 0.6346
2025-07-28 08:03:49,292 - INFO -   mmlu_business_ethics:
2025-07-28 08:03:49,292 - INFO -     - accuracy: 0.6500
2025-07-28 08:03:49,292 - INFO -   mmlu_clinical_knowledge:
2025-07-28 08:03:49,292 - INFO -     - accuracy: 0.5500
2025-07-28 08:03:49,292 - INFO -   mmlu_college_medicine:
2025-07-28 08:03:49,292 - INFO -     - accuracy: 0.6000
2025-07-28 08:03:49,293 - INFO -   mmlu_global_facts:
2025-07-28 08:03:49,293 - INFO -     - accuracy: 0.3000
2025-07-28 08:03:49,293 - INFO -   mmlu_human_aging:
2025-07-28 08:03:49,293 - INFO -     - accuracy: 0.6000
2025-07-28 08:03:49,293 - INFO -   mmlu_management:
2025-07-28 08:03:49,293 - INFO -     - accuracy: 0.6500
2025-07-28 08:03:49,293 - INFO -   mmlu_marketing:
2025-07-28 08:03:49,293 - INFO -     - accuracy: 0.8000
2025-07-28 08:03:49,293 - INFO -   mmlu_medical_genetics:
2025-07-28 08:03:49,294 - INFO -     - accuracy: 0.8500
2025-07-28 08:03:49,294 - INFO -   mmlu_miscellaneous:
2025-07-28 08:03:49,294 - INFO -     - accuracy: 0.9000
2025-07-28 08:03:49,294 - INFO -   mmlu_nutrition:
2025-07-28 08:03:49,294 - INFO -     - accuracy: 0.8000
2025-07-28 08:03:49,294 - INFO -   mmlu_professional_accounting:
2025-07-28 08:03:49,294 - INFO -     - accuracy: 0.4500
2025-07-28 08:03:49,294 - INFO -   mmlu_professional_medicine:
2025-07-28 08:03:49,294 - INFO -     - accuracy: 0.6500
2025-07-28 08:03:49,295 - INFO -   mmlu_virology:
2025-07-28 08:03:49,295 - INFO -     - accuracy: 0.4500
2025-07-28 08:03:49,295 - INFO -   mmlu_social_sciences:
2025-07-28 08:03:49,295 - INFO -     - accuracy: 0.6750
2025-07-28 08:03:49,295 - INFO -   mmlu_econometrics:
2025-07-28 08:03:49,295 - INFO -     - accuracy: 0.3500
2025-07-28 08:03:49,295 - INFO -   mmlu_high_school_geography:
2025-07-28 08:03:49,295 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,295 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 08:03:49,296 - INFO -     - accuracy: 0.9000
2025-07-28 08:03:49,296 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 08:03:49,296 - INFO -     - accuracy: 0.6500
2025-07-28 08:03:49,296 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 08:03:49,296 - INFO -     - accuracy: 0.5500
2025-07-28 08:03:49,296 - INFO -   mmlu_high_school_psychology:
2025-07-28 08:03:49,296 - INFO -     - accuracy: 0.7500
2025-07-28 08:03:49,296 - INFO -   mmlu_human_sexuality:
2025-07-28 08:03:49,296 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,297 - INFO -   mmlu_professional_psychology:
2025-07-28 08:03:49,297 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,297 - INFO -   mmlu_public_relations:
2025-07-28 08:03:49,297 - INFO -     - accuracy: 0.5000
2025-07-28 08:03:49,297 - INFO -   mmlu_security_studies:
2025-07-28 08:03:49,297 - INFO -     - accuracy: 0.8500
2025-07-28 08:03:49,297 - INFO -   mmlu_sociology:
2025-07-28 08:03:49,297 - INFO -     - accuracy: 0.6000
2025-07-28 08:03:49,297 - INFO -   mmlu_us_foreign_policy:
2025-07-28 08:03:49,298 - INFO -     - accuracy: 0.8500
2025-07-28 08:03:49,298 - INFO -   mmlu_stem:
2025-07-28 08:03:49,298 - INFO -     - accuracy: 0.5263
2025-07-28 08:03:49,298 - INFO -   mmlu_abstract_algebra:
2025-07-28 08:03:49,298 - INFO -     - accuracy: 0.4000
2025-07-28 08:03:49,298 - INFO -   mmlu_anatomy:
2025-07-28 08:03:49,298 - INFO -     - accuracy: 0.5000
2025-07-28 08:03:49,298 - INFO -   mmlu_astronomy:
2025-07-28 08:03:49,298 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,299 - INFO -   mmlu_college_biology:
2025-07-28 08:03:49,299 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,299 - INFO -   mmlu_college_chemistry:
2025-07-28 08:03:49,299 - INFO -     - accuracy: 0.4000
2025-07-28 08:03:49,299 - INFO -   mmlu_college_computer_science:
2025-07-28 08:03:49,299 - INFO -     - accuracy: 0.5000
2025-07-28 08:03:49,299 - INFO -   mmlu_college_mathematics:
2025-07-28 08:03:49,299 - INFO -     - accuracy: 0.5500
2025-07-28 08:03:49,299 - INFO -   mmlu_college_physics:
2025-07-28 08:03:49,300 - INFO -     - accuracy: 0.5000
2025-07-28 08:03:49,300 - INFO -   mmlu_computer_security:
2025-07-28 08:03:49,300 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,300 - INFO -   mmlu_conceptual_physics:
2025-07-28 08:03:49,300 - INFO -     - accuracy: 0.6000
2025-07-28 08:03:49,300 - INFO -   mmlu_electrical_engineering:
2025-07-28 08:03:49,300 - INFO -     - accuracy: 0.3000
2025-07-28 08:03:49,300 - INFO -   mmlu_elementary_mathematics:
2025-07-28 08:03:49,300 - INFO -     - accuracy: 0.3000
2025-07-28 08:03:49,301 - INFO -   mmlu_high_school_biology:
2025-07-28 08:03:49,301 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,301 - INFO -   mmlu_high_school_chemistry:
2025-07-28 08:03:49,301 - INFO -     - accuracy: 0.5000
2025-07-28 08:03:49,301 - INFO -   mmlu_high_school_computer_science:
2025-07-28 08:03:49,301 - INFO -     - accuracy: 0.7000
2025-07-28 08:03:49,301 - INFO -   mmlu_high_school_mathematics:
2025-07-28 08:03:49,301 - INFO -     - accuracy: 0.2000
2025-07-28 08:03:49,301 - INFO -   mmlu_high_school_physics:
2025-07-28 08:03:49,302 - INFO -     - accuracy: 0.6500
2025-07-28 08:03:49,302 - INFO -   mmlu_high_school_statistics:
2025-07-28 08:03:49,302 - INFO -     - accuracy: 0.6000
2025-07-28 08:03:49,302 - INFO -   mmlu_machine_learning:
2025-07-28 08:03:49,302 - INFO -     - accuracy: 0.5000
2025-07-28 08:03:49,302 - INFO - ============================================================

2025-07-28 08:03:49,337 - INFO - Mistral-7B-v0.3_harness_4: Processing task 8/10: arc_challenge
2025-07-28 08:03:49,339 - INFO - Mistral-7B-v0.3_harness_4: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 08:03:49,339 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 08:03:49,339 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:03:58,881 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 08:04:04,191 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 08:04:04,192 - INFO - 
============================================================
2025-07-28 08:04:04,192 - INFO - Task 'arc_challenge' Results:
2025-07-28 08:04:04,193 - INFO - ============================================================
2025-07-28 08:04:04,193 - INFO -   arc_challenge:
2025-07-28 08:04:04,193 - INFO -     - accuracy: 0.4500
2025-07-28 08:04:04,193 - INFO -     - accuracy_norm: 0.5000
2025-07-28 08:04:04,193 - INFO - ============================================================

2025-07-28 08:04:04,225 - INFO - Mistral-7B-v0.3_harness_4: Processing task 9/10: arc_easy
2025-07-28 08:04:04,227 - INFO - Mistral-7B-v0.3_harness_4: Task 'arc_easy' will use num_fewshot=0
2025-07-28 08:04:04,228 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 08:04:04,228 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:04:13,822 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 08:04:18,915 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 08:04:18,916 - INFO - 
============================================================
2025-07-28 08:04:18,916 - INFO - Task 'arc_easy' Results:
2025-07-28 08:04:18,917 - INFO - ============================================================
2025-07-28 08:04:18,917 - INFO -   arc_easy:
2025-07-28 08:04:18,917 - INFO -     - accuracy: 0.8500
2025-07-28 08:04:18,917 - INFO -     - accuracy_norm: 0.7000
2025-07-28 08:04:18,917 - INFO - ============================================================

2025-07-28 08:04:18,949 - INFO - Mistral-7B-v0.3_harness_4: Processing task 10/10: hellaswag
2025-07-28 08:04:18,951 - INFO - Mistral-7B-v0.3_harness_4: Task 'hellaswag' will use num_fewshot=0
2025-07-28 08:04:18,951 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 08:04:18,951 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:04:34,731 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 08:04:40,048 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 08:04:40,049 - INFO - 
============================================================
2025-07-28 08:04:40,049 - INFO - Task 'hellaswag' Results:
2025-07-28 08:04:40,049 - INFO - ============================================================
2025-07-28 08:04:40,049 - INFO -   hellaswag:
2025-07-28 08:04:40,050 - INFO -     - accuracy: 0.4500
2025-07-28 08:04:40,050 - INFO -     - accuracy_norm: 0.7500
2025-07-28 08:04:40,050 - INFO - ============================================================

2025-07-28 08:04:40,083 - INFO - Mistral-7B-v0.3_harness_4: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 08:04:40,085 - INFO - [Process 1865749] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_073925/model_results/Mistral-7B-v0.3/Mistral-7B-v0.3_harness_4.json
2025-07-28 08:04:40,087 - INFO - [Process 1865749] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Mistral-7B-v0.3/Mistral-7B-v0.3_harness_4.json
2025-07-28 08:04:40,368 - INFO - Results uploaded to WandB as artifact
2025-07-28 08:04:40,376 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 08:04:40,378 - INFO - [Process 1865749] Successfully completed Mistral-7B-v0.3_harness_4
2025-07-28 08:04:43,618 - INFO - Run Mistral-7B-v0.3_harness_4 finished successfully
2025-07-28 08:04:43,619 - INFO - [Process 1865749] Qwen3-8B_harness_5 assigned to cuda:0
2025-07-28 08:04:43,619 - INFO - [Process 1865749] Qwen3-8B_harness_5 - using custom limit: 20
2025-07-28 08:04:45,012 - INFO - WandB run initialized: Qwen3-8B_20250728_080443 (ID: 2d5a7535)
2025-07-28 08:04:45,228 - INFO - Qwen3-8B_harness_5: Test mode (limit=2), setting num_fewshot=0
2025-07-28 08:04:45,228 - INFO - Qwen3-8B_harness_5: Processing task 1/10: kmmlu
2025-07-28 08:04:45,228 - INFO - Qwen3-8B_harness_5: Task 'kmmlu' will use num_fewshot=0
2025-07-28 08:04:45,228 - INFO - Qwen3-8B_harness_5: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 08:04:45,229 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:06:00,681 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 08:06:00,681 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 08:06:00,681 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 08:06:00,682 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 08:06:00,682 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 08:06:00,682 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 08:06:00,682 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 08:06:00,682 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 08:06:00,682 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 08:06:00,682 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 08:06:00,682 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 08:06:00,682 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 08:06:00,683 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 08:06:00,683 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 08:06:00,683 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 08:06:00,683 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 08:06:00,683 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 08:06:00,683 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 08:06:00,683 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 08:06:00,683 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 08:06:00,683 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 08:06:00,683 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 08:06:00,684 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 08:06:00,684 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 08:06:00,684 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 08:06:00,684 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 08:06:00,684 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 08:06:00,684 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 08:06:00,684 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 08:06:00,684 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 08:06:00,684 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 08:06:00,684 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 08:06:00,685 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 08:06:00,685 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 08:06:00,685 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 08:06:00,685 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 08:06:00,685 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 08:06:00,685 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 08:06:00,685 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 08:06:00,685 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 08:06:00,685 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 08:06:00,686 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 08:06:00,686 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 08:06:00,686 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 08:06:00,686 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 08:06:43,852 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 08:06:43,852 - INFO - 
============================================================
2025-07-28 08:06:43,854 - INFO - Task 'kmmlu' Results:
2025-07-28 08:06:43,854 - INFO - ============================================================
2025-07-28 08:06:43,854 - INFO -   kmmlu:
2025-07-28 08:06:43,854 - INFO -     - accuracy: 0.4333
2025-07-28 08:06:43,854 - INFO -   kmmlu_applied_science:
2025-07-28 08:06:43,854 - INFO -     - accuracy: 0.3500
2025-07-28 08:06:43,855 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 08:06:43,855 - INFO -     - accuracy: 0.3000
2025-07-28 08:06:43,855 - INFO -   kmmlu_electronics_engineering:
2025-07-28 08:06:43,855 - INFO -     - accuracy: 0.5500
2025-07-28 08:06:43,855 - INFO -   kmmlu_energy_management:
2025-07-28 08:06:43,855 - INFO -     - accuracy: 0.1500
2025-07-28 08:06:43,855 - INFO -   kmmlu_environmental_science:
2025-07-28 08:06:43,855 - INFO -     - accuracy: 0.3000
2025-07-28 08:06:43,855 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 08:06:43,856 - INFO -     - accuracy: 0.5500
2025-07-28 08:06:43,856 - INFO -   kmmlu_geomatics:
2025-07-28 08:06:43,856 - INFO -     - accuracy: 0.2500
2025-07-28 08:06:43,856 - INFO -   kmmlu_industrial_engineer:
2025-07-28 08:06:43,856 - INFO -     - accuracy: 0.2500
2025-07-28 08:06:43,856 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 08:06:43,856 - INFO -     - accuracy: 0.4500
2025-07-28 08:06:43,856 - INFO -   kmmlu_maritime_engineering:
2025-07-28 08:06:43,856 - INFO -     - accuracy: 0.3000
2025-07-28 08:06:43,857 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 08:06:43,857 - INFO -     - accuracy: 0.3500
2025-07-28 08:06:43,857 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 08:06:43,857 - INFO -     - accuracy: 0.3500
2025-07-28 08:06:43,857 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 08:06:43,857 - INFO -     - accuracy: 0.4000
2025-07-28 08:06:43,857 - INFO -   kmmlu_humss:
2025-07-28 08:06:43,857 - INFO -     - accuracy: 0.5000
2025-07-28 08:06:43,857 - INFO -   kmmlu_accounting:
2025-07-28 08:06:43,858 - INFO -     - accuracy: 0.5000
2025-07-28 08:06:43,858 - INFO -   kmmlu_criminal_law:
2025-07-28 08:06:43,858 - INFO -     - accuracy: 0.4000
2025-07-28 08:06:43,858 - INFO -   kmmlu_economics:
2025-07-28 08:06:43,858 - INFO -     - accuracy: 0.7500
2025-07-28 08:06:43,858 - INFO -   kmmlu_education:
2025-07-28 08:06:43,858 - INFO -     - accuracy: 0.7000
2025-07-28 08:06:43,858 - INFO -   kmmlu_korean_history:
2025-07-28 08:06:43,858 - INFO -     - accuracy: 0.4500
2025-07-28 08:06:43,859 - INFO -   kmmlu_law:
2025-07-28 08:06:43,859 - INFO -     - accuracy: 0.2000
2025-07-28 08:06:43,859 - INFO -   kmmlu_management:
2025-07-28 08:06:43,859 - INFO -     - accuracy: 0.6000
2025-07-28 08:06:43,859 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 08:06:43,859 - INFO -     - accuracy: 0.8500
2025-07-28 08:06:43,859 - INFO -   kmmlu_psychology:
2025-07-28 08:06:43,859 - INFO -     - accuracy: 0.3000
2025-07-28 08:06:43,859 - INFO -   kmmlu_social_welfare:
2025-07-28 08:06:43,860 - INFO -     - accuracy: 0.4000
2025-07-28 08:06:43,860 - INFO -   kmmlu_taxation:
2025-07-28 08:06:43,860 - INFO -     - accuracy: 0.3500
2025-07-28 08:06:43,860 - INFO -   kmmlu_other:
2025-07-28 08:06:43,860 - INFO -     - accuracy: 0.4455
2025-07-28 08:06:43,860 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 08:06:43,860 - INFO -     - accuracy: 0.3000
2025-07-28 08:06:43,860 - INFO -   kmmlu_construction:
2025-07-28 08:06:43,860 - INFO -     - accuracy: 0.4500
2025-07-28 08:06:43,861 - INFO -   kmmlu_fashion:
2025-07-28 08:06:43,861 - INFO -     - accuracy: 0.2500
2025-07-28 08:06:43,861 - INFO -   kmmlu_food_processing:
2025-07-28 08:06:43,861 - INFO -     - accuracy: 0.3500
2025-07-28 08:06:43,861 - INFO -   kmmlu_health:
2025-07-28 08:06:43,861 - INFO -     - accuracy: 0.6000
2025-07-28 08:06:43,861 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 08:06:43,861 - INFO -     - accuracy: 0.6500
2025-07-28 08:06:43,861 - INFO -   kmmlu_marketing:
2025-07-28 08:06:43,861 - INFO -     - accuracy: 0.6000
2025-07-28 08:06:43,862 - INFO -   kmmlu_patent:
2025-07-28 08:06:43,862 - INFO -     - accuracy: 0.4500
2025-07-28 08:06:43,862 - INFO -   kmmlu_public_safety:
2025-07-28 08:06:43,862 - INFO -     - accuracy: 0.5000
2025-07-28 08:06:43,862 - INFO -   kmmlu_real_estate:
2025-07-28 08:06:43,862 - INFO -     - accuracy: 0.3000
2025-07-28 08:06:43,862 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 08:06:43,862 - INFO -     - accuracy: 0.4500
2025-07-28 08:06:43,863 - INFO -   kmmlu_stem:
2025-07-28 08:06:43,863 - INFO -     - accuracy: 0.4455
2025-07-28 08:06:43,863 - INFO -   kmmlu_biology:
2025-07-28 08:06:43,863 - INFO -     - accuracy: 0.3000
2025-07-28 08:06:43,863 - INFO -   kmmlu_chemical_engineering:
2025-07-28 08:06:43,863 - INFO -     - accuracy: 0.5000
2025-07-28 08:06:43,863 - INFO -   kmmlu_chemistry:
2025-07-28 08:06:43,863 - INFO -     - accuracy: 0.3000
2025-07-28 08:06:43,863 - INFO -   kmmlu_civil_engineering:
2025-07-28 08:06:43,863 - INFO -     - accuracy: 0.2000
2025-07-28 08:06:43,864 - INFO -   kmmlu_computer_science:
2025-07-28 08:06:43,864 - INFO -     - accuracy: 0.9000
2025-07-28 08:06:43,864 - INFO -   kmmlu_ecology:
2025-07-28 08:06:43,864 - INFO -     - accuracy: 0.5000
2025-07-28 08:06:43,864 - INFO -   kmmlu_electrical_engineering:
2025-07-28 08:06:43,864 - INFO -     - accuracy: 0.4500
2025-07-28 08:06:43,864 - INFO -   kmmlu_information_technology:
2025-07-28 08:06:43,864 - INFO -     - accuracy: 0.5500
2025-07-28 08:06:43,864 - INFO -   kmmlu_materials_engineering:
2025-07-28 08:06:43,865 - INFO -     - accuracy: 0.4500
2025-07-28 08:06:43,865 - INFO -   kmmlu_math:
2025-07-28 08:06:43,865 - INFO -     - accuracy: 0.3500
2025-07-28 08:06:43,865 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 08:06:43,865 - INFO -     - accuracy: 0.4000
2025-07-28 08:06:43,865 - INFO - ============================================================

2025-07-28 08:06:43,905 - INFO - Qwen3-8B_harness_5: Processing task 2/10: kmmlu_hard
2025-07-28 08:06:43,906 - INFO - Qwen3-8B_harness_5: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 08:06:43,907 - INFO - Qwen3-8B_harness_5: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 08:06:43,907 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:07:56,942 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 08:07:56,942 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 08:07:56,942 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 08:07:56,952 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 08:07:56,952 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 08:07:56,952 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 08:07:56,952 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 08:07:56,952 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 08:07:56,953 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 08:07:56,954 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 08:07:56,955 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 08:07:56,956 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 08:07:56,956 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 08:08:39,491 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 08:08:39,492 - INFO - 
============================================================
2025-07-28 08:08:39,492 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 08:08:39,493 - INFO - ============================================================
2025-07-28 08:08:39,494 - INFO -   kmmlu_hard:
2025-07-28 08:08:39,494 - INFO -     - accuracy: 0.2700
2025-07-28 08:08:39,494 - INFO -   kmmlu_hard_applied_science:
2025-07-28 08:08:39,494 - INFO -     - accuracy: 0.2833
2025-07-28 08:08:39,494 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 08:08:39,494 - INFO -     - accuracy: 0.2500
2025-07-28 08:08:39,494 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 08:08:39,495 - INFO -     - accuracy: 0.3500
2025-07-28 08:08:39,495 - INFO -   kmmlu_hard_energy_management:
2025-07-28 08:08:39,495 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,495 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 08:08:39,495 - INFO -     - accuracy: 0.1500
2025-07-28 08:08:39,495 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 08:08:39,495 - INFO -     - accuracy: 0.1500
2025-07-28 08:08:39,495 - INFO -   kmmlu_hard_geomatics:
2025-07-28 08:08:39,495 - INFO -     - accuracy: 0.1500
2025-07-28 08:08:39,496 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 08:08:39,496 - INFO -     - accuracy: 0.4500
2025-07-28 08:08:39,496 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 08:08:39,496 - INFO -     - accuracy: 0.4000
2025-07-28 08:08:39,496 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 08:08:39,496 - INFO -     - accuracy: 0.0500
2025-07-28 08:08:39,496 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 08:08:39,496 - INFO -     - accuracy: 0.1500
2025-07-28 08:08:39,496 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 08:08:39,497 - INFO -     - accuracy: 0.5000
2025-07-28 08:08:39,497 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 08:08:39,497 - INFO -     - accuracy: 0.5000
2025-07-28 08:08:39,497 - INFO -   kmmlu_hard_humss:
2025-07-28 08:08:39,497 - INFO -     - accuracy: 0.2273
2025-07-28 08:08:39,497 - INFO -   kmmlu_hard_accounting:
2025-07-28 08:08:39,497 - INFO -     - accuracy: 0.2500
2025-07-28 08:08:39,497 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 08:08:39,497 - INFO -     - accuracy: 0.1500
2025-07-28 08:08:39,498 - INFO -   kmmlu_hard_economics:
2025-07-28 08:08:39,498 - INFO -     - accuracy: 0.1500
2025-07-28 08:08:39,498 - INFO -   kmmlu_hard_education:
2025-07-28 08:08:39,498 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,498 - INFO -   kmmlu_hard_korean_history:
2025-07-28 08:08:39,498 - INFO -     - accuracy: 0.1500
2025-07-28 08:08:39,498 - INFO -   kmmlu_hard_law:
2025-07-28 08:08:39,498 - INFO -     - accuracy: 0.1000
2025-07-28 08:08:39,498 - INFO -   kmmlu_hard_management:
2025-07-28 08:08:39,498 - INFO -     - accuracy: 0.4000
2025-07-28 08:08:39,499 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 08:08:39,499 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,499 - INFO -   kmmlu_hard_psychology:
2025-07-28 08:08:39,499 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,499 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 08:08:39,499 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,499 - INFO -   kmmlu_hard_taxation:
2025-07-28 08:08:39,499 - INFO -     - accuracy: 0.1000
2025-07-28 08:08:39,499 - INFO -   kmmlu_hard_other:
2025-07-28 08:08:39,500 - INFO -     - accuracy: 0.2818
2025-07-28 08:08:39,500 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 08:08:39,500 - INFO -     - accuracy: 0.1500
2025-07-28 08:08:39,500 - INFO -   kmmlu_hard_construction:
2025-07-28 08:08:39,500 - INFO -     - accuracy: 0.3500
2025-07-28 08:08:39,500 - INFO -   kmmlu_hard_fashion:
2025-07-28 08:08:39,500 - INFO -     - accuracy: 0.2000
2025-07-28 08:08:39,500 - INFO -   kmmlu_hard_food_processing:
2025-07-28 08:08:39,500 - INFO -     - accuracy: 0.3500
2025-07-28 08:08:39,500 - INFO -   kmmlu_hard_health:
2025-07-28 08:08:39,500 - INFO -     - accuracy: 0.1500
2025-07-28 08:08:39,501 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 08:08:39,501 - INFO -     - accuracy: 0.4000
2025-07-28 08:08:39,501 - INFO -   kmmlu_hard_marketing:
2025-07-28 08:08:39,501 - INFO -     - accuracy: 0.3500
2025-07-28 08:08:39,501 - INFO -   kmmlu_hard_patent:
2025-07-28 08:08:39,501 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,501 - INFO -   kmmlu_hard_public_safety:
2025-07-28 08:08:39,501 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,501 - INFO -   kmmlu_hard_real_estate:
2025-07-28 08:08:39,501 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,502 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 08:08:39,502 - INFO -     - accuracy: 0.2500
2025-07-28 08:08:39,502 - INFO -   kmmlu_hard_stem:
2025-07-28 08:08:39,502 - INFO -     - accuracy: 0.2864
2025-07-28 08:08:39,502 - INFO -   kmmlu_hard_biology:
2025-07-28 08:08:39,502 - INFO -     - accuracy: 0.1500
2025-07-28 08:08:39,502 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 08:08:39,502 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,502 - INFO -   kmmlu_hard_chemistry:
2025-07-28 08:08:39,503 - INFO -     - accuracy: 0.3500
2025-07-28 08:08:39,503 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 08:08:39,503 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,503 - INFO -   kmmlu_hard_computer_science:
2025-07-28 08:08:39,503 - INFO -     - accuracy: 0.4000
2025-07-28 08:08:39,503 - INFO -   kmmlu_hard_ecology:
2025-07-28 08:08:39,503 - INFO -     - accuracy: 0.3500
2025-07-28 08:08:39,503 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 08:08:39,503 - INFO -     - accuracy: 0.3000
2025-07-28 08:08:39,504 - INFO -   kmmlu_hard_information_technology:
2025-07-28 08:08:39,504 - INFO -     - accuracy: 0.4000
2025-07-28 08:08:39,504 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 08:08:39,504 - INFO -     - accuracy: 0.2000
2025-07-28 08:08:39,504 - INFO -   kmmlu_hard_math:
2025-07-28 08:08:39,504 - INFO -     - accuracy: 0.2000
2025-07-28 08:08:39,504 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 08:08:39,504 - INFO -     - accuracy: 0.2000
2025-07-28 08:08:39,504 - INFO - ============================================================

2025-07-28 08:08:39,543 - INFO - Qwen3-8B_harness_5: Processing task 3/10: haerae
2025-07-28 08:08:39,545 - INFO - Qwen3-8B_harness_5: Task 'haerae' will use num_fewshot=0
2025-07-28 08:08:39,545 - INFO - Qwen3-8B_harness_5: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 08:08:39,546 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:08:58,371 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 08:08:58,371 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 08:08:58,372 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 08:08:58,372 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 08:08:58,372 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 08:09:21,697 - INFO - Qwen3-8B_harness_5: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 08:09:21,699 - INFO - 
============================================================
2025-07-28 08:09:21,700 - INFO - Task 'haerae' Results:
2025-07-28 08:09:21,700 - INFO - ============================================================
2025-07-28 08:09:21,700 - INFO -   haerae:
2025-07-28 08:09:21,700 - INFO -     - accuracy: 0.6700
2025-07-28 08:09:21,700 - INFO -     - accuracy_norm: 0.6700
2025-07-28 08:09:21,701 - INFO -   haerae_general_knowledge:
2025-07-28 08:09:21,701 - INFO -     - accuracy: 0.8000
2025-07-28 08:09:21,701 - INFO -     - accuracy_norm: 0.8000
2025-07-28 08:09:21,701 - INFO -   haerae_history:
2025-07-28 08:09:21,701 - INFO -     - accuracy: 0.4500
2025-07-28 08:09:21,701 - INFO -     - accuracy_norm: 0.4500
2025-07-28 08:09:21,701 - INFO -   haerae_loan_word:
2025-07-28 08:09:21,701 - INFO -     - accuracy: 0.8500
2025-07-28 08:09:21,701 - INFO -     - accuracy_norm: 0.8500
2025-07-28 08:09:21,702 - INFO -   haerae_rare_word:
2025-07-28 08:09:21,702 - INFO -     - accuracy: 0.5500
2025-07-28 08:09:21,702 - INFO -     - accuracy_norm: 0.5500
2025-07-28 08:09:21,702 - INFO -   haerae_standard_nomenclature:
2025-07-28 08:09:21,702 - INFO -     - accuracy: 0.7000
2025-07-28 08:09:21,702 - INFO -     - accuracy_norm: 0.7000
2025-07-28 08:09:21,702 - INFO - ============================================================

2025-07-28 08:09:21,739 - INFO - Qwen3-8B_harness_5: Processing task 4/10: kobest
2025-07-28 08:09:21,741 - INFO - Qwen3-8B_harness_5: Task 'kobest' will use num_fewshot=0
2025-07-28 08:09:21,741 - INFO - Qwen3-8B_harness_5: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 08:09:21,741 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:09:42,847 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 08:09:42,848 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 08:09:42,849 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 08:09:42,849 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 08:09:42,849 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 08:09:55,467 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 08:09:55,468 - INFO - 
============================================================
2025-07-28 08:09:55,469 - INFO - Task 'kobest' Results:
2025-07-28 08:09:55,470 - INFO - ============================================================
2025-07-28 08:09:55,470 - INFO -   kobest:
2025-07-28 08:09:55,470 - INFO -     - accuracy: 0.6300
2025-07-28 08:09:55,470 - INFO -     - accuracy_norm: 0.5500
2025-07-28 08:09:55,470 - INFO -     - f1: 0.5957
2025-07-28 08:09:55,470 - INFO -   kobest_boolq:
2025-07-28 08:09:55,470 - INFO -     - accuracy: 0.6000
2025-07-28 08:09:55,470 - INFO -     - f1: 0.4667
2025-07-28 08:09:55,470 - INFO -   kobest_copa:
2025-07-28 08:09:55,470 - INFO -     - accuracy: 0.6500
2025-07-28 08:09:55,471 - INFO -     - f1: 0.6491
2025-07-28 08:09:55,471 - INFO -   kobest_hellaswag:
2025-07-28 08:09:55,471 - INFO -     - accuracy: 0.4000
2025-07-28 08:09:55,471 - INFO -     - accuracy_norm: 0.5500
2025-07-28 08:09:55,471 - INFO -     - f1: 0.3958
2025-07-28 08:09:55,471 - INFO -   kobest_sentineg:
2025-07-28 08:09:55,471 - INFO -     - accuracy: 0.8500
2025-07-28 08:09:55,471 - INFO -     - f1: 0.8400
2025-07-28 08:09:55,471 - INFO -   kobest_wic:
2025-07-28 08:09:55,471 - INFO -     - accuracy: 0.6500
2025-07-28 08:09:55,471 - INFO -     - f1: 0.6267
2025-07-28 08:09:55,472 - INFO - ============================================================

2025-07-28 08:09:55,510 - INFO - Qwen3-8B_harness_5: Processing task 5/10: csatqa
2025-07-28 08:09:55,511 - INFO - Qwen3-8B_harness_5: Task 'csatqa' detected as zero-shot task
2025-07-28 08:09:55,511 - INFO - Qwen3-8B_harness_5: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 08:09:55,512 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:10:09,658 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 08:10:09,658 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 08:10:09,659 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 08:10:09,659 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 08:10:09,659 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 08:10:09,659 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 08:11:37,792 - INFO - Qwen3-8B_harness_5: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 08:11:37,794 - INFO - 
============================================================
2025-07-28 08:11:37,795 - INFO - Task 'csatqa' Results:
2025-07-28 08:11:37,795 - INFO - ============================================================
2025-07-28 08:11:37,796 - INFO -   csatqa:
2025-07-28 08:11:37,796 - INFO -     - accuracy: 0.4685
2025-07-28 08:11:37,796 - INFO -     - accuracy_norm: 0.4685
2025-07-28 08:11:37,796 - INFO -   csatqa_gr:
2025-07-28 08:11:37,796 - INFO -     - accuracy: 0.2000
2025-07-28 08:11:37,796 - INFO -     - accuracy_norm: 0.2000
2025-07-28 08:11:37,796 - INFO -   csatqa_li:
2025-07-28 08:11:37,796 - INFO -     - accuracy: 0.5500
2025-07-28 08:11:37,796 - INFO -     - accuracy_norm: 0.5500
2025-07-28 08:11:37,797 - INFO -   csatqa_rch:
2025-07-28 08:11:37,797 - INFO -     - accuracy: 0.6000
2025-07-28 08:11:37,797 - INFO -     - accuracy_norm: 0.6000
2025-07-28 08:11:37,797 - INFO -   csatqa_rcs:
2025-07-28 08:11:37,797 - INFO -     - accuracy: 0.5500
2025-07-28 08:11:37,797 - INFO -     - accuracy_norm: 0.5500
2025-07-28 08:11:37,797 - INFO -   csatqa_rcss:
2025-07-28 08:11:37,797 - INFO -     - accuracy: 0.5000
2025-07-28 08:11:37,797 - INFO -     - accuracy_norm: 0.5000
2025-07-28 08:11:37,797 - INFO -   csatqa_wr:
2025-07-28 08:11:37,797 - INFO -     - accuracy: 0.3636
2025-07-28 08:11:37,797 - INFO -     - accuracy_norm: 0.3636
2025-07-28 08:11:37,798 - INFO - ============================================================

2025-07-28 08:11:37,844 - INFO - Qwen3-8B_harness_5: Processing task 6/10: kormedmcqa
2025-07-28 08:11:37,844 - INFO - Qwen3-8B_harness_5: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 08:11:37,846 - INFO - Qwen3-8B_harness_5: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 08:11:37,847 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:12:00,845 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 08:12:00,846 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 08:12:00,846 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 08:12:00,846 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 08:13:53,545 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 08:13:53,546 - INFO - 
============================================================
2025-07-28 08:13:53,547 - INFO - Task 'kormedmcqa' Results:
2025-07-28 08:13:53,547 - INFO - ============================================================
2025-07-28 08:13:53,548 - INFO -   kormedmcqa:
2025-07-28 08:13:53,548 - INFO -     - exact_match: 0.2500
2025-07-28 08:13:53,548 - INFO -   kormedmcqa_dentist:
2025-07-28 08:13:53,548 - INFO -     - exact_match: 0.1000
2025-07-28 08:13:53,548 - INFO -   kormedmcqa_doctor:
2025-07-28 08:13:53,548 - INFO -     - exact_match: 0.1000
2025-07-28 08:13:53,548 - INFO -   kormedmcqa_nurse:
2025-07-28 08:13:53,549 - INFO -     - exact_match: 0.2500
2025-07-28 08:13:53,549 - INFO -   kormedmcqa_pharm:
2025-07-28 08:13:53,549 - INFO -     - exact_match: 0.5500
2025-07-28 08:13:53,549 - INFO - ============================================================

2025-07-28 08:13:53,587 - INFO - Qwen3-8B_harness_5: Processing task 7/10: mmlu
2025-07-28 08:13:53,589 - INFO - Qwen3-8B_harness_5: Task 'mmlu' will use num_fewshot=0
2025-07-28 08:13:53,589 - INFO - Qwen3-8B_harness_5: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 08:13:53,590 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:16:47,039 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 08:16:47,039 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 08:16:47,040 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 08:16:47,041 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 08:16:47,042 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 08:16:47,043 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 08:16:47,044 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 08:16:47,044 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 08:16:47,044 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 08:16:47,044 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 08:16:47,044 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 08:16:47,044 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 08:16:47,044 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 08:16:47,044 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 08:16:47,044 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 08:17:39,406 - INFO - Qwen3-8B_harness_5: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 08:17:39,407 - INFO - 
============================================================
2025-07-28 08:17:39,408 - INFO - Task 'mmlu' Results:
2025-07-28 08:17:39,408 - INFO - ============================================================
2025-07-28 08:17:39,409 - INFO -   mmlu:
2025-07-28 08:17:39,409 - INFO -     - accuracy: 0.7614
2025-07-28 08:17:39,409 - INFO -   mmlu_humanities:
2025-07-28 08:17:39,409 - INFO -     - accuracy: 0.7692
2025-07-28 08:17:39,409 - INFO -   mmlu_formal_logic:
2025-07-28 08:17:39,410 - INFO -     - accuracy: 0.7000
2025-07-28 08:17:39,410 - INFO -   mmlu_high_school_european_history:
2025-07-28 08:17:39,410 - INFO -     - accuracy: 0.8500
2025-07-28 08:17:39,410 - INFO -   mmlu_high_school_us_history:
2025-07-28 08:17:39,410 - INFO -     - accuracy: 0.9000
2025-07-28 08:17:39,410 - INFO -   mmlu_high_school_world_history:
2025-07-28 08:17:39,410 - INFO -     - accuracy: 0.9000
2025-07-28 08:17:39,410 - INFO -   mmlu_international_law:
2025-07-28 08:17:39,410 - INFO -     - accuracy: 0.9000
2025-07-28 08:17:39,411 - INFO -   mmlu_jurisprudence:
2025-07-28 08:17:39,411 - INFO -     - accuracy: 0.8500
2025-07-28 08:17:39,411 - INFO -   mmlu_logical_fallacies:
2025-07-28 08:17:39,411 - INFO -     - accuracy: 0.8000
2025-07-28 08:17:39,411 - INFO -   mmlu_moral_disputes:
2025-07-28 08:17:39,411 - INFO -     - accuracy: 0.6500
2025-07-28 08:17:39,411 - INFO -   mmlu_moral_scenarios:
2025-07-28 08:17:39,411 - INFO -     - accuracy: 0.2500
2025-07-28 08:17:39,411 - INFO -   mmlu_philosophy:
2025-07-28 08:17:39,412 - INFO -     - accuracy: 0.7500
2025-07-28 08:17:39,412 - INFO -   mmlu_prehistory:
2025-07-28 08:17:39,412 - INFO -     - accuracy: 0.8000
2025-07-28 08:17:39,412 - INFO -   mmlu_professional_law:
2025-07-28 08:17:39,412 - INFO -     - accuracy: 0.6500
2025-07-28 08:17:39,412 - INFO -   mmlu_world_religions:
2025-07-28 08:17:39,412 - INFO -     - accuracy: 1.0000
2025-07-28 08:17:39,412 - INFO -   mmlu_other:
2025-07-28 08:17:39,412 - INFO -     - accuracy: 0.7500
2025-07-28 08:17:39,413 - INFO -   mmlu_business_ethics:
2025-07-28 08:17:39,413 - INFO -     - accuracy: 0.8500
2025-07-28 08:17:39,413 - INFO -   mmlu_clinical_knowledge:
2025-07-28 08:17:39,413 - INFO -     - accuracy: 0.8000
2025-07-28 08:17:39,413 - INFO -   mmlu_college_medicine:
2025-07-28 08:17:39,413 - INFO -     - accuracy: 0.7000
2025-07-28 08:17:39,413 - INFO -   mmlu_global_facts:
2025-07-28 08:17:39,413 - INFO -     - accuracy: 0.5500
2025-07-28 08:17:39,413 - INFO -   mmlu_human_aging:
2025-07-28 08:17:39,413 - INFO -     - accuracy: 0.8500
2025-07-28 08:17:39,414 - INFO -   mmlu_management:
2025-07-28 08:17:39,414 - INFO -     - accuracy: 0.8500
2025-07-28 08:17:39,414 - INFO -   mmlu_marketing:
2025-07-28 08:17:39,414 - INFO -     - accuracy: 0.8000
2025-07-28 08:17:39,414 - INFO -   mmlu_medical_genetics:
2025-07-28 08:17:39,414 - INFO -     - accuracy: 1.0000
2025-07-28 08:17:39,414 - INFO -   mmlu_miscellaneous:
2025-07-28 08:17:39,414 - INFO -     - accuracy: 0.7500
2025-07-28 08:17:39,414 - INFO -   mmlu_nutrition:
2025-07-28 08:17:39,414 - INFO -     - accuracy: 0.8000
2025-07-28 08:17:39,415 - INFO -   mmlu_professional_accounting:
2025-07-28 08:17:39,415 - INFO -     - accuracy: 0.4500
2025-07-28 08:17:39,415 - INFO -   mmlu_professional_medicine:
2025-07-28 08:17:39,415 - INFO -     - accuracy: 0.8000
2025-07-28 08:17:39,415 - INFO -   mmlu_virology:
2025-07-28 08:17:39,415 - INFO -     - accuracy: 0.5500
2025-07-28 08:17:39,415 - INFO -   mmlu_social_sciences:
2025-07-28 08:17:39,415 - INFO -     - accuracy: 0.8542
2025-07-28 08:17:39,415 - INFO -   mmlu_econometrics:
2025-07-28 08:17:39,415 - INFO -     - accuracy: 0.8000
2025-07-28 08:17:39,416 - INFO -   mmlu_high_school_geography:
2025-07-28 08:17:39,416 - INFO -     - accuracy: 0.8500
2025-07-28 08:17:39,416 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 08:17:39,416 - INFO -     - accuracy: 0.9500
2025-07-28 08:17:39,416 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 08:17:39,416 - INFO -     - accuracy: 0.8500
2025-07-28 08:17:39,416 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 08:17:39,416 - INFO -     - accuracy: 0.8500
2025-07-28 08:17:39,416 - INFO -   mmlu_high_school_psychology:
2025-07-28 08:17:39,416 - INFO -     - accuracy: 1.0000
2025-07-28 08:17:39,417 - INFO -   mmlu_human_sexuality:
2025-07-28 08:17:39,417 - INFO -     - accuracy: 0.8500
2025-07-28 08:17:39,417 - INFO -   mmlu_professional_psychology:
2025-07-28 08:17:39,417 - INFO -     - accuracy: 0.9000
2025-07-28 08:17:39,417 - INFO -   mmlu_public_relations:
2025-07-28 08:17:39,417 - INFO -     - accuracy: 0.6500
2025-07-28 08:17:39,417 - INFO -   mmlu_security_studies:
2025-07-28 08:17:39,417 - INFO -     - accuracy: 0.8500
2025-07-28 08:17:39,417 - INFO -   mmlu_sociology:
2025-07-28 08:17:39,418 - INFO -     - accuracy: 0.8000
2025-07-28 08:17:39,418 - INFO -   mmlu_us_foreign_policy:
2025-07-28 08:17:39,418 - INFO -     - accuracy: 0.9000
2025-07-28 08:17:39,418 - INFO -   mmlu_stem:
2025-07-28 08:17:39,418 - INFO -     - accuracy: 0.7053
2025-07-28 08:17:39,418 - INFO -   mmlu_abstract_algebra:
2025-07-28 08:17:39,418 - INFO -     - accuracy: 0.3500
2025-07-28 08:17:39,418 - INFO -   mmlu_anatomy:
2025-07-28 08:17:39,418 - INFO -     - accuracy: 0.7500
2025-07-28 08:17:39,419 - INFO -   mmlu_astronomy:
2025-07-28 08:17:39,419 - INFO -     - accuracy: 0.9500
2025-07-28 08:17:39,419 - INFO -   mmlu_college_biology:
2025-07-28 08:17:39,419 - INFO -     - accuracy: 0.9000
2025-07-28 08:17:39,419 - INFO -   mmlu_college_chemistry:
2025-07-28 08:17:39,419 - INFO -     - accuracy: 0.5500
2025-07-28 08:17:39,419 - INFO -   mmlu_college_computer_science:
2025-07-28 08:17:39,419 - INFO -     - accuracy: 0.7500
2025-07-28 08:17:39,419 - INFO -   mmlu_college_mathematics:
2025-07-28 08:17:39,419 - INFO -     - accuracy: 0.4500
2025-07-28 08:17:39,420 - INFO -   mmlu_college_physics:
2025-07-28 08:17:39,420 - INFO -     - accuracy: 0.7000
2025-07-28 08:17:39,420 - INFO -   mmlu_computer_security:
2025-07-28 08:17:39,420 - INFO -     - accuracy: 0.7500
2025-07-28 08:17:39,420 - INFO -   mmlu_conceptual_physics:
2025-07-28 08:17:39,420 - INFO -     - accuracy: 1.0000
2025-07-28 08:17:39,420 - INFO -   mmlu_electrical_engineering:
2025-07-28 08:17:39,420 - INFO -     - accuracy: 0.5500
2025-07-28 08:17:39,420 - INFO -   mmlu_elementary_mathematics:
2025-07-28 08:17:39,421 - INFO -     - accuracy: 0.6500
2025-07-28 08:17:39,421 - INFO -   mmlu_high_school_biology:
2025-07-28 08:17:39,421 - INFO -     - accuracy: 0.9500
2025-07-28 08:17:39,421 - INFO -   mmlu_high_school_chemistry:
2025-07-28 08:17:39,421 - INFO -     - accuracy: 0.7500
2025-07-28 08:17:39,421 - INFO -   mmlu_high_school_computer_science:
2025-07-28 08:17:39,421 - INFO -     - accuracy: 0.9000
2025-07-28 08:17:39,421 - INFO -   mmlu_high_school_mathematics:
2025-07-28 08:17:39,421 - INFO -     - accuracy: 0.5500
2025-07-28 08:17:39,422 - INFO -   mmlu_high_school_physics:
2025-07-28 08:17:39,422 - INFO -     - accuracy: 0.5500
2025-07-28 08:17:39,422 - INFO -   mmlu_high_school_statistics:
2025-07-28 08:17:39,422 - INFO -     - accuracy: 0.8000
2025-07-28 08:17:39,422 - INFO -   mmlu_machine_learning:
2025-07-28 08:17:39,422 - INFO -     - accuracy: 0.5500
2025-07-28 08:17:39,422 - INFO - ============================================================

2025-07-28 08:17:39,462 - INFO - Qwen3-8B_harness_5: Processing task 8/10: arc_challenge
2025-07-28 08:17:39,464 - INFO - Qwen3-8B_harness_5: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 08:17:39,464 - INFO - Qwen3-8B_harness_5: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 08:17:39,465 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:17:49,225 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 08:17:55,331 - INFO - Qwen3-8B_harness_5: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 08:17:55,333 - INFO - 
============================================================
2025-07-28 08:17:55,333 - INFO - Task 'arc_challenge' Results:
2025-07-28 08:17:55,333 - INFO - ============================================================
2025-07-28 08:17:55,333 - INFO -   arc_challenge:
2025-07-28 08:17:55,333 - INFO -     - accuracy: 0.4500
2025-07-28 08:17:55,333 - INFO -     - accuracy_norm: 0.5000
2025-07-28 08:17:55,333 - INFO - ============================================================

2025-07-28 08:17:55,371 - INFO - Qwen3-8B_harness_5: Processing task 9/10: arc_easy
2025-07-28 08:17:55,372 - INFO - Qwen3-8B_harness_5: Task 'arc_easy' will use num_fewshot=0
2025-07-28 08:17:55,372 - INFO - Qwen3-8B_harness_5: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 08:17:55,373 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:18:05,158 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 08:18:10,967 - INFO - Qwen3-8B_harness_5: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 08:18:10,968 - INFO - 
============================================================
2025-07-28 08:18:10,970 - INFO - Task 'arc_easy' Results:
2025-07-28 08:18:10,970 - INFO - ============================================================
2025-07-28 08:18:10,970 - INFO -   arc_easy:
2025-07-28 08:18:10,971 - INFO -     - accuracy: 0.7500
2025-07-28 08:18:10,971 - INFO -     - accuracy_norm: 0.7000
2025-07-28 08:18:10,971 - INFO - ============================================================

2025-07-28 08:18:11,009 - INFO - Qwen3-8B_harness_5: Processing task 10/10: hellaswag
2025-07-28 08:18:11,010 - INFO - Qwen3-8B_harness_5: Task 'hellaswag' will use num_fewshot=0
2025-07-28 08:18:11,010 - INFO - Qwen3-8B_harness_5: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 08:18:11,011 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:18:28,610 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 08:18:34,932 - INFO - Qwen3-8B_harness_5: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 08:18:34,934 - INFO - 
============================================================
2025-07-28 08:18:34,936 - INFO - Task 'hellaswag' Results:
2025-07-28 08:18:34,936 - INFO - ============================================================
2025-07-28 08:18:34,936 - INFO -   hellaswag:
2025-07-28 08:18:34,936 - INFO -     - accuracy: 0.4000
2025-07-28 08:18:34,936 - INFO -     - accuracy_norm: 0.5500
2025-07-28 08:18:34,937 - INFO - ============================================================

2025-07-28 08:18:34,974 - INFO - Qwen3-8B_harness_5: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 08:18:34,977 - INFO - [Process 1865749] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_073925/model_results/Qwen3-8B/Qwen3-8B_harness_5.json
2025-07-28 08:18:34,979 - INFO - [Process 1865749] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Qwen3-8B/Qwen3-8B_harness_5.json
2025-07-28 08:18:35,268 - INFO - Results uploaded to WandB as artifact
2025-07-28 08:18:35,277 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 08:18:35,279 - INFO - [Process 1865749] Successfully completed Qwen3-8B_harness_5
2025-07-28 08:18:38,325 - INFO - Run Qwen3-8B_harness_5 finished successfully
2025-07-28 08:18:38,326 - INFO - [Process 1865749] Llama-DNA-1.0-8B-Instruct_harness_6 assigned to cuda:0
2025-07-28 08:18:38,326 - INFO - [Process 1865749] Llama-DNA-1.0-8B-Instruct_harness_6 - using custom limit: 20
2025-07-28 08:18:39,914 - INFO - WandB run initialized: Llama-DNA-1.0-8B-Instruct_20250728_081838 (ID: 03094734)
2025-07-28 08:18:40,123 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Test mode (limit=2), setting num_fewshot=0
2025-07-28 08:18:40,124 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 1/10: kmmlu
2025-07-28 08:18:40,124 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kmmlu' will use num_fewshot=0
2025-07-28 08:18:40,124 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 08:18:40,125 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:19:57,490 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 08:19:57,490 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 08:19:57,490 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 08:19:57,490 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 08:19:57,490 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 08:19:57,490 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 08:19:57,491 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 08:19:57,491 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 08:19:57,491 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 08:19:57,491 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 08:19:57,491 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 08:19:57,491 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 08:19:57,491 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 08:19:57,491 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 08:19:57,491 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 08:19:57,491 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 08:19:57,492 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 08:19:57,492 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 08:19:57,492 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 08:19:57,492 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 08:19:57,492 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 08:19:57,492 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 08:19:57,492 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 08:19:57,492 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 08:19:57,492 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 08:19:57,492 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 08:19:57,493 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 08:19:57,493 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 08:19:57,493 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 08:19:57,493 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 08:19:57,493 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 08:19:57,493 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 08:19:57,493 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 08:19:57,493 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 08:19:57,493 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 08:19:57,493 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 08:19:57,494 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 08:19:57,494 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 08:19:57,494 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 08:19:57,494 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 08:19:57,494 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 08:19:57,494 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 08:19:57,494 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 08:19:57,494 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 08:19:57,494 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 08:20:30,339 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 08:20:30,340 - INFO - 
============================================================
2025-07-28 08:20:30,340 - INFO - Task 'kmmlu' Results:
2025-07-28 08:20:30,341 - INFO - ============================================================
2025-07-28 08:20:30,341 - INFO -   kmmlu:
2025-07-28 08:20:30,341 - INFO -     - accuracy: 0.4344
2025-07-28 08:20:30,341 - INFO -   kmmlu_applied_science:
2025-07-28 08:20:30,342 - INFO -     - accuracy: 0.3875
2025-07-28 08:20:30,342 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 08:20:30,342 - INFO -     - accuracy: 0.2500
2025-07-28 08:20:30,342 - INFO -   kmmlu_electronics_engineering:
2025-07-28 08:20:30,342 - INFO -     - accuracy: 0.5000
2025-07-28 08:20:30,342 - INFO -   kmmlu_energy_management:
2025-07-28 08:20:30,342 - INFO -     - accuracy: 0.3000
2025-07-28 08:20:30,342 - INFO -   kmmlu_environmental_science:
2025-07-28 08:20:30,342 - INFO -     - accuracy: 0.4500
2025-07-28 08:20:30,342 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 08:20:30,343 - INFO -     - accuracy: 0.4000
2025-07-28 08:20:30,343 - INFO -   kmmlu_geomatics:
2025-07-28 08:20:30,343 - INFO -     - accuracy: 0.4000
2025-07-28 08:20:30,343 - INFO -   kmmlu_industrial_engineer:
2025-07-28 08:20:30,343 - INFO -     - accuracy: 0.3500
2025-07-28 08:20:30,343 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 08:20:30,343 - INFO -     - accuracy: 0.4500
2025-07-28 08:20:30,343 - INFO -   kmmlu_maritime_engineering:
2025-07-28 08:20:30,343 - INFO -     - accuracy: 0.3500
2025-07-28 08:20:30,343 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 08:20:30,343 - INFO -     - accuracy: 0.3000
2025-07-28 08:20:30,344 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 08:20:30,344 - INFO -     - accuracy: 0.3000
2025-07-28 08:20:30,344 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 08:20:30,344 - INFO -     - accuracy: 0.6000
2025-07-28 08:20:30,344 - INFO -   kmmlu_humss:
2025-07-28 08:20:30,344 - INFO -     - accuracy: 0.4409
2025-07-28 08:20:30,344 - INFO -   kmmlu_accounting:
2025-07-28 08:20:30,344 - INFO -     - accuracy: 0.6000
2025-07-28 08:20:30,344 - INFO -   kmmlu_criminal_law:
2025-07-28 08:20:30,344 - INFO -     - accuracy: 0.2000
2025-07-28 08:20:30,344 - INFO -   kmmlu_economics:
2025-07-28 08:20:30,345 - INFO -     - accuracy: 0.7000
2025-07-28 08:20:30,345 - INFO -   kmmlu_education:
2025-07-28 08:20:30,345 - INFO -     - accuracy: 0.6000
2025-07-28 08:20:30,345 - INFO -   kmmlu_korean_history:
2025-07-28 08:20:30,345 - INFO -     - accuracy: 0.3500
2025-07-28 08:20:30,345 - INFO -   kmmlu_law:
2025-07-28 08:20:30,345 - INFO -     - accuracy: 0.2000
2025-07-28 08:20:30,345 - INFO -   kmmlu_management:
2025-07-28 08:20:30,345 - INFO -     - accuracy: 0.3500
2025-07-28 08:20:30,345 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 08:20:30,345 - INFO -     - accuracy: 0.7500
2025-07-28 08:20:30,346 - INFO -   kmmlu_psychology:
2025-07-28 08:20:30,346 - INFO -     - accuracy: 0.3500
2025-07-28 08:20:30,346 - INFO -   kmmlu_social_welfare:
2025-07-28 08:20:30,346 - INFO -     - accuracy: 0.4500
2025-07-28 08:20:30,346 - INFO -   kmmlu_taxation:
2025-07-28 08:20:30,346 - INFO -     - accuracy: 0.3000
2025-07-28 08:20:30,346 - INFO -   kmmlu_other:
2025-07-28 08:20:30,346 - INFO -     - accuracy: 0.4318
2025-07-28 08:20:30,346 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 08:20:30,346 - INFO -     - accuracy: 0.3500
2025-07-28 08:20:30,347 - INFO -   kmmlu_construction:
2025-07-28 08:20:30,347 - INFO -     - accuracy: 0.3000
2025-07-28 08:20:30,347 - INFO -   kmmlu_fashion:
2025-07-28 08:20:30,347 - INFO -     - accuracy: 0.1500
2025-07-28 08:20:30,347 - INFO -   kmmlu_food_processing:
2025-07-28 08:20:30,347 - INFO -     - accuracy: 0.4000
2025-07-28 08:20:30,347 - INFO -   kmmlu_health:
2025-07-28 08:20:30,347 - INFO -     - accuracy: 0.7500
2025-07-28 08:20:30,347 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 08:20:30,347 - INFO -     - accuracy: 0.7500
2025-07-28 08:20:30,347 - INFO -   kmmlu_marketing:
2025-07-28 08:20:30,348 - INFO -     - accuracy: 0.5500
2025-07-28 08:20:30,348 - INFO -   kmmlu_patent:
2025-07-28 08:20:30,348 - INFO -     - accuracy: 0.3000
2025-07-28 08:20:30,348 - INFO -   kmmlu_public_safety:
2025-07-28 08:20:30,348 - INFO -     - accuracy: 0.4500
2025-07-28 08:20:30,348 - INFO -   kmmlu_real_estate:
2025-07-28 08:20:30,348 - INFO -     - accuracy: 0.3500
2025-07-28 08:20:30,348 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 08:20:30,348 - INFO -     - accuracy: 0.4000
2025-07-28 08:20:30,348 - INFO -   kmmlu_stem:
2025-07-28 08:20:30,348 - INFO -     - accuracy: 0.4818
2025-07-28 08:20:30,349 - INFO -   kmmlu_biology:
2025-07-28 08:20:30,349 - INFO -     - accuracy: 0.3000
2025-07-28 08:20:30,349 - INFO -   kmmlu_chemical_engineering:
2025-07-28 08:20:30,349 - INFO -     - accuracy: 0.3500
2025-07-28 08:20:30,349 - INFO -   kmmlu_chemistry:
2025-07-28 08:20:30,349 - INFO -     - accuracy: 0.3000
2025-07-28 08:20:30,349 - INFO -   kmmlu_civil_engineering:
2025-07-28 08:20:30,349 - INFO -     - accuracy: 0.6500
2025-07-28 08:20:30,349 - INFO -   kmmlu_computer_science:
2025-07-28 08:20:30,349 - INFO -     - accuracy: 0.8500
2025-07-28 08:20:30,349 - INFO -   kmmlu_ecology:
2025-07-28 08:20:30,350 - INFO -     - accuracy: 0.5000
2025-07-28 08:20:30,350 - INFO -   kmmlu_electrical_engineering:
2025-07-28 08:20:30,350 - INFO -     - accuracy: 0.4000
2025-07-28 08:20:30,350 - INFO -   kmmlu_information_technology:
2025-07-28 08:20:30,350 - INFO -     - accuracy: 0.6500
2025-07-28 08:20:30,350 - INFO -   kmmlu_materials_engineering:
2025-07-28 08:20:30,350 - INFO -     - accuracy: 0.5000
2025-07-28 08:20:30,350 - INFO -   kmmlu_math:
2025-07-28 08:20:30,350 - INFO -     - accuracy: 0.3000
2025-07-28 08:20:30,350 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 08:20:30,350 - INFO -     - accuracy: 0.5000
2025-07-28 08:20:30,351 - INFO - ============================================================

2025-07-28 08:20:30,387 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 2/10: kmmlu_hard
2025-07-28 08:20:30,388 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 08:20:30,389 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 08:20:30,389 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:21:45,040 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 08:21:45,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 08:21:45,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 08:21:45,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 08:21:45,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 08:21:45,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 08:21:45,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 08:21:45,041 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 08:21:45,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 08:21:45,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 08:21:45,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 08:21:45,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 08:21:45,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 08:21:45,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 08:21:45,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 08:21:45,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 08:21:45,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 08:21:45,042 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 08:21:45,043 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 08:21:45,043 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 08:21:45,043 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 08:21:45,043 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 08:21:45,043 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 08:21:45,043 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 08:21:45,043 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 08:21:45,043 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 08:21:45,043 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 08:21:45,043 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 08:21:45,044 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 08:21:45,045 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 08:21:45,045 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 08:21:45,045 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 08:21:45,045 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 08:21:45,045 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 08:21:45,045 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 08:22:17,911 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 08:22:17,914 - INFO - 
============================================================
2025-07-28 08:22:17,914 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 08:22:17,914 - INFO - ============================================================
2025-07-28 08:22:17,914 - INFO -   kmmlu_hard:
2025-07-28 08:22:17,914 - INFO -     - accuracy: 0.2822
2025-07-28 08:22:17,915 - INFO -   kmmlu_hard_applied_science:
2025-07-28 08:22:17,915 - INFO -     - accuracy: 0.2875
2025-07-28 08:22:17,915 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 08:22:17,915 - INFO -     - accuracy: 0.2500
2025-07-28 08:22:17,915 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 08:22:17,915 - INFO -     - accuracy: 0.3000
2025-07-28 08:22:17,915 - INFO -   kmmlu_hard_energy_management:
2025-07-28 08:22:17,915 - INFO -     - accuracy: 0.2000
2025-07-28 08:22:17,916 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 08:22:17,916 - INFO -     - accuracy: 0.4000
2025-07-28 08:22:17,916 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 08:22:17,916 - INFO -     - accuracy: 0.1500
2025-07-28 08:22:17,916 - INFO -   kmmlu_hard_geomatics:
2025-07-28 08:22:17,916 - INFO -     - accuracy: 0.3000
2025-07-28 08:22:17,916 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 08:22:17,916 - INFO -     - accuracy: 0.2000
2025-07-28 08:22:17,916 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 08:22:17,917 - INFO -     - accuracy: 0.4000
2025-07-28 08:22:17,917 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 08:22:17,917 - INFO -     - accuracy: 0.3000
2025-07-28 08:22:17,917 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 08:22:17,917 - INFO -     - accuracy: 0.3500
2025-07-28 08:22:17,917 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 08:22:17,917 - INFO -     - accuracy: 0.1500
2025-07-28 08:22:17,917 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 08:22:17,917 - INFO -     - accuracy: 0.4500
2025-07-28 08:22:17,918 - INFO -   kmmlu_hard_humss:
2025-07-28 08:22:17,918 - INFO -     - accuracy: 0.2091
2025-07-28 08:22:17,918 - INFO -   kmmlu_hard_accounting:
2025-07-28 08:22:17,918 - INFO -     - accuracy: 0.1000
2025-07-28 08:22:17,918 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 08:22:17,918 - INFO -     - accuracy: 0.0500
2025-07-28 08:22:17,918 - INFO -   kmmlu_hard_economics:
2025-07-28 08:22:17,918 - INFO -     - accuracy: 0.3000
2025-07-28 08:22:17,918 - INFO -   kmmlu_hard_education:
2025-07-28 08:22:17,918 - INFO -     - accuracy: 0.2500
2025-07-28 08:22:17,918 - INFO -   kmmlu_hard_korean_history:
2025-07-28 08:22:17,919 - INFO -     - accuracy: 0.1500
2025-07-28 08:22:17,919 - INFO -   kmmlu_hard_law:
2025-07-28 08:22:17,919 - INFO -     - accuracy: 0.1500
2025-07-28 08:22:17,919 - INFO -   kmmlu_hard_management:
2025-07-28 08:22:17,919 - INFO -     - accuracy: 0.2500
2025-07-28 08:22:17,919 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 08:22:17,919 - INFO -     - accuracy: 0.2000
2025-07-28 08:22:17,919 - INFO -   kmmlu_hard_psychology:
2025-07-28 08:22:17,919 - INFO -     - accuracy: 0.5500
2025-07-28 08:22:17,919 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 08:22:17,919 - INFO -     - accuracy: 0.1500
2025-07-28 08:22:17,920 - INFO -   kmmlu_hard_taxation:
2025-07-28 08:22:17,920 - INFO -     - accuracy: 0.1500
2025-07-28 08:22:17,920 - INFO -   kmmlu_hard_other:
2025-07-28 08:22:17,920 - INFO -     - accuracy: 0.3091
2025-07-28 08:22:17,920 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 08:22:17,920 - INFO -     - accuracy: 0.1500
2025-07-28 08:22:17,920 - INFO -   kmmlu_hard_construction:
2025-07-28 08:22:17,920 - INFO -     - accuracy: 0.4500
2025-07-28 08:22:17,921 - INFO -   kmmlu_hard_fashion:
2025-07-28 08:22:17,921 - INFO -     - accuracy: 0.3500
2025-07-28 08:22:17,921 - INFO -   kmmlu_hard_food_processing:
2025-07-28 08:22:17,921 - INFO -     - accuracy: 0.4000
2025-07-28 08:22:17,921 - INFO -   kmmlu_hard_health:
2025-07-28 08:22:17,921 - INFO -     - accuracy: 0.1500
2025-07-28 08:22:17,921 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 08:22:17,921 - INFO -     - accuracy: 0.4500
2025-07-28 08:22:17,921 - INFO -   kmmlu_hard_marketing:
2025-07-28 08:22:17,921 - INFO -     - accuracy: 0.5500
2025-07-28 08:22:17,922 - INFO -   kmmlu_hard_patent:
2025-07-28 08:22:17,922 - INFO -     - accuracy: 0.1000
2025-07-28 08:22:17,922 - INFO -   kmmlu_hard_public_safety:
2025-07-28 08:22:17,922 - INFO -     - accuracy: 0.2000
2025-07-28 08:22:17,922 - INFO -   kmmlu_hard_real_estate:
2025-07-28 08:22:17,922 - INFO -     - accuracy: 0.3000
2025-07-28 08:22:17,922 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 08:22:17,922 - INFO -     - accuracy: 0.3000
2025-07-28 08:22:17,922 - INFO -   kmmlu_hard_stem:
2025-07-28 08:22:17,923 - INFO -     - accuracy: 0.3227
2025-07-28 08:22:17,944 - INFO -   kmmlu_hard_biology:
2025-07-28 08:22:17,944 - INFO -     - accuracy: 0.1500
2025-07-28 08:22:17,945 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 08:22:17,945 - INFO -     - accuracy: 0.2000
2025-07-28 08:22:17,945 - INFO -   kmmlu_hard_chemistry:
2025-07-28 08:22:17,945 - INFO -     - accuracy: 0.2500
2025-07-28 08:22:17,945 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 08:22:17,945 - INFO -     - accuracy: 0.3000
2025-07-28 08:22:17,945 - INFO -   kmmlu_hard_computer_science:
2025-07-28 08:22:17,945 - INFO -     - accuracy: 0.5500
2025-07-28 08:22:17,945 - INFO -   kmmlu_hard_ecology:
2025-07-28 08:22:17,946 - INFO -     - accuracy: 0.2000
2025-07-28 08:22:17,946 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 08:22:17,946 - INFO -     - accuracy: 0.3500
2025-07-28 08:22:17,946 - INFO -   kmmlu_hard_information_technology:
2025-07-28 08:22:17,946 - INFO -     - accuracy: 0.3500
2025-07-28 08:22:17,946 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 08:22:17,946 - INFO -     - accuracy: 0.5000
2025-07-28 08:22:17,946 - INFO -   kmmlu_hard_math:
2025-07-28 08:22:17,946 - INFO -     - accuracy: 0.4000
2025-07-28 08:22:17,947 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 08:22:17,947 - INFO -     - accuracy: 0.3000
2025-07-28 08:22:17,947 - INFO - ============================================================

2025-07-28 08:22:17,983 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 3/10: haerae
2025-07-28 08:22:17,985 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'haerae' will use num_fewshot=0
2025-07-28 08:22:17,985 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 08:22:17,986 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:22:37,211 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 08:22:37,211 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 08:22:37,211 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 08:22:37,212 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 08:22:37,212 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 08:22:54,675 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 08:22:54,677 - INFO - 
============================================================
2025-07-28 08:22:54,678 - INFO - Task 'haerae' Results:
2025-07-28 08:22:54,678 - INFO - ============================================================
2025-07-28 08:22:54,678 - INFO -   haerae:
2025-07-28 08:22:54,678 - INFO -     - accuracy: 0.6800
2025-07-28 08:22:54,678 - INFO -     - accuracy_norm: 0.6800
2025-07-28 08:22:54,678 - INFO -   haerae_general_knowledge:
2025-07-28 08:22:54,678 - INFO -     - accuracy: 0.7000
2025-07-28 08:22:54,678 - INFO -     - accuracy_norm: 0.7000
2025-07-28 08:22:54,679 - INFO -   haerae_history:
2025-07-28 08:22:54,679 - INFO -     - accuracy: 0.5000
2025-07-28 08:22:54,679 - INFO -     - accuracy_norm: 0.5000
2025-07-28 08:22:54,679 - INFO -   haerae_loan_word:
2025-07-28 08:22:54,679 - INFO -     - accuracy: 0.8500
2025-07-28 08:22:54,679 - INFO -     - accuracy_norm: 0.8500
2025-07-28 08:22:54,679 - INFO -   haerae_rare_word:
2025-07-28 08:22:54,679 - INFO -     - accuracy: 0.6500
2025-07-28 08:22:54,679 - INFO -     - accuracy_norm: 0.6500
2025-07-28 08:22:54,679 - INFO -   haerae_standard_nomenclature:
2025-07-28 08:22:54,680 - INFO -     - accuracy: 0.7000
2025-07-28 08:22:54,680 - INFO -     - accuracy_norm: 0.7000
2025-07-28 08:22:54,680 - INFO - ============================================================

2025-07-28 08:22:54,715 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 4/10: kobest
2025-07-28 08:22:54,717 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kobest' will use num_fewshot=0
2025-07-28 08:22:54,717 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 08:22:54,718 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:23:15,964 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 08:23:15,964 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 08:23:15,964 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 08:23:15,965 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 08:23:15,965 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 08:23:26,015 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 08:23:26,017 - INFO - 
============================================================
2025-07-28 08:23:26,018 - INFO - Task 'kobest' Results:
2025-07-28 08:23:26,019 - INFO - ============================================================
2025-07-28 08:23:26,019 - INFO -   kobest:
2025-07-28 08:23:26,019 - INFO -     - accuracy: 0.7500
2025-07-28 08:23:26,019 - INFO -     - accuracy_norm: 0.7000
2025-07-28 08:23:26,019 - INFO -     - f1: 0.7401
2025-07-28 08:23:26,019 - INFO -   kobest_boolq:
2025-07-28 08:23:26,019 - INFO -     - accuracy: 0.7000
2025-07-28 08:23:26,019 - INFO -     - f1: 0.6703
2025-07-28 08:23:26,020 - INFO -   kobest_copa:
2025-07-28 08:23:26,020 - INFO -     - accuracy: 0.8000
2025-07-28 08:23:26,020 - INFO -     - f1: 0.8000
2025-07-28 08:23:26,020 - INFO -   kobest_hellaswag:
2025-07-28 08:23:26,020 - INFO -     - accuracy: 0.5000
2025-07-28 08:23:26,020 - INFO -     - accuracy_norm: 0.7000
2025-07-28 08:23:26,020 - INFO -     - f1: 0.5000
2025-07-28 08:23:26,020 - INFO -   kobest_sentineg:
2025-07-28 08:23:26,020 - INFO -     - accuracy: 0.9500
2025-07-28 08:23:26,020 - INFO -     - f1: 0.9499
2025-07-28 08:23:26,021 - INFO -   kobest_wic:
2025-07-28 08:23:26,021 - INFO -     - accuracy: 0.8000
2025-07-28 08:23:26,021 - INFO -     - f1: 0.7802
2025-07-28 08:23:26,021 - INFO - ============================================================

2025-07-28 08:23:26,057 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 5/10: csatqa
2025-07-28 08:23:26,058 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'csatqa' detected as zero-shot task
2025-07-28 08:23:26,059 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 08:23:26,059 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:23:40,505 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 08:23:40,506 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 08:23:40,506 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 08:23:40,506 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 08:23:40,506 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 08:23:40,506 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 08:24:56,497 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 08:24:56,499 - INFO - 
============================================================
2025-07-28 08:24:56,501 - INFO - Task 'csatqa' Results:
2025-07-28 08:24:56,501 - INFO - ============================================================
2025-07-28 08:24:56,501 - INFO -   csatqa:
2025-07-28 08:24:56,501 - INFO -     - accuracy: 0.4054
2025-07-28 08:24:56,501 - INFO -     - accuracy_norm: 0.4054
2025-07-28 08:24:56,501 - INFO -   csatqa_gr:
2025-07-28 08:24:56,501 - INFO -     - accuracy: 0.2000
2025-07-28 08:24:56,501 - INFO -     - accuracy_norm: 0.2000
2025-07-28 08:24:56,502 - INFO -   csatqa_li:
2025-07-28 08:24:56,502 - INFO -     - accuracy: 0.4500
2025-07-28 08:24:56,502 - INFO -     - accuracy_norm: 0.4500
2025-07-28 08:24:56,502 - INFO -   csatqa_rch:
2025-07-28 08:24:56,502 - INFO -     - accuracy: 0.4500
2025-07-28 08:24:56,502 - INFO -     - accuracy_norm: 0.4500
2025-07-28 08:24:56,502 - INFO -   csatqa_rcs:
2025-07-28 08:24:56,502 - INFO -     - accuracy: 0.5000
2025-07-28 08:24:56,502 - INFO -     - accuracy_norm: 0.5000
2025-07-28 08:24:56,503 - INFO -   csatqa_rcss:
2025-07-28 08:24:56,503 - INFO -     - accuracy: 0.5000
2025-07-28 08:24:56,503 - INFO -     - accuracy_norm: 0.5000
2025-07-28 08:24:56,503 - INFO -   csatqa_wr:
2025-07-28 08:24:56,503 - INFO -     - accuracy: 0.2727
2025-07-28 08:24:56,503 - INFO -     - accuracy_norm: 0.2727
2025-07-28 08:24:56,503 - INFO - ============================================================

2025-07-28 08:24:56,545 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 6/10: kormedmcqa
2025-07-28 08:24:56,547 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 08:24:56,547 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 08:24:56,548 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:25:17,624 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 08:25:17,625 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 08:25:17,625 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 08:25:17,625 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 08:25:25,620 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 08:25:25,622 - INFO - 
============================================================
2025-07-28 08:25:25,622 - INFO - Task 'kormedmcqa' Results:
2025-07-28 08:25:25,623 - INFO - ============================================================
2025-07-28 08:25:25,623 - INFO -   kormedmcqa:
2025-07-28 08:25:25,623 - INFO -     - exact_match: 0.5750
2025-07-28 08:25:25,623 - INFO -   kormedmcqa_dentist:
2025-07-28 08:25:25,624 - INFO -     - exact_match: 0.4500
2025-07-28 08:25:25,624 - INFO -   kormedmcqa_doctor:
2025-07-28 08:25:25,624 - INFO -     - exact_match: 0.3500
2025-07-28 08:25:25,624 - INFO -   kormedmcqa_nurse:
2025-07-28 08:25:25,624 - INFO -     - exact_match: 0.7000
2025-07-28 08:25:25,624 - INFO -   kormedmcqa_pharm:
2025-07-28 08:25:25,624 - INFO -     - exact_match: 0.8000
2025-07-28 08:25:25,625 - INFO - ============================================================

2025-07-28 08:25:25,660 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 7/10: mmlu
2025-07-28 08:25:25,662 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'mmlu' will use num_fewshot=0
2025-07-28 08:25:25,662 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 08:25:25,662 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:28:15,674 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 08:28:15,674 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 08:28:15,675 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 08:28:15,675 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 08:28:15,675 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 08:28:15,675 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 08:28:15,675 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 08:28:15,675 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 08:28:15,675 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 08:28:15,675 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 08:28:15,675 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 08:28:15,676 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 08:28:15,676 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 08:28:15,676 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 08:28:15,676 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 08:28:15,676 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 08:28:15,676 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 08:28:15,676 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 08:28:15,676 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 08:28:15,676 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 08:28:15,677 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 08:28:15,678 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 08:28:15,678 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 08:28:15,678 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 08:28:15,678 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 08:28:15,678 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 08:28:15,678 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 08:28:15,678 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 08:28:15,678 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 08:28:15,678 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 08:28:15,678 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 08:28:15,679 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 08:28:15,680 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 08:28:15,680 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 08:28:15,680 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 08:28:15,680 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 08:28:15,680 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 08:28:56,046 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 08:28:56,047 - INFO - 
============================================================
2025-07-28 08:28:56,048 - INFO - Task 'mmlu' Results:
2025-07-28 08:28:56,048 - INFO - ============================================================
2025-07-28 08:28:56,048 - INFO -   mmlu:
2025-07-28 08:28:56,048 - INFO -     - accuracy: 0.6640
2025-07-28 08:28:56,048 - INFO -   mmlu_humanities:
2025-07-28 08:28:56,048 - INFO -     - accuracy: 0.7385
2025-07-28 08:28:56,048 - INFO -   mmlu_formal_logic:
2025-07-28 08:28:56,049 - INFO -     - accuracy: 0.5500
2025-07-28 08:28:56,049 - INFO -   mmlu_high_school_european_history:
2025-07-28 08:28:56,049 - INFO -     - accuracy: 0.7000
2025-07-28 08:28:56,049 - INFO -   mmlu_high_school_us_history:
2025-07-28 08:28:56,049 - INFO -     - accuracy: 0.8500
2025-07-28 08:28:56,049 - INFO -   mmlu_high_school_world_history:
2025-07-28 08:28:56,049 - INFO -     - accuracy: 0.9000
2025-07-28 08:28:56,049 - INFO -   mmlu_international_law:
2025-07-28 08:28:56,049 - INFO -     - accuracy: 0.8000
2025-07-28 08:28:56,050 - INFO -   mmlu_jurisprudence:
2025-07-28 08:28:56,050 - INFO -     - accuracy: 0.7500
2025-07-28 08:28:56,072 - INFO -   mmlu_logical_fallacies:
2025-07-28 08:28:56,073 - INFO -     - accuracy: 0.9000
2025-07-28 08:28:56,073 - INFO -   mmlu_moral_disputes:
2025-07-28 08:28:56,073 - INFO -     - accuracy: 0.6000
2025-07-28 08:28:56,073 - INFO -   mmlu_moral_scenarios:
2025-07-28 08:28:56,073 - INFO -     - accuracy: 0.3500
2025-07-28 08:28:56,073 - INFO -   mmlu_philosophy:
2025-07-28 08:28:56,073 - INFO -     - accuracy: 0.8500
2025-07-28 08:28:56,073 - INFO -   mmlu_prehistory:
2025-07-28 08:28:56,074 - INFO -     - accuracy: 0.8000
2025-07-28 08:28:56,074 - INFO -   mmlu_professional_law:
2025-07-28 08:28:56,074 - INFO -     - accuracy: 0.7000
2025-07-28 08:28:56,074 - INFO -   mmlu_world_religions:
2025-07-28 08:28:56,074 - INFO -     - accuracy: 0.8500
2025-07-28 08:28:56,074 - INFO -   mmlu_other:
2025-07-28 08:28:56,074 - INFO -     - accuracy: 0.7000
2025-07-28 08:28:56,074 - INFO -   mmlu_business_ethics:
2025-07-28 08:28:56,075 - INFO -     - accuracy: 0.8000
2025-07-28 08:28:56,075 - INFO -   mmlu_clinical_knowledge:
2025-07-28 08:28:56,075 - INFO -     - accuracy: 0.7500
2025-07-28 08:28:56,075 - INFO -   mmlu_college_medicine:
2025-07-28 08:28:56,075 - INFO -     - accuracy: 0.6500
2025-07-28 08:28:56,075 - INFO -   mmlu_global_facts:
2025-07-28 08:28:56,075 - INFO -     - accuracy: 0.4500
2025-07-28 08:28:56,075 - INFO -   mmlu_human_aging:
2025-07-28 08:28:56,075 - INFO -     - accuracy: 0.6000
2025-07-28 08:28:56,076 - INFO -   mmlu_management:
2025-07-28 08:28:56,076 - INFO -     - accuracy: 0.8500
2025-07-28 08:28:56,076 - INFO -   mmlu_marketing:
2025-07-28 08:28:56,076 - INFO -     - accuracy: 0.8000
2025-07-28 08:28:56,076 - INFO -   mmlu_medical_genetics:
2025-07-28 08:28:56,076 - INFO -     - accuracy: 0.8500
2025-07-28 08:28:56,076 - INFO -   mmlu_miscellaneous:
2025-07-28 08:28:56,076 - INFO -     - accuracy: 0.8000
2025-07-28 08:28:56,076 - INFO -   mmlu_nutrition:
2025-07-28 08:28:56,076 - INFO -     - accuracy: 0.7500
2025-07-28 08:28:56,077 - INFO -   mmlu_professional_accounting:
2025-07-28 08:28:56,077 - INFO -     - accuracy: 0.4500
2025-07-28 08:28:56,077 - INFO -   mmlu_professional_medicine:
2025-07-28 08:28:56,077 - INFO -     - accuracy: 0.7500
2025-07-28 08:28:56,077 - INFO -   mmlu_virology:
2025-07-28 08:28:56,077 - INFO -     - accuracy: 0.6000
2025-07-28 08:28:56,077 - INFO -   mmlu_social_sciences:
2025-07-28 08:28:56,077 - INFO -     - accuracy: 0.7542
2025-07-28 08:28:56,077 - INFO -   mmlu_econometrics:
2025-07-28 08:28:56,078 - INFO -     - accuracy: 0.6000
2025-07-28 08:28:56,078 - INFO -   mmlu_high_school_geography:
2025-07-28 08:28:56,078 - INFO -     - accuracy: 0.8500
2025-07-28 08:28:56,078 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 08:28:56,078 - INFO -     - accuracy: 0.9500
2025-07-28 08:28:56,078 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 08:28:56,078 - INFO -     - accuracy: 0.5500
2025-07-28 08:28:56,078 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 08:28:56,078 - INFO -     - accuracy: 0.6500
2025-07-28 08:28:56,079 - INFO -   mmlu_high_school_psychology:
2025-07-28 08:28:56,079 - INFO -     - accuracy: 0.9000
2025-07-28 08:28:56,079 - INFO -   mmlu_human_sexuality:
2025-07-28 08:28:56,079 - INFO -     - accuracy: 0.7500
2025-07-28 08:28:56,079 - INFO -   mmlu_professional_psychology:
2025-07-28 08:28:56,079 - INFO -     - accuracy: 0.8000
2025-07-28 08:28:56,079 - INFO -   mmlu_public_relations:
2025-07-28 08:28:56,079 - INFO -     - accuracy: 0.6000
2025-07-28 08:28:56,079 - INFO -   mmlu_security_studies:
2025-07-28 08:28:56,080 - INFO -     - accuracy: 0.7000
2025-07-28 08:28:56,080 - INFO -   mmlu_sociology:
2025-07-28 08:28:56,080 - INFO -     - accuracy: 0.8000
2025-07-28 08:28:56,080 - INFO -   mmlu_us_foreign_policy:
2025-07-28 08:28:56,080 - INFO -     - accuracy: 0.9000
2025-07-28 08:28:56,080 - INFO -   mmlu_stem:
2025-07-28 08:28:56,080 - INFO -     - accuracy: 0.5316
2025-07-28 08:28:56,080 - INFO -   mmlu_abstract_algebra:
2025-07-28 08:28:56,080 - INFO -     - accuracy: 0.2000
2025-07-28 08:28:56,081 - INFO -   mmlu_anatomy:
2025-07-28 08:28:56,081 - INFO -     - accuracy: 0.6500
2025-07-28 08:28:56,081 - INFO -   mmlu_astronomy:
2025-07-28 08:28:56,081 - INFO -     - accuracy: 0.9000
2025-07-28 08:28:56,081 - INFO -   mmlu_college_biology:
2025-07-28 08:28:56,081 - INFO -     - accuracy: 0.8000
2025-07-28 08:28:56,081 - INFO -   mmlu_college_chemistry:
2025-07-28 08:28:56,081 - INFO -     - accuracy: 0.3000
2025-07-28 08:28:56,081 - INFO -   mmlu_college_computer_science:
2025-07-28 08:28:56,081 - INFO -     - accuracy: 0.2500
2025-07-28 08:28:56,081 - INFO -   mmlu_college_mathematics:
2025-07-28 08:28:56,081 - INFO -     - accuracy: 0.3000
2025-07-28 08:28:56,082 - INFO -   mmlu_college_physics:
2025-07-28 08:28:56,082 - INFO -     - accuracy: 0.3500
2025-07-28 08:28:56,082 - INFO -   mmlu_computer_security:
2025-07-28 08:28:56,082 - INFO -     - accuracy: 0.7500
2025-07-28 08:28:56,082 - INFO -   mmlu_conceptual_physics:
2025-07-28 08:28:56,082 - INFO -     - accuracy: 0.6000
2025-07-28 08:28:56,082 - INFO -   mmlu_electrical_engineering:
2025-07-28 08:28:56,082 - INFO -     - accuracy: 0.6500
2025-07-28 08:28:56,082 - INFO -   mmlu_elementary_mathematics:
2025-07-28 08:28:56,082 - INFO -     - accuracy: 0.2000
2025-07-28 08:28:56,083 - INFO -   mmlu_high_school_biology:
2025-07-28 08:28:56,083 - INFO -     - accuracy: 0.8500
2025-07-28 08:28:56,083 - INFO -   mmlu_high_school_chemistry:
2025-07-28 08:28:56,083 - INFO -     - accuracy: 0.6000
2025-07-28 08:28:56,083 - INFO -   mmlu_high_school_computer_science:
2025-07-28 08:28:56,083 - INFO -     - accuracy: 0.8500
2025-07-28 08:28:56,083 - INFO -   mmlu_high_school_mathematics:
2025-07-28 08:28:56,083 - INFO -     - accuracy: 0.3500
2025-07-28 08:28:56,083 - INFO -   mmlu_high_school_physics:
2025-07-28 08:28:56,084 - INFO -     - accuracy: 0.3500
2025-07-28 08:28:56,084 - INFO -   mmlu_high_school_statistics:
2025-07-28 08:28:56,084 - INFO -     - accuracy: 0.6000
2025-07-28 08:28:56,084 - INFO -   mmlu_machine_learning:
2025-07-28 08:28:56,084 - INFO -     - accuracy: 0.5500
2025-07-28 08:28:56,084 - INFO - ============================================================

2025-07-28 08:28:56,122 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 8/10: arc_challenge
2025-07-28 08:28:56,124 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 08:28:56,124 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 08:28:56,124 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:29:07,449 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 08:29:12,633 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 08:29:12,635 - INFO - 
============================================================
2025-07-28 08:29:12,636 - INFO - Task 'arc_challenge' Results:
2025-07-28 08:29:12,636 - INFO - ============================================================
2025-07-28 08:29:12,636 - INFO -   arc_challenge:
2025-07-28 08:29:12,636 - INFO -     - accuracy: 0.5500
2025-07-28 08:29:12,636 - INFO -     - accuracy_norm: 0.6000
2025-07-28 08:29:12,637 - INFO - ============================================================

2025-07-28 08:29:12,673 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 9/10: arc_easy
2025-07-28 08:29:12,673 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'arc_easy' will use num_fewshot=0
2025-07-28 08:29:12,674 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 08:29:12,675 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:29:22,531 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 08:29:27,610 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 08:29:27,612 - INFO - 
============================================================
2025-07-28 08:29:27,612 - INFO - Task 'arc_easy' Results:
2025-07-28 08:29:27,612 - INFO - ============================================================
2025-07-28 08:29:27,613 - INFO -   arc_easy:
2025-07-28 08:29:27,613 - INFO -     - accuracy: 0.8000
2025-07-28 08:29:27,613 - INFO -     - accuracy_norm: 0.7000
2025-07-28 08:29:27,613 - INFO - ============================================================

2025-07-28 08:29:27,649 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 10/10: hellaswag
2025-07-28 08:29:27,650 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'hellaswag' will use num_fewshot=0
2025-07-28 08:29:27,651 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 08:29:27,651 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:29:44,148 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 08:29:49,626 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 08:29:49,628 - INFO - 
============================================================
2025-07-28 08:29:49,629 - INFO - Task 'hellaswag' Results:
2025-07-28 08:29:49,630 - INFO - ============================================================
2025-07-28 08:29:49,630 - INFO -   hellaswag:
2025-07-28 08:29:49,630 - INFO -     - accuracy: 0.4500
2025-07-28 08:29:49,630 - INFO -     - accuracy_norm: 0.6000
2025-07-28 08:29:49,630 - INFO - ============================================================

2025-07-28 08:29:49,667 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 08:29:49,670 - INFO - [Process 1865749] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_073925/model_results/Llama-DNA-1.0-8B-Instruct/Llama-DNA-1.0-8B-Instruct_harness_6.json
2025-07-28 08:29:49,671 - INFO - [Process 1865749] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Llama-DNA-1.0-8B-Instruct/Llama-DNA-1.0-8B-Instruct_harness_6.json
2025-07-28 08:29:50,021 - INFO - Results uploaded to WandB as artifact
2025-07-28 08:29:50,030 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 08:29:50,032 - INFO - [Process 1865749] Successfully completed Llama-DNA-1.0-8B-Instruct_harness_6
2025-07-28 08:29:53,470 - INFO - Run Llama-DNA-1.0-8B-Instruct_harness_6 finished successfully
2025-07-28 08:29:53,470 - INFO - Processing 6 small models in parallel
2025-07-28 08:29:58,403 - INFO - [Process 1881867] gemma-3-4b-it_harness_2 assigned to cuda:0
2025-07-28 08:29:58,403 - INFO - [Process 1881867] gemma-3-4b-it_harness_2 - using custom limit: 20
2025-07-28 08:30:00,104 - INFO - WandB run initialized: gemma-3-4b-it_20250728_082958 (ID: 03c308d0)
2025-07-28 08:30:01,799 - INFO - gemma-3-4b-it_harness_2: Gemma settings applied - max_gen_toks=256
2025-07-28 08:30:01,799 - INFO - gemma-3-4b-it_harness_2: Test mode (limit=2), setting num_fewshot=0
2025-07-28 08:30:01,799 - INFO - gemma-3-4b-it_harness_2: Gemma model detected, adjusting settings
2025-07-28 08:30:01,800 - INFO - gemma-3-4b-it_harness_2: Processing task 1/10: kmmlu
2025-07-28 08:30:01,800 - INFO - gemma-3-4b-it_harness_2: Task 'kmmlu' will use num_fewshot=0
2025-07-28 08:30:01,800 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 08:30:01,801 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:31:17,814 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 08:31:17,814 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 08:31:17,814 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 08:31:17,814 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 08:31:17,814 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 08:31:17,815 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 08:31:17,815 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 08:31:17,815 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 08:31:17,815 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 08:31:17,815 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 08:31:17,815 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 08:31:17,815 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 08:31:17,815 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 08:31:17,815 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 08:31:17,815 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 08:31:17,816 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 08:31:17,816 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 08:31:17,816 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 08:31:17,816 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 08:31:17,816 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 08:31:17,816 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 08:31:17,816 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 08:31:17,816 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 08:31:17,816 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 08:31:17,816 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 08:31:17,817 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 08:31:17,817 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 08:31:17,817 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 08:31:17,817 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 08:31:17,817 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 08:31:17,817 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 08:31:17,817 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 08:31:17,817 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 08:31:17,817 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 08:31:17,817 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 08:31:17,818 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 08:31:17,818 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 08:31:17,818 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 08:31:17,818 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 08:31:17,818 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 08:31:17,818 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 08:31:17,818 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 08:31:17,818 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 08:31:17,818 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 08:31:17,818 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 08:32:28,925 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 08:32:28,927 - INFO - 
============================================================
2025-07-28 08:32:28,928 - INFO - Task 'kmmlu' Results:
2025-07-28 08:32:28,929 - INFO - ============================================================
2025-07-28 08:32:28,930 - INFO -   kmmlu:
2025-07-28 08:32:28,930 - INFO -     - accuracy: 0.3056
2025-07-28 08:32:28,931 - INFO -   kmmlu_applied_science:
2025-07-28 08:32:28,931 - INFO -     - accuracy: 0.2167
2025-07-28 08:32:28,931 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 08:32:28,931 - INFO -     - accuracy: 0.2000
2025-07-28 08:32:28,931 - INFO -   kmmlu_electronics_engineering:
2025-07-28 08:32:28,931 - INFO -     - accuracy: 0.2500
2025-07-28 08:32:28,932 - INFO -   kmmlu_energy_management:
2025-07-28 08:32:28,932 - INFO -     - accuracy: 0.1000
2025-07-28 08:32:28,932 - INFO -   kmmlu_environmental_science:
2025-07-28 08:32:28,932 - INFO -     - accuracy: 0.2000
2025-07-28 08:32:28,932 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 08:32:28,932 - INFO -     - accuracy: 0.1000
2025-07-28 08:32:28,932 - INFO -   kmmlu_geomatics:
2025-07-28 08:32:28,932 - INFO -     - accuracy: 0.1000
2025-07-28 08:32:28,932 - INFO -   kmmlu_industrial_engineer:
2025-07-28 08:32:28,932 - INFO -     - accuracy: 0.2500
2025-07-28 08:32:28,932 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 08:32:28,933 - INFO -     - accuracy: 0.3000
2025-07-28 08:32:28,933 - INFO -   kmmlu_maritime_engineering:
2025-07-28 08:32:28,933 - INFO -     - accuracy: 0.3000
2025-07-28 08:32:28,933 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 08:32:28,933 - INFO -     - accuracy: 0.1500
2025-07-28 08:32:28,933 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 08:32:28,933 - INFO -     - accuracy: 0.2500
2025-07-28 08:32:28,933 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 08:32:28,933 - INFO -     - accuracy: 0.4000
2025-07-28 08:32:28,933 - INFO -   kmmlu_humss:
2025-07-28 08:32:28,933 - INFO -     - accuracy: 0.3409
2025-07-28 08:32:28,934 - INFO -   kmmlu_accounting:
2025-07-28 08:32:28,934 - INFO -     - accuracy: 0.2500
2025-07-28 08:32:28,934 - INFO -   kmmlu_criminal_law:
2025-07-28 08:32:28,934 - INFO -     - accuracy: 0.3000
2025-07-28 08:32:28,934 - INFO -   kmmlu_economics:
2025-07-28 08:32:28,934 - INFO -     - accuracy: 0.5500
2025-07-28 08:32:28,934 - INFO -   kmmlu_education:
2025-07-28 08:32:28,934 - INFO -     - accuracy: 0.4500
2025-07-28 08:32:28,934 - INFO -   kmmlu_korean_history:
2025-07-28 08:32:28,934 - INFO -     - accuracy: 0.2000
2025-07-28 08:32:28,935 - INFO -   kmmlu_law:
2025-07-28 08:32:28,935 - INFO -     - accuracy: 0.2500
2025-07-28 08:32:28,935 - INFO -   kmmlu_management:
2025-07-28 08:32:28,935 - INFO -     - accuracy: 0.5500
2025-07-28 08:32:28,935 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 08:32:28,935 - INFO -     - accuracy: 0.5000
2025-07-28 08:32:28,935 - INFO -   kmmlu_psychology:
2025-07-28 08:32:28,935 - INFO -     - accuracy: 0.1000
2025-07-28 08:32:28,935 - INFO -   kmmlu_social_welfare:
2025-07-28 08:32:28,935 - INFO -     - accuracy: 0.3000
2025-07-28 08:32:28,936 - INFO -   kmmlu_taxation:
2025-07-28 08:32:28,936 - INFO -     - accuracy: 0.3000
2025-07-28 08:32:28,936 - INFO -   kmmlu_other:
2025-07-28 08:32:28,936 - INFO -     - accuracy: 0.3636
2025-07-28 08:32:28,936 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 08:32:28,943 - INFO -     - accuracy: 0.3500
2025-07-28 08:32:28,943 - INFO -   kmmlu_construction:
2025-07-28 08:32:28,943 - INFO -     - accuracy: 0.4000
2025-07-28 08:32:28,943 - INFO -   kmmlu_fashion:
2025-07-28 08:32:28,943 - INFO -     - accuracy: 0.1500
2025-07-28 08:32:28,944 - INFO -   kmmlu_food_processing:
2025-07-28 08:32:28,944 - INFO -     - accuracy: 0.4000
2025-07-28 08:32:28,944 - INFO -   kmmlu_health:
2025-07-28 08:32:28,944 - INFO -     - accuracy: 0.7500
2025-07-28 08:32:28,944 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 08:32:28,944 - INFO -     - accuracy: 0.5000
2025-07-28 08:32:28,944 - INFO -   kmmlu_marketing:
2025-07-28 08:32:28,944 - INFO -     - accuracy: 0.4500
2025-07-28 08:32:28,944 - INFO -   kmmlu_patent:
2025-07-28 08:32:28,945 - INFO -     - accuracy: 0.2500
2025-07-28 08:32:28,945 - INFO -   kmmlu_public_safety:
2025-07-28 08:32:28,945 - INFO -     - accuracy: 0.2500
2025-07-28 08:32:28,945 - INFO -   kmmlu_real_estate:
2025-07-28 08:32:28,945 - INFO -     - accuracy: 0.3500
2025-07-28 08:32:28,945 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 08:32:28,945 - INFO -     - accuracy: 0.1500
2025-07-28 08:32:28,945 - INFO -   kmmlu_stem:
2025-07-28 08:32:28,945 - INFO -     - accuracy: 0.3091
2025-07-28 08:32:28,946 - INFO -   kmmlu_biology:
2025-07-28 08:32:28,946 - INFO -     - accuracy: 0.4500
2025-07-28 08:32:28,946 - INFO -   kmmlu_chemical_engineering:
2025-07-28 08:32:28,946 - INFO -     - accuracy: 0.1500
2025-07-28 08:32:28,946 - INFO -   kmmlu_chemistry:
2025-07-28 08:32:28,946 - INFO -     - accuracy: 0.2500
2025-07-28 08:32:28,946 - INFO -   kmmlu_civil_engineering:
2025-07-28 08:32:28,946 - INFO -     - accuracy: 0.2000
2025-07-28 08:32:28,946 - INFO -   kmmlu_computer_science:
2025-07-28 08:32:28,946 - INFO -     - accuracy: 0.5000
2025-07-28 08:32:28,947 - INFO -   kmmlu_ecology:
2025-07-28 08:32:28,948 - INFO -     - accuracy: 0.4500
2025-07-28 08:32:28,948 - INFO -   kmmlu_electrical_engineering:
2025-07-28 08:32:28,948 - INFO -     - accuracy: 0.1500
2025-07-28 08:32:28,948 - INFO -   kmmlu_information_technology:
2025-07-28 08:32:28,948 - INFO -     - accuracy: 0.3000
2025-07-28 08:32:28,949 - INFO -   kmmlu_materials_engineering:
2025-07-28 08:32:28,949 - INFO -     - accuracy: 0.4500
2025-07-28 08:32:28,949 - INFO -   kmmlu_math:
2025-07-28 08:32:28,949 - INFO -     - accuracy: 0.2500
2025-07-28 08:32:28,949 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 08:32:28,949 - INFO -     - accuracy: 0.2500
2025-07-28 08:32:28,949 - INFO - ============================================================

2025-07-28 08:32:28,972 - INFO - gemma-3-4b-it_harness_2: Processing task 2/10: kmmlu_hard
2025-07-28 08:32:28,973 - INFO - gemma-3-4b-it_harness_2: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 08:32:28,973 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 08:32:28,974 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:33:41,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 08:33:41,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 08:33:41,362 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 08:33:41,363 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 08:33:41,364 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 08:33:41,365 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 08:33:41,366 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 08:33:41,366 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 08:33:41,366 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 08:33:41,366 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 08:33:41,366 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 08:33:41,366 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 08:33:41,366 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 08:33:41,366 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 08:34:53,715 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 08:34:53,716 - INFO - 
============================================================
2025-07-28 08:34:53,717 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 08:34:53,718 - INFO - ============================================================
2025-07-28 08:34:53,719 - INFO -   kmmlu_hard:
2025-07-28 08:34:53,719 - INFO -     - accuracy: 0.2078
2025-07-28 08:34:53,720 - INFO -   kmmlu_hard_applied_science:
2025-07-28 08:34:53,720 - INFO -     - accuracy: 0.2250
2025-07-28 08:34:53,720 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 08:34:53,720 - INFO -     - accuracy: 0.0500
2025-07-28 08:34:53,720 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 08:34:53,720 - INFO -     - accuracy: 0.2500
2025-07-28 08:34:53,720 - INFO -   kmmlu_hard_energy_management:
2025-07-28 08:34:53,720 - INFO -     - accuracy: 0.3000
2025-07-28 08:34:53,720 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 08:34:53,720 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,721 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 08:34:53,721 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,721 - INFO -   kmmlu_hard_geomatics:
2025-07-28 08:34:53,721 - INFO -     - accuracy: 0.3000
2025-07-28 08:34:53,721 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 08:34:53,721 - INFO -     - accuracy: 0.3000
2025-07-28 08:34:53,721 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 08:34:53,721 - INFO -     - accuracy: 0.3500
2025-07-28 08:34:53,721 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 08:34:53,721 - INFO -     - accuracy: 0.1000
2025-07-28 08:34:53,722 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 08:34:53,722 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,722 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 08:34:53,722 - INFO -     - accuracy: 0.2500
2025-07-28 08:34:53,722 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 08:34:53,722 - INFO -     - accuracy: 0.2500
2025-07-28 08:34:53,722 - INFO -   kmmlu_hard_humss:
2025-07-28 08:34:53,722 - INFO -     - accuracy: 0.1818
2025-07-28 08:34:53,722 - INFO -   kmmlu_hard_accounting:
2025-07-28 08:34:53,722 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,722 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 08:34:53,723 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,723 - INFO -   kmmlu_hard_economics:
2025-07-28 08:34:53,723 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,723 - INFO -   kmmlu_hard_education:
2025-07-28 08:34:53,723 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,745 - INFO -   kmmlu_hard_korean_history:
2025-07-28 08:34:53,745 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,745 - INFO -   kmmlu_hard_law:
2025-07-28 08:34:53,745 - INFO -     - accuracy: 0.0000
2025-07-28 08:34:53,745 - INFO -   kmmlu_hard_management:
2025-07-28 08:34:53,745 - INFO -     - accuracy: 0.2500
2025-07-28 08:34:53,745 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 08:34:53,745 - INFO -     - accuracy: 0.4000
2025-07-28 08:34:53,746 - INFO -   kmmlu_hard_psychology:
2025-07-28 08:34:53,746 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,746 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 08:34:53,746 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,746 - INFO -   kmmlu_hard_taxation:
2025-07-28 08:34:53,746 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,746 - INFO -   kmmlu_hard_other:
2025-07-28 08:34:53,746 - INFO -     - accuracy: 0.2273
2025-07-28 08:34:53,746 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 08:34:53,746 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,747 - INFO -   kmmlu_hard_construction:
2025-07-28 08:34:53,747 - INFO -     - accuracy: 0.2500
2025-07-28 08:34:53,747 - INFO -   kmmlu_hard_fashion:
2025-07-28 08:34:53,747 - INFO -     - accuracy: 0.4000
2025-07-28 08:34:53,747 - INFO -   kmmlu_hard_food_processing:
2025-07-28 08:34:53,747 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,747 - INFO -   kmmlu_hard_health:
2025-07-28 08:34:53,747 - INFO -     - accuracy: 0.2500
2025-07-28 08:34:53,747 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 08:34:53,747 - INFO -     - accuracy: 0.4000
2025-07-28 08:34:53,747 - INFO -   kmmlu_hard_marketing:
2025-07-28 08:34:53,748 - INFO -     - accuracy: 0.2500
2025-07-28 08:34:53,748 - INFO -   kmmlu_hard_patent:
2025-07-28 08:34:53,748 - INFO -     - accuracy: 0.1000
2025-07-28 08:34:53,748 - INFO -   kmmlu_hard_public_safety:
2025-07-28 08:34:53,748 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,748 - INFO -   kmmlu_hard_real_estate:
2025-07-28 08:34:53,748 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,748 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 08:34:53,748 - INFO -     - accuracy: 0.1000
2025-07-28 08:34:53,748 - INFO -   kmmlu_hard_stem:
2025-07-28 08:34:53,748 - INFO -     - accuracy: 0.1955
2025-07-28 08:34:53,749 - INFO -   kmmlu_hard_biology:
2025-07-28 08:34:53,749 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,749 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 08:34:53,749 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,749 - INFO -   kmmlu_hard_chemistry:
2025-07-28 08:34:53,749 - INFO -     - accuracy: 0.3000
2025-07-28 08:34:53,749 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 08:34:53,749 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,749 - INFO -   kmmlu_hard_computer_science:
2025-07-28 08:34:53,749 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,749 - INFO -   kmmlu_hard_ecology:
2025-07-28 08:34:53,750 - INFO -     - accuracy: 0.0500
2025-07-28 08:34:53,750 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 08:34:53,750 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,750 - INFO -   kmmlu_hard_information_technology:
2025-07-28 08:34:53,750 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,750 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 08:34:53,750 - INFO -     - accuracy: 0.4000
2025-07-28 08:34:53,750 - INFO -   kmmlu_hard_math:
2025-07-28 08:34:53,750 - INFO -     - accuracy: 0.2000
2025-07-28 08:34:53,750 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 08:34:53,750 - INFO -     - accuracy: 0.1500
2025-07-28 08:34:53,751 - INFO - ============================================================

2025-07-28 08:34:53,774 - INFO - gemma-3-4b-it_harness_2: Processing task 3/10: haerae
2025-07-28 08:34:53,776 - INFO - gemma-3-4b-it_harness_2: Task 'haerae' will use num_fewshot=0
2025-07-28 08:34:53,776 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 08:34:53,776 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:35:14,584 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 08:35:14,585 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 08:35:14,585 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 08:35:14,585 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 08:35:14,585 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 08:35:53,256 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 08:35:53,258 - INFO - 
============================================================
2025-07-28 08:35:53,259 - INFO - Task 'haerae' Results:
2025-07-28 08:35:53,260 - INFO - ============================================================
2025-07-28 08:35:53,260 - INFO -   haerae:
2025-07-28 08:35:53,260 - INFO -     - accuracy: 0.5800
2025-07-28 08:35:53,260 - INFO -     - accuracy_norm: 0.5800
2025-07-28 08:35:53,261 - INFO -   haerae_general_knowledge:
2025-07-28 08:35:53,261 - INFO -     - accuracy: 0.7000
2025-07-28 08:35:53,261 - INFO -     - accuracy_norm: 0.7000
2025-07-28 08:35:53,261 - INFO -   haerae_history:
2025-07-28 08:35:53,261 - INFO -     - accuracy: 0.6000
2025-07-28 08:35:53,261 - INFO -     - accuracy_norm: 0.6000
2025-07-28 08:35:53,261 - INFO -   haerae_loan_word:
2025-07-28 08:35:53,261 - INFO -     - accuracy: 0.4000
2025-07-28 08:35:53,261 - INFO -     - accuracy_norm: 0.4000
2025-07-28 08:35:53,261 - INFO -   haerae_rare_word:
2025-07-28 08:35:53,262 - INFO -     - accuracy: 0.6000
2025-07-28 08:35:53,262 - INFO -     - accuracy_norm: 0.6000
2025-07-28 08:35:53,262 - INFO -   haerae_standard_nomenclature:
2025-07-28 08:35:53,262 - INFO -     - accuracy: 0.6000
2025-07-28 08:35:53,262 - INFO -     - accuracy_norm: 0.6000
2025-07-28 08:35:53,262 - INFO - ============================================================

2025-07-28 08:35:53,285 - INFO - gemma-3-4b-it_harness_2: Processing task 4/10: kobest
2025-07-28 08:35:53,287 - INFO - gemma-3-4b-it_harness_2: Task 'kobest' will use num_fewshot=0
2025-07-28 08:35:53,287 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 08:35:53,287 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:36:17,084 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 08:36:17,084 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 08:36:17,084 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 08:36:17,084 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 08:36:17,085 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 08:36:36,905 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 08:36:36,907 - INFO - 
============================================================
2025-07-28 08:36:36,908 - INFO - Task 'kobest' Results:
2025-07-28 08:36:36,909 - INFO - ============================================================
2025-07-28 08:36:36,910 - INFO -   kobest:
2025-07-28 08:36:36,910 - INFO -     - accuracy: 0.6500
2025-07-28 08:36:36,910 - INFO -     - accuracy_norm: 0.6000
2025-07-28 08:36:36,910 - INFO -     - f1: 0.5707
2025-07-28 08:36:36,910 - INFO -   kobest_boolq:
2025-07-28 08:36:36,911 - INFO -     - accuracy: 0.9000
2025-07-28 08:36:36,911 - INFO -     - f1: 0.8990
2025-07-28 08:36:36,911 - INFO -   kobest_copa:
2025-07-28 08:36:36,911 - INFO -     - accuracy: 0.8500
2025-07-28 08:36:36,911 - INFO -     - f1: 0.8496
2025-07-28 08:36:36,911 - INFO -   kobest_hellaswag:
2025-07-28 08:36:36,911 - INFO -     - accuracy: 0.4000
2025-07-28 08:36:36,911 - INFO -     - accuracy_norm: 0.6000
2025-07-28 08:36:36,911 - INFO -     - f1: 0.3951
2025-07-28 08:36:36,911 - INFO -   kobest_sentineg:
2025-07-28 08:36:36,912 - INFO -     - accuracy: 0.5500
2025-07-28 08:36:36,912 - INFO -     - f1: 0.3548
2025-07-28 08:36:36,912 - INFO -   kobest_wic:
2025-07-28 08:36:36,912 - INFO -     - accuracy: 0.5500
2025-07-28 08:36:36,912 - INFO -     - f1: 0.3548
2025-07-28 08:36:36,912 - INFO - ============================================================

2025-07-28 08:36:36,936 - INFO - gemma-3-4b-it_harness_2: Processing task 5/10: csatqa
2025-07-28 08:36:36,937 - INFO - gemma-3-4b-it_harness_2: Task 'csatqa' detected as zero-shot task
2025-07-28 08:36:36,937 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 08:36:36,938 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:36:53,424 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 08:36:53,424 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 08:36:53,424 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 08:36:53,424 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 08:36:53,425 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 08:36:53,425 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 08:38:03,328 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 08:38:03,330 - INFO - 
============================================================
2025-07-28 08:38:03,331 - INFO - Task 'csatqa' Results:
2025-07-28 08:38:03,332 - INFO - ============================================================
2025-07-28 08:38:03,334 - INFO -   csatqa:
2025-07-28 08:38:03,334 - INFO -     - accuracy: 0.3063
2025-07-28 08:38:03,334 - INFO -     - accuracy_norm: 0.3063
2025-07-28 08:38:03,334 - INFO -   csatqa_gr:
2025-07-28 08:38:03,334 - INFO -     - accuracy: 0.1500
2025-07-28 08:38:03,334 - INFO -     - accuracy_norm: 0.1500
2025-07-28 08:38:03,334 - INFO -   csatqa_li:
2025-07-28 08:38:03,334 - INFO -     - accuracy: 0.4500
2025-07-28 08:38:03,334 - INFO -     - accuracy_norm: 0.4500
2025-07-28 08:38:03,335 - INFO -   csatqa_rch:
2025-07-28 08:38:03,335 - INFO -     - accuracy: 0.2500
2025-07-28 08:38:03,335 - INFO -     - accuracy_norm: 0.2500
2025-07-28 08:38:03,335 - INFO -   csatqa_rcs:
2025-07-28 08:38:03,335 - INFO -     - accuracy: 0.3000
2025-07-28 08:38:03,335 - INFO -     - accuracy_norm: 0.3000
2025-07-28 08:38:03,335 - INFO -   csatqa_rcss:
2025-07-28 08:38:03,335 - INFO -     - accuracy: 0.4000
2025-07-28 08:38:03,335 - INFO -     - accuracy_norm: 0.4000
2025-07-28 08:38:03,335 - INFO -   csatqa_wr:
2025-07-28 08:38:03,335 - INFO -     - accuracy: 0.2727
2025-07-28 08:38:03,335 - INFO -     - accuracy_norm: 0.2727
2025-07-28 08:38:03,336 - INFO - ============================================================

2025-07-28 08:38:03,371 - INFO - gemma-3-4b-it_harness_2: Processing task 6/10: kormedmcqa
2025-07-28 08:38:03,373 - INFO - gemma-3-4b-it_harness_2: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 08:38:03,373 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 08:38:03,373 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:38:25,683 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 08:38:25,684 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 08:38:25,684 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 08:38:25,684 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 08:40:30,009 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 08:40:30,011 - INFO - 
============================================================
2025-07-28 08:40:30,012 - INFO - Task 'kormedmcqa' Results:
2025-07-28 08:40:30,013 - INFO - ============================================================
2025-07-28 08:40:30,014 - INFO -   kormedmcqa:
2025-07-28 08:40:30,014 - INFO -     - exact_match: 0.2250
2025-07-28 08:40:30,014 - INFO -   kormedmcqa_dentist:
2025-07-28 08:40:30,014 - INFO -     - exact_match: 0.0500
2025-07-28 08:40:30,014 - INFO -   kormedmcqa_doctor:
2025-07-28 08:40:30,015 - INFO -     - exact_match: 0.2000
2025-07-28 08:40:30,015 - INFO -   kormedmcqa_nurse:
2025-07-28 08:40:30,015 - INFO -     - exact_match: 0.4000
2025-07-28 08:40:30,015 - INFO -   kormedmcqa_pharm:
2025-07-28 08:40:30,015 - INFO -     - exact_match: 0.2500
2025-07-28 08:40:30,015 - INFO - ============================================================

2025-07-28 08:40:30,039 - INFO - gemma-3-4b-it_harness_2: Processing task 7/10: mmlu
2025-07-28 08:40:30,041 - INFO - gemma-3-4b-it_harness_2: Task 'mmlu' will use num_fewshot=0
2025-07-28 08:40:30,041 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 08:40:30,042 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:43:30,433 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 08:43:30,434 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 08:43:30,434 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 08:43:30,434 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 08:43:30,434 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 08:43:30,434 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 08:43:30,434 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 08:43:30,434 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 08:43:30,434 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 08:43:30,434 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 08:43:30,434 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 08:43:30,435 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 08:43:30,436 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 08:43:30,437 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 08:43:30,438 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 08:43:30,439 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 08:43:30,439 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 08:44:55,958 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 08:44:55,960 - INFO - 
============================================================
2025-07-28 08:44:55,961 - INFO - Task 'mmlu' Results:
2025-07-28 08:44:55,962 - INFO - ============================================================
2025-07-28 08:44:55,964 - INFO -   mmlu:
2025-07-28 08:44:55,965 - INFO -     - accuracy: 0.6070
2025-07-28 08:44:55,965 - INFO -   mmlu_humanities:
2025-07-28 08:44:55,965 - INFO -     - accuracy: 0.6308
2025-07-28 08:44:55,966 - INFO -   mmlu_formal_logic:
2025-07-28 08:44:55,966 - INFO -     - accuracy: 0.3000
2025-07-28 08:44:55,966 - INFO -   mmlu_high_school_european_history:
2025-07-28 08:44:55,966 - INFO -     - accuracy: 0.7500
2025-07-28 08:44:55,966 - INFO -   mmlu_high_school_us_history:
2025-07-28 08:44:55,966 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,966 - INFO -   mmlu_high_school_world_history:
2025-07-28 08:44:55,966 - INFO -     - accuracy: 0.8500
2025-07-28 08:44:55,967 - INFO -   mmlu_international_law:
2025-07-28 08:44:55,967 - INFO -     - accuracy: 0.8000
2025-07-28 08:44:55,967 - INFO -   mmlu_jurisprudence:
2025-07-28 08:44:55,967 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,967 - INFO -   mmlu_logical_fallacies:
2025-07-28 08:44:55,967 - INFO -     - accuracy: 0.7500
2025-07-28 08:44:55,967 - INFO -   mmlu_moral_disputes:
2025-07-28 08:44:55,967 - INFO -     - accuracy: 0.6500
2025-07-28 08:44:55,967 - INFO -   mmlu_moral_scenarios:
2025-07-28 08:44:55,967 - INFO -     - accuracy: 0.3000
2025-07-28 08:44:55,968 - INFO -   mmlu_philosophy:
2025-07-28 08:44:55,968 - INFO -     - accuracy: 0.6500
2025-07-28 08:44:55,968 - INFO -   mmlu_prehistory:
2025-07-28 08:44:55,968 - INFO -     - accuracy: 0.4500
2025-07-28 08:44:55,968 - INFO -   mmlu_professional_law:
2025-07-28 08:44:55,968 - INFO -     - accuracy: 0.4500
2025-07-28 08:44:55,968 - INFO -   mmlu_world_religions:
2025-07-28 08:44:55,968 - INFO -     - accuracy: 0.8500
2025-07-28 08:44:55,968 - INFO -   mmlu_other:
2025-07-28 08:44:55,968 - INFO -     - accuracy: 0.6269
2025-07-28 08:44:55,969 - INFO -   mmlu_business_ethics:
2025-07-28 08:44:55,969 - INFO -     - accuracy: 0.7500
2025-07-28 08:44:55,969 - INFO -   mmlu_clinical_knowledge:
2025-07-28 08:44:55,969 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,969 - INFO -   mmlu_college_medicine:
2025-07-28 08:44:55,969 - INFO -     - accuracy: 0.5500
2025-07-28 08:44:55,969 - INFO -   mmlu_global_facts:
2025-07-28 08:44:55,969 - INFO -     - accuracy: 0.3500
2025-07-28 08:44:55,969 - INFO -   mmlu_human_aging:
2025-07-28 08:44:55,970 - INFO -     - accuracy: 0.7500
2025-07-28 08:44:55,970 - INFO -   mmlu_management:
2025-07-28 08:44:55,970 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,970 - INFO -   mmlu_marketing:
2025-07-28 08:44:55,970 - INFO -     - accuracy: 0.7500
2025-07-28 08:44:55,970 - INFO -   mmlu_medical_genetics:
2025-07-28 08:44:55,970 - INFO -     - accuracy: 0.8000
2025-07-28 08:44:55,970 - INFO -   mmlu_miscellaneous:
2025-07-28 08:44:55,970 - INFO -     - accuracy: 0.7500
2025-07-28 08:44:55,971 - INFO -   mmlu_nutrition:
2025-07-28 08:44:55,971 - INFO -     - accuracy: 0.6500
2025-07-28 08:44:55,971 - INFO -   mmlu_professional_accounting:
2025-07-28 08:44:55,971 - INFO -     - accuracy: 0.3500
2025-07-28 08:44:55,971 - INFO -   mmlu_professional_medicine:
2025-07-28 08:44:55,971 - INFO -     - accuracy: 0.4500
2025-07-28 08:44:55,971 - INFO -   mmlu_virology:
2025-07-28 08:44:55,971 - INFO -     - accuracy: 0.6000
2025-07-28 08:44:55,971 - INFO -   mmlu_social_sciences:
2025-07-28 08:44:55,972 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,972 - INFO -   mmlu_econometrics:
2025-07-28 08:44:55,972 - INFO -     - accuracy: 0.5000
2025-07-28 08:44:55,972 - INFO -   mmlu_high_school_geography:
2025-07-28 08:44:55,972 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,972 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 08:44:55,972 - INFO -     - accuracy: 0.8500
2025-07-28 08:44:55,972 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 08:44:55,972 - INFO -     - accuracy: 0.5000
2025-07-28 08:44:55,973 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 08:44:55,973 - INFO -     - accuracy: 0.5000
2025-07-28 08:44:55,973 - INFO -   mmlu_high_school_psychology:
2025-07-28 08:44:55,973 - INFO -     - accuracy: 0.9000
2025-07-28 08:44:55,973 - INFO -   mmlu_human_sexuality:
2025-07-28 08:44:55,973 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,973 - INFO -   mmlu_professional_psychology:
2025-07-28 08:44:55,973 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,974 - INFO -   mmlu_public_relations:
2025-07-28 08:44:55,974 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,974 - INFO -   mmlu_security_studies:
2025-07-28 08:44:55,974 - INFO -     - accuracy: 0.8000
2025-07-28 08:44:55,974 - INFO -   mmlu_sociology:
2025-07-28 08:44:55,974 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,974 - INFO -   mmlu_us_foreign_policy:
2025-07-28 08:44:55,974 - INFO -     - accuracy: 0.8500
2025-07-28 08:44:55,974 - INFO -   mmlu_stem:
2025-07-28 08:44:55,975 - INFO -     - accuracy: 0.5184
2025-07-28 08:44:55,975 - INFO -   mmlu_abstract_algebra:
2025-07-28 08:44:55,975 - INFO -     - accuracy: 0.3500
2025-07-28 08:44:55,975 - INFO -   mmlu_anatomy:
2025-07-28 08:44:55,975 - INFO -     - accuracy: 0.6000
2025-07-28 08:44:55,975 - INFO -   mmlu_astronomy:
2025-07-28 08:44:55,975 - INFO -     - accuracy: 0.7500
2025-07-28 08:44:55,975 - INFO -   mmlu_college_biology:
2025-07-28 08:44:55,975 - INFO -     - accuracy: 0.7500
2025-07-28 08:44:55,976 - INFO -   mmlu_college_chemistry:
2025-07-28 08:44:55,976 - INFO -     - accuracy: 0.3500
2025-07-28 08:44:55,976 - INFO -   mmlu_college_computer_science:
2025-07-28 08:44:55,976 - INFO -     - accuracy: 0.3500
2025-07-28 08:44:55,976 - INFO -   mmlu_college_mathematics:
2025-07-28 08:44:55,976 - INFO -     - accuracy: 0.4000
2025-07-28 08:44:55,976 - INFO -   mmlu_college_physics:
2025-07-28 08:44:55,976 - INFO -     - accuracy: 0.4500
2025-07-28 08:44:55,976 - INFO -   mmlu_computer_security:
2025-07-28 08:44:55,977 - INFO -     - accuracy: 0.6500
2025-07-28 08:44:55,977 - INFO -   mmlu_conceptual_physics:
2025-07-28 08:44:55,977 - INFO -     - accuracy: 0.6500
2025-07-28 08:44:55,977 - INFO -   mmlu_electrical_engineering:
2025-07-28 08:44:55,977 - INFO -     - accuracy: 0.4000
2025-07-28 08:44:55,977 - INFO -   mmlu_elementary_mathematics:
2025-07-28 08:44:55,977 - INFO -     - accuracy: 0.4500
2025-07-28 08:44:55,977 - INFO -   mmlu_high_school_biology:
2025-07-28 08:44:55,977 - INFO -     - accuracy: 0.7000
2025-07-28 08:44:55,978 - INFO -   mmlu_high_school_chemistry:
2025-07-28 08:44:55,978 - INFO -     - accuracy: 0.5500
2025-07-28 08:44:55,978 - INFO -   mmlu_high_school_computer_science:
2025-07-28 08:44:55,978 - INFO -     - accuracy: 0.8500
2025-07-28 08:44:55,978 - INFO -   mmlu_high_school_mathematics:
2025-07-28 08:44:55,978 - INFO -     - accuracy: 0.3500
2025-07-28 08:44:55,978 - INFO -   mmlu_high_school_physics:
2025-07-28 08:44:55,978 - INFO -     - accuracy: 0.3000
2025-07-28 08:44:55,978 - INFO -   mmlu_high_school_statistics:
2025-07-28 08:44:55,979 - INFO -     - accuracy: 0.4500
2025-07-28 08:44:55,979 - INFO -   mmlu_machine_learning:
2025-07-28 08:44:55,979 - INFO -     - accuracy: 0.5000
2025-07-28 08:44:55,979 - INFO - ============================================================

2025-07-28 08:44:56,003 - INFO - gemma-3-4b-it_harness_2: Processing task 8/10: arc_challenge
2025-07-28 08:44:56,005 - INFO - gemma-3-4b-it_harness_2: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 08:44:56,005 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 08:44:56,006 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:45:07,859 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 08:45:20,078 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 08:45:20,080 - INFO - 
============================================================
2025-07-28 08:45:20,081 - INFO - Task 'arc_challenge' Results:
2025-07-28 08:45:20,083 - INFO - ============================================================
2025-07-28 08:45:20,083 - INFO -   arc_challenge:
2025-07-28 08:45:20,083 - INFO -     - accuracy: 0.5500
2025-07-28 08:45:20,083 - INFO -     - accuracy_norm: 0.5500
2025-07-28 08:45:20,083 - INFO - ============================================================

2025-07-28 08:45:20,106 - INFO - gemma-3-4b-it_harness_2: Processing task 9/10: arc_easy
2025-07-28 08:45:20,108 - INFO - gemma-3-4b-it_harness_2: Task 'arc_easy' will use num_fewshot=0
2025-07-28 08:45:20,108 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 08:45:20,109 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:45:30,403 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 08:45:37,586 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 08:45:37,587 - INFO - 
============================================================
2025-07-28 08:45:37,589 - INFO - Task 'arc_easy' Results:
2025-07-28 08:45:37,590 - INFO - ============================================================
2025-07-28 08:45:37,590 - INFO -   arc_easy:
2025-07-28 08:45:37,590 - INFO -     - accuracy: 0.8000
2025-07-28 08:45:37,591 - INFO -     - accuracy_norm: 0.6500
2025-07-28 08:45:37,591 - INFO - ============================================================

2025-07-28 08:45:37,614 - INFO - gemma-3-4b-it_harness_2: Processing task 10/10: hellaswag
2025-07-28 08:45:37,615 - INFO - gemma-3-4b-it_harness_2: Task 'hellaswag' will use num_fewshot=0
2025-07-28 08:45:37,615 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 08:45:37,616 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:45:55,764 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 08:46:04,807 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 08:46:04,810 - INFO - 
============================================================
2025-07-28 08:46:04,812 - INFO - Task 'hellaswag' Results:
2025-07-28 08:46:04,813 - INFO - ============================================================
2025-07-28 08:46:04,814 - INFO -   hellaswag:
2025-07-28 08:46:04,816 - INFO -     - accuracy: 0.5000
2025-07-28 08:46:04,816 - INFO -     - accuracy_norm: 0.7000
2025-07-28 08:46:04,816 - INFO - ============================================================

2025-07-28 08:46:04,840 - INFO - gemma-3-4b-it_harness_2: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 08:46:04,845 - INFO - [Process 1881867] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/gemma-3-4b-it/gemma-3-4b-it_harness_2.json
2025-07-28 08:46:05,136 - INFO - Results uploaded to WandB as artifact
2025-07-28 08:46:05,146 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 08:46:05,147 - INFO - [Process 1881867] Successfully completed gemma-3-4b-it_harness_2
2025-07-28 08:46:08,183 - INFO - Run gemma-3-4b-it_harness_2 finished successfully
2025-07-28 08:46:08,183 - INFO - [Process 1881867] EXAONE-3.5-2.4B-Instruct_harness_7 assigned to cuda:0
2025-07-28 08:46:08,184 - INFO - [Process 1881867] EXAONE-3.5-2.4B-Instruct_harness_7 - using custom limit: 20
2025-07-28 08:46:09,436 - INFO - WandB run initialized: EXAONE-3.5-2.4B-Instruct_20250728_084608 (ID: 9dadbb1c)
2025-07-28 08:46:09,649 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Test mode (limit=2), setting num_fewshot=0
2025-07-28 08:46:09,649 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 1/10: kmmlu
2025-07-28 08:46:09,650 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kmmlu' will use num_fewshot=0
2025-07-28 08:46:09,650 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 08:46:09,650 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:47:21,633 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 08:47:21,633 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 08:47:21,633 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 08:47:21,634 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 08:47:21,635 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 08:47:21,636 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 08:47:21,637 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 08:47:21,637 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 08:47:21,637 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 08:47:21,637 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 08:47:21,637 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 08:47:21,637 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 08:47:21,637 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 08:47:21,637 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 08:47:24,152 - WARNING - We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
2025-07-28 08:48:08,585 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 08:48:08,586 - INFO - 
============================================================
2025-07-28 08:48:08,588 - INFO - Task 'kmmlu' Results:
2025-07-28 08:48:08,589 - INFO - ============================================================
2025-07-28 08:48:08,589 - INFO -   kmmlu:
2025-07-28 08:48:08,590 - INFO -     - accuracy: 0.3756
2025-07-28 08:48:08,590 - INFO -   kmmlu_applied_science:
2025-07-28 08:48:08,590 - INFO -     - accuracy: 0.3500
2025-07-28 08:48:08,590 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 08:48:08,591 - INFO -     - accuracy: 0.2500
2025-07-28 08:48:08,591 - INFO -   kmmlu_electronics_engineering:
2025-07-28 08:48:08,591 - INFO -     - accuracy: 0.3500
2025-07-28 08:48:08,591 - INFO -   kmmlu_energy_management:
2025-07-28 08:48:08,591 - INFO -     - accuracy: 0.1500
2025-07-28 08:48:08,592 - INFO -   kmmlu_environmental_science:
2025-07-28 08:48:08,592 - INFO -     - accuracy: 0.2500
2025-07-28 08:48:08,592 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 08:48:08,592 - INFO -     - accuracy: 0.6000
2025-07-28 08:48:08,592 - INFO -   kmmlu_geomatics:
2025-07-28 08:48:08,592 - INFO -     - accuracy: 0.4000
2025-07-28 08:48:08,592 - INFO -   kmmlu_industrial_engineer:
2025-07-28 08:48:08,593 - INFO -     - accuracy: 0.3500
2025-07-28 08:48:08,593 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 08:48:08,593 - INFO -     - accuracy: 0.3500
2025-07-28 08:48:08,593 - INFO -   kmmlu_maritime_engineering:
2025-07-28 08:48:08,593 - INFO -     - accuracy: 0.4000
2025-07-28 08:48:08,593 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 08:48:08,593 - INFO -     - accuracy: 0.3000
2025-07-28 08:48:08,594 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 08:48:08,594 - INFO -     - accuracy: 0.5500
2025-07-28 08:48:08,594 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 08:48:08,594 - INFO -     - accuracy: 0.2500
2025-07-28 08:48:08,594 - INFO -   kmmlu_humss:
2025-07-28 08:48:08,594 - INFO -     - accuracy: 0.3909
2025-07-28 08:48:08,594 - INFO -   kmmlu_accounting:
2025-07-28 08:48:08,594 - INFO -     - accuracy: 0.5000
2025-07-28 08:48:08,594 - INFO -   kmmlu_criminal_law:
2025-07-28 08:48:08,595 - INFO -     - accuracy: 0.3000
2025-07-28 08:48:08,595 - INFO -   kmmlu_economics:
2025-07-28 08:48:08,595 - INFO -     - accuracy: 0.6000
2025-07-28 08:48:08,595 - INFO -   kmmlu_education:
2025-07-28 08:48:08,595 - INFO -     - accuracy: 0.4500
2025-07-28 08:48:08,595 - INFO -   kmmlu_korean_history:
2025-07-28 08:48:08,595 - INFO -     - accuracy: 0.2000
2025-07-28 08:48:08,595 - INFO -   kmmlu_law:
2025-07-28 08:48:08,596 - INFO -     - accuracy: 0.3500
2025-07-28 08:48:08,596 - INFO -   kmmlu_management:
2025-07-28 08:48:08,596 - INFO -     - accuracy: 0.4500
2025-07-28 08:48:08,596 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 08:48:08,596 - INFO -     - accuracy: 0.6000
2025-07-28 08:48:08,596 - INFO -   kmmlu_psychology:
2025-07-28 08:48:08,596 - INFO -     - accuracy: 0.2000
2025-07-28 08:48:08,597 - INFO -   kmmlu_social_welfare:
2025-07-28 08:48:08,597 - INFO -     - accuracy: 0.5000
2025-07-28 08:48:08,597 - INFO -   kmmlu_taxation:
2025-07-28 08:48:08,597 - INFO -     - accuracy: 0.1500
2025-07-28 08:48:08,597 - INFO -   kmmlu_other:
2025-07-28 08:48:08,597 - INFO -     - accuracy: 0.3727
2025-07-28 08:48:08,598 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 08:48:08,598 - INFO -     - accuracy: 0.4000
2025-07-28 08:48:08,598 - INFO -   kmmlu_construction:
2025-07-28 08:48:08,598 - INFO -     - accuracy: 0.3500
2025-07-28 08:48:08,598 - INFO -   kmmlu_fashion:
2025-07-28 08:48:08,598 - INFO -     - accuracy: 0.2500
2025-07-28 08:48:08,599 - INFO -   kmmlu_food_processing:
2025-07-28 08:48:08,599 - INFO -     - accuracy: 0.2500
2025-07-28 08:48:08,599 - INFO -   kmmlu_health:
2025-07-28 08:48:08,599 - INFO -     - accuracy: 0.5500
2025-07-28 08:48:08,599 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 08:48:08,599 - INFO -     - accuracy: 0.5500
2025-07-28 08:48:08,599 - INFO -   kmmlu_marketing:
2025-07-28 08:48:08,600 - INFO -     - accuracy: 0.5000
2025-07-28 08:48:08,600 - INFO -   kmmlu_patent:
2025-07-28 08:48:08,600 - INFO -     - accuracy: 0.3500
2025-07-28 08:48:08,630 - INFO -   kmmlu_public_safety:
2025-07-28 08:48:08,630 - INFO -     - accuracy: 0.3000
2025-07-28 08:48:08,631 - INFO -   kmmlu_real_estate:
2025-07-28 08:48:08,631 - INFO -     - accuracy: 0.3500
2025-07-28 08:48:08,631 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 08:48:08,631 - INFO -     - accuracy: 0.2500
2025-07-28 08:48:08,631 - INFO -   kmmlu_stem:
2025-07-28 08:48:08,631 - INFO -     - accuracy: 0.3909
2025-07-28 08:48:08,631 - INFO -   kmmlu_biology:
2025-07-28 08:48:08,631 - INFO -     - accuracy: 0.3500
2025-07-28 08:48:08,632 - INFO -   kmmlu_chemical_engineering:
2025-07-28 08:48:08,632 - INFO -     - accuracy: 0.4000
2025-07-28 08:48:08,632 - INFO -   kmmlu_chemistry:
2025-07-28 08:48:08,632 - INFO -     - accuracy: 0.4500
2025-07-28 08:48:08,632 - INFO -   kmmlu_civil_engineering:
2025-07-28 08:48:08,632 - INFO -     - accuracy: 0.5000
2025-07-28 08:48:08,632 - INFO -   kmmlu_computer_science:
2025-07-28 08:48:08,632 - INFO -     - accuracy: 0.6500
2025-07-28 08:48:08,633 - INFO -   kmmlu_ecology:
2025-07-28 08:48:08,633 - INFO -     - accuracy: 0.3500
2025-07-28 08:48:08,633 - INFO -   kmmlu_electrical_engineering:
2025-07-28 08:48:08,633 - INFO -     - accuracy: 0.3000
2025-07-28 08:48:08,633 - INFO -   kmmlu_information_technology:
2025-07-28 08:48:08,633 - INFO -     - accuracy: 0.5000
2025-07-28 08:48:08,633 - INFO -   kmmlu_materials_engineering:
2025-07-28 08:48:08,633 - INFO -     - accuracy: 0.2500
2025-07-28 08:48:08,633 - INFO -   kmmlu_math:
2025-07-28 08:48:08,634 - INFO -     - accuracy: 0.2500
2025-07-28 08:48:08,634 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 08:48:08,634 - INFO -     - accuracy: 0.3000
2025-07-28 08:48:08,634 - INFO - ============================================================

2025-07-28 08:48:08,658 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 2/10: kmmlu_hard
2025-07-28 08:48:08,659 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 08:48:08,660 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 08:48:08,660 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:49:24,405 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 08:49:24,405 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 08:49:24,406 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 08:49:24,406 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 08:49:24,406 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 08:49:24,406 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 08:49:24,406 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 08:49:24,406 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 08:49:24,406 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 08:49:24,406 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 08:49:24,406 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 08:49:24,407 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 08:49:24,408 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 08:49:24,409 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 08:50:11,836 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 08:50:11,837 - INFO - 
============================================================
2025-07-28 08:50:11,838 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 08:50:11,839 - INFO - ============================================================
2025-07-28 08:50:11,840 - INFO -   kmmlu_hard:
2025-07-28 08:50:11,840 - INFO -     - accuracy: 0.2300
2025-07-28 08:50:11,840 - INFO -   kmmlu_hard_applied_science:
2025-07-28 08:50:11,840 - INFO -     - accuracy: 0.2625
2025-07-28 08:50:11,841 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 08:50:11,841 - INFO -     - accuracy: 0.3000
2025-07-28 08:50:11,841 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 08:50:11,841 - INFO -     - accuracy: 0.2500
2025-07-28 08:50:11,841 - INFO -   kmmlu_hard_energy_management:
2025-07-28 08:50:11,841 - INFO -     - accuracy: 0.2000
2025-07-28 08:50:11,841 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 08:50:11,841 - INFO -     - accuracy: 0.3500
2025-07-28 08:50:11,842 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 08:50:11,842 - INFO -     - accuracy: 0.3000
2025-07-28 08:50:11,842 - INFO -   kmmlu_hard_geomatics:
2025-07-28 08:50:11,842 - INFO -     - accuracy: 0.3000
2025-07-28 08:50:11,842 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 08:50:11,842 - INFO -     - accuracy: 0.2500
2025-07-28 08:50:11,842 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 08:50:11,842 - INFO -     - accuracy: 0.2500
2025-07-28 08:50:11,842 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 08:50:11,843 - INFO -     - accuracy: 0.2000
2025-07-28 08:50:11,843 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 08:50:11,843 - INFO -     - accuracy: 0.1500
2025-07-28 08:50:11,843 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 08:50:11,843 - INFO -     - accuracy: 0.1500
2025-07-28 08:50:11,843 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 08:50:11,843 - INFO -     - accuracy: 0.4500
2025-07-28 08:50:11,843 - INFO -   kmmlu_hard_humss:
2025-07-28 08:50:11,843 - INFO -     - accuracy: 0.1636
2025-07-28 08:50:11,844 - INFO -   kmmlu_hard_accounting:
2025-07-28 08:50:11,844 - INFO -     - accuracy: 0.1500
2025-07-28 08:50:11,844 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 08:50:11,844 - INFO -     - accuracy: 0.1500
2025-07-28 08:50:11,844 - INFO -   kmmlu_hard_economics:
2025-07-28 08:50:11,844 - INFO -     - accuracy: 0.3000
2025-07-28 08:50:11,844 - INFO -   kmmlu_hard_education:
2025-07-28 08:50:11,844 - INFO -     - accuracy: 0.2500
2025-07-28 08:50:11,844 - INFO -   kmmlu_hard_korean_history:
2025-07-28 08:50:11,844 - INFO -     - accuracy: 0.1500
2025-07-28 08:50:11,844 - INFO -   kmmlu_hard_law:
2025-07-28 08:50:11,845 - INFO -     - accuracy: 0.1000
2025-07-28 08:50:11,845 - INFO -   kmmlu_hard_management:
2025-07-28 08:50:11,845 - INFO -     - accuracy: 0.1000
2025-07-28 08:50:11,845 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 08:50:11,845 - INFO -     - accuracy: 0.0500
2025-07-28 08:50:11,845 - INFO -   kmmlu_hard_psychology:
2025-07-28 08:50:11,845 - INFO -     - accuracy: 0.1000
2025-07-28 08:50:11,845 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 08:50:11,845 - INFO -     - accuracy: 0.2500
2025-07-28 08:50:11,846 - INFO -   kmmlu_hard_taxation:
2025-07-28 08:50:11,846 - INFO -     - accuracy: 0.2000
2025-07-28 08:50:11,846 - INFO -   kmmlu_hard_other:
2025-07-28 08:50:11,846 - INFO -     - accuracy: 0.2636
2025-07-28 08:50:11,846 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 08:50:11,846 - INFO -     - accuracy: 0.3000
2025-07-28 08:50:11,846 - INFO -   kmmlu_hard_construction:
2025-07-28 08:50:11,846 - INFO -     - accuracy: 0.3000
2025-07-28 08:50:11,846 - INFO -   kmmlu_hard_fashion:
2025-07-28 08:50:11,847 - INFO -     - accuracy: 0.3000
2025-07-28 08:50:11,847 - INFO -   kmmlu_hard_food_processing:
2025-07-28 08:50:11,847 - INFO -     - accuracy: 0.2500
2025-07-28 08:50:11,847 - INFO -   kmmlu_hard_health:
2025-07-28 08:50:11,847 - INFO -     - accuracy: 0.2000
2025-07-28 08:50:11,847 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 08:50:11,847 - INFO -     - accuracy: 0.3500
2025-07-28 08:50:11,847 - INFO -   kmmlu_hard_marketing:
2025-07-28 08:50:11,847 - INFO -     - accuracy: 0.3500
2025-07-28 08:50:11,848 - INFO -   kmmlu_hard_patent:
2025-07-28 08:50:11,848 - INFO -     - accuracy: 0.2000
2025-07-28 08:50:11,848 - INFO -   kmmlu_hard_public_safety:
2025-07-28 08:50:11,848 - INFO -     - accuracy: 0.1000
2025-07-28 08:50:11,848 - INFO -   kmmlu_hard_real_estate:
2025-07-28 08:50:11,848 - INFO -     - accuracy: 0.3000
2025-07-28 08:50:11,848 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 08:50:11,848 - INFO -     - accuracy: 0.2500
2025-07-28 08:50:11,848 - INFO -   kmmlu_hard_stem:
2025-07-28 08:50:11,849 - INFO -     - accuracy: 0.2273
2025-07-28 08:50:11,849 - INFO -   kmmlu_hard_biology:
2025-07-28 08:50:11,849 - INFO -     - accuracy: 0.0500
2025-07-28 08:50:11,849 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 08:50:11,849 - INFO -     - accuracy: 0.1000
2025-07-28 08:50:11,849 - INFO -   kmmlu_hard_chemistry:
2025-07-28 08:50:11,849 - INFO -     - accuracy: 0.2000
2025-07-28 08:50:11,849 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 08:50:11,849 - INFO -     - accuracy: 0.1000
2025-07-28 08:50:11,850 - INFO -   kmmlu_hard_computer_science:
2025-07-28 08:50:11,850 - INFO -     - accuracy: 0.4500
2025-07-28 08:50:11,850 - INFO -   kmmlu_hard_ecology:
2025-07-28 08:50:11,850 - INFO -     - accuracy: 0.3000
2025-07-28 08:50:11,850 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 08:50:11,850 - INFO -     - accuracy: 0.3500
2025-07-28 08:50:11,850 - INFO -   kmmlu_hard_information_technology:
2025-07-28 08:50:11,850 - INFO -     - accuracy: 0.3000
2025-07-28 08:50:11,851 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 08:50:11,851 - INFO -     - accuracy: 0.3500
2025-07-28 08:50:11,851 - INFO -   kmmlu_hard_math:
2025-07-28 08:50:11,851 - INFO -     - accuracy: 0.0500
2025-07-28 08:50:11,851 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 08:50:11,851 - INFO -     - accuracy: 0.2500
2025-07-28 08:50:11,851 - INFO - ============================================================

2025-07-28 08:50:11,876 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 3/10: haerae
2025-07-28 08:50:11,877 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'haerae' will use num_fewshot=0
2025-07-28 08:50:11,877 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 08:50:11,877 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:50:29,808 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 08:50:29,808 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 08:50:29,808 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 08:50:29,808 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 08:50:29,808 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 08:50:53,994 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 08:50:53,996 - INFO - 
============================================================
2025-07-28 08:50:53,997 - INFO - Task 'haerae' Results:
2025-07-28 08:50:53,998 - INFO - ============================================================
2025-07-28 08:50:53,999 - INFO -   haerae:
2025-07-28 08:50:53,999 - INFO -     - accuracy: 0.7400
2025-07-28 08:50:53,999 - INFO -     - accuracy_norm: 0.7400
2025-07-28 08:50:53,999 - INFO -   haerae_general_knowledge:
2025-07-28 08:50:54,000 - INFO -     - accuracy: 0.7500
2025-07-28 08:50:54,000 - INFO -     - accuracy_norm: 0.7500
2025-07-28 08:50:54,000 - INFO -   haerae_history:
2025-07-28 08:50:54,000 - INFO -     - accuracy: 0.8000
2025-07-28 08:50:54,000 - INFO -     - accuracy_norm: 0.8000
2025-07-28 08:50:54,000 - INFO -   haerae_loan_word:
2025-07-28 08:50:54,000 - INFO -     - accuracy: 0.9000
2025-07-28 08:50:54,000 - INFO -     - accuracy_norm: 0.9000
2025-07-28 08:50:54,000 - INFO -   haerae_rare_word:
2025-07-28 08:50:54,001 - INFO -     - accuracy: 0.5000
2025-07-28 08:50:54,001 - INFO -     - accuracy_norm: 0.5000
2025-07-28 08:50:54,001 - INFO -   haerae_standard_nomenclature:
2025-07-28 08:50:54,001 - INFO -     - accuracy: 0.7500
2025-07-28 08:50:54,001 - INFO -     - accuracy_norm: 0.7500
2025-07-28 08:50:54,001 - INFO - ============================================================

2025-07-28 08:50:54,025 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 4/10: kobest
2025-07-28 08:50:54,026 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kobest' will use num_fewshot=0
2025-07-28 08:50:54,026 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 08:50:54,027 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:51:14,545 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 08:51:14,546 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 08:51:14,547 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 08:51:14,547 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 08:51:14,547 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 08:51:25,454 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 08:51:25,456 - INFO - 
============================================================
2025-07-28 08:51:25,457 - INFO - Task 'kobest' Results:
2025-07-28 08:51:25,458 - INFO - ============================================================
2025-07-28 08:51:25,458 - INFO -   kobest:
2025-07-28 08:51:25,459 - INFO -     - accuracy: 0.6900
2025-07-28 08:51:25,459 - INFO -     - accuracy_norm: 0.6500
2025-07-28 08:51:25,459 - INFO -     - f1: 0.6724
2025-07-28 08:51:25,460 - INFO -   kobest_boolq:
2025-07-28 08:51:25,460 - INFO -     - accuracy: 0.8000
2025-07-28 08:51:25,460 - INFO -     - f1: 0.7917
2025-07-28 08:51:25,460 - INFO -   kobest_copa:
2025-07-28 08:51:25,460 - INFO -     - accuracy: 0.7000
2025-07-28 08:51:25,460 - INFO -     - f1: 0.6970
2025-07-28 08:51:25,460 - INFO -   kobest_hellaswag:
2025-07-28 08:51:25,460 - INFO -     - accuracy: 0.4500
2025-07-28 08:51:25,460 - INFO -     - accuracy_norm: 0.6500
2025-07-28 08:51:25,461 - INFO -     - f1: 0.4495
2025-07-28 08:51:25,461 - INFO -   kobest_sentineg:
2025-07-28 08:51:25,461 - INFO -     - accuracy: 0.9000
2025-07-28 08:51:25,461 - INFO -     - f1: 0.9000
2025-07-28 08:51:25,461 - INFO -   kobest_wic:
2025-07-28 08:51:25,461 - INFO -     - accuracy: 0.6000
2025-07-28 08:51:25,461 - INFO -     - f1: 0.5238
2025-07-28 08:51:25,461 - INFO - ============================================================

2025-07-28 08:51:25,486 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 5/10: csatqa
2025-07-28 08:51:25,487 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'csatqa' detected as zero-shot task
2025-07-28 08:51:25,487 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 08:51:25,487 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:51:37,293 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 08:51:37,293 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 08:51:37,294 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 08:51:37,294 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 08:51:37,294 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 08:51:37,294 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 08:55:07,989 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 08:55:07,992 - INFO - 
============================================================
2025-07-28 08:55:07,993 - INFO - Task 'csatqa' Results:
2025-07-28 08:55:07,993 - INFO - ============================================================
2025-07-28 08:55:07,995 - INFO -   csatqa:
2025-07-28 08:55:07,995 - INFO -     - accuracy: 0.3153
2025-07-28 08:55:07,995 - INFO -     - accuracy_norm: 0.3153
2025-07-28 08:55:07,995 - INFO -   csatqa_gr:
2025-07-28 08:55:07,995 - INFO -     - accuracy: 0.0500
2025-07-28 08:55:07,995 - INFO -     - accuracy_norm: 0.0500
2025-07-28 08:55:07,995 - INFO -   csatqa_li:
2025-07-28 08:55:07,997 - INFO -     - accuracy: 0.4000
2025-07-28 08:55:07,997 - INFO -     - accuracy_norm: 0.4000
2025-07-28 08:55:07,997 - INFO -   csatqa_rch:
2025-07-28 08:55:07,997 - INFO -     - accuracy: 0.4500
2025-07-28 08:55:07,998 - INFO -     - accuracy_norm: 0.4500
2025-07-28 08:55:07,998 - INFO -   csatqa_rcs:
2025-07-28 08:55:07,998 - INFO -     - accuracy: 0.3000
2025-07-28 08:55:07,998 - INFO -     - accuracy_norm: 0.3000
2025-07-28 08:55:07,998 - INFO -   csatqa_rcss:
2025-07-28 08:55:07,999 - INFO -     - accuracy: 0.4000
2025-07-28 08:55:07,999 - INFO -     - accuracy_norm: 0.4000
2025-07-28 08:55:07,999 - INFO -   csatqa_wr:
2025-07-28 08:55:07,999 - INFO -     - accuracy: 0.2727
2025-07-28 08:55:07,999 - INFO -     - accuracy_norm: 0.2727
2025-07-28 08:55:07,999 - INFO - ============================================================

2025-07-28 08:55:08,033 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 6/10: kormedmcqa
2025-07-28 08:55:08,035 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 08:55:08,035 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 08:55:08,036 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:55:27,001 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 08:55:27,001 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 08:55:27,001 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 08:55:27,002 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 08:55:35,897 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 08:55:35,899 - INFO - 
============================================================
2025-07-28 08:55:35,900 - INFO - Task 'kormedmcqa' Results:
2025-07-28 08:55:35,900 - INFO - ============================================================
2025-07-28 08:55:35,901 - INFO -   kormedmcqa:
2025-07-28 08:55:35,902 - INFO -     - exact_match: 0.5250
2025-07-28 08:55:35,902 - INFO -   kormedmcqa_dentist:
2025-07-28 08:55:35,902 - INFO -     - exact_match: 0.5000
2025-07-28 08:55:35,902 - INFO -   kormedmcqa_doctor:
2025-07-28 08:55:35,903 - INFO -     - exact_match: 0.5000
2025-07-28 08:55:35,903 - INFO -   kormedmcqa_nurse:
2025-07-28 08:55:35,903 - INFO -     - exact_match: 0.6500
2025-07-28 08:55:35,903 - INFO -   kormedmcqa_pharm:
2025-07-28 08:55:35,903 - INFO -     - exact_match: 0.4500
2025-07-28 08:55:35,903 - INFO - ============================================================

2025-07-28 08:55:35,927 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 7/10: mmlu
2025-07-28 08:55:35,928 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'mmlu' will use num_fewshot=0
2025-07-28 08:55:35,929 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 08:55:35,930 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:58:18,816 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 08:58:18,816 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 08:58:18,816 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 08:58:18,816 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 08:58:18,816 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 08:58:18,817 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 08:58:18,817 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 08:58:18,817 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 08:58:18,817 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 08:58:18,817 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 08:58:18,817 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 08:58:18,817 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 08:58:18,818 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 08:58:18,818 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 08:58:18,818 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 08:58:18,818 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 08:58:18,818 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 08:58:18,818 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 08:58:18,819 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 08:58:18,819 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 08:58:18,819 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 08:58:18,819 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 08:58:18,819 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 08:58:18,819 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 08:58:18,819 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 08:58:18,819 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 08:58:18,820 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 08:58:18,820 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 08:58:18,820 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 08:58:18,820 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 08:58:18,820 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 08:58:18,820 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 08:58:18,820 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 08:58:18,821 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 08:58:18,821 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 08:58:18,821 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 08:58:18,821 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 08:58:18,821 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 08:58:18,821 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 08:58:18,821 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 08:58:18,822 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 08:58:18,822 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 08:58:18,822 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 08:58:18,822 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 08:58:18,822 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 08:58:18,822 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 08:58:18,822 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 08:58:18,823 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 08:58:18,823 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 08:58:18,823 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 08:58:18,823 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 08:58:18,823 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 08:58:18,823 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 08:58:18,823 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 08:58:18,824 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 08:58:18,824 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 08:58:18,824 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 08:59:21,227 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 08:59:21,228 - INFO - 
============================================================
2025-07-28 08:59:21,229 - INFO - Task 'mmlu' Results:
2025-07-28 08:59:21,231 - INFO - ============================================================
2025-07-28 08:59:21,231 - INFO -   mmlu:
2025-07-28 08:59:21,231 - INFO -     - accuracy: 0.5991
2025-07-28 08:59:21,232 - INFO -   mmlu_humanities:
2025-07-28 08:59:21,232 - INFO -     - accuracy: 0.6038
2025-07-28 08:59:21,232 - INFO -   mmlu_formal_logic:
2025-07-28 08:59:21,232 - INFO -     - accuracy: 0.4000
2025-07-28 08:59:21,232 - INFO -   mmlu_high_school_european_history:
2025-07-28 08:59:21,232 - INFO -     - accuracy: 0.6500
2025-07-28 08:59:21,232 - INFO -   mmlu_high_school_us_history:
2025-07-28 08:59:21,232 - INFO -     - accuracy: 0.6500
2025-07-28 08:59:21,232 - INFO -   mmlu_high_school_world_history:
2025-07-28 08:59:21,232 - INFO -     - accuracy: 0.7500
2025-07-28 08:59:21,233 - INFO -   mmlu_international_law:
2025-07-28 08:59:21,233 - INFO -     - accuracy: 0.7500
2025-07-28 08:59:21,233 - INFO -   mmlu_jurisprudence:
2025-07-28 08:59:21,233 - INFO -     - accuracy: 0.7000
2025-07-28 08:59:21,233 - INFO -   mmlu_logical_fallacies:
2025-07-28 08:59:21,233 - INFO -     - accuracy: 0.6000
2025-07-28 08:59:21,233 - INFO -   mmlu_moral_disputes:
2025-07-28 08:59:21,233 - INFO -     - accuracy: 0.4500
2025-07-28 08:59:21,233 - INFO -   mmlu_moral_scenarios:
2025-07-28 08:59:21,233 - INFO -     - accuracy: 0.2500
2025-07-28 08:59:21,233 - INFO -   mmlu_philosophy:
2025-07-28 08:59:21,234 - INFO -     - accuracy: 0.7000
2025-07-28 08:59:21,234 - INFO -   mmlu_prehistory:
2025-07-28 08:59:21,234 - INFO -     - accuracy: 0.6500
2025-07-28 08:59:21,234 - INFO -   mmlu_professional_law:
2025-07-28 08:59:21,234 - INFO -     - accuracy: 0.6000
2025-07-28 08:59:21,234 - INFO -   mmlu_world_religions:
2025-07-28 08:59:21,234 - INFO -     - accuracy: 0.7000
2025-07-28 08:59:21,234 - INFO -   mmlu_other:
2025-07-28 08:59:21,234 - INFO -     - accuracy: 0.5962
2025-07-28 08:59:21,234 - INFO -   mmlu_business_ethics:
2025-07-28 08:59:21,234 - INFO -     - accuracy: 0.8000
2025-07-28 08:59:21,235 - INFO -   mmlu_clinical_knowledge:
2025-07-28 08:59:21,235 - INFO -     - accuracy: 0.6000
2025-07-28 08:59:21,235 - INFO -   mmlu_college_medicine:
2025-07-28 08:59:21,235 - INFO -     - accuracy: 0.6000
2025-07-28 08:59:21,235 - INFO -   mmlu_global_facts:
2025-07-28 08:59:21,235 - INFO -     - accuracy: 0.3000
2025-07-28 08:59:21,235 - INFO -   mmlu_human_aging:
2025-07-28 08:59:21,235 - INFO -     - accuracy: 0.6500
2025-07-28 08:59:21,235 - INFO -   mmlu_management:
2025-07-28 08:59:21,235 - INFO -     - accuracy: 0.7000
2025-07-28 08:59:21,236 - INFO -   mmlu_marketing:
2025-07-28 08:59:21,236 - INFO -     - accuracy: 0.7500
2025-07-28 08:59:21,236 - INFO -   mmlu_medical_genetics:
2025-07-28 08:59:21,236 - INFO -     - accuracy: 0.8000
2025-07-28 08:59:21,236 - INFO -   mmlu_miscellaneous:
2025-07-28 08:59:21,236 - INFO -     - accuracy: 0.6000
2025-07-28 08:59:21,236 - INFO -   mmlu_nutrition:
2025-07-28 08:59:21,236 - INFO -     - accuracy: 0.6500
2025-07-28 08:59:21,236 - INFO -   mmlu_professional_accounting:
2025-07-28 08:59:21,236 - INFO -     - accuracy: 0.2500
2025-07-28 08:59:21,236 - INFO -   mmlu_professional_medicine:
2025-07-28 08:59:21,236 - INFO -     - accuracy: 0.5000
2025-07-28 08:59:21,237 - INFO -   mmlu_virology:
2025-07-28 08:59:21,237 - INFO -     - accuracy: 0.5500
2025-07-28 08:59:21,237 - INFO -   mmlu_social_sciences:
2025-07-28 08:59:21,237 - INFO -     - accuracy: 0.6958
2025-07-28 08:59:21,237 - INFO -   mmlu_econometrics:
2025-07-28 08:59:21,237 - INFO -     - accuracy: 0.3500
2025-07-28 08:59:21,237 - INFO -   mmlu_high_school_geography:
2025-07-28 08:59:21,237 - INFO -     - accuracy: 0.8000
2025-07-28 08:59:21,237 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 08:59:21,237 - INFO -     - accuracy: 0.8500
2025-07-28 08:59:21,238 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 08:59:21,238 - INFO -     - accuracy: 0.6000
2025-07-28 08:59:21,238 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 08:59:21,238 - INFO -     - accuracy: 0.7500
2025-07-28 08:59:21,238 - INFO -   mmlu_high_school_psychology:
2025-07-28 08:59:21,238 - INFO -     - accuracy: 0.6500
2025-07-28 08:59:21,238 - INFO -   mmlu_human_sexuality:
2025-07-28 08:59:21,238 - INFO -     - accuracy: 0.9500
2025-07-28 08:59:21,238 - INFO -   mmlu_professional_psychology:
2025-07-28 08:59:21,238 - INFO -     - accuracy: 0.8000
2025-07-28 08:59:21,238 - INFO -   mmlu_public_relations:
2025-07-28 08:59:21,239 - INFO -     - accuracy: 0.3500
2025-07-28 08:59:21,239 - INFO -   mmlu_security_studies:
2025-07-28 08:59:21,239 - INFO -     - accuracy: 0.7500
2025-07-28 08:59:21,239 - INFO -   mmlu_sociology:
2025-07-28 08:59:21,239 - INFO -     - accuracy: 0.7000
2025-07-28 08:59:21,239 - INFO -   mmlu_us_foreign_policy:
2025-07-28 08:59:21,239 - INFO -     - accuracy: 0.8000
2025-07-28 08:59:21,239 - INFO -   mmlu_stem:
2025-07-28 08:59:21,239 - INFO -     - accuracy: 0.5368
2025-07-28 08:59:21,239 - INFO -   mmlu_abstract_algebra:
2025-07-28 08:59:21,239 - INFO -     - accuracy: 0.2500
2025-07-28 08:59:21,240 - INFO -   mmlu_anatomy:
2025-07-28 08:59:21,240 - INFO -     - accuracy: 0.4500
2025-07-28 08:59:21,240 - INFO -   mmlu_astronomy:
2025-07-28 08:59:21,240 - INFO -     - accuracy: 0.8000
2025-07-28 08:59:21,240 - INFO -   mmlu_college_biology:
2025-07-28 08:59:21,240 - INFO -     - accuracy: 0.9000
2025-07-28 08:59:21,240 - INFO -   mmlu_college_chemistry:
2025-07-28 08:59:21,240 - INFO -     - accuracy: 0.6000
2025-07-28 08:59:21,240 - INFO -   mmlu_college_computer_science:
2025-07-28 08:59:21,240 - INFO -     - accuracy: 0.4500
2025-07-28 08:59:21,240 - INFO -   mmlu_college_mathematics:
2025-07-28 08:59:21,240 - INFO -     - accuracy: 0.3500
2025-07-28 08:59:21,241 - INFO -   mmlu_college_physics:
2025-07-28 08:59:21,241 - INFO -     - accuracy: 0.5000
2025-07-28 08:59:21,241 - INFO -   mmlu_computer_security:
2025-07-28 08:59:21,241 - INFO -     - accuracy: 0.7000
2025-07-28 08:59:21,241 - INFO -   mmlu_conceptual_physics:
2025-07-28 08:59:21,241 - INFO -     - accuracy: 0.5500
2025-07-28 08:59:21,241 - INFO -   mmlu_electrical_engineering:
2025-07-28 08:59:21,241 - INFO -     - accuracy: 0.4500
2025-07-28 08:59:21,241 - INFO -   mmlu_elementary_mathematics:
2025-07-28 08:59:21,241 - INFO -     - accuracy: 0.4500
2025-07-28 08:59:21,242 - INFO -   mmlu_high_school_biology:
2025-07-28 08:59:21,242 - INFO -     - accuracy: 0.7500
2025-07-28 08:59:21,242 - INFO -   mmlu_high_school_chemistry:
2025-07-28 08:59:21,242 - INFO -     - accuracy: 0.6000
2025-07-28 08:59:21,242 - INFO -   mmlu_high_school_computer_science:
2025-07-28 08:59:21,242 - INFO -     - accuracy: 0.8500
2025-07-28 08:59:21,242 - INFO -   mmlu_high_school_mathematics:
2025-07-28 08:59:21,242 - INFO -     - accuracy: 0.3000
2025-07-28 08:59:21,242 - INFO -   mmlu_high_school_physics:
2025-07-28 08:59:21,242 - INFO -     - accuracy: 0.3500
2025-07-28 08:59:21,242 - INFO -   mmlu_high_school_statistics:
2025-07-28 08:59:21,243 - INFO -     - accuracy: 0.5000
2025-07-28 08:59:21,243 - INFO -   mmlu_machine_learning:
2025-07-28 08:59:21,243 - INFO -     - accuracy: 0.4000
2025-07-28 08:59:21,243 - INFO - ============================================================

2025-07-28 08:59:21,268 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 8/10: arc_challenge
2025-07-28 08:59:21,269 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 08:59:21,269 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 08:59:21,270 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:59:29,487 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 08:59:34,960 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 08:59:34,962 - INFO - 
============================================================
2025-07-28 08:59:34,963 - INFO - Task 'arc_challenge' Results:
2025-07-28 08:59:34,965 - INFO - ============================================================
2025-07-28 08:59:34,965 - INFO -   arc_challenge:
2025-07-28 08:59:34,965 - INFO -     - accuracy: 0.6000
2025-07-28 08:59:34,965 - INFO -     - accuracy_norm: 0.4500
2025-07-28 08:59:34,965 - INFO - ============================================================

2025-07-28 08:59:34,990 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 9/10: arc_easy
2025-07-28 08:59:34,991 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'arc_easy' will use num_fewshot=0
2025-07-28 08:59:34,991 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 08:59:34,992 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 08:59:43,279 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 08:59:48,059 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 08:59:48,061 - INFO - 
============================================================
2025-07-28 08:59:48,062 - INFO - Task 'arc_easy' Results:
2025-07-28 08:59:48,064 - INFO - ============================================================
2025-07-28 08:59:48,064 - INFO -   arc_easy:
2025-07-28 08:59:48,064 - INFO -     - accuracy: 0.8000
2025-07-28 08:59:48,064 - INFO -     - accuracy_norm: 0.7500
2025-07-28 08:59:48,064 - INFO - ============================================================

2025-07-28 08:59:48,088 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 10/10: hellaswag
2025-07-28 08:59:48,090 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'hellaswag' will use num_fewshot=0
2025-07-28 08:59:48,090 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 08:59:48,091 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:00:02,219 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 09:00:07,667 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 09:00:07,668 - INFO - 
============================================================
2025-07-28 09:00:07,669 - INFO - Task 'hellaswag' Results:
2025-07-28 09:00:07,671 - INFO - ============================================================
2025-07-28 09:00:07,671 - INFO -   hellaswag:
2025-07-28 09:00:07,671 - INFO -     - accuracy: 0.4000
2025-07-28 09:00:07,671 - INFO -     - accuracy_norm: 0.7000
2025-07-28 09:00:07,672 - INFO - ============================================================

2025-07-28 09:00:07,696 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 09:00:07,699 - INFO - [Process 1881867] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/EXAONE-3.5-2.4B-Instruct/EXAONE-3.5-2.4B-Instruct_harness_7.json
2025-07-28 09:00:07,969 - INFO - Results uploaded to WandB as artifact
2025-07-28 09:00:07,979 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 09:00:07,981 - INFO - [Process 1881867] Successfully completed EXAONE-3.5-2.4B-Instruct_harness_7
2025-07-28 09:00:10,921 - INFO - Run EXAONE-3.5-2.4B-Instruct_harness_7 finished successfully
2025-07-28 09:00:10,922 - INFO - [Process 1881867] HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9 assigned to cuda:0
2025-07-28 09:00:10,922 - INFO - [Process 1881867] HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9 - using custom limit: 20
2025-07-28 09:00:12,104 - INFO - WandB run initialized: HyperCLOVAX-SEED-Text-Instruct-1.5B_20250728_090010 (ID: 71bd7739)
2025-07-28 09:00:12,808 - ERROR - [Process 1881867] Error in HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9: 401 Client Error. (Request ID: Root=1-68873c1c-2ee2857e02e4c49901075d17;c76efc0f-faf0-41ea-ab11-c10d76f35bf3)

Cannot access gated repo for url https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes.
Access to model naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B is restricted. You must have access to it and be authenticated to access it. Please log in.
Traceback (most recent call last):
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/gwlee/Benchmark/AIDE_Benchmark/code/core/evaluation_lm.py", line 630, in evaluate_single
    local_path = ensure_model_local(model_id)
  File "/home/gwlee/Benchmark/AIDE_Benchmark/code/core/evaluation_lm.py", line 149, in ensure_model_local
    local_path = snapshot_download(repo_id=repo_id, cache_dir=cache_dir, local_files_only=False)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py", line 296, in snapshot_download
    thread_map(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/tqdm/contrib/concurrent.py", line 69, in thread_map
    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/tqdm/contrib/concurrent.py", line 51, in _executor_map
    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 621, in result_iterator
    yield _result_or_cancel(fs.pop())
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 319, in _result_or_cancel
    return fut.result(timeout)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py", line 270, in _inner_hf_hub_download
    return hf_hub_download(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 426, in hf_raise_for_status
    raise _format(GatedRepoError, message, response) from e
huggingface_hub.errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-68873c1c-2ee2857e02e4c49901075d17;c76efc0f-faf0-41ea-ab11-c10d76f35bf3)

Cannot access gated repo for url https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes.
Access to model naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-07-28 09:00:14,051 - ERROR - Run HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9 failed: 401 Client Error. (Request ID: Root=1-68873c1c-2ee2857e02e4c49901075d17;c76efc0f-faf0-41ea-ab11-c10d76f35bf3)

Cannot access gated repo for url https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes.
Access to model naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-07-28 09:00:14,051 - INFO - [Process 1881867] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10 assigned to cuda:0
2025-07-28 09:00:14,051 - INFO - [Process 1881867] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10 - using custom limit: 20
2025-07-28 09:00:15,387 - INFO - WandB run initialized: HyperCLOVAX-SEED-Text-Instruct-0.5B_20250728_090014 (ID: f06132cd)
2025-07-28 09:00:15,609 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Test mode (limit=2), setting num_fewshot=0
2025-07-28 09:00:15,609 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 1/10: kmmlu
2025-07-28 09:00:15,610 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kmmlu' will use num_fewshot=0
2025-07-28 09:00:15,610 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 09:00:15,610 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:01:28,493 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 09:01:28,493 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 09:01:28,493 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 09:01:28,493 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 09:01:28,493 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 09:01:28,493 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 09:01:28,493 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 09:01:28,494 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 09:01:28,495 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 09:01:28,496 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 09:01:28,497 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 09:01:28,497 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 09:01:28,497 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 09:01:28,497 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 09:01:53,437 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 09:01:53,439 - INFO - 
============================================================
2025-07-28 09:01:53,440 - INFO - Task 'kmmlu' Results:
2025-07-28 09:01:53,441 - INFO - ============================================================
2025-07-28 09:01:53,442 - INFO -   kmmlu:
2025-07-28 09:01:53,442 - INFO -     - accuracy: 0.3400
2025-07-28 09:01:53,443 - INFO -   kmmlu_applied_science:
2025-07-28 09:01:53,443 - INFO -     - accuracy: 0.3167
2025-07-28 09:01:53,443 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 09:01:53,443 - INFO -     - accuracy: 0.2500
2025-07-28 09:01:53,444 - INFO -   kmmlu_electronics_engineering:
2025-07-28 09:01:53,444 - INFO -     - accuracy: 0.4000
2025-07-28 09:01:53,445 - INFO -   kmmlu_energy_management:
2025-07-28 09:01:53,445 - INFO -     - accuracy: 0.1500
2025-07-28 09:01:53,445 - INFO -   kmmlu_environmental_science:
2025-07-28 09:01:53,446 - INFO -     - accuracy: 0.2500
2025-07-28 09:01:53,446 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 09:01:53,446 - INFO -     - accuracy: 0.3000
2025-07-28 09:01:53,446 - INFO -   kmmlu_geomatics:
2025-07-28 09:01:53,446 - INFO -     - accuracy: 0.4500
2025-07-28 09:01:53,446 - INFO -   kmmlu_industrial_engineer:
2025-07-28 09:01:53,446 - INFO -     - accuracy: 0.4000
2025-07-28 09:01:53,446 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 09:01:53,447 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,447 - INFO -   kmmlu_maritime_engineering:
2025-07-28 09:01:53,447 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,447 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 09:01:53,447 - INFO -     - accuracy: 0.3000
2025-07-28 09:01:53,447 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 09:01:53,447 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,447 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 09:01:53,447 - INFO -     - accuracy: 0.2500
2025-07-28 09:01:53,448 - INFO -   kmmlu_humss:
2025-07-28 09:01:53,448 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,448 - INFO -   kmmlu_accounting:
2025-07-28 09:01:53,448 - INFO -     - accuracy: 0.5000
2025-07-28 09:01:53,448 - INFO -   kmmlu_criminal_law:
2025-07-28 09:01:53,448 - INFO -     - accuracy: 0.4000
2025-07-28 09:01:53,448 - INFO -   kmmlu_economics:
2025-07-28 09:01:53,448 - INFO -     - accuracy: 0.4000
2025-07-28 09:01:53,449 - INFO -   kmmlu_education:
2025-07-28 09:01:53,449 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,449 - INFO -   kmmlu_korean_history:
2025-07-28 09:01:53,449 - INFO -     - accuracy: 0.2500
2025-07-28 09:01:53,449 - INFO -   kmmlu_law:
2025-07-28 09:01:53,449 - INFO -     - accuracy: 0.2000
2025-07-28 09:01:53,449 - INFO -   kmmlu_management:
2025-07-28 09:01:53,449 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,449 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 09:01:53,450 - INFO -     - accuracy: 0.4000
2025-07-28 09:01:53,450 - INFO -   kmmlu_psychology:
2025-07-28 09:01:53,450 - INFO -     - accuracy: 0.3000
2025-07-28 09:01:53,450 - INFO -   kmmlu_social_welfare:
2025-07-28 09:01:53,450 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,450 - INFO -   kmmlu_taxation:
2025-07-28 09:01:53,450 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,450 - INFO -   kmmlu_other:
2025-07-28 09:01:53,450 - INFO -     - accuracy: 0.3409
2025-07-28 09:01:53,451 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 09:01:53,451 - INFO -     - accuracy: 0.1000
2025-07-28 09:01:53,451 - INFO -   kmmlu_construction:
2025-07-28 09:01:53,451 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,451 - INFO -   kmmlu_fashion:
2025-07-28 09:01:53,451 - INFO -     - accuracy: 0.2500
2025-07-28 09:01:53,451 - INFO -   kmmlu_food_processing:
2025-07-28 09:01:53,451 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,451 - INFO -   kmmlu_health:
2025-07-28 09:01:53,452 - INFO -     - accuracy: 0.5000
2025-07-28 09:01:53,452 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 09:01:53,452 - INFO -     - accuracy: 0.6000
2025-07-28 09:01:53,452 - INFO -   kmmlu_marketing:
2025-07-28 09:01:53,452 - INFO -     - accuracy: 0.4500
2025-07-28 09:01:53,452 - INFO -   kmmlu_patent:
2025-07-28 09:01:53,452 - INFO -     - accuracy: 0.2500
2025-07-28 09:01:53,452 - INFO -   kmmlu_public_safety:
2025-07-28 09:01:53,452 - INFO -     - accuracy: 0.2500
2025-07-28 09:01:53,453 - INFO -   kmmlu_real_estate:
2025-07-28 09:01:53,453 - INFO -     - accuracy: 0.2500
2025-07-28 09:01:53,453 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 09:01:53,453 - INFO -     - accuracy: 0.4000
2025-07-28 09:01:53,453 - INFO -   kmmlu_stem:
2025-07-28 09:01:53,453 - INFO -     - accuracy: 0.3545
2025-07-28 09:01:53,453 - INFO -   kmmlu_biology:
2025-07-28 09:01:53,453 - INFO -     - accuracy: 0.3000
2025-07-28 09:01:53,453 - INFO -   kmmlu_chemical_engineering:
2025-07-28 09:01:53,454 - INFO -     - accuracy: 0.2500
2025-07-28 09:01:53,454 - INFO -   kmmlu_chemistry:
2025-07-28 09:01:53,454 - INFO -     - accuracy: 0.2500
2025-07-28 09:01:53,454 - INFO -   kmmlu_civil_engineering:
2025-07-28 09:01:53,454 - INFO -     - accuracy: 0.3000
2025-07-28 09:01:53,454 - INFO -   kmmlu_computer_science:
2025-07-28 09:01:53,454 - INFO -     - accuracy: 0.3000
2025-07-28 09:01:53,454 - INFO -   kmmlu_ecology:
2025-07-28 09:01:53,454 - INFO -     - accuracy: 0.6000
2025-07-28 09:01:53,455 - INFO -   kmmlu_electrical_engineering:
2025-07-28 09:01:53,455 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,455 - INFO -   kmmlu_information_technology:
2025-07-28 09:01:53,455 - INFO -     - accuracy: 0.5000
2025-07-28 09:01:53,455 - INFO -   kmmlu_materials_engineering:
2025-07-28 09:01:53,455 - INFO -     - accuracy: 0.3000
2025-07-28 09:01:53,455 - INFO -   kmmlu_math:
2025-07-28 09:01:53,455 - INFO -     - accuracy: 0.3500
2025-07-28 09:01:53,455 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 09:01:53,456 - INFO -     - accuracy: 0.4000
2025-07-28 09:01:53,456 - INFO - ============================================================

2025-07-28 09:01:53,459 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 2/10: kmmlu_hard
2025-07-28 09:01:53,460 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 09:01:53,460 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 09:01:53,460 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:03:05,486 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 09:03:05,487 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 09:03:05,487 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 09:03:05,487 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 09:03:05,487 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 09:03:05,487 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 09:03:05,487 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 09:03:05,487 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 09:03:05,487 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 09:03:05,487 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 09:03:05,487 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 09:03:05,488 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 09:03:05,489 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 09:03:05,490 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 09:03:05,491 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 09:03:30,386 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 09:03:30,387 - INFO - 
============================================================
2025-07-28 09:03:30,388 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 09:03:30,390 - INFO - ============================================================
2025-07-28 09:03:30,390 - INFO -   kmmlu_hard:
2025-07-28 09:03:30,391 - INFO -     - accuracy: 0.2256
2025-07-28 09:03:30,391 - INFO -   kmmlu_hard_applied_science:
2025-07-28 09:03:30,391 - INFO -     - accuracy: 0.2417
2025-07-28 09:03:30,391 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 09:03:30,391 - INFO -     - accuracy: 0.1000
2025-07-28 09:03:30,392 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 09:03:30,392 - INFO -     - accuracy: 0.2000
2025-07-28 09:03:30,392 - INFO -   kmmlu_hard_energy_management:
2025-07-28 09:03:30,392 - INFO -     - accuracy: 0.2500
2025-07-28 09:03:30,393 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 09:03:30,393 - INFO -     - accuracy: 0.2000
2025-07-28 09:03:30,393 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 09:03:30,393 - INFO -     - accuracy: 0.3000
2025-07-28 09:03:30,393 - INFO -   kmmlu_hard_geomatics:
2025-07-28 09:03:30,393 - INFO -     - accuracy: 0.5000
2025-07-28 09:03:30,393 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 09:03:30,394 - INFO -     - accuracy: 0.0500
2025-07-28 09:03:30,394 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 09:03:30,394 - INFO -     - accuracy: 0.2500
2025-07-28 09:03:30,394 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 09:03:30,394 - INFO -     - accuracy: 0.3000
2025-07-28 09:03:30,394 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 09:03:30,394 - INFO -     - accuracy: 0.1000
2025-07-28 09:03:30,394 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 09:03:30,395 - INFO -     - accuracy: 0.3000
2025-07-28 09:03:30,395 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 09:03:30,395 - INFO -     - accuracy: 0.3500
2025-07-28 09:03:30,395 - INFO -   kmmlu_hard_humss:
2025-07-28 09:03:30,395 - INFO -     - accuracy: 0.1773
2025-07-28 09:03:30,395 - INFO -   kmmlu_hard_accounting:
2025-07-28 09:03:30,395 - INFO -     - accuracy: 0.1000
2025-07-28 09:03:30,395 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 09:03:30,395 - INFO -     - accuracy: 0.2000
2025-07-28 09:03:30,396 - INFO -   kmmlu_hard_economics:
2025-07-28 09:03:30,396 - INFO -     - accuracy: 0.1500
2025-07-28 09:03:30,396 - INFO -   kmmlu_hard_education:
2025-07-28 09:03:30,396 - INFO -     - accuracy: 0.1500
2025-07-28 09:03:30,396 - INFO -   kmmlu_hard_korean_history:
2025-07-28 09:03:30,396 - INFO -     - accuracy: 0.1000
2025-07-28 09:03:30,396 - INFO -   kmmlu_hard_law:
2025-07-28 09:03:30,396 - INFO -     - accuracy: 0.1000
2025-07-28 09:03:30,397 - INFO -   kmmlu_hard_management:
2025-07-28 09:03:30,397 - INFO -     - accuracy: 0.3000
2025-07-28 09:03:30,397 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 09:03:30,397 - INFO -     - accuracy: 0.2000
2025-07-28 09:03:30,397 - INFO -   kmmlu_hard_psychology:
2025-07-28 09:03:30,397 - INFO -     - accuracy: 0.2000
2025-07-28 09:03:30,397 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 09:03:30,397 - INFO -     - accuracy: 0.2500
2025-07-28 09:03:30,406 - INFO -   kmmlu_hard_taxation:
2025-07-28 09:03:30,406 - INFO -     - accuracy: 0.2000
2025-07-28 09:03:30,406 - INFO -   kmmlu_hard_other:
2025-07-28 09:03:30,406 - INFO -     - accuracy: 0.2545
2025-07-28 09:03:30,406 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 09:03:30,406 - INFO -     - accuracy: 0.1500
2025-07-28 09:03:30,407 - INFO -   kmmlu_hard_construction:
2025-07-28 09:03:30,407 - INFO -     - accuracy: 0.2000
2025-07-28 09:03:30,407 - INFO -   kmmlu_hard_fashion:
2025-07-28 09:03:30,407 - INFO -     - accuracy: 0.3500
2025-07-28 09:03:30,407 - INFO -   kmmlu_hard_food_processing:
2025-07-28 09:03:30,407 - INFO -     - accuracy: 0.0500
2025-07-28 09:03:30,407 - INFO -   kmmlu_hard_health:
2025-07-28 09:03:30,407 - INFO -     - accuracy: 0.0500
2025-07-28 09:03:30,407 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 09:03:30,407 - INFO -     - accuracy: 0.3500
2025-07-28 09:03:30,408 - INFO -   kmmlu_hard_marketing:
2025-07-28 09:03:30,408 - INFO -     - accuracy: 0.4500
2025-07-28 09:03:30,408 - INFO -   kmmlu_hard_patent:
2025-07-28 09:03:30,408 - INFO -     - accuracy: 0.1500
2025-07-28 09:03:30,408 - INFO -   kmmlu_hard_public_safety:
2025-07-28 09:03:30,408 - INFO -     - accuracy: 0.2500
2025-07-28 09:03:30,408 - INFO -   kmmlu_hard_real_estate:
2025-07-28 09:03:30,408 - INFO -     - accuracy: 0.4000
2025-07-28 09:03:30,408 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 09:03:30,408 - INFO -     - accuracy: 0.4000
2025-07-28 09:03:30,409 - INFO -   kmmlu_hard_stem:
2025-07-28 09:03:30,409 - INFO -     - accuracy: 0.2273
2025-07-28 09:03:30,409 - INFO -   kmmlu_hard_biology:
2025-07-28 09:03:30,409 - INFO -     - accuracy: 0.3000
2025-07-28 09:03:30,409 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 09:03:30,409 - INFO -     - accuracy: 0.0500
2025-07-28 09:03:30,409 - INFO -   kmmlu_hard_chemistry:
2025-07-28 09:03:30,409 - INFO -     - accuracy: 0.1000
2025-07-28 09:03:30,409 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 09:03:30,409 - INFO -     - accuracy: 0.2500
2025-07-28 09:03:30,410 - INFO -   kmmlu_hard_computer_science:
2025-07-28 09:03:30,410 - INFO -     - accuracy: 0.3500
2025-07-28 09:03:30,410 - INFO -   kmmlu_hard_ecology:
2025-07-28 09:03:30,410 - INFO -     - accuracy: 0.2500
2025-07-28 09:03:30,410 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 09:03:30,410 - INFO -     - accuracy: 0.4500
2025-07-28 09:03:30,410 - INFO -   kmmlu_hard_information_technology:
2025-07-28 09:03:30,410 - INFO -     - accuracy: 0.2500
2025-07-28 09:03:30,410 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 09:03:30,410 - INFO -     - accuracy: 0.0500
2025-07-28 09:03:30,410 - INFO -   kmmlu_hard_math:
2025-07-28 09:03:30,410 - INFO -     - accuracy: 0.2500
2025-07-28 09:03:30,411 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 09:03:30,411 - INFO -     - accuracy: 0.2000
2025-07-28 09:03:30,411 - INFO - ============================================================

2025-07-28 09:03:30,414 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 3/10: haerae
2025-07-28 09:03:30,415 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'haerae' will use num_fewshot=0
2025-07-28 09:03:30,415 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 09:03:30,415 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:03:48,065 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 09:03:48,065 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 09:03:48,065 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 09:03:48,065 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 09:03:48,065 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 09:04:01,454 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 09:04:01,455 - INFO - 
============================================================
2025-07-28 09:04:01,455 - INFO - Task 'haerae' Results:
2025-07-28 09:04:01,455 - INFO - ============================================================
2025-07-28 09:04:01,455 - INFO -   haerae:
2025-07-28 09:04:01,455 - INFO -     - accuracy: 0.6900
2025-07-28 09:04:01,456 - INFO -     - accuracy_norm: 0.6900
2025-07-28 09:04:01,457 - INFO -   haerae_general_knowledge:
2025-07-28 09:04:01,458 - INFO -     - accuracy: 0.7500
2025-07-28 09:04:01,459 - INFO -     - accuracy_norm: 0.7500
2025-07-28 09:04:01,459 - INFO -   haerae_history:
2025-07-28 09:04:01,459 - INFO -     - accuracy: 0.6000
2025-07-28 09:04:01,460 - INFO -     - accuracy_norm: 0.6000
2025-07-28 09:04:01,460 - INFO -   haerae_loan_word:
2025-07-28 09:04:01,460 - INFO -     - accuracy: 0.9000
2025-07-28 09:04:01,460 - INFO -     - accuracy_norm: 0.9000
2025-07-28 09:04:01,460 - INFO -   haerae_rare_word:
2025-07-28 09:04:01,460 - INFO -     - accuracy: 0.4500
2025-07-28 09:04:01,460 - INFO -     - accuracy_norm: 0.4500
2025-07-28 09:04:01,460 - INFO -   haerae_standard_nomenclature:
2025-07-28 09:04:01,460 - INFO -     - accuracy: 0.7500
2025-07-28 09:04:01,460 - INFO -     - accuracy_norm: 0.7500
2025-07-28 09:04:01,461 - INFO - ============================================================

2025-07-28 09:04:01,464 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 4/10: kobest
2025-07-28 09:04:01,465 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kobest' will use num_fewshot=0
2025-07-28 09:04:01,465 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 09:04:01,465 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:04:19,708 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 09:04:19,709 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 09:04:19,709 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 09:04:19,709 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 09:04:19,709 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 09:04:27,421 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 09:04:27,421 - INFO - 
============================================================
2025-07-28 09:04:27,422 - INFO - Task 'kobest' Results:
2025-07-28 09:04:27,422 - INFO - ============================================================
2025-07-28 09:04:27,422 - INFO -   kobest:
2025-07-28 09:04:27,422 - INFO -     - accuracy: 0.6300
2025-07-28 09:04:27,423 - INFO -     - accuracy_norm: 0.6000
2025-07-28 09:04:27,424 - INFO -     - f1: 0.5577
2025-07-28 09:04:27,425 - INFO -   kobest_boolq:
2025-07-28 09:04:27,426 - INFO -     - accuracy: 0.6000
2025-07-28 09:04:27,426 - INFO -     - f1: 0.4667
2025-07-28 09:04:27,426 - INFO -   kobest_copa:
2025-07-28 09:04:27,426 - INFO -     - accuracy: 0.8000
2025-07-28 09:04:27,426 - INFO -     - f1: 0.8000
2025-07-28 09:04:27,426 - INFO -   kobest_hellaswag:
2025-07-28 09:04:27,426 - INFO -     - accuracy: 0.4500
2025-07-28 09:04:27,426 - INFO -     - accuracy_norm: 0.6000
2025-07-28 09:04:27,426 - INFO -     - f1: 0.4520
2025-07-28 09:04:27,427 - INFO -   kobest_sentineg:
2025-07-28 09:04:27,427 - INFO -     - accuracy: 0.7500
2025-07-28 09:04:27,427 - INFO -     - f1: 0.7151
2025-07-28 09:04:27,427 - INFO -   kobest_wic:
2025-07-28 09:04:27,427 - INFO -     - accuracy: 0.5500
2025-07-28 09:04:27,427 - INFO -     - f1: 0.3548
2025-07-28 09:04:27,427 - INFO - ============================================================

2025-07-28 09:04:27,431 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 5/10: csatqa
2025-07-28 09:04:27,431 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'csatqa' detected as zero-shot task
2025-07-28 09:04:27,431 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 09:04:27,432 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:04:40,126 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 09:04:40,127 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 09:04:40,127 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 09:04:40,127 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 09:04:40,127 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 09:04:40,127 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 09:04:58,304 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 09:04:58,305 - INFO - 
============================================================
2025-07-28 09:04:58,305 - INFO - Task 'csatqa' Results:
2025-07-28 09:04:58,305 - INFO - ============================================================
2025-07-28 09:04:58,305 - INFO -   csatqa:
2025-07-28 09:04:58,306 - INFO -     - accuracy: 0.3243
2025-07-28 09:04:58,307 - INFO -     - accuracy_norm: 0.3243
2025-07-28 09:04:58,308 - INFO -   csatqa_gr:
2025-07-28 09:04:58,310 - INFO -     - accuracy: 0.2000
2025-07-28 09:04:58,310 - INFO -     - accuracy_norm: 0.2000
2025-07-28 09:04:58,310 - INFO -   csatqa_li:
2025-07-28 09:04:58,310 - INFO -     - accuracy: 0.5500
2025-07-28 09:04:58,310 - INFO -     - accuracy_norm: 0.5500
2025-07-28 09:04:58,310 - INFO -   csatqa_rch:
2025-07-28 09:04:58,310 - INFO -     - accuracy: 0.2000
2025-07-28 09:04:58,310 - INFO -     - accuracy_norm: 0.2000
2025-07-28 09:04:58,310 - INFO -   csatqa_rcs:
2025-07-28 09:04:58,311 - INFO -     - accuracy: 0.2000
2025-07-28 09:04:58,311 - INFO -     - accuracy_norm: 0.2000
2025-07-28 09:04:58,311 - INFO -   csatqa_rcss:
2025-07-28 09:04:58,311 - INFO -     - accuracy: 0.5000
2025-07-28 09:04:58,311 - INFO -     - accuracy_norm: 0.5000
2025-07-28 09:04:58,311 - INFO -   csatqa_wr:
2025-07-28 09:04:58,311 - INFO -     - accuracy: 0.2727
2025-07-28 09:04:58,311 - INFO -     - accuracy_norm: 0.2727
2025-07-28 09:04:58,311 - INFO - ============================================================

2025-07-28 09:04:58,318 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 6/10: kormedmcqa
2025-07-28 09:04:58,319 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 09:04:58,319 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 09:04:58,319 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:05:15,647 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 09:05:15,647 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 09:05:15,647 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 09:05:15,647 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 09:05:50,220 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 09:05:50,220 - INFO - 
============================================================
2025-07-28 09:05:50,221 - INFO - Task 'kormedmcqa' Results:
2025-07-28 09:05:50,221 - INFO - ============================================================
2025-07-28 09:05:50,221 - INFO -   kormedmcqa:
2025-07-28 09:05:50,221 - INFO -     - exact_match: 0.1250
2025-07-28 09:05:50,221 - INFO -   kormedmcqa_dentist:
2025-07-28 09:05:50,222 - INFO -     - exact_match: 0.2000
2025-07-28 09:05:50,224 - INFO -   kormedmcqa_doctor:
2025-07-28 09:05:50,224 - INFO -     - exact_match: 0.0500
2025-07-28 09:05:50,225 - INFO -   kormedmcqa_nurse:
2025-07-28 09:05:50,225 - INFO -     - exact_match: 0.2000
2025-07-28 09:05:50,226 - INFO -   kormedmcqa_pharm:
2025-07-28 09:05:50,226 - INFO -     - exact_match: 0.0500
2025-07-28 09:05:50,226 - INFO - ============================================================

2025-07-28 09:05:50,230 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 7/10: mmlu
2025-07-28 09:05:50,230 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'mmlu' will use num_fewshot=0
2025-07-28 09:05:50,231 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 09:05:50,231 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:08:36,744 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 09:08:36,744 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 09:08:36,744 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 09:08:36,744 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 09:08:36,744 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 09:08:36,744 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 09:08:36,745 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 09:08:36,746 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 09:08:36,746 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 09:08:36,746 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 09:08:36,746 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 09:08:36,746 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 09:08:36,746 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 09:08:36,746 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 09:08:36,746 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 09:08:36,746 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 09:08:36,746 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 09:08:36,747 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 09:08:36,748 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 09:08:36,749 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 09:08:36,749 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 09:08:36,749 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 09:08:36,749 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 09:08:36,749 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 09:08:36,749 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 09:09:06,861 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 09:09:06,863 - INFO - 
============================================================
2025-07-28 09:09:06,864 - INFO - Task 'mmlu' Results:
2025-07-28 09:09:06,864 - INFO - ============================================================
2025-07-28 09:09:06,866 - INFO -   mmlu:
2025-07-28 09:09:06,866 - INFO -     - accuracy: 0.4553
2025-07-28 09:09:06,866 - INFO -   mmlu_humanities:
2025-07-28 09:09:06,866 - INFO -     - accuracy: 0.4538
2025-07-28 09:09:06,866 - INFO -   mmlu_formal_logic:
2025-07-28 09:09:06,866 - INFO -     - accuracy: 0.2000
2025-07-28 09:09:06,866 - INFO -   mmlu_high_school_european_history:
2025-07-28 09:09:06,867 - INFO -     - accuracy: 0.6500
2025-07-28 09:09:06,867 - INFO -   mmlu_high_school_us_history:
2025-07-28 09:09:06,867 - INFO -     - accuracy: 0.5000
2025-07-28 09:09:06,867 - INFO -   mmlu_high_school_world_history:
2025-07-28 09:09:06,867 - INFO -     - accuracy: 0.5500
2025-07-28 09:09:06,867 - INFO -   mmlu_international_law:
2025-07-28 09:09:06,867 - INFO -     - accuracy: 0.6500
2025-07-28 09:09:06,867 - INFO -   mmlu_jurisprudence:
2025-07-28 09:09:06,867 - INFO -     - accuracy: 0.5500
2025-07-28 09:09:06,867 - INFO -   mmlu_logical_fallacies:
2025-07-28 09:09:06,867 - INFO -     - accuracy: 0.5000
2025-07-28 09:09:06,868 - INFO -   mmlu_moral_disputes:
2025-07-28 09:09:06,868 - INFO -     - accuracy: 0.3500
2025-07-28 09:09:06,868 - INFO -   mmlu_moral_scenarios:
2025-07-28 09:09:06,868 - INFO -     - accuracy: 0.2500
2025-07-28 09:09:06,868 - INFO -   mmlu_philosophy:
2025-07-28 09:09:06,868 - INFO -     - accuracy: 0.5000
2025-07-28 09:09:06,868 - INFO -   mmlu_prehistory:
2025-07-28 09:09:06,868 - INFO -     - accuracy: 0.3500
2025-07-28 09:09:06,868 - INFO -   mmlu_professional_law:
2025-07-28 09:09:06,868 - INFO -     - accuracy: 0.3500
2025-07-28 09:09:06,869 - INFO -   mmlu_world_religions:
2025-07-28 09:09:06,869 - INFO -     - accuracy: 0.5000
2025-07-28 09:09:06,869 - INFO -   mmlu_other:
2025-07-28 09:09:06,869 - INFO -     - accuracy: 0.5192
2025-07-28 09:09:06,869 - INFO -   mmlu_business_ethics:
2025-07-28 09:09:06,869 - INFO -     - accuracy: 0.5000
2025-07-28 09:09:06,869 - INFO -   mmlu_clinical_knowledge:
2025-07-28 09:09:06,869 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,869 - INFO -   mmlu_college_medicine:
2025-07-28 09:09:06,869 - INFO -     - accuracy: 0.6000
2025-07-28 09:09:06,869 - INFO -   mmlu_global_facts:
2025-07-28 09:09:06,870 - INFO -     - accuracy: 0.5500
2025-07-28 09:09:06,870 - INFO -   mmlu_human_aging:
2025-07-28 09:09:06,870 - INFO -     - accuracy: 0.6000
2025-07-28 09:09:06,870 - INFO -   mmlu_management:
2025-07-28 09:09:06,870 - INFO -     - accuracy: 0.5000
2025-07-28 09:09:06,870 - INFO -   mmlu_marketing:
2025-07-28 09:09:06,870 - INFO -     - accuracy: 0.5500
2025-07-28 09:09:06,870 - INFO -   mmlu_medical_genetics:
2025-07-28 09:09:06,870 - INFO -     - accuracy: 0.4500
2025-07-28 09:09:06,870 - INFO -   mmlu_miscellaneous:
2025-07-28 09:09:06,871 - INFO -     - accuracy: 0.6000
2025-07-28 09:09:06,871 - INFO -   mmlu_nutrition:
2025-07-28 09:09:06,871 - INFO -     - accuracy: 0.7500
2025-07-28 09:09:06,871 - INFO -   mmlu_professional_accounting:
2025-07-28 09:09:06,871 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,871 - INFO -   mmlu_professional_medicine:
2025-07-28 09:09:06,871 - INFO -     - accuracy: 0.4500
2025-07-28 09:09:06,871 - INFO -   mmlu_virology:
2025-07-28 09:09:06,871 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,871 - INFO -   mmlu_social_sciences:
2025-07-28 09:09:06,871 - INFO -     - accuracy: 0.5083
2025-07-28 09:09:06,872 - INFO -   mmlu_econometrics:
2025-07-28 09:09:06,872 - INFO -     - accuracy: 0.1500
2025-07-28 09:09:06,872 - INFO -   mmlu_high_school_geography:
2025-07-28 09:09:06,872 - INFO -     - accuracy: 0.5000
2025-07-28 09:09:06,872 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 09:09:06,872 - INFO -     - accuracy: 0.7000
2025-07-28 09:09:06,872 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 09:09:06,872 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,872 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 09:09:06,872 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,873 - INFO -   mmlu_high_school_psychology:
2025-07-28 09:09:06,873 - INFO -     - accuracy: 0.7000
2025-07-28 09:09:06,873 - INFO -   mmlu_human_sexuality:
2025-07-28 09:09:06,873 - INFO -     - accuracy: 0.6500
2025-07-28 09:09:06,873 - INFO -   mmlu_professional_psychology:
2025-07-28 09:09:06,873 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,873 - INFO -   mmlu_public_relations:
2025-07-28 09:09:06,873 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,873 - INFO -   mmlu_security_studies:
2025-07-28 09:09:06,873 - INFO -     - accuracy: 0.7000
2025-07-28 09:09:06,873 - INFO -   mmlu_sociology:
2025-07-28 09:09:06,874 - INFO -     - accuracy: 0.3500
2025-07-28 09:09:06,874 - INFO -   mmlu_us_foreign_policy:
2025-07-28 09:09:06,874 - INFO -     - accuracy: 0.7500
2025-07-28 09:09:06,874 - INFO -   mmlu_stem:
2025-07-28 09:09:06,874 - INFO -     - accuracy: 0.3789
2025-07-28 09:09:06,874 - INFO -   mmlu_abstract_algebra:
2025-07-28 09:09:06,874 - INFO -     - accuracy: 0.3500
2025-07-28 09:09:06,874 - INFO -   mmlu_anatomy:
2025-07-28 09:09:06,874 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,874 - INFO -   mmlu_astronomy:
2025-07-28 09:09:06,875 - INFO -     - accuracy: 0.4500
2025-07-28 09:09:06,875 - INFO -   mmlu_college_biology:
2025-07-28 09:09:06,875 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,875 - INFO -   mmlu_college_chemistry:
2025-07-28 09:09:06,875 - INFO -     - accuracy: 0.3500
2025-07-28 09:09:06,875 - INFO -   mmlu_college_computer_science:
2025-07-28 09:09:06,875 - INFO -     - accuracy: 0.3500
2025-07-28 09:09:06,875 - INFO -   mmlu_college_mathematics:
2025-07-28 09:09:06,875 - INFO -     - accuracy: 0.3000
2025-07-28 09:09:06,875 - INFO -   mmlu_college_physics:
2025-07-28 09:09:06,875 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,876 - INFO -   mmlu_computer_security:
2025-07-28 09:09:06,876 - INFO -     - accuracy: 0.5000
2025-07-28 09:09:06,876 - INFO -   mmlu_conceptual_physics:
2025-07-28 09:09:06,876 - INFO -     - accuracy: 0.5000
2025-07-28 09:09:06,876 - INFO -   mmlu_electrical_engineering:
2025-07-28 09:09:06,876 - INFO -     - accuracy: 0.2500
2025-07-28 09:09:06,876 - INFO -   mmlu_elementary_mathematics:
2025-07-28 09:09:06,876 - INFO -     - accuracy: 0.2500
2025-07-28 09:09:06,876 - INFO -   mmlu_high_school_biology:
2025-07-28 09:09:06,876 - INFO -     - accuracy: 0.4500
2025-07-28 09:09:06,877 - INFO -   mmlu_high_school_chemistry:
2025-07-28 09:09:06,877 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:06,877 - INFO -   mmlu_high_school_computer_science:
2025-07-28 09:09:06,877 - INFO -     - accuracy: 0.6000
2025-07-28 09:09:06,877 - INFO -   mmlu_high_school_mathematics:
2025-07-28 09:09:06,877 - INFO -     - accuracy: 0.2500
2025-07-28 09:09:06,877 - INFO -   mmlu_high_school_physics:
2025-07-28 09:09:06,877 - INFO -     - accuracy: 0.4500
2025-07-28 09:09:06,877 - INFO -   mmlu_high_school_statistics:
2025-07-28 09:09:06,877 - INFO -     - accuracy: 0.2000
2025-07-28 09:09:06,877 - INFO -   mmlu_machine_learning:
2025-07-28 09:09:06,878 - INFO -     - accuracy: 0.3500
2025-07-28 09:09:06,878 - INFO - ============================================================

2025-07-28 09:09:06,882 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 8/10: arc_challenge
2025-07-28 09:09:06,883 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 09:09:06,883 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 09:09:06,883 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:09:13,605 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 09:09:18,302 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 09:09:18,302 - INFO - 
============================================================
2025-07-28 09:09:18,302 - INFO - Task 'arc_challenge' Results:
2025-07-28 09:09:18,302 - INFO - ============================================================
2025-07-28 09:09:18,303 - INFO -   arc_challenge:
2025-07-28 09:09:18,303 - INFO -     - accuracy: 0.4000
2025-07-28 09:09:18,304 - INFO -     - accuracy_norm: 0.2500
2025-07-28 09:09:18,305 - INFO - ============================================================

2025-07-28 09:09:18,310 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 9/10: arc_easy
2025-07-28 09:09:18,310 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'arc_easy' will use num_fewshot=0
2025-07-28 09:09:18,311 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 09:09:18,311 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:09:26,084 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 09:09:30,703 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 09:09:30,704 - INFO - 
============================================================
2025-07-28 09:09:30,704 - INFO - Task 'arc_easy' Results:
2025-07-28 09:09:30,704 - INFO - ============================================================
2025-07-28 09:09:30,704 - INFO -   arc_easy:
2025-07-28 09:09:30,704 - INFO -     - accuracy: 0.6500
2025-07-28 09:09:30,705 - INFO -     - accuracy_norm: 0.5500
2025-07-28 09:09:30,707 - INFO - ============================================================

2025-07-28 09:09:30,711 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 10/10: hellaswag
2025-07-28 09:09:30,712 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'hellaswag' will use num_fewshot=0
2025-07-28 09:09:30,712 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 09:09:30,713 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:09:43,910 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 09:09:48,718 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 09:09:48,720 - INFO - 
============================================================
2025-07-28 09:09:48,721 - INFO - Task 'hellaswag' Results:
2025-07-28 09:09:48,722 - INFO - ============================================================
2025-07-28 09:09:48,723 - INFO -   hellaswag:
2025-07-28 09:09:48,723 - INFO -     - accuracy: 0.3500
2025-07-28 09:09:48,723 - INFO -     - accuracy_norm: 0.3000
2025-07-28 09:09:48,723 - INFO - ============================================================

2025-07-28 09:09:48,727 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 09:09:48,729 - INFO - [Process 1881867] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/HyperCLOVAX-SEED-Text-Instruct-0.5B/HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10.json
2025-07-28 09:09:49,057 - INFO - Results uploaded to WandB as artifact
2025-07-28 09:09:49,065 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 09:09:49,067 - INFO - [Process 1881867] Successfully completed HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10
2025-07-28 09:09:52,161 - INFO - Run HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10 finished successfully
2025-07-28 09:09:52,162 - INFO - [Process 1881867] kanana-1.5-2.1b-instruct-2505_harness_11 assigned to cuda:0
2025-07-28 09:09:52,162 - INFO - [Process 1881867] kanana-1.5-2.1b-instruct-2505_harness_11 - using custom limit: 20
2025-07-28 09:09:53,618 - INFO - WandB run initialized: kanana-1.5-2.1b-instruct-2505_20250728_090952 (ID: cf7b9a03)
2025-07-28 09:09:53,821 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Test mode (limit=2), setting num_fewshot=0
2025-07-28 09:09:53,821 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 1/10: kmmlu
2025-07-28 09:09:53,821 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kmmlu' will use num_fewshot=0
2025-07-28 09:09:53,821 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 09:09:53,822 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 09:09:53,822 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:11:08,341 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 09:11:08,342 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 09:11:08,342 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 09:11:08,342 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 09:11:08,342 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 09:11:08,342 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 09:11:08,342 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 09:11:08,342 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 09:11:08,343 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 09:11:08,344 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 09:11:08,345 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 09:11:08,346 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 09:11:08,346 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 09:11:08,346 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 09:11:39,307 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 09:11:39,308 - INFO - 
============================================================
2025-07-28 09:11:39,309 - INFO - Task 'kmmlu' Results:
2025-07-28 09:11:39,311 - INFO - ============================================================
2025-07-28 09:11:39,312 - INFO -   kmmlu:
2025-07-28 09:11:39,312 - INFO -     - accuracy: 0.3333
2025-07-28 09:11:39,312 - INFO -   kmmlu_applied_science:
2025-07-28 09:11:39,312 - INFO -     - accuracy: 0.2250
2025-07-28 09:11:39,313 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 09:11:39,313 - INFO -     - accuracy: 0.1500
2025-07-28 09:11:39,313 - INFO -   kmmlu_electronics_engineering:
2025-07-28 09:11:39,313 - INFO -     - accuracy: 0.1500
2025-07-28 09:11:39,313 - INFO -   kmmlu_energy_management:
2025-07-28 09:11:39,313 - INFO -     - accuracy: 0.1000
2025-07-28 09:11:39,313 - INFO -   kmmlu_environmental_science:
2025-07-28 09:11:39,313 - INFO -     - accuracy: 0.1500
2025-07-28 09:11:39,314 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 09:11:39,314 - INFO -     - accuracy: 0.3500
2025-07-28 09:11:39,314 - INFO -   kmmlu_geomatics:
2025-07-28 09:11:39,314 - INFO -     - accuracy: 0.2000
2025-07-28 09:11:39,314 - INFO -   kmmlu_industrial_engineer:
2025-07-28 09:11:39,314 - INFO -     - accuracy: 0.3500
2025-07-28 09:11:39,314 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 09:11:39,314 - INFO -     - accuracy: 0.3000
2025-07-28 09:11:39,314 - INFO -   kmmlu_maritime_engineering:
2025-07-28 09:11:39,315 - INFO -     - accuracy: 0.2500
2025-07-28 09:11:39,315 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 09:11:39,315 - INFO -     - accuracy: 0.2000
2025-07-28 09:11:39,315 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 09:11:39,315 - INFO -     - accuracy: 0.3500
2025-07-28 09:11:39,315 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 09:11:39,315 - INFO -     - accuracy: 0.1500
2025-07-28 09:11:39,315 - INFO -   kmmlu_humss:
2025-07-28 09:11:39,315 - INFO -     - accuracy: 0.4182
2025-07-28 09:11:39,315 - INFO -   kmmlu_accounting:
2025-07-28 09:11:39,316 - INFO -     - accuracy: 0.5500
2025-07-28 09:11:39,316 - INFO -   kmmlu_criminal_law:
2025-07-28 09:11:39,316 - INFO -     - accuracy: 0.4000
2025-07-28 09:11:39,316 - INFO -   kmmlu_economics:
2025-07-28 09:11:39,316 - INFO -     - accuracy: 0.5500
2025-07-28 09:11:39,316 - INFO -   kmmlu_education:
2025-07-28 09:11:39,316 - INFO -     - accuracy: 0.6500
2025-07-28 09:11:39,316 - INFO -   kmmlu_korean_history:
2025-07-28 09:11:39,316 - INFO -     - accuracy: 0.3000
2025-07-28 09:11:39,316 - INFO -   kmmlu_law:
2025-07-28 09:11:39,317 - INFO -     - accuracy: 0.2000
2025-07-28 09:11:39,317 - INFO -   kmmlu_management:
2025-07-28 09:11:39,317 - INFO -     - accuracy: 0.2000
2025-07-28 09:11:39,317 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 09:11:39,317 - INFO -     - accuracy: 0.6500
2025-07-28 09:11:39,317 - INFO -   kmmlu_psychology:
2025-07-28 09:11:39,317 - INFO -     - accuracy: 0.3500
2025-07-28 09:11:39,317 - INFO -   kmmlu_social_welfare:
2025-07-28 09:11:39,317 - INFO -     - accuracy: 0.3000
2025-07-28 09:11:39,317 - INFO -   kmmlu_taxation:
2025-07-28 09:11:39,318 - INFO -     - accuracy: 0.4500
2025-07-28 09:11:39,318 - INFO -   kmmlu_other:
2025-07-28 09:11:39,318 - INFO -     - accuracy: 0.3455
2025-07-28 09:11:39,318 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 09:11:39,318 - INFO -     - accuracy: 0.2500
2025-07-28 09:11:39,318 - INFO -   kmmlu_construction:
2025-07-28 09:11:39,318 - INFO -     - accuracy: 0.2500
2025-07-28 09:11:39,318 - INFO -   kmmlu_fashion:
2025-07-28 09:11:39,318 - INFO -     - accuracy: 0.4500
2025-07-28 09:11:39,319 - INFO -   kmmlu_food_processing:
2025-07-28 09:11:39,319 - INFO -     - accuracy: 0.4000
2025-07-28 09:11:39,319 - INFO -   kmmlu_health:
2025-07-28 09:11:39,319 - INFO -     - accuracy: 0.4500
2025-07-28 09:11:39,319 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 09:11:39,319 - INFO -     - accuracy: 0.4000
2025-07-28 09:11:39,319 - INFO -   kmmlu_marketing:
2025-07-28 09:11:39,319 - INFO -     - accuracy: 0.5000
2025-07-28 09:11:39,319 - INFO -   kmmlu_patent:
2025-07-28 09:11:39,320 - INFO -     - accuracy: 0.1500
2025-07-28 09:11:39,320 - INFO -   kmmlu_public_safety:
2025-07-28 09:11:39,320 - INFO -     - accuracy: 0.3000
2025-07-28 09:11:39,320 - INFO -   kmmlu_real_estate:
2025-07-28 09:11:39,320 - INFO -     - accuracy: 0.3000
2025-07-28 09:11:39,320 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 09:11:39,320 - INFO -     - accuracy: 0.3500
2025-07-28 09:11:39,320 - INFO -   kmmlu_stem:
2025-07-28 09:11:39,320 - INFO -     - accuracy: 0.3545
2025-07-28 09:11:39,321 - INFO -   kmmlu_biology:
2025-07-28 09:11:39,321 - INFO -     - accuracy: 0.3000
2025-07-28 09:11:39,321 - INFO -   kmmlu_chemical_engineering:
2025-07-28 09:11:39,321 - INFO -     - accuracy: 0.2000
2025-07-28 09:11:39,321 - INFO -   kmmlu_chemistry:
2025-07-28 09:11:39,321 - INFO -     - accuracy: 0.3000
2025-07-28 09:11:39,321 - INFO -   kmmlu_civil_engineering:
2025-07-28 09:11:39,321 - INFO -     - accuracy: 0.2500
2025-07-28 09:11:39,321 - INFO -   kmmlu_computer_science:
2025-07-28 09:11:39,322 - INFO -     - accuracy: 0.7500
2025-07-28 09:11:39,322 - INFO -   kmmlu_ecology:
2025-07-28 09:11:39,322 - INFO -     - accuracy: 0.2500
2025-07-28 09:11:39,322 - INFO -   kmmlu_electrical_engineering:
2025-07-28 09:11:39,322 - INFO -     - accuracy: 0.4500
2025-07-28 09:11:39,322 - INFO -   kmmlu_information_technology:
2025-07-28 09:11:39,322 - INFO -     - accuracy: 0.5500
2025-07-28 09:11:39,322 - INFO -   kmmlu_materials_engineering:
2025-07-28 09:11:39,322 - INFO -     - accuracy: 0.2500
2025-07-28 09:11:39,323 - INFO -   kmmlu_math:
2025-07-28 09:11:39,323 - INFO -     - accuracy: 0.3000
2025-07-28 09:11:39,323 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 09:11:39,323 - INFO -     - accuracy: 0.3000
2025-07-28 09:11:39,323 - INFO - ============================================================

2025-07-28 09:11:39,335 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 2/10: kmmlu_hard
2025-07-28 09:11:39,335 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 09:11:39,336 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 09:11:39,336 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 09:11:39,336 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:12:54,968 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 09:12:54,968 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 09:12:54,968 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 09:12:54,968 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 09:12:54,968 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 09:12:54,968 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 09:12:54,969 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 09:12:54,969 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 09:12:54,969 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 09:12:54,969 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 09:12:54,969 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 09:12:54,969 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 09:12:54,969 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 09:12:54,969 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 09:12:54,969 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 09:12:54,970 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 09:12:54,970 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 09:12:54,970 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 09:12:54,970 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 09:12:54,970 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 09:12:54,970 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 09:12:54,970 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 09:12:54,970 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 09:12:54,970 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 09:12:54,970 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 09:12:54,971 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 09:12:54,971 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 09:12:54,971 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 09:12:54,971 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 09:12:54,971 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 09:12:54,971 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 09:12:54,971 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 09:12:54,971 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 09:12:54,971 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 09:12:54,971 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 09:12:54,972 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 09:12:54,972 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 09:12:54,972 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 09:12:54,972 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 09:12:54,972 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 09:12:54,972 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 09:12:54,972 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 09:12:54,972 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 09:12:54,972 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 09:12:54,972 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 09:13:26,055 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 09:13:26,056 - INFO - 
============================================================
2025-07-28 09:13:26,058 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 09:13:26,059 - INFO - ============================================================
2025-07-28 09:13:26,059 - INFO -   kmmlu_hard:
2025-07-28 09:13:26,060 - INFO -     - accuracy: 0.2278
2025-07-28 09:13:26,060 - INFO -   kmmlu_hard_applied_science:
2025-07-28 09:13:26,060 - INFO -     - accuracy: 0.2417
2025-07-28 09:13:26,060 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 09:13:26,060 - INFO -     - accuracy: 0.1500
2025-07-28 09:13:26,060 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 09:13:26,060 - INFO -     - accuracy: 0.4500
2025-07-28 09:13:26,061 - INFO -   kmmlu_hard_energy_management:
2025-07-28 09:13:26,061 - INFO -     - accuracy: 0.2000
2025-07-28 09:13:26,061 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 09:13:26,061 - INFO -     - accuracy: 0.2500
2025-07-28 09:13:26,061 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 09:13:26,061 - INFO -     - accuracy: 0.0000
2025-07-28 09:13:26,061 - INFO -   kmmlu_hard_geomatics:
2025-07-28 09:13:26,061 - INFO -     - accuracy: 0.2500
2025-07-28 09:13:26,061 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 09:13:26,061 - INFO -     - accuracy: 0.2000
2025-07-28 09:13:26,062 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 09:13:26,062 - INFO -     - accuracy: 0.2500
2025-07-28 09:13:26,062 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 09:13:26,062 - INFO -     - accuracy: 0.1500
2025-07-28 09:13:26,062 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 09:13:26,062 - INFO -     - accuracy: 0.3000
2025-07-28 09:13:26,062 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 09:13:26,062 - INFO -     - accuracy: 0.3000
2025-07-28 09:13:26,062 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 09:13:26,062 - INFO -     - accuracy: 0.4000
2025-07-28 09:13:26,063 - INFO -   kmmlu_hard_humss:
2025-07-28 09:13:26,063 - INFO -     - accuracy: 0.2545
2025-07-28 09:13:26,063 - INFO -   kmmlu_hard_accounting:
2025-07-28 09:13:26,063 - INFO -     - accuracy: 0.2500
2025-07-28 09:13:26,063 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 09:13:26,063 - INFO -     - accuracy: 0.4000
2025-07-28 09:13:26,063 - INFO -   kmmlu_hard_economics:
2025-07-28 09:13:26,063 - INFO -     - accuracy: 0.1500
2025-07-28 09:13:26,063 - INFO -   kmmlu_hard_education:
2025-07-28 09:13:26,063 - INFO -     - accuracy: 0.2500
2025-07-28 09:13:26,064 - INFO -   kmmlu_hard_korean_history:
2025-07-28 09:13:26,064 - INFO -     - accuracy: 0.2000
2025-07-28 09:13:26,064 - INFO -   kmmlu_hard_law:
2025-07-28 09:13:26,064 - INFO -     - accuracy: 0.2500
2025-07-28 09:13:26,064 - INFO -   kmmlu_hard_management:
2025-07-28 09:13:26,064 - INFO -     - accuracy: 0.3000
2025-07-28 09:13:26,064 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 09:13:26,064 - INFO -     - accuracy: 0.6000
2025-07-28 09:13:26,065 - INFO -   kmmlu_hard_psychology:
2025-07-28 09:13:26,065 - INFO -     - accuracy: 0.1000
2025-07-28 09:13:26,065 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 09:13:26,065 - INFO -     - accuracy: 0.2000
2025-07-28 09:13:26,065 - INFO -   kmmlu_hard_taxation:
2025-07-28 09:13:26,065 - INFO -     - accuracy: 0.1000
2025-07-28 09:13:26,065 - INFO -   kmmlu_hard_other:
2025-07-28 09:13:26,065 - INFO -     - accuracy: 0.1909
2025-07-28 09:13:26,065 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 09:13:26,065 - INFO -     - accuracy: 0.1000
2025-07-28 09:13:26,066 - INFO -   kmmlu_hard_construction:
2025-07-28 09:13:26,066 - INFO -     - accuracy: 0.2500
2025-07-28 09:13:26,066 - INFO -   kmmlu_hard_fashion:
2025-07-28 09:13:26,066 - INFO -     - accuracy: 0.2500
2025-07-28 09:13:26,066 - INFO -   kmmlu_hard_food_processing:
2025-07-28 09:13:26,066 - INFO -     - accuracy: 0.1000
2025-07-28 09:13:26,066 - INFO -   kmmlu_hard_health:
2025-07-28 09:13:26,066 - INFO -     - accuracy: 0.0500
2025-07-28 09:13:26,067 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 09:13:26,067 - INFO -     - accuracy: 0.3500
2025-07-28 09:13:26,067 - INFO -   kmmlu_hard_marketing:
2025-07-28 09:13:26,067 - INFO -     - accuracy: 0.1500
2025-07-28 09:13:26,067 - INFO -   kmmlu_hard_patent:
2025-07-28 09:13:26,067 - INFO -     - accuracy: 0.0500
2025-07-28 09:13:26,067 - INFO -   kmmlu_hard_public_safety:
2025-07-28 09:13:26,067 - INFO -     - accuracy: 0.0500
2025-07-28 09:13:26,067 - INFO -   kmmlu_hard_real_estate:
2025-07-28 09:13:26,067 - INFO -     - accuracy: 0.4500
2025-07-28 09:13:26,068 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 09:13:26,068 - INFO -     - accuracy: 0.3000
2025-07-28 09:13:26,068 - INFO -   kmmlu_hard_stem:
2025-07-28 09:13:26,068 - INFO -     - accuracy: 0.2227
2025-07-28 09:13:26,068 - INFO -   kmmlu_hard_biology:
2025-07-28 09:13:26,068 - INFO -     - accuracy: 0.2000
2025-07-28 09:13:26,068 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 09:13:26,068 - INFO -     - accuracy: 0.2000
2025-07-28 09:13:26,068 - INFO -   kmmlu_hard_chemistry:
2025-07-28 09:13:26,069 - INFO -     - accuracy: 0.3000
2025-07-28 09:13:26,069 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 09:13:26,069 - INFO -     - accuracy: 0.1500
2025-07-28 09:13:26,069 - INFO -   kmmlu_hard_computer_science:
2025-07-28 09:13:26,069 - INFO -     - accuracy: 0.3500
2025-07-28 09:13:26,069 - INFO -   kmmlu_hard_ecology:
2025-07-28 09:13:26,069 - INFO -     - accuracy: 0.2000
2025-07-28 09:13:26,069 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 09:13:26,069 - INFO -     - accuracy: 0.2000
2025-07-28 09:13:26,070 - INFO -   kmmlu_hard_information_technology:
2025-07-28 09:13:26,070 - INFO -     - accuracy: 0.3500
2025-07-28 09:13:26,070 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 09:13:26,070 - INFO -     - accuracy: 0.1000
2025-07-28 09:13:26,070 - INFO -   kmmlu_hard_math:
2025-07-28 09:13:26,070 - INFO -     - accuracy: 0.1500
2025-07-28 09:13:26,070 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 09:13:26,070 - INFO -     - accuracy: 0.2500
2025-07-28 09:13:26,070 - INFO - ============================================================

2025-07-28 09:13:26,082 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 3/10: haerae
2025-07-28 09:13:26,083 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'haerae' will use num_fewshot=0
2025-07-28 09:13:26,083 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 09:13:26,083 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 09:13:26,083 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:13:42,353 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 09:13:42,354 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 09:13:42,354 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 09:13:42,354 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 09:13:42,354 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 09:13:59,150 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 09:13:59,152 - INFO - 
============================================================
2025-07-28 09:13:59,153 - INFO - Task 'haerae' Results:
2025-07-28 09:13:59,155 - INFO - ============================================================
2025-07-28 09:13:59,155 - INFO -   haerae:
2025-07-28 09:13:59,155 - INFO -     - accuracy: 0.8300
2025-07-28 09:13:59,155 - INFO -     - accuracy_norm: 0.8300
2025-07-28 09:13:59,155 - INFO -   haerae_general_knowledge:
2025-07-28 09:13:59,155 - INFO -     - accuracy: 0.8000
2025-07-28 09:13:59,155 - INFO -     - accuracy_norm: 0.8000
2025-07-28 09:13:59,156 - INFO -   haerae_history:
2025-07-28 09:13:59,156 - INFO -     - accuracy: 0.9000
2025-07-28 09:13:59,156 - INFO -     - accuracy_norm: 0.9000
2025-07-28 09:13:59,156 - INFO -   haerae_loan_word:
2025-07-28 09:13:59,156 - INFO -     - accuracy: 0.9000
2025-07-28 09:13:59,156 - INFO -     - accuracy_norm: 0.9000
2025-07-28 09:13:59,156 - INFO -   haerae_rare_word:
2025-07-28 09:13:59,156 - INFO -     - accuracy: 0.6000
2025-07-28 09:13:59,156 - INFO -     - accuracy_norm: 0.6000
2025-07-28 09:13:59,156 - INFO -   haerae_standard_nomenclature:
2025-07-28 09:13:59,157 - INFO -     - accuracy: 0.9500
2025-07-28 09:13:59,157 - INFO -     - accuracy_norm: 0.9500
2025-07-28 09:13:59,157 - INFO - ============================================================

2025-07-28 09:13:59,168 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 4/10: kobest
2025-07-28 09:13:59,169 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kobest' will use num_fewshot=0
2025-07-28 09:13:59,169 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 09:13:59,169 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 09:13:59,170 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:14:18,433 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 09:14:18,433 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 09:14:18,433 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 09:14:18,433 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 09:14:18,433 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 09:14:28,431 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 09:14:28,432 - INFO - 
============================================================
2025-07-28 09:14:28,433 - INFO - Task 'kobest' Results:
2025-07-28 09:14:28,434 - INFO - ============================================================
2025-07-28 09:14:28,435 - INFO -   kobest:
2025-07-28 09:14:28,436 - INFO -     - accuracy: 0.6700
2025-07-28 09:14:28,436 - INFO -     - accuracy_norm: 0.7500
2025-07-28 09:14:28,436 - INFO -     - f1: 0.6136
2025-07-28 09:14:28,436 - INFO -   kobest_boolq:
2025-07-28 09:14:28,436 - INFO -     - accuracy: 0.6000
2025-07-28 09:14:28,436 - INFO -     - f1: 0.5238
2025-07-28 09:14:28,436 - INFO -   kobest_copa:
2025-07-28 09:14:28,436 - INFO -     - accuracy: 0.8500
2025-07-28 09:14:28,437 - INFO -     - f1: 0.8496
2025-07-28 09:14:28,437 - INFO -   kobest_hellaswag:
2025-07-28 09:14:28,437 - INFO -     - accuracy: 0.4000
2025-07-28 09:14:28,437 - INFO -     - accuracy_norm: 0.7500
2025-07-28 09:14:28,437 - INFO -     - f1: 0.3909
2025-07-28 09:14:28,437 - INFO -   kobest_sentineg:
2025-07-28 09:14:28,437 - INFO -     - accuracy: 0.9500
2025-07-28 09:14:28,437 - INFO -     - f1: 0.9488
2025-07-28 09:14:28,437 - INFO -   kobest_wic:
2025-07-28 09:14:28,438 - INFO -     - accuracy: 0.5500
2025-07-28 09:14:28,438 - INFO -     - f1: 0.3548
2025-07-28 09:14:28,438 - INFO - ============================================================

2025-07-28 09:14:28,449 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 5/10: csatqa
2025-07-28 09:14:28,450 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'csatqa' detected as zero-shot task
2025-07-28 09:14:28,450 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 09:14:28,450 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 09:14:28,451 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:14:40,291 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 09:14:40,291 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 09:14:40,291 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 09:14:40,292 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 09:14:40,292 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 09:14:40,292 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 09:15:17,239 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 09:15:17,243 - INFO - 
============================================================
2025-07-28 09:15:17,244 - INFO - Task 'csatqa' Results:
2025-07-28 09:15:17,244 - INFO - ============================================================
2025-07-28 09:15:17,244 - INFO -   csatqa:
2025-07-28 09:15:17,244 - INFO -     - accuracy: 0.3423
2025-07-28 09:15:17,245 - INFO -     - accuracy_norm: 0.3423
2025-07-28 09:15:17,245 - INFO -   csatqa_gr:
2025-07-28 09:15:17,245 - INFO -     - accuracy: 0.1000
2025-07-28 09:15:17,245 - INFO -     - accuracy_norm: 0.1000
2025-07-28 09:15:17,245 - INFO -   csatqa_li:
2025-07-28 09:15:17,245 - INFO -     - accuracy: 0.5000
2025-07-28 09:15:17,245 - INFO -     - accuracy_norm: 0.5000
2025-07-28 09:15:17,245 - INFO -   csatqa_rch:
2025-07-28 09:15:17,246 - INFO -     - accuracy: 0.3000
2025-07-28 09:15:17,246 - INFO -     - accuracy_norm: 0.3000
2025-07-28 09:15:17,246 - INFO -   csatqa_rcs:
2025-07-28 09:15:17,246 - INFO -     - accuracy: 0.4000
2025-07-28 09:15:17,246 - INFO -     - accuracy_norm: 0.4000
2025-07-28 09:15:17,246 - INFO -   csatqa_rcss:
2025-07-28 09:15:17,246 - INFO -     - accuracy: 0.4500
2025-07-28 09:15:17,246 - INFO -     - accuracy_norm: 0.4500
2025-07-28 09:15:17,246 - INFO -   csatqa_wr:
2025-07-28 09:15:17,247 - INFO -     - accuracy: 0.2727
2025-07-28 09:15:17,247 - INFO -     - accuracy_norm: 0.2727
2025-07-28 09:15:17,247 - INFO - ============================================================

2025-07-28 09:15:17,264 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 6/10: kormedmcqa
2025-07-28 09:15:17,265 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 09:15:17,265 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 09:15:17,265 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 09:15:17,266 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:15:35,779 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 09:15:35,779 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 09:15:35,780 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 09:15:35,780 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 09:16:17,070 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 09:16:17,071 - INFO - 
============================================================
2025-07-28 09:16:17,072 - INFO - Task 'kormedmcqa' Results:
2025-07-28 09:16:17,074 - INFO - ============================================================
2025-07-28 09:16:17,074 - INFO -   kormedmcqa:
2025-07-28 09:16:17,074 - INFO -     - exact_match: 0.3125
2025-07-28 09:16:17,075 - INFO -   kormedmcqa_dentist:
2025-07-28 09:16:17,075 - INFO -     - exact_match: 0.2000
2025-07-28 09:16:17,075 - INFO -   kormedmcqa_doctor:
2025-07-28 09:16:17,075 - INFO -     - exact_match: 0.2500
2025-07-28 09:16:17,075 - INFO -   kormedmcqa_nurse:
2025-07-28 09:16:17,075 - INFO -     - exact_match: 0.5000
2025-07-28 09:16:17,075 - INFO -   kormedmcqa_pharm:
2025-07-28 09:16:17,075 - INFO -     - exact_match: 0.3000
2025-07-28 09:16:17,076 - INFO - ============================================================

2025-07-28 09:16:17,087 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 7/10: mmlu
2025-07-28 09:16:17,088 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'mmlu' will use num_fewshot=0
2025-07-28 09:16:17,088 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 09:16:17,088 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 09:16:17,089 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:19:00,101 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 09:19:00,101 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 09:19:00,101 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 09:19:00,101 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 09:19:00,101 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 09:19:00,101 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 09:19:00,102 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 09:19:00,102 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 09:19:00,102 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 09:19:00,102 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 09:19:00,102 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 09:19:00,102 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 09:19:00,102 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 09:19:00,102 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 09:19:00,102 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 09:19:00,102 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 09:19:00,103 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 09:19:00,103 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 09:19:00,103 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 09:19:00,103 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 09:19:00,103 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 09:19:00,103 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 09:19:00,103 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 09:19:00,103 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 09:19:00,103 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 09:19:00,103 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 09:19:00,104 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 09:19:00,104 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 09:19:00,104 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 09:19:00,104 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 09:19:00,104 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 09:19:00,104 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 09:19:00,104 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 09:19:00,104 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 09:19:00,104 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 09:19:00,104 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 09:19:00,105 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 09:19:00,106 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 09:19:00,106 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 09:19:00,106 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 09:19:00,106 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 09:19:00,106 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 09:19:00,106 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 09:19:00,106 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 09:19:00,106 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 09:19:00,106 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 09:19:00,106 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 09:19:38,685 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 09:19:38,686 - INFO - 
============================================================
2025-07-28 09:19:38,687 - INFO - Task 'mmlu' Results:
2025-07-28 09:19:38,688 - INFO - ============================================================
2025-07-28 09:19:38,689 - INFO -   mmlu:
2025-07-28 09:19:38,690 - INFO -     - accuracy: 0.5632
2025-07-28 09:19:38,690 - INFO -   mmlu_humanities:
2025-07-28 09:19:38,690 - INFO -     - accuracy: 0.5808
2025-07-28 09:19:38,690 - INFO -   mmlu_formal_logic:
2025-07-28 09:19:38,690 - INFO -     - accuracy: 0.3500
2025-07-28 09:19:38,690 - INFO -   mmlu_high_school_european_history:
2025-07-28 09:19:38,690 - INFO -     - accuracy: 0.6500
2025-07-28 09:19:38,691 - INFO -   mmlu_high_school_us_history:
2025-07-28 09:19:38,691 - INFO -     - accuracy: 0.6000
2025-07-28 09:19:38,691 - INFO -   mmlu_high_school_world_history:
2025-07-28 09:19:38,691 - INFO -     - accuracy: 0.8500
2025-07-28 09:19:38,691 - INFO -   mmlu_international_law:
2025-07-28 09:19:38,691 - INFO -     - accuracy: 0.7500
2025-07-28 09:19:38,691 - INFO -   mmlu_jurisprudence:
2025-07-28 09:19:38,691 - INFO -     - accuracy: 0.6500
2025-07-28 09:19:38,691 - INFO -   mmlu_logical_fallacies:
2025-07-28 09:19:38,692 - INFO -     - accuracy: 0.7000
2025-07-28 09:19:38,692 - INFO -   mmlu_moral_disputes:
2025-07-28 09:19:38,692 - INFO -     - accuracy: 0.5500
2025-07-28 09:19:38,693 - INFO -   mmlu_moral_scenarios:
2025-07-28 09:19:38,693 - INFO -     - accuracy: 0.2000
2025-07-28 09:19:38,694 - INFO -   mmlu_philosophy:
2025-07-28 09:19:38,695 - INFO -     - accuracy: 0.7500
2025-07-28 09:19:38,695 - INFO -   mmlu_prehistory:
2025-07-28 09:19:38,695 - INFO -     - accuracy: 0.5000
2025-07-28 09:19:38,695 - INFO -   mmlu_professional_law:
2025-07-28 09:19:38,695 - INFO -     - accuracy: 0.4000
2025-07-28 09:19:38,696 - INFO -   mmlu_world_religions:
2025-07-28 09:19:38,696 - INFO -     - accuracy: 0.6000
2025-07-28 09:19:38,696 - INFO -   mmlu_other:
2025-07-28 09:19:38,696 - INFO -     - accuracy: 0.5808
2025-07-28 09:19:38,696 - INFO -   mmlu_business_ethics:
2025-07-28 09:19:38,696 - INFO -     - accuracy: 0.7000
2025-07-28 09:19:38,696 - INFO -   mmlu_clinical_knowledge:
2025-07-28 09:19:38,696 - INFO -     - accuracy: 0.7500
2025-07-28 09:19:38,697 - INFO -   mmlu_college_medicine:
2025-07-28 09:19:38,697 - INFO -     - accuracy: 0.5500
2025-07-28 09:19:38,697 - INFO -   mmlu_global_facts:
2025-07-28 09:19:38,697 - INFO -     - accuracy: 0.4000
2025-07-28 09:19:38,697 - INFO -   mmlu_human_aging:
2025-07-28 09:19:38,697 - INFO -     - accuracy: 0.6500
2025-07-28 09:19:38,698 - INFO -   mmlu_management:
2025-07-28 09:19:38,698 - INFO -     - accuracy: 0.6000
2025-07-28 09:19:38,698 - INFO -   mmlu_marketing:
2025-07-28 09:19:38,698 - INFO -     - accuracy: 0.7000
2025-07-28 09:19:38,698 - INFO -   mmlu_medical_genetics:
2025-07-28 09:19:38,698 - INFO -     - accuracy: 0.9000
2025-07-28 09:19:38,699 - INFO -   mmlu_miscellaneous:
2025-07-28 09:19:38,716 - INFO -     - accuracy: 0.7000
2025-07-28 09:19:38,716 - INFO -   mmlu_nutrition:
2025-07-28 09:19:38,717 - INFO -     - accuracy: 0.6500
2025-07-28 09:19:38,717 - INFO -   mmlu_professional_accounting:
2025-07-28 09:19:38,717 - INFO -     - accuracy: 0.3500
2025-07-28 09:19:38,717 - INFO -   mmlu_professional_medicine:
2025-07-28 09:19:38,717 - INFO -     - accuracy: 0.3000
2025-07-28 09:19:38,718 - INFO -   mmlu_virology:
2025-07-28 09:19:38,718 - INFO -     - accuracy: 0.3000
2025-07-28 09:19:38,718 - INFO -   mmlu_social_sciences:
2025-07-28 09:19:38,718 - INFO -     - accuracy: 0.6208
2025-07-28 09:19:38,718 - INFO -   mmlu_econometrics:
2025-07-28 09:19:38,718 - INFO -     - accuracy: 0.4000
2025-07-28 09:19:38,719 - INFO -   mmlu_high_school_geography:
2025-07-28 09:19:38,719 - INFO -     - accuracy: 0.8000
2025-07-28 09:19:38,719 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 09:19:38,719 - INFO -     - accuracy: 0.7500
2025-07-28 09:19:38,719 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 09:19:38,719 - INFO -     - accuracy: 0.5000
2025-07-28 09:19:38,720 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 09:19:38,720 - INFO -     - accuracy: 0.5000
2025-07-28 09:19:38,720 - INFO -   mmlu_high_school_psychology:
2025-07-28 09:19:38,720 - INFO -     - accuracy: 0.8000
2025-07-28 09:19:38,720 - INFO -   mmlu_human_sexuality:
2025-07-28 09:19:38,721 - INFO -     - accuracy: 0.6500
2025-07-28 09:19:38,721 - INFO -   mmlu_professional_psychology:
2025-07-28 09:19:38,721 - INFO -     - accuracy: 0.6500
2025-07-28 09:19:38,721 - INFO -   mmlu_public_relations:
2025-07-28 09:19:38,721 - INFO -     - accuracy: 0.4000
2025-07-28 09:19:38,721 - INFO -   mmlu_security_studies:
2025-07-28 09:19:38,722 - INFO -     - accuracy: 0.6500
2025-07-28 09:19:38,722 - INFO -   mmlu_sociology:
2025-07-28 09:19:38,722 - INFO -     - accuracy: 0.6000
2025-07-28 09:19:38,722 - INFO -   mmlu_us_foreign_policy:
2025-07-28 09:19:38,722 - INFO -     - accuracy: 0.7500
2025-07-28 09:19:38,722 - INFO -   mmlu_stem:
2025-07-28 09:19:38,723 - INFO -     - accuracy: 0.5026
2025-07-28 09:19:38,723 - INFO -   mmlu_abstract_algebra:
2025-07-28 09:19:38,723 - INFO -     - accuracy: 0.2500
2025-07-28 09:19:38,723 - INFO -   mmlu_anatomy:
2025-07-28 09:19:38,723 - INFO -     - accuracy: 0.5500
2025-07-28 09:19:38,723 - INFO -   mmlu_astronomy:
2025-07-28 09:19:38,723 - INFO -     - accuracy: 0.7500
2025-07-28 09:19:38,724 - INFO -   mmlu_college_biology:
2025-07-28 09:19:38,724 - INFO -     - accuracy: 0.6500
2025-07-28 09:19:38,724 - INFO -   mmlu_college_chemistry:
2025-07-28 09:19:38,724 - INFO -     - accuracy: 0.4500
2025-07-28 09:19:38,724 - INFO -   mmlu_college_computer_science:
2025-07-28 09:19:38,724 - INFO -     - accuracy: 0.4500
2025-07-28 09:19:38,725 - INFO -   mmlu_college_mathematics:
2025-07-28 09:19:38,725 - INFO -     - accuracy: 0.4000
2025-07-28 09:19:38,725 - INFO -   mmlu_college_physics:
2025-07-28 09:19:38,725 - INFO -     - accuracy: 0.4500
2025-07-28 09:19:38,725 - INFO -   mmlu_computer_security:
2025-07-28 09:19:38,725 - INFO -     - accuracy: 0.6500
2025-07-28 09:19:38,726 - INFO -   mmlu_conceptual_physics:
2025-07-28 09:19:38,726 - INFO -     - accuracy: 0.6000
2025-07-28 09:19:38,726 - INFO -   mmlu_electrical_engineering:
2025-07-28 09:19:38,726 - INFO -     - accuracy: 0.4500
2025-07-28 09:19:38,726 - INFO -   mmlu_elementary_mathematics:
2025-07-28 09:19:38,727 - INFO -     - accuracy: 0.3000
2025-07-28 09:19:38,727 - INFO -   mmlu_high_school_biology:
2025-07-28 09:19:38,727 - INFO -     - accuracy: 0.8500
2025-07-28 09:19:38,727 - INFO -   mmlu_high_school_chemistry:
2025-07-28 09:19:38,727 - INFO -     - accuracy: 0.4000
2025-07-28 09:19:38,728 - INFO -   mmlu_high_school_computer_science:
2025-07-28 09:19:38,728 - INFO -     - accuracy: 0.6500
2025-07-28 09:19:38,728 - INFO -   mmlu_high_school_mathematics:
2025-07-28 09:19:38,728 - INFO -     - accuracy: 0.3500
2025-07-28 09:19:38,728 - INFO -   mmlu_high_school_physics:
2025-07-28 09:19:38,729 - INFO -     - accuracy: 0.6000
2025-07-28 09:19:38,729 - INFO -   mmlu_high_school_statistics:
2025-07-28 09:19:38,729 - INFO -     - accuracy: 0.4000
2025-07-28 09:19:38,729 - INFO -   mmlu_machine_learning:
2025-07-28 09:19:38,729 - INFO -     - accuracy: 0.3500
2025-07-28 09:19:38,730 - INFO - ============================================================

2025-07-28 09:19:38,743 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 8/10: arc_challenge
2025-07-28 09:19:38,744 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 09:19:38,744 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 09:19:38,744 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 09:19:38,744 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:19:46,634 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 09:19:51,905 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 09:19:51,906 - INFO - 
============================================================
2025-07-28 09:19:51,907 - INFO - Task 'arc_challenge' Results:
2025-07-28 09:19:51,908 - INFO - ============================================================
2025-07-28 09:19:51,909 - INFO -   arc_challenge:
2025-07-28 09:19:51,909 - INFO -     - accuracy: 0.5500
2025-07-28 09:19:51,909 - INFO -     - accuracy_norm: 0.5500
2025-07-28 09:19:51,909 - INFO - ============================================================

2025-07-28 09:19:51,920 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 9/10: arc_easy
2025-07-28 09:19:51,921 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'arc_easy' will use num_fewshot=0
2025-07-28 09:19:51,921 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 09:19:51,921 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 09:19:51,922 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:19:59,372 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 09:20:04,463 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 09:20:04,465 - INFO - 
============================================================
2025-07-28 09:20:04,466 - INFO - Task 'arc_easy' Results:
2025-07-28 09:20:04,467 - INFO - ============================================================
2025-07-28 09:20:04,467 - INFO -   arc_easy:
2025-07-28 09:20:04,467 - INFO -     - accuracy: 0.7000
2025-07-28 09:20:04,467 - INFO -     - accuracy_norm: 0.6500
2025-07-28 09:20:04,468 - INFO - ============================================================

2025-07-28 09:20:04,479 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 10/10: hellaswag
2025-07-28 09:20:04,479 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'hellaswag' will use num_fewshot=0
2025-07-28 09:20:04,480 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 09:20:04,480 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-28 09:20:04,480 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:20:18,047 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 09:20:23,509 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 09:20:23,510 - INFO - 
============================================================
2025-07-28 09:20:23,511 - INFO - Task 'hellaswag' Results:
2025-07-28 09:20:23,513 - INFO - ============================================================
2025-07-28 09:20:23,514 - INFO -   hellaswag:
2025-07-28 09:20:23,514 - INFO -     - accuracy: 0.4000
2025-07-28 09:20:23,514 - INFO -     - accuracy_norm: 0.4500
2025-07-28 09:20:23,514 - INFO - ============================================================

2025-07-28 09:20:23,526 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 09:20:23,528 - INFO - [Process 1881867] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/kanana-1.5-2.1b-instruct-2505/kanana-1.5-2.1b-instruct-2505_harness_11.json
2025-07-28 09:20:23,862 - INFO - Results uploaded to WandB as artifact
2025-07-28 09:20:23,872 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 09:20:23,873 - INFO - [Process 1881867] Successfully completed kanana-1.5-2.1b-instruct-2505_harness_11
2025-07-28 09:20:27,003 - INFO - Run kanana-1.5-2.1b-instruct-2505_harness_11 finished successfully
2025-07-28 09:20:27,004 - INFO - [Process 1881867] eagle-3b-preview_harness_12 assigned to cuda:0
2025-07-28 09:20:27,004 - INFO - [Process 1881867] eagle-3b-preview_harness_12 - using custom limit: 20
2025-07-28 09:20:28,147 - INFO - WandB run initialized: eagle-3b-preview_20250728_092027 (ID: f227ef58)
2025-07-28 09:20:28,367 - INFO - eagle-3b-preview_harness_12: Test mode (limit=2), setting num_fewshot=0
2025-07-28 09:20:28,367 - INFO - eagle-3b-preview_harness_12: Processing task 1/10: kmmlu
2025-07-28 09:20:28,368 - INFO - eagle-3b-preview_harness_12: Task 'kmmlu' will use num_fewshot=0
2025-07-28 09:20:28,368 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 09:20:28,368 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:21:40,975 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 09:21:40,975 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 09:21:40,975 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 09:21:40,976 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 09:21:40,977 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 09:21:40,978 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 09:21:40,979 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 09:21:40,979 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 09:21:40,979 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 09:21:40,979 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 09:21:40,979 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 09:21:40,979 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 09:21:40,979 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 09:21:40,979 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 09:21:58,551 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 09:21:58,552 - INFO - 
============================================================
2025-07-28 09:21:58,552 - INFO - Task 'kmmlu' Results:
2025-07-28 09:21:58,552 - INFO - ============================================================
2025-07-28 09:21:58,552 - INFO -   kmmlu:
2025-07-28 09:21:58,553 - INFO -     - accuracy: 0.1922
2025-07-28 09:21:58,553 - INFO -   kmmlu_applied_science:
2025-07-28 09:21:58,553 - INFO -     - accuracy: 0.1333
2025-07-28 09:21:58,553 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 09:21:58,553 - INFO -     - accuracy: 0.0000
2025-07-28 09:21:58,553 - INFO -   kmmlu_electronics_engineering:
2025-07-28 09:21:58,553 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,553 - INFO -   kmmlu_energy_management:
2025-07-28 09:21:58,553 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,554 - INFO -   kmmlu_environmental_science:
2025-07-28 09:21:58,554 - INFO -     - accuracy: 0.1500
2025-07-28 09:21:58,554 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 09:21:58,554 - INFO -     - accuracy: 0.3000
2025-07-28 09:21:58,554 - INFO -   kmmlu_geomatics:
2025-07-28 09:21:58,554 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,554 - INFO -   kmmlu_industrial_engineer:
2025-07-28 09:21:58,554 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,554 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 09:21:58,554 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,554 - INFO -   kmmlu_maritime_engineering:
2025-07-28 09:21:58,555 - INFO -     - accuracy: 0.1500
2025-07-28 09:21:58,555 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 09:21:58,555 - INFO -     - accuracy: 0.1500
2025-07-28 09:21:58,555 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 09:21:58,555 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,555 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 09:21:58,555 - INFO -     - accuracy: 0.2500
2025-07-28 09:21:58,555 - INFO -   kmmlu_humss:
2025-07-28 09:21:58,555 - INFO -     - accuracy: 0.2136
2025-07-28 09:21:58,555 - INFO -   kmmlu_accounting:
2025-07-28 09:21:58,555 - INFO -     - accuracy: 0.2000
2025-07-28 09:21:58,556 - INFO -   kmmlu_criminal_law:
2025-07-28 09:21:58,556 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,556 - INFO -   kmmlu_economics:
2025-07-28 09:21:58,556 - INFO -     - accuracy: 0.2000
2025-07-28 09:21:58,556 - INFO -   kmmlu_education:
2025-07-28 09:21:58,556 - INFO -     - accuracy: 0.1500
2025-07-28 09:21:58,556 - INFO -   kmmlu_korean_history:
2025-07-28 09:21:58,556 - INFO -     - accuracy: 0.2500
2025-07-28 09:21:58,556 - INFO -   kmmlu_law:
2025-07-28 09:21:58,556 - INFO -     - accuracy: 0.2500
2025-07-28 09:21:58,557 - INFO -   kmmlu_management:
2025-07-28 09:21:58,557 - INFO -     - accuracy: 0.4000
2025-07-28 09:21:58,557 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 09:21:58,557 - INFO -     - accuracy: 0.3000
2025-07-28 09:21:58,557 - INFO -   kmmlu_psychology:
2025-07-28 09:21:58,557 - INFO -     - accuracy: 0.2000
2025-07-28 09:21:58,557 - INFO -   kmmlu_social_welfare:
2025-07-28 09:21:58,557 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,557 - INFO -   kmmlu_taxation:
2025-07-28 09:21:58,557 - INFO -     - accuracy: 0.2000
2025-07-28 09:21:58,557 - INFO -   kmmlu_other:
2025-07-28 09:21:58,557 - INFO -     - accuracy: 0.2273
2025-07-28 09:21:58,558 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 09:21:58,558 - INFO -     - accuracy: 0.3500
2025-07-28 09:21:58,558 - INFO -   kmmlu_construction:
2025-07-28 09:21:58,558 - INFO -     - accuracy: 0.0500
2025-07-28 09:21:58,558 - INFO -   kmmlu_fashion:
2025-07-28 09:21:58,558 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,558 - INFO -   kmmlu_food_processing:
2025-07-28 09:21:58,558 - INFO -     - accuracy: 0.2000
2025-07-28 09:21:58,559 - INFO -   kmmlu_health:
2025-07-28 09:21:58,559 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,559 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 09:21:58,559 - INFO -     - accuracy: 0.1500
2025-07-28 09:21:58,559 - INFO -   kmmlu_marketing:
2025-07-28 09:21:58,559 - INFO -     - accuracy: 0.3500
2025-07-28 09:21:58,559 - INFO -   kmmlu_patent:
2025-07-28 09:21:58,559 - INFO -     - accuracy: 0.3000
2025-07-28 09:21:58,559 - INFO -   kmmlu_public_safety:
2025-07-28 09:21:58,559 - INFO -     - accuracy: 0.2500
2025-07-28 09:21:58,559 - INFO -   kmmlu_real_estate:
2025-07-28 09:21:58,560 - INFO -     - accuracy: 0.4000
2025-07-28 09:21:58,560 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 09:21:58,560 - INFO -     - accuracy: 0.2500
2025-07-28 09:21:58,560 - INFO -   kmmlu_stem:
2025-07-28 09:21:58,560 - INFO -     - accuracy: 0.2000
2025-07-28 09:21:58,560 - INFO -   kmmlu_biology:
2025-07-28 09:21:58,560 - INFO -     - accuracy: 0.2000
2025-07-28 09:21:58,560 - INFO -   kmmlu_chemical_engineering:
2025-07-28 09:21:58,560 - INFO -     - accuracy: 0.3500
2025-07-28 09:21:58,560 - INFO -   kmmlu_chemistry:
2025-07-28 09:21:58,560 - INFO -     - accuracy: 0.2000
2025-07-28 09:21:58,561 - INFO -   kmmlu_civil_engineering:
2025-07-28 09:21:58,561 - INFO -     - accuracy: 0.1500
2025-07-28 09:21:58,561 - INFO -   kmmlu_computer_science:
2025-07-28 09:21:58,561 - INFO -     - accuracy: 0.2500
2025-07-28 09:21:58,561 - INFO -   kmmlu_ecology:
2025-07-28 09:21:58,561 - INFO -     - accuracy: 0.2000
2025-07-28 09:21:58,561 - INFO -   kmmlu_electrical_engineering:
2025-07-28 09:21:58,561 - INFO -     - accuracy: 0.1000
2025-07-28 09:21:58,561 - INFO -   kmmlu_information_technology:
2025-07-28 09:21:58,561 - INFO -     - accuracy: 0.1500
2025-07-28 09:21:58,562 - INFO -   kmmlu_materials_engineering:
2025-07-28 09:21:58,562 - INFO -     - accuracy: 0.0500
2025-07-28 09:21:58,562 - INFO -   kmmlu_math:
2025-07-28 09:21:58,562 - INFO -     - accuracy: 0.2500
2025-07-28 09:21:58,562 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 09:21:58,562 - INFO -     - accuracy: 0.3000
2025-07-28 09:21:58,562 - INFO - ============================================================

2025-07-28 09:21:58,577 - INFO - eagle-3b-preview_harness_12: Processing task 2/10: kmmlu_hard
2025-07-28 09:21:58,577 - INFO - eagle-3b-preview_harness_12: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 09:21:58,578 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 09:21:58,598 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:23:10,704 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 09:23:10,704 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 09:23:10,705 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 09:23:10,706 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 09:23:10,707 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 09:23:10,708 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 09:23:10,708 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 09:23:10,708 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 09:23:10,708 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 09:23:10,708 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 09:23:10,708 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 09:23:10,708 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 09:23:10,708 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 09:23:10,708 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 09:23:28,485 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 09:23:28,486 - INFO - 
============================================================
2025-07-28 09:23:28,486 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 09:23:28,487 - INFO - ============================================================
2025-07-28 09:23:28,487 - INFO -   kmmlu_hard:
2025-07-28 09:23:28,487 - INFO -     - accuracy: 0.2056
2025-07-28 09:23:28,487 - INFO -   kmmlu_hard_applied_science:
2025-07-28 09:23:28,487 - INFO -     - accuracy: 0.1958
2025-07-28 09:23:28,488 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 09:23:28,488 - INFO -     - accuracy: 0.2500
2025-07-28 09:23:28,488 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 09:23:28,488 - INFO -     - accuracy: 0.1500
2025-07-28 09:23:28,488 - INFO -   kmmlu_hard_energy_management:
2025-07-28 09:23:28,488 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,488 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 09:23:28,488 - INFO -     - accuracy: 0.2500
2025-07-28 09:23:28,488 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 09:23:28,488 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,489 - INFO -   kmmlu_hard_geomatics:
2025-07-28 09:23:28,489 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,489 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 09:23:28,489 - INFO -     - accuracy: 0.1500
2025-07-28 09:23:28,489 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 09:23:28,489 - INFO -     - accuracy: 0.1500
2025-07-28 09:23:28,489 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 09:23:28,489 - INFO -     - accuracy: 0.3500
2025-07-28 09:23:28,489 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 09:23:28,489 - INFO -     - accuracy: 0.0500
2025-07-28 09:23:28,489 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 09:23:28,490 - INFO -     - accuracy: 0.1000
2025-07-28 09:23:28,490 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 09:23:28,490 - INFO -     - accuracy: 0.3000
2025-07-28 09:23:28,490 - INFO -   kmmlu_hard_humss:
2025-07-28 09:23:28,490 - INFO -     - accuracy: 0.1909
2025-07-28 09:23:28,490 - INFO -   kmmlu_hard_accounting:
2025-07-28 09:23:28,490 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,490 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 09:23:28,490 - INFO -     - accuracy: 0.1500
2025-07-28 09:23:28,490 - INFO -   kmmlu_hard_economics:
2025-07-28 09:23:28,490 - INFO -     - accuracy: 0.3000
2025-07-28 09:23:28,491 - INFO -   kmmlu_hard_education:
2025-07-28 09:23:28,491 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,491 - INFO -   kmmlu_hard_korean_history:
2025-07-28 09:23:28,491 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,491 - INFO -   kmmlu_hard_law:
2025-07-28 09:23:28,491 - INFO -     - accuracy: 0.2500
2025-07-28 09:23:28,491 - INFO -   kmmlu_hard_management:
2025-07-28 09:23:28,491 - INFO -     - accuracy: 0.0500
2025-07-28 09:23:28,491 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 09:23:28,491 - INFO -     - accuracy: 0.2500
2025-07-28 09:23:28,492 - INFO -   kmmlu_hard_psychology:
2025-07-28 09:23:28,492 - INFO -     - accuracy: 0.3500
2025-07-28 09:23:28,492 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 09:23:28,492 - INFO -     - accuracy: 0.0000
2025-07-28 09:23:28,492 - INFO -   kmmlu_hard_taxation:
2025-07-28 09:23:28,492 - INFO -     - accuracy: 0.1500
2025-07-28 09:23:28,492 - INFO -   kmmlu_hard_other:
2025-07-28 09:23:28,492 - INFO -     - accuracy: 0.2273
2025-07-28 09:23:28,492 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 09:23:28,492 - INFO -     - accuracy: 0.3500
2025-07-28 09:23:28,492 - INFO -   kmmlu_hard_construction:
2025-07-28 09:23:28,493 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,493 - INFO -   kmmlu_hard_fashion:
2025-07-28 09:23:28,493 - INFO -     - accuracy: 0.2500
2025-07-28 09:23:28,493 - INFO -   kmmlu_hard_food_processing:
2025-07-28 09:23:28,493 - INFO -     - accuracy: 0.3500
2025-07-28 09:23:28,493 - INFO -   kmmlu_hard_health:
2025-07-28 09:23:28,493 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,493 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 09:23:28,493 - INFO -     - accuracy: 0.1500
2025-07-28 09:23:28,493 - INFO -   kmmlu_hard_marketing:
2025-07-28 09:23:28,493 - INFO -     - accuracy: 0.3000
2025-07-28 09:23:28,494 - INFO -   kmmlu_hard_patent:
2025-07-28 09:23:28,494 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,494 - INFO -   kmmlu_hard_public_safety:
2025-07-28 09:23:28,494 - INFO -     - accuracy: 0.1500
2025-07-28 09:23:28,494 - INFO -   kmmlu_hard_real_estate:
2025-07-28 09:23:28,494 - INFO -     - accuracy: 0.1500
2025-07-28 09:23:28,494 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 09:23:28,494 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,494 - INFO -   kmmlu_hard_stem:
2025-07-28 09:23:28,494 - INFO -     - accuracy: 0.2091
2025-07-28 09:23:28,494 - INFO -   kmmlu_hard_biology:
2025-07-28 09:23:28,495 - INFO -     - accuracy: 0.3500
2025-07-28 09:23:28,495 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 09:23:28,495 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,495 - INFO -   kmmlu_hard_chemistry:
2025-07-28 09:23:28,495 - INFO -     - accuracy: 0.1000
2025-07-28 09:23:28,495 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 09:23:28,495 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,495 - INFO -   kmmlu_hard_computer_science:
2025-07-28 09:23:28,495 - INFO -     - accuracy: 0.1500
2025-07-28 09:23:28,495 - INFO -   kmmlu_hard_ecology:
2025-07-28 09:23:28,495 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,496 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 09:23:28,496 - INFO -     - accuracy: 0.1500
2025-07-28 09:23:28,496 - INFO -   kmmlu_hard_information_technology:
2025-07-28 09:23:28,496 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,496 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 09:23:28,496 - INFO -     - accuracy: 0.3000
2025-07-28 09:23:28,496 - INFO -   kmmlu_hard_math:
2025-07-28 09:23:28,496 - INFO -     - accuracy: 0.2500
2025-07-28 09:23:28,496 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 09:23:28,496 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:28,497 - INFO - ============================================================

2025-07-28 09:23:28,511 - INFO - eagle-3b-preview_harness_12: Processing task 3/10: haerae
2025-07-28 09:23:28,512 - INFO - eagle-3b-preview_harness_12: Task 'haerae' will use num_fewshot=0
2025-07-28 09:23:28,513 - INFO - eagle-3b-preview_harness_12: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 09:23:28,513 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:23:45,168 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 09:23:45,169 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 09:23:45,169 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 09:23:45,169 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 09:23:45,169 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 09:23:54,833 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 09:23:54,835 - INFO - 
============================================================
2025-07-28 09:23:54,835 - INFO - Task 'haerae' Results:
2025-07-28 09:23:54,835 - INFO - ============================================================
2025-07-28 09:23:54,835 - INFO -   haerae:
2025-07-28 09:23:54,835 - INFO -     - accuracy: 0.1700
2025-07-28 09:23:54,836 - INFO -     - accuracy_norm: 0.1700
2025-07-28 09:23:54,836 - INFO -   haerae_general_knowledge:
2025-07-28 09:23:54,836 - INFO -     - accuracy: 0.2000
2025-07-28 09:23:54,836 - INFO -     - accuracy_norm: 0.2000
2025-07-28 09:23:54,836 - INFO -   haerae_history:
2025-07-28 09:23:54,836 - INFO -     - accuracy: 0.0000
2025-07-28 09:23:54,836 - INFO -     - accuracy_norm: 0.0000
2025-07-28 09:23:54,836 - INFO -   haerae_loan_word:
2025-07-28 09:23:54,837 - INFO -     - accuracy: 0.2500
2025-07-28 09:23:54,837 - INFO -     - accuracy_norm: 0.2500
2025-07-28 09:23:54,837 - INFO -   haerae_rare_word:
2025-07-28 09:23:54,837 - INFO -     - accuracy: 0.3000
2025-07-28 09:23:54,837 - INFO -     - accuracy_norm: 0.3000
2025-07-28 09:23:54,837 - INFO -   haerae_standard_nomenclature:
2025-07-28 09:23:54,837 - INFO -     - accuracy: 0.1000
2025-07-28 09:23:54,837 - INFO -     - accuracy_norm: 0.1000
2025-07-28 09:23:54,837 - INFO - ============================================================

2025-07-28 09:23:54,852 - INFO - eagle-3b-preview_harness_12: Processing task 4/10: kobest
2025-07-28 09:23:54,853 - INFO - eagle-3b-preview_harness_12: Task 'kobest' will use num_fewshot=0
2025-07-28 09:23:54,854 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 09:23:54,854 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:24:15,142 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 09:24:15,142 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 09:24:15,142 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 09:24:15,142 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 09:24:15,142 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 09:24:21,198 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 09:24:21,199 - INFO - 
============================================================
2025-07-28 09:24:21,199 - INFO - Task 'kobest' Results:
2025-07-28 09:24:21,200 - INFO - ============================================================
2025-07-28 09:24:21,200 - INFO -   kobest:
2025-07-28 09:24:21,200 - INFO -     - accuracy: 0.4700
2025-07-28 09:24:21,200 - INFO -     - accuracy_norm: 0.4500
2025-07-28 09:24:21,200 - INFO -     - f1: 0.3983
2025-07-28 09:24:21,200 - INFO -   kobest_boolq:
2025-07-28 09:24:21,200 - INFO -     - accuracy: 0.5000
2025-07-28 09:24:21,200 - INFO -     - f1: 0.3333
2025-07-28 09:24:21,200 - INFO -   kobest_copa:
2025-07-28 09:24:21,201 - INFO -     - accuracy: 0.5500
2025-07-28 09:24:21,201 - INFO -     - f1: 0.5489
2025-07-28 09:24:21,201 - INFO -   kobest_hellaswag:
2025-07-28 09:24:21,201 - INFO -     - accuracy: 0.3500
2025-07-28 09:24:21,201 - INFO -     - accuracy_norm: 0.4500
2025-07-28 09:24:21,201 - INFO -     - f1: 0.3547
2025-07-28 09:24:21,201 - INFO -   kobest_sentineg:
2025-07-28 09:24:21,201 - INFO -     - accuracy: 0.4000
2025-07-28 09:24:21,201 - INFO -     - f1: 0.4000
2025-07-28 09:24:21,201 - INFO -   kobest_wic:
2025-07-28 09:24:21,201 - INFO -     - accuracy: 0.5500
2025-07-28 09:24:21,202 - INFO -     - f1: 0.3548
2025-07-28 09:24:21,202 - INFO - ============================================================

2025-07-28 09:24:21,217 - INFO - eagle-3b-preview_harness_12: Processing task 5/10: csatqa
2025-07-28 09:24:21,219 - INFO - eagle-3b-preview_harness_12: Task 'csatqa' detected as zero-shot task
2025-07-28 09:24:21,219 - INFO - eagle-3b-preview_harness_12: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 09:24:21,219 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:24:34,312 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 09:24:34,313 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 09:24:34,313 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 09:24:34,313 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 09:24:34,313 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 09:24:34,313 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 09:25:06,852 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 09:25:06,853 - INFO - 
============================================================
2025-07-28 09:25:06,854 - INFO - Task 'csatqa' Results:
2025-07-28 09:25:06,854 - INFO - ============================================================
2025-07-28 09:25:06,854 - INFO -   csatqa:
2025-07-28 09:25:06,854 - INFO -     - accuracy: 0.1532
2025-07-28 09:25:06,854 - INFO -     - accuracy_norm: 0.1532
2025-07-28 09:25:06,854 - INFO -   csatqa_gr:
2025-07-28 09:25:06,854 - INFO -     - accuracy: 0.1000
2025-07-28 09:25:06,855 - INFO -     - accuracy_norm: 0.1000
2025-07-28 09:25:06,855 - INFO -   csatqa_li:
2025-07-28 09:25:06,855 - INFO -     - accuracy: 0.2000
2025-07-28 09:25:06,855 - INFO -     - accuracy_norm: 0.2000
2025-07-28 09:25:06,855 - INFO -   csatqa_rch:
2025-07-28 09:25:06,855 - INFO -     - accuracy: 0.1500
2025-07-28 09:25:06,855 - INFO -     - accuracy_norm: 0.1500
2025-07-28 09:25:06,856 - INFO -   csatqa_rcs:
2025-07-28 09:25:06,856 - INFO -     - accuracy: 0.2000
2025-07-28 09:25:06,856 - INFO -     - accuracy_norm: 0.2000
2025-07-28 09:25:06,856 - INFO -   csatqa_rcss:
2025-07-28 09:25:06,856 - INFO -     - accuracy: 0.1000
2025-07-28 09:25:06,856 - INFO -     - accuracy_norm: 0.1000
2025-07-28 09:25:06,856 - INFO -   csatqa_wr:
2025-07-28 09:25:06,856 - INFO -     - accuracy: 0.1818
2025-07-28 09:25:06,856 - INFO -     - accuracy_norm: 0.1818
2025-07-28 09:25:06,857 - INFO - ============================================================

2025-07-28 09:25:06,874 - INFO - eagle-3b-preview_harness_12: Processing task 6/10: kormedmcqa
2025-07-28 09:25:06,875 - INFO - eagle-3b-preview_harness_12: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 09:25:06,876 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 09:25:06,876 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:25:25,395 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 09:25:25,396 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 09:25:25,396 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 09:25:25,396 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 09:25:46,042 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 09:25:46,043 - INFO - 
============================================================
2025-07-28 09:25:46,044 - INFO - Task 'kormedmcqa' Results:
2025-07-28 09:25:46,044 - INFO - ============================================================
2025-07-28 09:25:46,044 - INFO -   kormedmcqa:
2025-07-28 09:25:46,044 - INFO -     - exact_match: 0.1875
2025-07-28 09:25:46,044 - INFO -   kormedmcqa_dentist:
2025-07-28 09:25:46,044 - INFO -     - exact_match: 0.1500
2025-07-28 09:25:46,045 - INFO -   kormedmcqa_doctor:
2025-07-28 09:25:46,045 - INFO -     - exact_match: 0.2000
2025-07-28 09:25:46,045 - INFO -   kormedmcqa_nurse:
2025-07-28 09:25:46,045 - INFO -     - exact_match: 0.1500
2025-07-28 09:25:46,045 - INFO -   kormedmcqa_pharm:
2025-07-28 09:25:46,045 - INFO -     - exact_match: 0.2500
2025-07-28 09:25:46,045 - INFO - ============================================================

2025-07-28 09:25:46,061 - INFO - eagle-3b-preview_harness_12: Processing task 7/10: mmlu
2025-07-28 09:25:46,062 - INFO - eagle-3b-preview_harness_12: Task 'mmlu' will use num_fewshot=0
2025-07-28 09:25:46,062 - INFO - eagle-3b-preview_harness_12: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 09:25:46,062 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:28:35,064 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 09:28:35,065 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 09:28:35,065 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 09:28:35,065 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 09:28:35,065 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 09:28:35,066 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 09:28:35,067 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 09:28:35,068 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 09:28:35,069 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 09:28:35,070 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 09:28:35,070 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 09:28:35,070 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 09:28:35,070 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 09:28:35,070 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 09:28:35,070 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 09:28:35,070 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 09:28:57,904 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 09:28:57,905 - INFO - 
============================================================
2025-07-28 09:28:57,905 - INFO - Task 'mmlu' Results:
2025-07-28 09:28:57,905 - INFO - ============================================================
2025-07-28 09:28:57,905 - INFO -   mmlu:
2025-07-28 09:28:57,905 - INFO -     - accuracy: 0.2368
2025-07-28 09:28:57,905 - INFO -   mmlu_humanities:
2025-07-28 09:28:57,906 - INFO -     - accuracy: 0.2269
2025-07-28 09:28:57,906 - INFO -   mmlu_formal_logic:
2025-07-28 09:28:57,906 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,906 - INFO -   mmlu_high_school_european_history:
2025-07-28 09:28:57,906 - INFO -     - accuracy: 0.2500
2025-07-28 09:28:57,906 - INFO -   mmlu_high_school_us_history:
2025-07-28 09:28:57,906 - INFO -     - accuracy: 0.1000
2025-07-28 09:28:57,906 - INFO -   mmlu_high_school_world_history:
2025-07-28 09:28:57,907 - INFO -     - accuracy: 0.2500
2025-07-28 09:28:57,907 - INFO -   mmlu_international_law:
2025-07-28 09:28:57,907 - INFO -     - accuracy: 0.1500
2025-07-28 09:28:57,907 - INFO -   mmlu_jurisprudence:
2025-07-28 09:28:57,907 - INFO -     - accuracy: 0.1500
2025-07-28 09:28:57,908 - INFO -   mmlu_logical_fallacies:
2025-07-28 09:28:57,908 - INFO -     - accuracy: 0.3500
2025-07-28 09:28:57,908 - INFO -   mmlu_moral_disputes:
2025-07-28 09:28:57,908 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,908 - INFO -   mmlu_moral_scenarios:
2025-07-28 09:28:57,908 - INFO -     - accuracy: 0.2500
2025-07-28 09:28:57,908 - INFO -   mmlu_philosophy:
2025-07-28 09:28:57,908 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,908 - INFO -   mmlu_prehistory:
2025-07-28 09:28:57,908 - INFO -     - accuracy: 0.3500
2025-07-28 09:28:57,909 - INFO -   mmlu_professional_law:
2025-07-28 09:28:57,909 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,909 - INFO -   mmlu_world_religions:
2025-07-28 09:28:57,909 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,909 - INFO -   mmlu_other:
2025-07-28 09:28:57,909 - INFO -     - accuracy: 0.2154
2025-07-28 09:28:57,909 - INFO -   mmlu_business_ethics:
2025-07-28 09:28:57,909 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,910 - INFO -   mmlu_clinical_knowledge:
2025-07-28 09:28:57,910 - INFO -     - accuracy: 0.1000
2025-07-28 09:28:57,910 - INFO -   mmlu_college_medicine:
2025-07-28 09:28:57,910 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,910 - INFO -   mmlu_global_facts:
2025-07-28 09:28:57,910 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,910 - INFO -   mmlu_human_aging:
2025-07-28 09:28:57,910 - INFO -     - accuracy: 0.0500
2025-07-28 09:28:57,910 - INFO -   mmlu_management:
2025-07-28 09:28:57,910 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,911 - INFO -   mmlu_marketing:
2025-07-28 09:28:57,911 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,911 - INFO -   mmlu_medical_genetics:
2025-07-28 09:28:57,911 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,911 - INFO -   mmlu_miscellaneous:
2025-07-28 09:28:57,911 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,918 - INFO -   mmlu_nutrition:
2025-07-28 09:28:57,918 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,918 - INFO -   mmlu_professional_accounting:
2025-07-28 09:28:57,918 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,918 - INFO -   mmlu_professional_medicine:
2025-07-28 09:28:57,919 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,919 - INFO -   mmlu_virology:
2025-07-28 09:28:57,919 - INFO -     - accuracy: 0.1500
2025-07-28 09:28:57,919 - INFO -   mmlu_social_sciences:
2025-07-28 09:28:57,919 - INFO -     - accuracy: 0.1917
2025-07-28 09:28:57,919 - INFO -   mmlu_econometrics:
2025-07-28 09:28:57,919 - INFO -     - accuracy: 0.1000
2025-07-28 09:28:57,919 - INFO -   mmlu_high_school_geography:
2025-07-28 09:28:57,919 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,920 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 09:28:57,920 - INFO -     - accuracy: 0.1500
2025-07-28 09:28:57,920 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 09:28:57,920 - INFO -     - accuracy: 0.1000
2025-07-28 09:28:57,920 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 09:28:57,920 - INFO -     - accuracy: 0.1000
2025-07-28 09:28:57,920 - INFO -   mmlu_high_school_psychology:
2025-07-28 09:28:57,920 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,920 - INFO -   mmlu_human_sexuality:
2025-07-28 09:28:57,921 - INFO -     - accuracy: 0.2500
2025-07-28 09:28:57,921 - INFO -   mmlu_professional_psychology:
2025-07-28 09:28:57,921 - INFO -     - accuracy: 0.1500
2025-07-28 09:28:57,921 - INFO -   mmlu_public_relations:
2025-07-28 09:28:57,921 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,921 - INFO -   mmlu_security_studies:
2025-07-28 09:28:57,921 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,921 - INFO -   mmlu_sociology:
2025-07-28 09:28:57,921 - INFO -     - accuracy: 0.3500
2025-07-28 09:28:57,922 - INFO -   mmlu_us_foreign_policy:
2025-07-28 09:28:57,922 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,922 - INFO -   mmlu_stem:
2025-07-28 09:28:57,922 - INFO -     - accuracy: 0.2868
2025-07-28 09:28:57,922 - INFO -   mmlu_abstract_algebra:
2025-07-28 09:28:57,922 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,922 - INFO -   mmlu_anatomy:
2025-07-28 09:28:57,922 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,923 - INFO -   mmlu_astronomy:
2025-07-28 09:28:57,923 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,923 - INFO -   mmlu_college_biology:
2025-07-28 09:28:57,923 - INFO -     - accuracy: 0.2500
2025-07-28 09:28:57,923 - INFO -   mmlu_college_chemistry:
2025-07-28 09:28:57,923 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,923 - INFO -   mmlu_college_computer_science:
2025-07-28 09:28:57,923 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,923 - INFO -   mmlu_college_mathematics:
2025-07-28 09:28:57,923 - INFO -     - accuracy: 0.4000
2025-07-28 09:28:57,924 - INFO -   mmlu_college_physics:
2025-07-28 09:28:57,924 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,924 - INFO -   mmlu_computer_security:
2025-07-28 09:28:57,924 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,924 - INFO -   mmlu_conceptual_physics:
2025-07-28 09:28:57,924 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,924 - INFO -   mmlu_electrical_engineering:
2025-07-28 09:28:57,924 - INFO -     - accuracy: 0.2500
2025-07-28 09:28:57,924 - INFO -   mmlu_elementary_mathematics:
2025-07-28 09:28:57,925 - INFO -     - accuracy: 0.2500
2025-07-28 09:28:57,925 - INFO -   mmlu_high_school_biology:
2025-07-28 09:28:57,925 - INFO -     - accuracy: 0.2500
2025-07-28 09:28:57,925 - INFO -   mmlu_high_school_chemistry:
2025-07-28 09:28:57,925 - INFO -     - accuracy: 0.4500
2025-07-28 09:28:57,925 - INFO -   mmlu_high_school_computer_science:
2025-07-28 09:28:57,925 - INFO -     - accuracy: 0.2000
2025-07-28 09:28:57,925 - INFO -   mmlu_high_school_mathematics:
2025-07-28 09:28:57,925 - INFO -     - accuracy: 0.2500
2025-07-28 09:28:57,926 - INFO -   mmlu_high_school_physics:
2025-07-28 09:28:57,926 - INFO -     - accuracy: 0.3500
2025-07-28 09:28:57,926 - INFO -   mmlu_high_school_statistics:
2025-07-28 09:28:57,926 - INFO -     - accuracy: 0.3000
2025-07-28 09:28:57,926 - INFO -   mmlu_machine_learning:
2025-07-28 09:28:57,926 - INFO -     - accuracy: 0.4000
2025-07-28 09:28:57,926 - INFO - ============================================================

2025-07-28 09:28:57,943 - INFO - eagle-3b-preview_harness_12: Processing task 8/10: arc_challenge
2025-07-28 09:28:57,944 - INFO - eagle-3b-preview_harness_12: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 09:28:57,944 - INFO - eagle-3b-preview_harness_12: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 09:28:57,944 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:29:06,071 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 09:29:10,204 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 09:29:10,206 - INFO - 
============================================================
2025-07-28 09:29:10,206 - INFO - Task 'arc_challenge' Results:
2025-07-28 09:29:10,207 - INFO - ============================================================
2025-07-28 09:29:10,207 - INFO -   arc_challenge:
2025-07-28 09:29:10,207 - INFO -     - accuracy: 0.2000
2025-07-28 09:29:10,207 - INFO -     - accuracy_norm: 0.1500
2025-07-28 09:29:10,207 - INFO - ============================================================

2025-07-28 09:29:10,221 - INFO - eagle-3b-preview_harness_12: Processing task 9/10: arc_easy
2025-07-28 09:29:10,223 - INFO - eagle-3b-preview_harness_12: Task 'arc_easy' will use num_fewshot=0
2025-07-28 09:29:10,223 - INFO - eagle-3b-preview_harness_12: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 09:29:10,223 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:29:18,148 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 09:29:22,228 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 09:29:22,230 - INFO - 
============================================================
2025-07-28 09:29:22,230 - INFO - Task 'arc_easy' Results:
2025-07-28 09:29:22,230 - INFO - ============================================================
2025-07-28 09:29:22,230 - INFO -   arc_easy:
2025-07-28 09:29:22,231 - INFO -     - accuracy: 0.5500
2025-07-28 09:29:22,231 - INFO -     - accuracy_norm: 0.4000
2025-07-28 09:29:22,231 - INFO - ============================================================

2025-07-28 09:29:22,246 - INFO - eagle-3b-preview_harness_12: Processing task 10/10: hellaswag
2025-07-28 09:29:22,247 - INFO - eagle-3b-preview_harness_12: Task 'hellaswag' will use num_fewshot=0
2025-07-28 09:29:22,247 - INFO - eagle-3b-preview_harness_12: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 09:29:22,248 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:29:36,198 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 09:29:40,355 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 09:29:40,357 - INFO - 
============================================================
2025-07-28 09:29:40,357 - INFO - Task 'hellaswag' Results:
2025-07-28 09:29:40,357 - INFO - ============================================================
2025-07-28 09:29:40,357 - INFO -   hellaswag:
2025-07-28 09:29:40,357 - INFO -     - accuracy: 0.3500
2025-07-28 09:29:40,357 - INFO -     - accuracy_norm: 0.4000
2025-07-28 09:29:40,358 - INFO - ============================================================

2025-07-28 09:29:40,373 - INFO - eagle-3b-preview_harness_12: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 09:29:40,375 - INFO - [Process 1881867] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/eagle-3b-preview/eagle-3b-preview_harness_12.json
2025-07-28 09:29:40,657 - INFO - Results uploaded to WandB as artifact
2025-07-28 09:29:40,666 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 09:29:40,668 - INFO - [Process 1881867] Successfully completed eagle-3b-preview_harness_12
2025-07-28 09:29:43,962 - INFO - Run eagle-3b-preview_harness_12 finished successfully
2025-07-28 09:29:45,291 - INFO - Processing 3 large models with single GPU
2025-07-28 09:29:45,292 - INFO - [Process 1865749] gemma-3-12b-it_harness_3 assigned to cuda:0
2025-07-28 09:29:45,292 - INFO - [Process 1865749] gemma-3-12b-it_harness_3 - using custom limit: 20
2025-07-28 09:29:46,554 - INFO - WandB run initialized: gemma-3-12b-it_20250728_092945 (ID: 8a9e3e52)
2025-07-28 09:29:48,287 - INFO - gemma-3-12b-it_harness_3: Gemma settings applied - max_gen_toks=256
2025-07-28 09:29:48,287 - INFO - gemma-3-12b-it_harness_3: Test mode (limit=2), setting num_fewshot=0
2025-07-28 09:29:48,287 - INFO - GPU memory available: 79.3GB
2025-07-28 09:29:48,287 - INFO - gemma-3-12b-it_harness_3: Using 8bit=True, batch_size=1
2025-07-28 09:29:48,287 - INFO - gemma-3-12b-it_harness_3: Gemma model detected, will handle cache settings after loading
2025-07-28 09:30:11,167 - INFO - gemma-3-12b-it_harness_3: Processing task 1/10: kmmlu
2025-07-28 09:30:11,168 - INFO - gemma-3-12b-it_harness_3: Task 'kmmlu' will use num_fewshot=0
2025-07-28 09:30:11,168 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 09:30:11,169 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:31:24,624 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 09:31:24,624 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 09:31:24,624 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 09:31:24,624 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 09:31:24,625 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 09:31:24,625 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 09:31:24,625 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 09:31:24,625 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 09:31:24,625 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 09:31:24,625 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 09:31:24,625 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 09:31:24,625 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 09:31:24,625 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 09:31:24,625 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 09:31:24,626 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 09:31:24,626 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 09:31:24,626 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 09:31:24,626 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 09:31:24,626 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 09:31:24,626 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 09:31:24,626 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 09:31:24,626 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 09:31:24,626 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 09:31:24,626 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 09:31:24,627 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 09:31:24,627 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 09:31:24,627 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 09:31:24,627 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 09:31:24,627 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 09:31:24,627 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 09:31:24,627 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 09:31:24,627 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 09:31:24,627 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 09:31:24,627 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 09:31:24,628 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 09:31:24,628 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 09:31:24,628 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 09:31:24,628 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 09:31:24,628 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 09:31:24,628 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 09:31:24,628 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 09:31:24,628 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 09:31:24,628 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 09:31:24,628 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 09:31:24,629 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 09:36:34,857 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 09:36:34,859 - INFO - 
============================================================
2025-07-28 09:36:34,860 - INFO - Task 'kmmlu' Results:
2025-07-28 09:36:34,861 - INFO - ============================================================
2025-07-28 09:36:34,861 - INFO -   kmmlu:
2025-07-28 09:36:34,861 - INFO -     - accuracy: 0.3733
2025-07-28 09:36:34,861 - INFO -   kmmlu_applied_science:
2025-07-28 09:36:34,861 - INFO -     - accuracy: 0.3250
2025-07-28 09:36:34,861 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 09:36:34,862 - INFO -     - accuracy: 0.3500
2025-07-28 09:36:34,862 - INFO -   kmmlu_electronics_engineering:
2025-07-28 09:36:34,862 - INFO -     - accuracy: 0.6500
2025-07-28 09:36:34,862 - INFO -   kmmlu_energy_management:
2025-07-28 09:36:34,862 - INFO -     - accuracy: 0.1000
2025-07-28 09:36:34,862 - INFO -   kmmlu_environmental_science:
2025-07-28 09:36:34,862 - INFO -     - accuracy: 0.3000
2025-07-28 09:36:34,862 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 09:36:34,863 - INFO -     - accuracy: 0.3000
2025-07-28 09:36:34,863 - INFO -   kmmlu_geomatics:
2025-07-28 09:36:34,863 - INFO -     - accuracy: 0.3000
2025-07-28 09:36:34,863 - INFO -   kmmlu_industrial_engineer:
2025-07-28 09:36:34,863 - INFO -     - accuracy: 0.3000
2025-07-28 09:36:34,863 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 09:36:34,863 - INFO -     - accuracy: 0.3000
2025-07-28 09:36:34,863 - INFO -   kmmlu_maritime_engineering:
2025-07-28 09:36:34,864 - INFO -     - accuracy: 0.3000
2025-07-28 09:36:34,864 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 09:36:34,864 - INFO -     - accuracy: 0.3500
2025-07-28 09:36:34,864 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 09:36:34,864 - INFO -     - accuracy: 0.2500
2025-07-28 09:36:34,864 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 09:36:34,864 - INFO -     - accuracy: 0.4000
2025-07-28 09:36:34,864 - INFO -   kmmlu_humss:
2025-07-28 09:36:34,864 - INFO -     - accuracy: 0.4682
2025-07-28 09:36:34,865 - INFO -   kmmlu_accounting:
2025-07-28 09:36:34,866 - INFO -     - accuracy: 0.5000
2025-07-28 09:36:34,866 - INFO -   kmmlu_criminal_law:
2025-07-28 09:36:34,866 - INFO -     - accuracy: 0.2500
2025-07-28 09:36:34,866 - INFO -   kmmlu_economics:
2025-07-28 09:36:34,866 - INFO -     - accuracy: 0.7500
2025-07-28 09:36:34,866 - INFO -   kmmlu_education:
2025-07-28 09:36:34,866 - INFO -     - accuracy: 0.5500
2025-07-28 09:36:34,866 - INFO -   kmmlu_korean_history:
2025-07-28 09:36:34,867 - INFO -     - accuracy: 0.2500
2025-07-28 09:36:34,867 - INFO -   kmmlu_law:
2025-07-28 09:36:34,867 - INFO -     - accuracy: 0.1000
2025-07-28 09:36:34,882 - INFO -   kmmlu_management:
2025-07-28 09:36:34,882 - INFO -     - accuracy: 0.6000
2025-07-28 09:36:34,882 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 09:36:34,882 - INFO -     - accuracy: 0.9000
2025-07-28 09:36:34,882 - INFO -   kmmlu_psychology:
2025-07-28 09:36:34,883 - INFO -     - accuracy: 0.3000
2025-07-28 09:36:34,883 - INFO -   kmmlu_social_welfare:
2025-07-28 09:36:34,883 - INFO -     - accuracy: 0.4500
2025-07-28 09:36:34,883 - INFO -   kmmlu_taxation:
2025-07-28 09:36:34,883 - INFO -     - accuracy: 0.5000
2025-07-28 09:36:34,883 - INFO -   kmmlu_other:
2025-07-28 09:36:34,883 - INFO -     - accuracy: 0.3409
2025-07-28 09:36:34,883 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 09:36:34,883 - INFO -     - accuracy: 0.1000
2025-07-28 09:36:34,884 - INFO -   kmmlu_construction:
2025-07-28 09:36:34,884 - INFO -     - accuracy: 0.3500
2025-07-28 09:36:34,884 - INFO -   kmmlu_fashion:
2025-07-28 09:36:34,884 - INFO -     - accuracy: 0.1000
2025-07-28 09:36:34,884 - INFO -   kmmlu_food_processing:
2025-07-28 09:36:34,884 - INFO -     - accuracy: 0.4500
2025-07-28 09:36:34,884 - INFO -   kmmlu_health:
2025-07-28 09:36:34,884 - INFO -     - accuracy: 0.6500
2025-07-28 09:36:34,885 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 09:36:34,885 - INFO -     - accuracy: 0.7000
2025-07-28 09:36:34,885 - INFO -   kmmlu_marketing:
2025-07-28 09:36:34,885 - INFO -     - accuracy: 0.5000
2025-07-28 09:36:34,885 - INFO -   kmmlu_patent:
2025-07-28 09:36:34,885 - INFO -     - accuracy: 0.1500
2025-07-28 09:36:34,885 - INFO -   kmmlu_public_safety:
2025-07-28 09:36:34,885 - INFO -     - accuracy: 0.3000
2025-07-28 09:36:34,885 - INFO -   kmmlu_real_estate:
2025-07-28 09:36:34,886 - INFO -     - accuracy: 0.2500
2025-07-28 09:36:34,886 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 09:36:34,886 - INFO -     - accuracy: 0.2000
2025-07-28 09:36:34,886 - INFO -   kmmlu_stem:
2025-07-28 09:36:34,886 - INFO -     - accuracy: 0.3636
2025-07-28 09:36:34,886 - INFO -   kmmlu_biology:
2025-07-28 09:36:34,886 - INFO -     - accuracy: 0.2500
2025-07-28 09:36:34,886 - INFO -   kmmlu_chemical_engineering:
2025-07-28 09:36:34,886 - INFO -     - accuracy: 0.2500
2025-07-28 09:36:34,887 - INFO -   kmmlu_chemistry:
2025-07-28 09:36:34,887 - INFO -     - accuracy: 0.4500
2025-07-28 09:36:34,887 - INFO -   kmmlu_civil_engineering:
2025-07-28 09:36:34,887 - INFO -     - accuracy: 0.3500
2025-07-28 09:36:34,887 - INFO -   kmmlu_computer_science:
2025-07-28 09:36:34,887 - INFO -     - accuracy: 0.6000
2025-07-28 09:36:34,887 - INFO -   kmmlu_ecology:
2025-07-28 09:36:34,887 - INFO -     - accuracy: 0.4000
2025-07-28 09:36:34,887 - INFO -   kmmlu_electrical_engineering:
2025-07-28 09:36:34,888 - INFO -     - accuracy: 0.2000
2025-07-28 09:36:34,888 - INFO -   kmmlu_information_technology:
2025-07-28 09:36:34,888 - INFO -     - accuracy: 0.5500
2025-07-28 09:36:34,888 - INFO -   kmmlu_materials_engineering:
2025-07-28 09:36:34,888 - INFO -     - accuracy: 0.4000
2025-07-28 09:36:34,888 - INFO -   kmmlu_math:
2025-07-28 09:36:34,888 - INFO -     - accuracy: 0.2000
2025-07-28 09:36:34,888 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 09:36:34,888 - INFO -     - accuracy: 0.3500
2025-07-28 09:36:34,889 - INFO - ============================================================

2025-07-28 09:36:34,893 - INFO - gemma-3-12b-it_harness_3: Processing task 2/10: kmmlu_hard
2025-07-28 09:36:34,894 - INFO - gemma-3-12b-it_harness_3: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 09:36:34,894 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 09:36:34,894 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:37:48,194 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 09:37:48,194 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 09:37:48,194 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 09:37:48,194 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 09:37:48,194 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 09:37:48,195 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 09:37:48,195 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 09:37:48,195 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 09:37:48,195 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 09:37:48,195 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 09:37:48,195 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 09:37:48,195 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 09:37:48,195 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 09:37:48,195 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 09:37:48,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 09:37:48,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 09:37:48,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 09:37:48,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 09:37:48,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 09:37:48,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 09:37:48,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 09:37:48,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 09:37:48,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 09:37:48,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 09:37:48,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 09:37:48,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 09:37:48,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 09:37:48,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 09:37:48,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 09:37:48,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 09:37:48,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 09:37:48,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 09:37:48,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 09:37:48,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 09:37:48,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 09:43:04,495 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 09:43:04,496 - INFO - 
============================================================
2025-07-28 09:43:04,498 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 09:43:04,499 - INFO - ============================================================
2025-07-28 09:43:04,499 - INFO -   kmmlu_hard:
2025-07-28 09:43:04,499 - INFO -     - accuracy: 0.2567
2025-07-28 09:43:04,499 - INFO -   kmmlu_hard_applied_science:
2025-07-28 09:43:04,499 - INFO -     - accuracy: 0.2542
2025-07-28 09:43:04,499 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 09:43:04,500 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,500 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 09:43:04,500 - INFO -     - accuracy: 0.2000
2025-07-28 09:43:04,500 - INFO -   kmmlu_hard_energy_management:
2025-07-28 09:43:04,500 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,500 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 09:43:04,500 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,500 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 09:43:04,500 - INFO -     - accuracy: 0.1000
2025-07-28 09:43:04,501 - INFO -   kmmlu_hard_geomatics:
2025-07-28 09:43:04,501 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,501 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 09:43:04,501 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,501 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 09:43:04,501 - INFO -     - accuracy: 0.3000
2025-07-28 09:43:04,501 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 09:43:04,501 - INFO -     - accuracy: 0.4000
2025-07-28 09:43:04,502 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 09:43:04,502 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,502 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 09:43:04,502 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,502 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 09:43:04,502 - INFO -     - accuracy: 0.3000
2025-07-28 09:43:04,502 - INFO -   kmmlu_hard_humss:
2025-07-28 09:43:04,502 - INFO -     - accuracy: 0.2364
2025-07-28 09:43:04,502 - INFO -   kmmlu_hard_accounting:
2025-07-28 09:43:04,502 - INFO -     - accuracy: 0.3000
2025-07-28 09:43:04,503 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 09:43:04,503 - INFO -     - accuracy: 0.1500
2025-07-28 09:43:04,503 - INFO -   kmmlu_hard_economics:
2025-07-28 09:43:04,503 - INFO -     - accuracy: 0.2000
2025-07-28 09:43:04,503 - INFO -   kmmlu_hard_education:
2025-07-28 09:43:04,503 - INFO -     - accuracy: 0.2000
2025-07-28 09:43:04,503 - INFO -   kmmlu_hard_korean_history:
2025-07-28 09:43:04,503 - INFO -     - accuracy: 0.1000
2025-07-28 09:43:04,503 - INFO -   kmmlu_hard_law:
2025-07-28 09:43:04,503 - INFO -     - accuracy: 0.2000
2025-07-28 09:43:04,503 - INFO -   kmmlu_hard_management:
2025-07-28 09:43:04,504 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,504 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 09:43:04,504 - INFO -     - accuracy: 0.3500
2025-07-28 09:43:04,504 - INFO -   kmmlu_hard_psychology:
2025-07-28 09:43:04,504 - INFO -     - accuracy: 0.1500
2025-07-28 09:43:04,504 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 09:43:04,504 - INFO -     - accuracy: 0.3500
2025-07-28 09:43:04,504 - INFO -   kmmlu_hard_taxation:
2025-07-28 09:43:04,504 - INFO -     - accuracy: 0.3500
2025-07-28 09:43:04,505 - INFO -   kmmlu_hard_other:
2025-07-28 09:43:04,505 - INFO -     - accuracy: 0.2636
2025-07-28 09:43:04,505 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 09:43:04,505 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,505 - INFO -   kmmlu_hard_construction:
2025-07-28 09:43:04,505 - INFO -     - accuracy: 0.3000
2025-07-28 09:43:04,505 - INFO -   kmmlu_hard_fashion:
2025-07-28 09:43:04,505 - INFO -     - accuracy: 0.3000
2025-07-28 09:43:04,505 - INFO -   kmmlu_hard_food_processing:
2025-07-28 09:43:04,505 - INFO -     - accuracy: 0.2000
2025-07-28 09:43:04,506 - INFO -   kmmlu_hard_health:
2025-07-28 09:43:04,506 - INFO -     - accuracy: 0.1000
2025-07-28 09:43:04,506 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 09:43:04,506 - INFO -     - accuracy: 0.3500
2025-07-28 09:43:04,506 - INFO -   kmmlu_hard_marketing:
2025-07-28 09:43:04,506 - INFO -     - accuracy: 0.5000
2025-07-28 09:43:04,506 - INFO -   kmmlu_hard_patent:
2025-07-28 09:43:04,506 - INFO -     - accuracy: 0.1500
2025-07-28 09:43:04,507 - INFO -   kmmlu_hard_public_safety:
2025-07-28 09:43:04,507 - INFO -     - accuracy: 0.2000
2025-07-28 09:43:04,507 - INFO -   kmmlu_hard_real_estate:
2025-07-28 09:43:04,507 - INFO -     - accuracy: 0.4000
2025-07-28 09:43:04,507 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 09:43:04,507 - INFO -     - accuracy: 0.1500
2025-07-28 09:43:04,507 - INFO -   kmmlu_hard_stem:
2025-07-28 09:43:04,507 - INFO -     - accuracy: 0.2727
2025-07-28 09:43:04,507 - INFO -   kmmlu_hard_biology:
2025-07-28 09:43:04,507 - INFO -     - accuracy: 0.3000
2025-07-28 09:43:04,508 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 09:43:04,508 - INFO -     - accuracy: 0.1000
2025-07-28 09:43:04,508 - INFO -   kmmlu_hard_chemistry:
2025-07-28 09:43:04,508 - INFO -     - accuracy: 0.5000
2025-07-28 09:43:04,508 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 09:43:04,508 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,508 - INFO -   kmmlu_hard_computer_science:
2025-07-28 09:43:04,508 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,508 - INFO -   kmmlu_hard_ecology:
2025-07-28 09:43:04,509 - INFO -     - accuracy: 0.2000
2025-07-28 09:43:04,509 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 09:43:04,509 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,509 - INFO -   kmmlu_hard_information_technology:
2025-07-28 09:43:04,509 - INFO -     - accuracy: 0.4500
2025-07-28 09:43:04,509 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 09:43:04,509 - INFO -     - accuracy: 0.1500
2025-07-28 09:43:04,509 - INFO -   kmmlu_hard_math:
2025-07-28 09:43:04,509 - INFO -     - accuracy: 0.3000
2025-07-28 09:43:04,510 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 09:43:04,510 - INFO -     - accuracy: 0.2500
2025-07-28 09:43:04,510 - INFO - ============================================================

2025-07-28 09:43:04,514 - INFO - gemma-3-12b-it_harness_3: Processing task 3/10: haerae
2025-07-28 09:43:04,514 - INFO - gemma-3-12b-it_harness_3: Task 'haerae' will use num_fewshot=0
2025-07-28 09:43:04,515 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 09:43:04,515 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:43:20,484 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 09:43:20,484 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 09:43:20,484 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 09:43:20,485 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 09:43:20,485 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 09:46:10,850 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 09:46:10,852 - INFO - 
============================================================
2025-07-28 09:46:10,853 - INFO - Task 'haerae' Results:
2025-07-28 09:46:10,854 - INFO - ============================================================
2025-07-28 09:46:10,855 - INFO -   haerae:
2025-07-28 09:46:10,855 - INFO -     - accuracy: 0.8100
2025-07-28 09:46:10,855 - INFO -     - accuracy_norm: 0.8100
2025-07-28 09:46:10,856 - INFO -   haerae_general_knowledge:
2025-07-28 09:46:10,856 - INFO -     - accuracy: 0.8500
2025-07-28 09:46:10,856 - INFO -     - accuracy_norm: 0.8500
2025-07-28 09:46:10,856 - INFO -   haerae_history:
2025-07-28 09:46:10,856 - INFO -     - accuracy: 0.7500
2025-07-28 09:46:10,856 - INFO -     - accuracy_norm: 0.7500
2025-07-28 09:46:10,856 - INFO -   haerae_loan_word:
2025-07-28 09:46:10,856 - INFO -     - accuracy: 0.9000
2025-07-28 09:46:10,856 - INFO -     - accuracy_norm: 0.9000
2025-07-28 09:46:10,856 - INFO -   haerae_rare_word:
2025-07-28 09:46:10,857 - INFO -     - accuracy: 0.7500
2025-07-28 09:46:10,857 - INFO -     - accuracy_norm: 0.7500
2025-07-28 09:46:10,857 - INFO -   haerae_standard_nomenclature:
2025-07-28 09:46:10,857 - INFO -     - accuracy: 0.8000
2025-07-28 09:46:10,857 - INFO -     - accuracy_norm: 0.8000
2025-07-28 09:46:10,857 - INFO - ============================================================

2025-07-28 09:46:10,860 - INFO - gemma-3-12b-it_harness_3: Processing task 4/10: kobest
2025-07-28 09:46:10,861 - INFO - gemma-3-12b-it_harness_3: Task 'kobest' will use num_fewshot=0
2025-07-28 09:46:10,861 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 09:46:10,861 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:46:29,187 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 09:46:29,188 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 09:46:29,188 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 09:46:29,188 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 09:46:29,188 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 09:47:53,708 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 09:47:53,709 - INFO - 
============================================================
2025-07-28 09:47:53,710 - INFO - Task 'kobest' Results:
2025-07-28 09:47:53,711 - INFO - ============================================================
2025-07-28 09:47:53,712 - INFO -   kobest:
2025-07-28 09:47:53,712 - INFO -     - accuracy: 0.7200
2025-07-28 09:47:53,712 - INFO -     - accuracy_norm: 0.7000
2025-07-28 09:47:53,712 - INFO -     - f1: 0.6822
2025-07-28 09:47:53,712 - INFO -   kobest_boolq:
2025-07-28 09:47:53,713 - INFO -     - accuracy: 0.9000
2025-07-28 09:47:53,713 - INFO -     - f1: 0.8958
2025-07-28 09:47:53,713 - INFO -   kobest_copa:
2025-07-28 09:47:53,713 - INFO -     - accuracy: 0.7500
2025-07-28 09:47:53,713 - INFO -     - f1: 0.7494
2025-07-28 09:47:53,713 - INFO -   kobest_hellaswag:
2025-07-28 09:47:53,713 - INFO -     - accuracy: 0.4500
2025-07-28 09:47:53,713 - INFO -     - accuracy_norm: 0.7000
2025-07-28 09:47:53,713 - INFO -     - f1: 0.4623
2025-07-28 09:47:53,714 - INFO -   kobest_sentineg:
2025-07-28 09:47:53,714 - INFO -     - accuracy: 0.9500
2025-07-28 09:47:53,714 - INFO -     - f1: 0.9488
2025-07-28 09:47:53,714 - INFO -   kobest_wic:
2025-07-28 09:47:53,714 - INFO -     - accuracy: 0.5500
2025-07-28 09:47:53,714 - INFO -     - f1: 0.3548
2025-07-28 09:47:53,714 - INFO - ============================================================

2025-07-28 09:47:53,717 - INFO - gemma-3-12b-it_harness_3: Processing task 5/10: csatqa
2025-07-28 09:47:53,718 - INFO - gemma-3-12b-it_harness_3: Task 'csatqa' detected as zero-shot task
2025-07-28 09:47:53,718 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 09:47:53,718 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:48:03,937 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 09:48:03,937 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 09:48:03,937 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 09:48:03,938 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 09:48:03,938 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 09:48:03,938 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 09:52:38,795 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 09:52:38,798 - INFO - 
============================================================
2025-07-28 09:52:38,799 - INFO - Task 'csatqa' Results:
2025-07-28 09:52:38,799 - INFO - ============================================================
2025-07-28 09:52:38,800 - INFO -   csatqa:
2025-07-28 09:52:38,800 - INFO -     - accuracy: 0.4775
2025-07-28 09:52:38,800 - INFO -     - accuracy_norm: 0.4775
2025-07-28 09:52:38,800 - INFO -   csatqa_gr:
2025-07-28 09:52:38,800 - INFO -     - accuracy: 0.2500
2025-07-28 09:52:38,800 - INFO -     - accuracy_norm: 0.2500
2025-07-28 09:52:38,800 - INFO -   csatqa_li:
2025-07-28 09:52:38,800 - INFO -     - accuracy: 0.4500
2025-07-28 09:52:38,800 - INFO -     - accuracy_norm: 0.4500
2025-07-28 09:52:38,800 - INFO -   csatqa_rch:
2025-07-28 09:52:38,801 - INFO -     - accuracy: 0.6000
2025-07-28 09:52:38,801 - INFO -     - accuracy_norm: 0.6000
2025-07-28 09:52:38,801 - INFO -   csatqa_rcs:
2025-07-28 09:52:38,801 - INFO -     - accuracy: 0.5500
2025-07-28 09:52:38,801 - INFO -     - accuracy_norm: 0.5500
2025-07-28 09:52:38,801 - INFO -   csatqa_rcss:
2025-07-28 09:52:38,801 - INFO -     - accuracy: 0.5500
2025-07-28 09:52:38,801 - INFO -     - accuracy_norm: 0.5500
2025-07-28 09:52:38,801 - INFO -   csatqa_wr:
2025-07-28 09:52:38,801 - INFO -     - accuracy: 0.4545
2025-07-28 09:52:38,801 - INFO -     - accuracy_norm: 0.4545
2025-07-28 09:52:38,802 - INFO - ============================================================

2025-07-28 09:52:38,815 - INFO - gemma-3-12b-it_harness_3: Processing task 6/10: kormedmcqa
2025-07-28 09:52:38,816 - INFO - gemma-3-12b-it_harness_3: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 09:52:38,816 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 09:52:38,816 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:52:55,880 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 09:52:55,881 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 09:52:55,881 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 09:52:55,881 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 09:54:49,439 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 09:54:49,441 - INFO - 
============================================================
2025-07-28 09:54:49,442 - INFO - Task 'kormedmcqa' Results:
2025-07-28 09:54:49,444 - INFO - ============================================================
2025-07-28 09:54:49,445 - INFO -   kormedmcqa:
2025-07-28 09:54:49,445 - INFO -     - exact_match: 0.5875
2025-07-28 09:54:49,445 - INFO -   kormedmcqa_dentist:
2025-07-28 09:54:49,445 - INFO -     - exact_match: 0.5000
2025-07-28 09:54:49,446 - INFO -   kormedmcqa_doctor:
2025-07-28 09:54:49,446 - INFO -     - exact_match: 0.5000
2025-07-28 09:54:49,446 - INFO -   kormedmcqa_nurse:
2025-07-28 09:54:49,446 - INFO -     - exact_match: 0.9500
2025-07-28 09:54:49,446 - INFO -   kormedmcqa_pharm:
2025-07-28 09:54:49,447 - INFO -     - exact_match: 0.4000
2025-07-28 09:54:49,447 - INFO - ============================================================

2025-07-28 09:54:49,449 - INFO - gemma-3-12b-it_harness_3: Processing task 7/10: mmlu
2025-07-28 09:54:49,449 - INFO - gemma-3-12b-it_harness_3: Task 'mmlu' will use num_fewshot=0
2025-07-28 09:54:49,449 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 09:54:49,450 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 09:57:35,743 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 09:57:35,743 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 09:57:35,744 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 09:57:35,744 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 09:57:35,744 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 09:57:35,744 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 09:57:35,744 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 09:57:35,744 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 09:57:35,745 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 09:57:35,745 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 09:57:35,745 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 09:57:35,745 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 09:57:35,745 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 09:57:35,745 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 09:57:35,745 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 09:57:35,745 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 09:57:35,746 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 09:57:35,746 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 09:57:35,747 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 09:57:35,747 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 09:57:35,747 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 09:57:35,747 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 09:57:35,747 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 09:57:35,747 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 09:57:35,747 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 09:57:35,747 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 09:57:35,747 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 09:57:35,748 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 09:57:35,748 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 09:57:35,748 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 09:57:35,748 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 09:57:35,748 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 09:57:35,748 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 09:57:35,748 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 09:57:35,748 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 09:57:35,748 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 09:57:35,748 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 09:57:35,749 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 09:57:35,749 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 09:57:35,749 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 09:57:35,749 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 09:57:35,749 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 09:57:35,749 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 09:57:35,749 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 09:57:35,749 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 09:57:35,749 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 09:57:35,749 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 09:57:35,750 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 09:57:35,750 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 09:57:35,750 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 09:57:35,750 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 09:57:35,750 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 09:57:35,750 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 09:57:35,750 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 09:57:35,750 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 09:57:35,750 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 09:57:35,750 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 10:04:01,185 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 10:04:01,187 - INFO - 
============================================================
2025-07-28 10:04:01,189 - INFO - Task 'mmlu' Results:
2025-07-28 10:04:01,191 - INFO - ============================================================
2025-07-28 10:04:01,191 - INFO -   mmlu:
2025-07-28 10:04:01,191 - INFO -     - accuracy: 0.7386
2025-07-28 10:04:01,191 - INFO -   mmlu_humanities:
2025-07-28 10:04:01,191 - INFO -     - accuracy: 0.7577
2025-07-28 10:04:01,191 - INFO -   mmlu_formal_logic:
2025-07-28 10:04:01,191 - INFO -     - accuracy: 0.6500
2025-07-28 10:04:01,191 - INFO -   mmlu_high_school_european_history:
2025-07-28 10:04:01,192 - INFO -     - accuracy: 0.8000
2025-07-28 10:04:01,192 - INFO -   mmlu_high_school_us_history:
2025-07-28 10:04:01,192 - INFO -     - accuracy: 0.8000
2025-07-28 10:04:01,192 - INFO -   mmlu_high_school_world_history:
2025-07-28 10:04:01,192 - INFO -     - accuracy: 0.9500
2025-07-28 10:04:01,192 - INFO -   mmlu_international_law:
2025-07-28 10:04:01,192 - INFO -     - accuracy: 0.8500
2025-07-28 10:04:01,192 - INFO -   mmlu_jurisprudence:
2025-07-28 10:04:01,192 - INFO -     - accuracy: 0.8000
2025-07-28 10:04:01,193 - INFO -   mmlu_logical_fallacies:
2025-07-28 10:04:01,193 - INFO -     - accuracy: 0.9000
2025-07-28 10:04:01,193 - INFO -   mmlu_moral_disputes:
2025-07-28 10:04:01,193 - INFO -     - accuracy: 0.7500
2025-07-28 10:04:01,193 - INFO -   mmlu_moral_scenarios:
2025-07-28 10:04:01,193 - INFO -     - accuracy: 0.2000
2025-07-28 10:04:01,193 - INFO -   mmlu_philosophy:
2025-07-28 10:04:01,193 - INFO -     - accuracy: 0.9000
2025-07-28 10:04:01,193 - INFO -   mmlu_prehistory:
2025-07-28 10:04:01,194 - INFO -     - accuracy: 0.7000
2025-07-28 10:04:01,194 - INFO -   mmlu_professional_law:
2025-07-28 10:04:01,194 - INFO -     - accuracy: 0.7500
2025-07-28 10:04:01,194 - INFO -   mmlu_world_religions:
2025-07-28 10:04:01,194 - INFO -     - accuracy: 0.8000
2025-07-28 10:04:01,194 - INFO -   mmlu_other:
2025-07-28 10:04:01,194 - INFO -     - accuracy: 0.7462
2025-07-28 10:04:01,194 - INFO -   mmlu_business_ethics:
2025-07-28 10:04:01,194 - INFO -     - accuracy: 0.7500
2025-07-28 10:04:01,195 - INFO -   mmlu_clinical_knowledge:
2025-07-28 10:04:01,195 - INFO -     - accuracy: 0.8500
2025-07-28 10:04:01,195 - INFO -   mmlu_college_medicine:
2025-07-28 10:04:01,195 - INFO -     - accuracy: 0.8000
2025-07-28 10:04:01,195 - INFO -   mmlu_global_facts:
2025-07-28 10:04:01,195 - INFO -     - accuracy: 0.4500
2025-07-28 10:04:01,195 - INFO -   mmlu_human_aging:
2025-07-28 10:04:01,195 - INFO -     - accuracy: 0.7000
2025-07-28 10:04:01,195 - INFO -   mmlu_management:
2025-07-28 10:04:01,196 - INFO -     - accuracy: 0.8000
2025-07-28 10:04:01,196 - INFO -   mmlu_marketing:
2025-07-28 10:04:01,196 - INFO -     - accuracy: 0.9500
2025-07-28 10:04:01,196 - INFO -   mmlu_medical_genetics:
2025-07-28 10:04:01,196 - INFO -     - accuracy: 0.9500
2025-07-28 10:04:01,196 - INFO -   mmlu_miscellaneous:
2025-07-28 10:04:01,196 - INFO -     - accuracy: 0.8500
2025-07-28 10:04:01,196 - INFO -   mmlu_nutrition:
2025-07-28 10:04:01,196 - INFO -     - accuracy: 0.7500
2025-07-28 10:04:01,197 - INFO -   mmlu_professional_accounting:
2025-07-28 10:04:01,197 - INFO -     - accuracy: 0.4500
2025-07-28 10:04:01,197 - INFO -   mmlu_professional_medicine:
2025-07-28 10:04:01,197 - INFO -     - accuracy: 0.8000
2025-07-28 10:04:01,197 - INFO -   mmlu_virology:
2025-07-28 10:04:01,197 - INFO -     - accuracy: 0.6000
2025-07-28 10:04:01,197 - INFO -   mmlu_social_sciences:
2025-07-28 10:04:01,197 - INFO -     - accuracy: 0.8000
2025-07-28 10:04:01,197 - INFO -   mmlu_econometrics:
2025-07-28 10:04:01,197 - INFO -     - accuracy: 0.5000
2025-07-28 10:04:01,198 - INFO -   mmlu_high_school_geography:
2025-07-28 10:04:01,198 - INFO -     - accuracy: 0.9500
2025-07-28 10:04:01,198 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 10:04:01,198 - INFO -     - accuracy: 0.8500
2025-07-28 10:04:01,198 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 10:04:01,198 - INFO -     - accuracy: 0.8500
2025-07-28 10:04:01,198 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 10:04:01,198 - INFO -     - accuracy: 0.6500
2025-07-28 10:04:01,198 - INFO -   mmlu_high_school_psychology:
2025-07-28 10:04:01,198 - INFO -     - accuracy: 0.9500
2025-07-28 10:04:01,199 - INFO -   mmlu_human_sexuality:
2025-07-28 10:04:01,199 - INFO -     - accuracy: 0.8500
2025-07-28 10:04:01,199 - INFO -   mmlu_professional_psychology:
2025-07-28 10:04:01,199 - INFO -     - accuracy: 0.9000
2025-07-28 10:04:01,199 - INFO -   mmlu_public_relations:
2025-07-28 10:04:01,199 - INFO -     - accuracy: 0.6000
2025-07-28 10:04:01,199 - INFO -   mmlu_security_studies:
2025-07-28 10:04:01,199 - INFO -     - accuracy: 0.8000
2025-07-28 10:04:01,199 - INFO -   mmlu_sociology:
2025-07-28 10:04:01,199 - INFO -     - accuracy: 0.7500
2025-07-28 10:04:01,200 - INFO -   mmlu_us_foreign_policy:
2025-07-28 10:04:01,200 - INFO -     - accuracy: 0.9500
2025-07-28 10:04:01,200 - INFO -   mmlu_stem:
2025-07-28 10:04:01,200 - INFO -     - accuracy: 0.6816
2025-07-28 10:04:01,200 - INFO -   mmlu_abstract_algebra:
2025-07-28 10:04:01,200 - INFO -     - accuracy: 0.3500
2025-07-28 10:04:01,200 - INFO -   mmlu_anatomy:
2025-07-28 10:04:01,200 - INFO -     - accuracy: 0.8500
2025-07-28 10:04:01,200 - INFO -   mmlu_astronomy:
2025-07-28 10:04:01,200 - INFO -     - accuracy: 0.9000
2025-07-28 10:04:01,200 - INFO -   mmlu_college_biology:
2025-07-28 10:04:01,201 - INFO -     - accuracy: 0.9500
2025-07-28 10:04:01,201 - INFO -   mmlu_college_chemistry:
2025-07-28 10:04:01,201 - INFO -     - accuracy: 0.3500
2025-07-28 10:04:01,201 - INFO -   mmlu_college_computer_science:
2025-07-28 10:04:01,201 - INFO -     - accuracy: 0.5500
2025-07-28 10:04:01,201 - INFO -   mmlu_college_mathematics:
2025-07-28 10:04:01,201 - INFO -     - accuracy: 0.4500
2025-07-28 10:04:01,201 - INFO -   mmlu_college_physics:
2025-07-28 10:04:01,201 - INFO -     - accuracy: 0.7000
2025-07-28 10:04:01,201 - INFO -   mmlu_computer_security:
2025-07-28 10:04:01,202 - INFO -     - accuracy: 0.8000
2025-07-28 10:04:01,202 - INFO -   mmlu_conceptual_physics:
2025-07-28 10:04:01,202 - INFO -     - accuracy: 0.9500
2025-07-28 10:04:01,202 - INFO -   mmlu_electrical_engineering:
2025-07-28 10:04:01,202 - INFO -     - accuracy: 0.6500
2025-07-28 10:04:01,202 - INFO -   mmlu_elementary_mathematics:
2025-07-28 10:04:01,202 - INFO -     - accuracy: 0.7500
2025-07-28 10:04:01,202 - INFO -   mmlu_high_school_biology:
2025-07-28 10:04:01,202 - INFO -     - accuracy: 0.9000
2025-07-28 10:04:01,202 - INFO -   mmlu_high_school_chemistry:
2025-07-28 10:04:01,203 - INFO -     - accuracy: 0.9000
2025-07-28 10:04:01,203 - INFO -   mmlu_high_school_computer_science:
2025-07-28 10:04:01,203 - INFO -     - accuracy: 0.8500
2025-07-28 10:04:01,203 - INFO -   mmlu_high_school_mathematics:
2025-07-28 10:04:01,203 - INFO -     - accuracy: 0.4000
2025-07-28 10:04:01,203 - INFO -   mmlu_high_school_physics:
2025-07-28 10:04:01,203 - INFO -     - accuracy: 0.5000
2025-07-28 10:04:01,203 - INFO -   mmlu_high_school_statistics:
2025-07-28 10:04:01,203 - INFO -     - accuracy: 0.7000
2025-07-28 10:04:01,204 - INFO -   mmlu_machine_learning:
2025-07-28 10:04:01,204 - INFO -     - accuracy: 0.4500
2025-07-28 10:04:01,204 - INFO - ============================================================

2025-07-28 10:04:01,209 - INFO - gemma-3-12b-it_harness_3: Processing task 8/10: arc_challenge
2025-07-28 10:04:01,210 - INFO - gemma-3-12b-it_harness_3: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 10:04:01,210 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 10:04:01,210 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:04:15,457 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 10:04:42,248 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 10:04:42,250 - INFO - 
============================================================
2025-07-28 10:04:42,252 - INFO - Task 'arc_challenge' Results:
2025-07-28 10:04:42,253 - INFO - ============================================================
2025-07-28 10:04:42,254 - INFO -   arc_challenge:
2025-07-28 10:04:42,254 - INFO -     - accuracy: 0.6500
2025-07-28 10:04:42,254 - INFO -     - accuracy_norm: 0.7000
2025-07-28 10:04:42,255 - INFO - ============================================================

2025-07-28 10:04:42,256 - INFO - gemma-3-12b-it_harness_3: Processing task 9/10: arc_easy
2025-07-28 10:04:42,257 - INFO - gemma-3-12b-it_harness_3: Task 'arc_easy' will use num_fewshot=0
2025-07-28 10:04:42,257 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 10:04:42,257 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:04:59,981 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 10:05:26,675 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 10:05:26,677 - INFO - 
============================================================
2025-07-28 10:05:26,678 - INFO - Task 'arc_easy' Results:
2025-07-28 10:05:26,680 - INFO - ============================================================
2025-07-28 10:05:26,681 - INFO -   arc_easy:
2025-07-28 10:05:26,681 - INFO -     - accuracy: 0.8000
2025-07-28 10:05:26,681 - INFO -     - accuracy_norm: 0.5500
2025-07-28 10:05:26,681 - INFO - ============================================================

2025-07-28 10:05:26,682 - INFO - gemma-3-12b-it_harness_3: Processing task 10/10: hellaswag
2025-07-28 10:05:26,683 - INFO - gemma-3-12b-it_harness_3: Task 'hellaswag' will use num_fewshot=0
2025-07-28 10:05:26,683 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 10:05:26,683 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:05:40,983 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 10:06:16,757 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 10:06:16,759 - INFO - 
============================================================
2025-07-28 10:06:16,760 - INFO - Task 'hellaswag' Results:
2025-07-28 10:06:16,762 - INFO - ============================================================
2025-07-28 10:06:16,764 - INFO -   hellaswag:
2025-07-28 10:06:16,764 - INFO -     - accuracy: 0.6000
2025-07-28 10:06:16,764 - INFO -     - accuracy_norm: 0.8000
2025-07-28 10:06:16,764 - INFO - ============================================================

2025-07-28 10:06:16,766 - INFO - gemma-3-12b-it_harness_3: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 10:06:16,768 - INFO - [Process 1865749] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_073925/model_results/gemma-3-12b-it/gemma-3-12b-it_harness_3.json
2025-07-28 10:06:16,769 - INFO - [Process 1865749] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/gemma-3-12b-it/gemma-3-12b-it_harness_3.json
2025-07-28 10:06:17,066 - INFO - Results uploaded to WandB as artifact
2025-07-28 10:06:17,075 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 10:06:17,076 - INFO - [Process 1865749] Successfully completed gemma-3-12b-it_harness_3
2025-07-28 10:06:20,232 - INFO - Run gemma-3-12b-it_harness_3 finished successfully
2025-07-28 10:06:20,234 - INFO - [Process 1865749] EXAONE-3.5-32B-Instruct_harness_8 assigned to cuda:0
2025-07-28 10:06:20,235 - INFO - [Process 1865749] EXAONE-3.5-32B-Instruct_harness_8 - using custom limit: 20
2025-07-28 10:06:21,454 - INFO - WandB run initialized: EXAONE-3.5-32B-Instruct_20250728_100620 (ID: 36f11146)
2025-07-28 10:06:21,691 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Test mode (limit=2), setting num_fewshot=0
2025-07-28 10:06:21,722 - INFO - GPU memory available: 79.3GB
2025-07-28 10:06:21,723 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Using 8bit=True, batch_size=1
2025-07-28 10:08:06,684 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 1/10: kmmlu
2025-07-28 10:08:06,684 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kmmlu' will use num_fewshot=0
2025-07-28 10:08:06,684 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 10:08:06,685 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:09:19,353 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 10:09:19,354 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 10:09:19,354 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 10:09:19,354 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 10:09:19,354 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 10:09:19,354 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 10:09:19,354 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 10:09:19,354 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 10:09:19,354 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 10:09:19,354 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 10:09:19,355 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 10:09:19,356 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 10:09:19,357 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 10:09:21,911 - WARNING - We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
2025-07-28 10:13:56,876 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 10:13:56,876 - INFO - 
============================================================
2025-07-28 10:13:56,876 - INFO - Task 'kmmlu' Results:
2025-07-28 10:13:56,877 - INFO - ============================================================
2025-07-28 10:13:56,877 - INFO -   kmmlu:
2025-07-28 10:13:56,877 - INFO -     - accuracy: 0.4211
2025-07-28 10:13:56,877 - INFO -   kmmlu_applied_science:
2025-07-28 10:13:56,877 - INFO -     - accuracy: 0.3292
2025-07-28 10:13:56,877 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 10:13:56,877 - INFO -     - accuracy: 0.3000
2025-07-28 10:13:56,877 - INFO -   kmmlu_electronics_engineering:
2025-07-28 10:13:56,878 - INFO -     - accuracy: 0.5000
2025-07-28 10:13:56,878 - INFO -   kmmlu_energy_management:
2025-07-28 10:13:56,878 - INFO -     - accuracy: 0.2500
2025-07-28 10:13:56,878 - INFO -   kmmlu_environmental_science:
2025-07-28 10:13:56,878 - INFO -     - accuracy: 0.2000
2025-07-28 10:13:56,878 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 10:13:56,878 - INFO -     - accuracy: 0.3500
2025-07-28 10:13:56,878 - INFO -   kmmlu_geomatics:
2025-07-28 10:13:56,879 - INFO -     - accuracy: 0.3000
2025-07-28 10:13:56,879 - INFO -   kmmlu_industrial_engineer:
2025-07-28 10:13:56,879 - INFO -     - accuracy: 0.4000
2025-07-28 10:13:56,879 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 10:13:56,879 - INFO -     - accuracy: 0.5000
2025-07-28 10:13:56,879 - INFO -   kmmlu_maritime_engineering:
2025-07-28 10:13:56,879 - INFO -     - accuracy: 0.1000
2025-07-28 10:13:56,879 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 10:13:56,880 - INFO -     - accuracy: 0.3000
2025-07-28 10:13:56,880 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 10:13:56,880 - INFO -     - accuracy: 0.4000
2025-07-28 10:13:56,880 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 10:13:56,880 - INFO -     - accuracy: 0.3500
2025-07-28 10:13:56,880 - INFO -   kmmlu_humss:
2025-07-28 10:13:56,880 - INFO -     - accuracy: 0.5227
2025-07-28 10:13:56,880 - INFO -   kmmlu_accounting:
2025-07-28 10:13:56,880 - INFO -     - accuracy: 0.6500
2025-07-28 10:13:56,881 - INFO -   kmmlu_criminal_law:
2025-07-28 10:13:56,881 - INFO -     - accuracy: 0.3000
2025-07-28 10:13:56,881 - INFO -   kmmlu_economics:
2025-07-28 10:13:56,881 - INFO -     - accuracy: 0.8000
2025-07-28 10:13:56,881 - INFO -   kmmlu_education:
2025-07-28 10:13:56,881 - INFO -     - accuracy: 0.8000
2025-07-28 10:13:56,881 - INFO -   kmmlu_korean_history:
2025-07-28 10:13:56,881 - INFO -     - accuracy: 0.4500
2025-07-28 10:13:56,881 - INFO -   kmmlu_law:
2025-07-28 10:13:56,881 - INFO -     - accuracy: 0.1500
2025-07-28 10:13:56,882 - INFO -   kmmlu_management:
2025-07-28 10:13:56,882 - INFO -     - accuracy: 0.6000
2025-07-28 10:13:56,882 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 10:13:56,882 - INFO -     - accuracy: 0.8000
2025-07-28 10:13:56,882 - INFO -   kmmlu_psychology:
2025-07-28 10:13:56,882 - INFO -     - accuracy: 0.3500
2025-07-28 10:13:56,882 - INFO -   kmmlu_social_welfare:
2025-07-28 10:13:56,882 - INFO -     - accuracy: 0.4500
2025-07-28 10:13:56,882 - INFO -   kmmlu_taxation:
2025-07-28 10:13:56,883 - INFO -     - accuracy: 0.4000
2025-07-28 10:13:56,883 - INFO -   kmmlu_other:
2025-07-28 10:13:56,883 - INFO -     - accuracy: 0.4318
2025-07-28 10:13:56,883 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 10:13:56,883 - INFO -     - accuracy: 0.4000
2025-07-28 10:13:56,883 - INFO -   kmmlu_construction:
2025-07-28 10:13:56,883 - INFO -     - accuracy: 0.5000
2025-07-28 10:13:56,883 - INFO -   kmmlu_fashion:
2025-07-28 10:13:56,883 - INFO -     - accuracy: 0.2500
2025-07-28 10:13:56,884 - INFO -   kmmlu_food_processing:
2025-07-28 10:13:56,884 - INFO -     - accuracy: 0.3500
2025-07-28 10:13:56,884 - INFO -   kmmlu_health:
2025-07-28 10:13:56,884 - INFO -     - accuracy: 0.6000
2025-07-28 10:13:56,884 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 10:13:56,884 - INFO -     - accuracy: 0.8500
2025-07-28 10:13:56,884 - INFO -   kmmlu_marketing:
2025-07-28 10:13:56,884 - INFO -     - accuracy: 0.4000
2025-07-28 10:13:56,884 - INFO -   kmmlu_patent:
2025-07-28 10:13:56,885 - INFO -     - accuracy: 0.4500
2025-07-28 10:13:56,885 - INFO -   kmmlu_public_safety:
2025-07-28 10:13:56,885 - INFO -     - accuracy: 0.1500
2025-07-28 10:13:56,885 - INFO -   kmmlu_real_estate:
2025-07-28 10:13:56,885 - INFO -     - accuracy: 0.5000
2025-07-28 10:13:56,885 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 10:13:56,885 - INFO -     - accuracy: 0.3000
2025-07-28 10:13:56,885 - INFO -   kmmlu_stem:
2025-07-28 10:13:56,885 - INFO -     - accuracy: 0.4091
2025-07-28 10:13:56,886 - INFO -   kmmlu_biology:
2025-07-28 10:13:56,886 - INFO -     - accuracy: 0.4000
2025-07-28 10:13:56,886 - INFO -   kmmlu_chemical_engineering:
2025-07-28 10:13:56,886 - INFO -     - accuracy: 0.4500
2025-07-28 10:13:56,886 - INFO -   kmmlu_chemistry:
2025-07-28 10:13:56,886 - INFO -     - accuracy: 0.4000
2025-07-28 10:13:56,886 - INFO -   kmmlu_civil_engineering:
2025-07-28 10:13:56,886 - INFO -     - accuracy: 0.2500
2025-07-28 10:13:56,886 - INFO -   kmmlu_computer_science:
2025-07-28 10:13:56,886 - INFO -     - accuracy: 0.6500
2025-07-28 10:13:56,887 - INFO -   kmmlu_ecology:
2025-07-28 10:13:56,887 - INFO -     - accuracy: 0.2500
2025-07-28 10:13:56,887 - INFO -   kmmlu_electrical_engineering:
2025-07-28 10:13:56,887 - INFO -     - accuracy: 0.2500
2025-07-28 10:13:56,887 - INFO -   kmmlu_information_technology:
2025-07-28 10:13:56,887 - INFO -     - accuracy: 0.6500
2025-07-28 10:13:56,887 - INFO -   kmmlu_materials_engineering:
2025-07-28 10:13:56,887 - INFO -     - accuracy: 0.5500
2025-07-28 10:13:56,887 - INFO -   kmmlu_math:
2025-07-28 10:13:56,888 - INFO -     - accuracy: 0.3000
2025-07-28 10:13:56,888 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 10:13:56,888 - INFO -     - accuracy: 0.3500
2025-07-28 10:13:56,888 - INFO - ============================================================

2025-07-28 10:13:56,900 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 2/10: kmmlu_hard
2025-07-28 10:13:56,901 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 10:13:56,901 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 10:13:56,902 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:15:06,254 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 10:15:06,255 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 10:15:06,255 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 10:15:06,255 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 10:15:06,255 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 10:15:06,255 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 10:15:06,255 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 10:15:06,255 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 10:15:06,256 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 10:15:06,257 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 10:15:06,258 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 10:15:06,259 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 10:15:06,259 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 10:15:06,259 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 10:19:47,918 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 10:19:47,919 - INFO - 
============================================================
2025-07-28 10:19:47,919 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 10:19:47,919 - INFO - ============================================================
2025-07-28 10:19:47,919 - INFO -   kmmlu_hard:
2025-07-28 10:19:47,919 - INFO -     - accuracy: 0.2400
2025-07-28 10:19:47,920 - INFO -   kmmlu_hard_applied_science:
2025-07-28 10:19:47,920 - INFO -     - accuracy: 0.2583
2025-07-28 10:19:47,920 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 10:19:47,920 - INFO -     - accuracy: 0.3000
2025-07-28 10:19:47,920 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 10:19:47,920 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,920 - INFO -   kmmlu_hard_energy_management:
2025-07-28 10:19:47,921 - INFO -     - accuracy: 0.1500
2025-07-28 10:19:47,921 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 10:19:47,921 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,921 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 10:19:47,921 - INFO -     - accuracy: 0.1000
2025-07-28 10:19:47,921 - INFO -   kmmlu_hard_geomatics:
2025-07-28 10:19:47,921 - INFO -     - accuracy: 0.3000
2025-07-28 10:19:47,921 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 10:19:47,921 - INFO -     - accuracy: 0.4000
2025-07-28 10:19:47,922 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 10:19:47,922 - INFO -     - accuracy: 0.3500
2025-07-28 10:19:47,922 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 10:19:47,922 - INFO -     - accuracy: 0.1500
2025-07-28 10:19:47,922 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 10:19:47,922 - INFO -     - accuracy: 0.3500
2025-07-28 10:19:47,922 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 10:19:47,922 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,923 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 10:19:47,923 - INFO -     - accuracy: 0.4000
2025-07-28 10:19:47,923 - INFO -   kmmlu_hard_humss:
2025-07-28 10:19:47,923 - INFO -     - accuracy: 0.2273
2025-07-28 10:19:47,923 - INFO -   kmmlu_hard_accounting:
2025-07-28 10:19:47,923 - INFO -     - accuracy: 0.3000
2025-07-28 10:19:47,923 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 10:19:47,923 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,923 - INFO -   kmmlu_hard_economics:
2025-07-28 10:19:47,924 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,924 - INFO -   kmmlu_hard_education:
2025-07-28 10:19:47,924 - INFO -     - accuracy: 0.4000
2025-07-28 10:19:47,924 - INFO -   kmmlu_hard_korean_history:
2025-07-28 10:19:47,924 - INFO -     - accuracy: 0.1500
2025-07-28 10:19:47,924 - INFO -   kmmlu_hard_law:
2025-07-28 10:19:47,924 - INFO -     - accuracy: 0.1000
2025-07-28 10:19:47,924 - INFO -   kmmlu_hard_management:
2025-07-28 10:19:47,924 - INFO -     - accuracy: 0.4000
2025-07-28 10:19:47,924 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 10:19:47,925 - INFO -     - accuracy: 0.1500
2025-07-28 10:19:47,925 - INFO -   kmmlu_hard_psychology:
2025-07-28 10:19:47,925 - INFO -     - accuracy: 0.1500
2025-07-28 10:19:47,925 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 10:19:47,925 - INFO -     - accuracy: 0.2500
2025-07-28 10:19:47,925 - INFO -   kmmlu_hard_taxation:
2025-07-28 10:19:47,925 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,925 - INFO -   kmmlu_hard_other:
2025-07-28 10:19:47,925 - INFO -     - accuracy: 0.2727
2025-07-28 10:19:47,925 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 10:19:47,926 - INFO -     - accuracy: 0.3000
2025-07-28 10:19:47,926 - INFO -   kmmlu_hard_construction:
2025-07-28 10:19:47,926 - INFO -     - accuracy: 0.1000
2025-07-28 10:19:47,926 - INFO -   kmmlu_hard_fashion:
2025-07-28 10:19:47,926 - INFO -     - accuracy: 0.4000
2025-07-28 10:19:47,926 - INFO -   kmmlu_hard_food_processing:
2025-07-28 10:19:47,926 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,926 - INFO -   kmmlu_hard_health:
2025-07-28 10:19:47,926 - INFO -     - accuracy: 0.3000
2025-07-28 10:19:47,926 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 10:19:47,927 - INFO -     - accuracy: 0.4000
2025-07-28 10:19:47,927 - INFO -   kmmlu_hard_marketing:
2025-07-28 10:19:47,927 - INFO -     - accuracy: 0.4000
2025-07-28 10:19:47,927 - INFO -   kmmlu_hard_patent:
2025-07-28 10:19:47,927 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,927 - INFO -   kmmlu_hard_public_safety:
2025-07-28 10:19:47,927 - INFO -     - accuracy: 0.3000
2025-07-28 10:19:47,927 - INFO -   kmmlu_hard_real_estate:
2025-07-28 10:19:47,927 - INFO -     - accuracy: 0.3000
2025-07-28 10:19:47,928 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 10:19:47,928 - INFO -     - accuracy: 0.1000
2025-07-28 10:19:47,928 - INFO -   kmmlu_hard_stem:
2025-07-28 10:19:47,928 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,928 - INFO -   kmmlu_hard_biology:
2025-07-28 10:19:47,928 - INFO -     - accuracy: 0.2500
2025-07-28 10:19:47,928 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 10:19:47,928 - INFO -     - accuracy: 0.1500
2025-07-28 10:19:47,928 - INFO -   kmmlu_hard_chemistry:
2025-07-28 10:19:47,928 - INFO -     - accuracy: 0.3500
2025-07-28 10:19:47,929 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 10:19:47,929 - INFO -     - accuracy: 0.0500
2025-07-28 10:19:47,929 - INFO -   kmmlu_hard_computer_science:
2025-07-28 10:19:47,929 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,929 - INFO -   kmmlu_hard_ecology:
2025-07-28 10:19:47,929 - INFO -     - accuracy: 0.1500
2025-07-28 10:19:47,929 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 10:19:47,929 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,929 - INFO -   kmmlu_hard_information_technology:
2025-07-28 10:19:47,930 - INFO -     - accuracy: 0.4000
2025-07-28 10:19:47,930 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 10:19:47,930 - INFO -     - accuracy: 0.2000
2025-07-28 10:19:47,930 - INFO -   kmmlu_hard_math:
2025-07-28 10:19:47,930 - INFO -     - accuracy: 0.2500
2025-07-28 10:19:47,930 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 10:19:47,930 - INFO -     - accuracy: 0.0000
2025-07-28 10:19:47,931 - INFO - ============================================================

2025-07-28 10:19:47,934 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 3/10: haerae
2025-07-28 10:19:47,935 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'haerae' will use num_fewshot=0
2025-07-28 10:19:47,935 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 10:19:47,935 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:20:04,018 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 10:20:04,018 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 10:20:04,019 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 10:20:04,019 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 10:20:04,019 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 10:22:40,039 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 10:22:40,040 - INFO - 
============================================================
2025-07-28 10:22:40,040 - INFO - Task 'haerae' Results:
2025-07-28 10:22:40,040 - INFO - ============================================================
2025-07-28 10:22:40,041 - INFO -   haerae:
2025-07-28 10:22:40,041 - INFO -     - accuracy: 0.8700
2025-07-28 10:22:40,041 - INFO -     - accuracy_norm: 0.8700
2025-07-28 10:22:40,041 - INFO -   haerae_general_knowledge:
2025-07-28 10:22:40,041 - INFO -     - accuracy: 0.8500
2025-07-28 10:22:40,041 - INFO -     - accuracy_norm: 0.8500
2025-07-28 10:22:40,041 - INFO -   haerae_history:
2025-07-28 10:22:40,041 - INFO -     - accuracy: 0.9500
2025-07-28 10:22:40,041 - INFO -     - accuracy_norm: 0.9500
2025-07-28 10:22:40,042 - INFO -   haerae_loan_word:
2025-07-28 10:22:40,042 - INFO -     - accuracy: 0.9000
2025-07-28 10:22:40,042 - INFO -     - accuracy_norm: 0.9000
2025-07-28 10:22:40,042 - INFO -   haerae_rare_word:
2025-07-28 10:22:40,042 - INFO -     - accuracy: 0.7500
2025-07-28 10:22:40,042 - INFO -     - accuracy_norm: 0.7500
2025-07-28 10:22:40,042 - INFO -   haerae_standard_nomenclature:
2025-07-28 10:22:40,042 - INFO -     - accuracy: 0.9000
2025-07-28 10:22:40,042 - INFO -     - accuracy_norm: 0.9000
2025-07-28 10:22:40,043 - INFO - ============================================================

2025-07-28 10:22:40,045 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 4/10: kobest
2025-07-28 10:22:40,046 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kobest' will use num_fewshot=0
2025-07-28 10:22:40,046 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 10:22:40,046 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:22:57,642 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 10:22:57,643 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 10:22:57,643 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 10:22:57,643 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 10:22:57,643 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 10:24:08,047 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 10:24:08,047 - INFO - 
============================================================
2025-07-28 10:24:08,048 - INFO - Task 'kobest' Results:
2025-07-28 10:24:08,048 - INFO - ============================================================
2025-07-28 10:24:08,048 - INFO -   kobest:
2025-07-28 10:24:08,048 - INFO -     - accuracy: 0.7600
2025-07-28 10:24:08,048 - INFO -     - accuracy_norm: 0.8500
2025-07-28 10:24:08,048 - INFO -     - f1: 0.7597
2025-07-28 10:24:08,048 - INFO -   kobest_boolq:
2025-07-28 10:24:08,049 - INFO -     - accuracy: 0.8500
2025-07-28 10:24:08,049 - INFO -     - f1: 0.8496
2025-07-28 10:24:08,049 - INFO -   kobest_copa:
2025-07-28 10:24:08,049 - INFO -     - accuracy: 0.9000
2025-07-28 10:24:08,049 - INFO -     - f1: 0.9000
2025-07-28 10:24:08,049 - INFO -   kobest_hellaswag:
2025-07-28 10:24:08,049 - INFO -     - accuracy: 0.5500
2025-07-28 10:24:08,049 - INFO -     - accuracy_norm: 0.8500
2025-07-28 10:24:08,049 - INFO -     - f1: 0.5530
2025-07-28 10:24:08,049 - INFO -   kobest_sentineg:
2025-07-28 10:24:08,050 - INFO -     - accuracy: 0.9000
2025-07-28 10:24:08,050 - INFO -     - f1: 0.8958
2025-07-28 10:24:08,050 - INFO -   kobest_wic:
2025-07-28 10:24:08,050 - INFO -     - accuracy: 0.6000
2025-07-28 10:24:08,050 - INFO -     - f1: 0.6000
2025-07-28 10:24:08,050 - INFO - ============================================================

2025-07-28 10:24:08,053 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 5/10: csatqa
2025-07-28 10:24:08,053 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'csatqa' detected as zero-shot task
2025-07-28 10:24:08,053 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 10:24:08,054 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:24:19,774 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 10:24:19,775 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 10:24:19,775 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 10:24:19,775 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 10:24:19,775 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 10:24:19,776 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 10:30:31,196 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 10:30:31,197 - INFO - 
============================================================
2025-07-28 10:30:31,197 - INFO - Task 'csatqa' Results:
2025-07-28 10:30:31,197 - INFO - ============================================================
2025-07-28 10:30:31,197 - INFO -   csatqa:
2025-07-28 10:30:31,197 - INFO -     - accuracy: 0.4865
2025-07-28 10:30:31,197 - INFO -     - accuracy_norm: 0.4865
2025-07-28 10:30:31,197 - INFO -   csatqa_gr:
2025-07-28 10:30:31,198 - INFO -     - accuracy: 0.1500
2025-07-28 10:30:31,198 - INFO -     - accuracy_norm: 0.1500
2025-07-28 10:30:31,198 - INFO -   csatqa_li:
2025-07-28 10:30:31,198 - INFO -     - accuracy: 0.7000
2025-07-28 10:30:31,198 - INFO -     - accuracy_norm: 0.7000
2025-07-28 10:30:31,198 - INFO -   csatqa_rch:
2025-07-28 10:30:31,198 - INFO -     - accuracy: 0.6000
2025-07-28 10:30:31,198 - INFO -     - accuracy_norm: 0.6000
2025-07-28 10:30:31,199 - INFO -   csatqa_rcs:
2025-07-28 10:30:31,199 - INFO -     - accuracy: 0.4000
2025-07-28 10:30:31,199 - INFO -     - accuracy_norm: 0.4000
2025-07-28 10:30:31,199 - INFO -   csatqa_rcss:
2025-07-28 10:30:31,199 - INFO -     - accuracy: 0.7000
2025-07-28 10:30:31,199 - INFO -     - accuracy_norm: 0.7000
2025-07-28 10:30:31,199 - INFO -   csatqa_wr:
2025-07-28 10:30:31,199 - INFO -     - accuracy: 0.2727
2025-07-28 10:30:31,199 - INFO -     - accuracy_norm: 0.2727
2025-07-28 10:30:31,200 - INFO - ============================================================

2025-07-28 10:30:31,212 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 6/10: kormedmcqa
2025-07-28 10:30:31,213 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 10:30:31,213 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 10:30:31,213 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:30:48,060 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 10:30:48,060 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 10:30:48,060 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 10:30:48,061 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 10:32:00,602 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 10:32:00,603 - INFO - 
============================================================
2025-07-28 10:32:00,603 - INFO - Task 'kormedmcqa' Results:
2025-07-28 10:32:00,604 - INFO - ============================================================
2025-07-28 10:32:00,604 - INFO -   kormedmcqa:
2025-07-28 10:32:00,604 - INFO -     - exact_match: 0.6125
2025-07-28 10:32:00,604 - INFO -   kormedmcqa_dentist:
2025-07-28 10:32:00,604 - INFO -     - exact_match: 0.4000
2025-07-28 10:32:00,604 - INFO -   kormedmcqa_doctor:
2025-07-28 10:32:00,605 - INFO -     - exact_match: 0.5000
2025-07-28 10:32:00,605 - INFO -   kormedmcqa_nurse:
2025-07-28 10:32:00,605 - INFO -     - exact_match: 0.9000
2025-07-28 10:32:00,605 - INFO -   kormedmcqa_pharm:
2025-07-28 10:32:00,605 - INFO -     - exact_match: 0.6500
2025-07-28 10:32:00,605 - INFO - ============================================================

2025-07-28 10:32:00,608 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 7/10: mmlu
2025-07-28 10:32:00,609 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'mmlu' will use num_fewshot=0
2025-07-28 10:32:00,609 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 10:32:00,609 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:34:39,097 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 10:34:39,097 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 10:34:39,098 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 10:34:39,098 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 10:34:39,098 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 10:34:39,098 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 10:34:39,098 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 10:34:39,098 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 10:34:39,098 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 10:34:39,098 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 10:34:39,098 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 10:34:39,099 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 10:34:39,099 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 10:34:39,099 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 10:34:39,099 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 10:34:39,099 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 10:34:39,099 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 10:34:39,099 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 10:34:39,099 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 10:34:39,099 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 10:34:39,099 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 10:34:39,100 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 10:34:39,100 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 10:34:39,100 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 10:34:39,100 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 10:34:39,100 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 10:34:39,100 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 10:34:39,100 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 10:34:39,100 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 10:34:39,100 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 10:34:39,100 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 10:34:39,101 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 10:34:39,101 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 10:34:39,101 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 10:34:39,101 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 10:34:39,101 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 10:34:39,101 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 10:34:39,101 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 10:34:39,101 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 10:34:39,101 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 10:34:39,101 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 10:34:39,102 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 10:34:39,102 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 10:34:39,102 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 10:34:39,102 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 10:34:39,102 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 10:34:39,102 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 10:34:39,102 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 10:34:39,102 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 10:34:39,102 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 10:34:39,102 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 10:34:39,103 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 10:34:39,103 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 10:34:39,103 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 10:34:39,103 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 10:34:39,103 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 10:34:39,103 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 10:40:37,248 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 10:40:37,249 - INFO - 
============================================================
2025-07-28 10:40:37,249 - INFO - Task 'mmlu' Results:
2025-07-28 10:40:37,249 - INFO - ============================================================
2025-07-28 10:40:37,249 - INFO -   mmlu:
2025-07-28 10:40:37,249 - INFO -     - accuracy: 0.7070
2025-07-28 10:40:37,249 - INFO -   mmlu_humanities:
2025-07-28 10:40:37,249 - INFO -     - accuracy: 0.7462
2025-07-28 10:40:37,250 - INFO -   mmlu_formal_logic:
2025-07-28 10:40:37,250 - INFO -     - accuracy: 0.6500
2025-07-28 10:40:37,250 - INFO -   mmlu_high_school_european_history:
2025-07-28 10:40:37,250 - INFO -     - accuracy: 0.6500
2025-07-28 10:40:37,250 - INFO -   mmlu_high_school_us_history:
2025-07-28 10:40:37,250 - INFO -     - accuracy: 0.8500
2025-07-28 10:40:37,250 - INFO -   mmlu_high_school_world_history:
2025-07-28 10:40:37,250 - INFO -     - accuracy: 0.9500
2025-07-28 10:40:37,250 - INFO -   mmlu_international_law:
2025-07-28 10:40:37,251 - INFO -     - accuracy: 0.8000
2025-07-28 10:40:37,251 - INFO -   mmlu_jurisprudence:
2025-07-28 10:40:37,251 - INFO -     - accuracy: 0.8000
2025-07-28 10:40:37,251 - INFO -   mmlu_logical_fallacies:
2025-07-28 10:40:37,251 - INFO -     - accuracy: 0.9000
2025-07-28 10:40:37,251 - INFO -   mmlu_moral_disputes:
2025-07-28 10:40:37,251 - INFO -     - accuracy: 0.7000
2025-07-28 10:40:37,251 - INFO -   mmlu_moral_scenarios:
2025-07-28 10:40:37,251 - INFO -     - accuracy: 0.3000
2025-07-28 10:40:37,252 - INFO -   mmlu_philosophy:
2025-07-28 10:40:37,252 - INFO -     - accuracy: 0.9500
2025-07-28 10:40:37,252 - INFO -   mmlu_prehistory:
2025-07-28 10:40:37,252 - INFO -     - accuracy: 0.7000
2025-07-28 10:40:37,252 - INFO -   mmlu_professional_law:
2025-07-28 10:40:37,252 - INFO -     - accuracy: 0.7000
2025-07-28 10:40:37,252 - INFO -   mmlu_world_religions:
2025-07-28 10:40:37,252 - INFO -     - accuracy: 0.7500
2025-07-28 10:40:37,252 - INFO -   mmlu_other:
2025-07-28 10:40:37,253 - INFO -     - accuracy: 0.6846
2025-07-28 10:40:37,253 - INFO -   mmlu_business_ethics:
2025-07-28 10:40:37,253 - INFO -     - accuracy: 0.9000
2025-07-28 10:40:37,253 - INFO -   mmlu_clinical_knowledge:
2025-07-28 10:40:37,253 - INFO -     - accuracy: 0.7000
2025-07-28 10:40:37,253 - INFO -   mmlu_college_medicine:
2025-07-28 10:40:37,253 - INFO -     - accuracy: 0.8500
2025-07-28 10:40:37,253 - INFO -   mmlu_global_facts:
2025-07-28 10:40:37,253 - INFO -     - accuracy: 0.3500
2025-07-28 10:40:37,253 - INFO -   mmlu_human_aging:
2025-07-28 10:40:37,254 - INFO -     - accuracy: 0.7000
2025-07-28 10:40:37,254 - INFO -   mmlu_management:
2025-07-28 10:40:37,254 - INFO -     - accuracy: 0.7500
2025-07-28 10:40:37,254 - INFO -   mmlu_marketing:
2025-07-28 10:40:37,254 - INFO -     - accuracy: 0.8500
2025-07-28 10:40:37,254 - INFO -   mmlu_medical_genetics:
2025-07-28 10:40:37,254 - INFO -     - accuracy: 0.7000
2025-07-28 10:40:37,254 - INFO -   mmlu_miscellaneous:
2025-07-28 10:40:37,254 - INFO -     - accuracy: 0.7500
2025-07-28 10:40:37,254 - INFO -   mmlu_nutrition:
2025-07-28 10:40:37,254 - INFO -     - accuracy: 0.7500
2025-07-28 10:40:37,255 - INFO -   mmlu_professional_accounting:
2025-07-28 10:40:37,255 - INFO -     - accuracy: 0.3500
2025-07-28 10:40:37,255 - INFO -   mmlu_professional_medicine:
2025-07-28 10:40:37,255 - INFO -     - accuracy: 0.7000
2025-07-28 10:40:37,255 - INFO -   mmlu_virology:
2025-07-28 10:40:37,255 - INFO -     - accuracy: 0.5500
2025-07-28 10:40:37,255 - INFO -   mmlu_social_sciences:
2025-07-28 10:40:37,255 - INFO -     - accuracy: 0.8125
2025-07-28 10:40:37,255 - INFO -   mmlu_econometrics:
2025-07-28 10:40:37,256 - INFO -     - accuracy: 0.6000
2025-07-28 10:40:37,256 - INFO -   mmlu_high_school_geography:
2025-07-28 10:40:37,256 - INFO -     - accuracy: 0.8500
2025-07-28 10:40:37,256 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 10:40:37,256 - INFO -     - accuracy: 1.0000
2025-07-28 10:40:37,256 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 10:40:37,256 - INFO -     - accuracy: 0.7500
2025-07-28 10:40:37,256 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 10:40:37,256 - INFO -     - accuracy: 0.7500
2025-07-28 10:40:37,257 - INFO -   mmlu_high_school_psychology:
2025-07-28 10:40:37,257 - INFO -     - accuracy: 1.0000
2025-07-28 10:40:37,257 - INFO -   mmlu_human_sexuality:
2025-07-28 10:40:37,257 - INFO -     - accuracy: 0.9000
2025-07-28 10:40:37,257 - INFO -   mmlu_professional_psychology:
2025-07-28 10:40:37,257 - INFO -     - accuracy: 0.8500
2025-07-28 10:40:37,257 - INFO -   mmlu_public_relations:
2025-07-28 10:40:37,257 - INFO -     - accuracy: 0.5000
2025-07-28 10:40:37,257 - INFO -   mmlu_security_studies:
2025-07-28 10:40:37,257 - INFO -     - accuracy: 0.9000
2025-07-28 10:40:37,258 - INFO -   mmlu_sociology:
2025-07-28 10:40:37,258 - INFO -     - accuracy: 0.6500
2025-07-28 10:40:37,258 - INFO -   mmlu_us_foreign_policy:
2025-07-28 10:40:37,258 - INFO -     - accuracy: 1.0000
2025-07-28 10:40:37,258 - INFO -   mmlu_stem:
2025-07-28 10:40:37,258 - INFO -     - accuracy: 0.6289
2025-07-28 10:40:37,258 - INFO -   mmlu_abstract_algebra:
2025-07-28 10:40:37,259 - INFO -     - accuracy: 0.2000
2025-07-28 10:40:37,259 - INFO -   mmlu_anatomy:
2025-07-28 10:40:37,259 - INFO -     - accuracy: 0.7500
2025-07-28 10:40:37,259 - INFO -   mmlu_astronomy:
2025-07-28 10:40:37,259 - INFO -     - accuracy: 0.9000
2025-07-28 10:40:37,259 - INFO -   mmlu_college_biology:
2025-07-28 10:40:37,259 - INFO -     - accuracy: 0.7000
2025-07-28 10:40:37,259 - INFO -   mmlu_college_chemistry:
2025-07-28 10:40:37,259 - INFO -     - accuracy: 0.4000
2025-07-28 10:40:37,260 - INFO -   mmlu_college_computer_science:
2025-07-28 10:40:37,260 - INFO -     - accuracy: 0.6500
2025-07-28 10:40:37,260 - INFO -   mmlu_college_mathematics:
2025-07-28 10:40:37,260 - INFO -     - accuracy: 0.3500
2025-07-28 10:40:37,260 - INFO -   mmlu_college_physics:
2025-07-28 10:40:37,260 - INFO -     - accuracy: 0.6000
2025-07-28 10:40:37,260 - INFO -   mmlu_computer_security:
2025-07-28 10:40:37,260 - INFO -     - accuracy: 0.7500
2025-07-28 10:40:37,260 - INFO -   mmlu_conceptual_physics:
2025-07-28 10:40:37,260 - INFO -     - accuracy: 0.9000
2025-07-28 10:40:37,261 - INFO -   mmlu_electrical_engineering:
2025-07-28 10:40:37,261 - INFO -     - accuracy: 0.6500
2025-07-28 10:40:37,261 - INFO -   mmlu_elementary_mathematics:
2025-07-28 10:40:37,261 - INFO -     - accuracy: 0.5500
2025-07-28 10:40:37,261 - INFO -   mmlu_high_school_biology:
2025-07-28 10:40:37,261 - INFO -     - accuracy: 0.9000
2025-07-28 10:40:37,261 - INFO -   mmlu_high_school_chemistry:
2025-07-28 10:40:37,261 - INFO -     - accuracy: 0.6500
2025-07-28 10:40:37,261 - INFO -   mmlu_high_school_computer_science:
2025-07-28 10:40:37,262 - INFO -     - accuracy: 0.9500
2025-07-28 10:40:37,262 - INFO -   mmlu_high_school_mathematics:
2025-07-28 10:40:37,262 - INFO -     - accuracy: 0.3000
2025-07-28 10:40:37,262 - INFO -   mmlu_high_school_physics:
2025-07-28 10:40:37,262 - INFO -     - accuracy: 0.4000
2025-07-28 10:40:37,262 - INFO -   mmlu_high_school_statistics:
2025-07-28 10:40:37,262 - INFO -     - accuracy: 0.8500
2025-07-28 10:40:37,262 - INFO -   mmlu_machine_learning:
2025-07-28 10:40:37,262 - INFO -     - accuracy: 0.5000
2025-07-28 10:40:37,263 - INFO - ============================================================

2025-07-28 10:40:37,268 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 8/10: arc_challenge
2025-07-28 10:40:37,268 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 10:40:37,269 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 10:40:37,269 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:40:44,013 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 10:41:09,383 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 10:41:09,384 - INFO - 
============================================================
2025-07-28 10:41:09,384 - INFO - Task 'arc_challenge' Results:
2025-07-28 10:41:09,384 - INFO - ============================================================
2025-07-28 10:41:09,384 - INFO -   arc_challenge:
2025-07-28 10:41:09,385 - INFO -     - accuracy: 0.6000
2025-07-28 10:41:09,385 - INFO -     - accuracy_norm: 0.6000
2025-07-28 10:41:09,385 - INFO - ============================================================

2025-07-28 10:41:09,386 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 9/10: arc_easy
2025-07-28 10:41:09,387 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'arc_easy' will use num_fewshot=0
2025-07-28 10:41:09,387 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 10:41:09,387 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:41:15,534 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 10:41:37,654 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 10:41:37,655 - INFO - 
============================================================
2025-07-28 10:41:37,655 - INFO - Task 'arc_easy' Results:
2025-07-28 10:41:37,655 - INFO - ============================================================
2025-07-28 10:41:37,655 - INFO -   arc_easy:
2025-07-28 10:41:37,655 - INFO -     - accuracy: 0.8500
2025-07-28 10:41:37,656 - INFO -     - accuracy_norm: 0.7500
2025-07-28 10:41:37,656 - INFO - ============================================================

2025-07-28 10:41:37,657 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 10/10: hellaswag
2025-07-28 10:41:37,658 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'hellaswag' will use num_fewshot=0
2025-07-28 10:41:37,658 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 10:41:37,658 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:41:50,734 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 10:42:16,987 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 10:42:16,988 - INFO - 
============================================================
2025-07-28 10:42:16,988 - INFO - Task 'hellaswag' Results:
2025-07-28 10:42:16,988 - INFO - ============================================================
2025-07-28 10:42:16,988 - INFO -   hellaswag:
2025-07-28 10:42:16,988 - INFO -     - accuracy: 0.5000
2025-07-28 10:42:16,988 - INFO -     - accuracy_norm: 0.6500
2025-07-28 10:42:16,989 - INFO - ============================================================

2025-07-28 10:42:16,990 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 10:42:16,992 - INFO - [Process 1865749] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_073925/model_results/EXAONE-3.5-32B-Instruct/EXAONE-3.5-32B-Instruct_harness_8.json
2025-07-28 10:42:16,993 - INFO - [Process 1865749] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/EXAONE-3.5-32B-Instruct/EXAONE-3.5-32B-Instruct_harness_8.json
2025-07-28 10:42:17,297 - INFO - Results uploaded to WandB as artifact
2025-07-28 10:42:17,306 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 10:42:17,307 - INFO - [Process 1865749] Successfully completed EXAONE-3.5-32B-Instruct_harness_8
2025-07-28 10:42:20,372 - INFO - Run EXAONE-3.5-32B-Instruct_harness_8 finished successfully
2025-07-28 10:42:20,375 - INFO - [Process 1865749] luxia-21.4b-alignment-v1.2_harness_13 assigned to cuda:0
2025-07-28 10:42:20,376 - INFO - [Process 1865749] luxia-21.4b-alignment-v1.2_harness_13 - using custom limit: 20
2025-07-28 10:42:21,875 - INFO - WandB run initialized: luxia-21.4b-alignment-v1.2_20250728_104220 (ID: 229a0d36)
2025-07-28 10:42:22,089 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Test mode (limit=2), setting num_fewshot=0
2025-07-28 10:42:22,167 - INFO - GPU memory available: 79.3GB
2025-07-28 10:42:22,169 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Using 8bit=True, batch_size=1
2025-07-28 10:43:00,688 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 1/10: kmmlu
2025-07-28 10:43:00,689 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'kmmlu' will use num_fewshot=0
2025-07-28 10:43:00,689 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'kmmlu' with num_fewshot=0
2025-07-28 10:43:00,689 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:44:15,118 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 0
2025-07-28 10:44:15,119 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 0
2025-07-28 10:44:15,119 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 0
2025-07-28 10:44:15,119 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 0
2025-07-28 10:44:15,119 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 0
2025-07-28 10:44:15,119 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 0
2025-07-28 10:44:15,119 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 0
2025-07-28 10:44:15,119 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 0
2025-07-28 10:44:15,120 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 0
2025-07-28 10:44:15,121 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 0
2025-07-28 10:44:15,122 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 0
2025-07-28 10:44:15,123 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 0
2025-07-28 10:44:15,123 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 0
2025-07-28 10:44:15,123 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 0
2025-07-28 10:48:11,807 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-28 10:48:11,807 - INFO - 
============================================================
2025-07-28 10:48:11,808 - INFO - Task 'kmmlu' Results:
2025-07-28 10:48:11,808 - INFO - ============================================================
2025-07-28 10:48:11,808 - INFO -   kmmlu:
2025-07-28 10:48:11,808 - INFO -     - accuracy: 0.2344
2025-07-28 10:48:11,809 - INFO -   kmmlu_applied_science:
2025-07-28 10:48:11,810 - INFO -     - accuracy: 0.1958
2025-07-28 10:48:11,810 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-28 10:48:11,810 - INFO -     - accuracy: 0.2500
2025-07-28 10:48:11,810 - INFO -   kmmlu_electronics_engineering:
2025-07-28 10:48:11,810 - INFO -     - accuracy: 0.2500
2025-07-28 10:48:11,811 - INFO -   kmmlu_energy_management:
2025-07-28 10:48:11,811 - INFO -     - accuracy: 0.0500
2025-07-28 10:48:11,811 - INFO -   kmmlu_environmental_science:
2025-07-28 10:48:11,811 - INFO -     - accuracy: 0.0500
2025-07-28 10:48:11,811 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-28 10:48:11,812 - INFO -     - accuracy: 0.1500
2025-07-28 10:48:11,812 - INFO -   kmmlu_geomatics:
2025-07-28 10:48:11,812 - INFO -     - accuracy: 0.2500
2025-07-28 10:48:11,812 - INFO -   kmmlu_industrial_engineer:
2025-07-28 10:48:11,812 - INFO -     - accuracy: 0.3000
2025-07-28 10:48:11,812 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-28 10:48:11,812 - INFO -     - accuracy: 0.1500
2025-07-28 10:48:11,812 - INFO -   kmmlu_maritime_engineering:
2025-07-28 10:48:11,813 - INFO -     - accuracy: 0.1000
2025-07-28 10:48:11,813 - INFO -   kmmlu_nondestructive_testing:
2025-07-28 10:48:11,813 - INFO -     - accuracy: 0.2500
2025-07-28 10:48:11,813 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-28 10:48:11,813 - INFO -     - accuracy: 0.1500
2025-07-28 10:48:11,813 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-28 10:48:11,813 - INFO -     - accuracy: 0.4000
2025-07-28 10:48:11,813 - INFO -   kmmlu_humss:
2025-07-28 10:48:11,813 - INFO -     - accuracy: 0.3045
2025-07-28 10:48:11,814 - INFO -   kmmlu_accounting:
2025-07-28 10:48:11,814 - INFO -     - accuracy: 0.5000
2025-07-28 10:48:11,814 - INFO -   kmmlu_criminal_law:
2025-07-28 10:48:11,814 - INFO -     - accuracy: 0.2000
2025-07-28 10:48:11,814 - INFO -   kmmlu_economics:
2025-07-28 10:48:11,814 - INFO -     - accuracy: 0.3500
2025-07-28 10:48:11,814 - INFO -   kmmlu_education:
2025-07-28 10:48:11,815 - INFO -     - accuracy: 0.4500
2025-07-28 10:48:11,815 - INFO -   kmmlu_korean_history:
2025-07-28 10:48:11,815 - INFO -     - accuracy: 0.2500
2025-07-28 10:48:11,815 - INFO -   kmmlu_law:
2025-07-28 10:48:11,815 - INFO -     - accuracy: 0.2000
2025-07-28 10:48:11,816 - INFO -   kmmlu_management:
2025-07-28 10:48:11,816 - INFO -     - accuracy: 0.2000
2025-07-28 10:48:11,816 - INFO -   kmmlu_political_science_and_sociology:
2025-07-28 10:48:11,816 - INFO -     - accuracy: 0.3500
2025-07-28 10:48:11,816 - INFO -   kmmlu_psychology:
2025-07-28 10:48:11,816 - INFO -     - accuracy: 0.1500
2025-07-28 10:48:11,816 - INFO -   kmmlu_social_welfare:
2025-07-28 10:48:11,817 - INFO -     - accuracy: 0.3000
2025-07-28 10:48:11,817 - INFO -   kmmlu_taxation:
2025-07-28 10:48:11,817 - INFO -     - accuracy: 0.4000
2025-07-28 10:48:11,817 - INFO -   kmmlu_other:
2025-07-28 10:48:11,817 - INFO -     - accuracy: 0.2182
2025-07-28 10:48:11,818 - INFO -   kmmlu_agricultural_sciences:
2025-07-28 10:48:11,818 - INFO -     - accuracy: 0.1000
2025-07-28 10:48:11,818 - INFO -   kmmlu_construction:
2025-07-28 10:48:11,818 - INFO -     - accuracy: 0.2000
2025-07-28 10:48:11,818 - INFO -   kmmlu_fashion:
2025-07-28 10:48:11,818 - INFO -     - accuracy: 0.2000
2025-07-28 10:48:11,819 - INFO -   kmmlu_food_processing:
2025-07-28 10:48:11,819 - INFO -     - accuracy: 0.2500
2025-07-28 10:48:11,819 - INFO -   kmmlu_health:
2025-07-28 10:48:11,819 - INFO -     - accuracy: 0.5500
2025-07-28 10:48:11,820 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-28 10:48:11,820 - INFO -     - accuracy: 0.2500
2025-07-28 10:48:11,820 - INFO -   kmmlu_marketing:
2025-07-28 10:48:11,820 - INFO -     - accuracy: 0.3000
2025-07-28 10:48:11,820 - INFO -   kmmlu_patent:
2025-07-28 10:48:11,821 - INFO -     - accuracy: 0.1500
2025-07-28 10:48:11,821 - INFO -   kmmlu_public_safety:
2025-07-28 10:48:11,821 - INFO -     - accuracy: 0.1500
2025-07-28 10:48:11,821 - INFO -   kmmlu_real_estate:
2025-07-28 10:48:11,821 - INFO -     - accuracy: 0.1000
2025-07-28 10:48:11,822 - INFO -   kmmlu_refrigerating_machinery:
2025-07-28 10:48:11,822 - INFO -     - accuracy: 0.1500
2025-07-28 10:48:11,822 - INFO -   kmmlu_stem:
2025-07-28 10:48:11,822 - INFO -     - accuracy: 0.2227
2025-07-28 10:48:11,822 - INFO -   kmmlu_biology:
2025-07-28 10:48:11,822 - INFO -     - accuracy: 0.3000
2025-07-28 10:48:11,823 - INFO -   kmmlu_chemical_engineering:
2025-07-28 10:48:11,823 - INFO -     - accuracy: 0.2000
2025-07-28 10:48:11,823 - INFO -   kmmlu_chemistry:
2025-07-28 10:48:11,823 - INFO -     - accuracy: 0.1500
2025-07-28 10:48:11,823 - INFO -   kmmlu_civil_engineering:
2025-07-28 10:48:11,823 - INFO -     - accuracy: 0.1000
2025-07-28 10:48:11,824 - INFO -   kmmlu_computer_science:
2025-07-28 10:48:11,824 - INFO -     - accuracy: 0.3500
2025-07-28 10:48:11,824 - INFO -   kmmlu_ecology:
2025-07-28 10:48:11,824 - INFO -     - accuracy: 0.1000
2025-07-28 10:48:11,825 - INFO -   kmmlu_electrical_engineering:
2025-07-28 10:48:11,825 - INFO -     - accuracy: 0.2500
2025-07-28 10:48:11,825 - INFO -   kmmlu_information_technology:
2025-07-28 10:48:11,825 - INFO -     - accuracy: 0.2500
2025-07-28 10:48:11,826 - INFO -   kmmlu_materials_engineering:
2025-07-28 10:48:11,826 - INFO -     - accuracy: 0.2000
2025-07-28 10:48:11,826 - INFO -   kmmlu_math:
2025-07-28 10:48:11,826 - INFO -     - accuracy: 0.3500
2025-07-28 10:48:11,826 - INFO -   kmmlu_mechanical_engineering:
2025-07-28 10:48:11,826 - INFO -     - accuracy: 0.2000
2025-07-28 10:48:11,826 - INFO - ============================================================

2025-07-28 10:48:11,829 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 2/10: kmmlu_hard
2025-07-28 10:48:11,829 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'kmmlu_hard' will use num_fewshot=0
2025-07-28 10:48:11,830 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'kmmlu_hard' with num_fewshot=0
2025-07-28 10:48:11,830 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:49:26,196 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 0
2025-07-28 10:49:26,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 0
2025-07-28 10:49:26,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 0
2025-07-28 10:49:26,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 0
2025-07-28 10:49:26,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 0
2025-07-28 10:49:26,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 0
2025-07-28 10:49:26,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 0
2025-07-28 10:49:26,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 0
2025-07-28 10:49:26,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 0
2025-07-28 10:49:26,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 0
2025-07-28 10:49:26,197 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 0
2025-07-28 10:49:26,198 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 0
2025-07-28 10:49:26,199 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 0
2025-07-28 10:49:26,200 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 0
2025-07-28 10:53:27,157 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-28 10:53:27,158 - INFO - 
============================================================
2025-07-28 10:53:27,158 - INFO - Task 'kmmlu_hard' Results:
2025-07-28 10:53:27,158 - INFO - ============================================================
2025-07-28 10:53:27,158 - INFO -   kmmlu_hard:
2025-07-28 10:53:27,158 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,158 - INFO -   kmmlu_hard_applied_science:
2025-07-28 10:53:27,158 - INFO -     - accuracy: 0.1667
2025-07-28 10:53:27,158 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-28 10:53:27,159 - INFO -     - accuracy: 0.0500
2025-07-28 10:53:27,159 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-28 10:53:27,159 - INFO -     - accuracy: 0.0000
2025-07-28 10:53:27,159 - INFO -   kmmlu_hard_energy_management:
2025-07-28 10:53:27,159 - INFO -     - accuracy: 0.3500
2025-07-28 10:53:27,159 - INFO -   kmmlu_hard_environmental_science:
2025-07-28 10:53:27,159 - INFO -     - accuracy: 0.0000
2025-07-28 10:53:27,159 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-28 10:53:27,159 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,160 - INFO -   kmmlu_hard_geomatics:
2025-07-28 10:53:27,160 - INFO -     - accuracy: 0.0500
2025-07-28 10:53:27,160 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-28 10:53:27,160 - INFO -     - accuracy: 0.2500
2025-07-28 10:53:27,160 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-28 10:53:27,160 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,160 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-28 10:53:27,160 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,160 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-28 10:53:27,161 - INFO -     - accuracy: 0.1500
2025-07-28 10:53:27,161 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-28 10:53:27,161 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,161 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-28 10:53:27,161 - INFO -     - accuracy: 0.3500
2025-07-28 10:53:27,161 - INFO -   kmmlu_hard_humss:
2025-07-28 10:53:27,161 - INFO -     - accuracy: 0.2545
2025-07-28 10:53:27,161 - INFO -   kmmlu_hard_accounting:
2025-07-28 10:53:27,162 - INFO -     - accuracy: 0.3500
2025-07-28 10:53:27,162 - INFO -   kmmlu_hard_criminal_law:
2025-07-28 10:53:27,162 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,162 - INFO -   kmmlu_hard_economics:
2025-07-28 10:53:27,162 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,162 - INFO -   kmmlu_hard_education:
2025-07-28 10:53:27,162 - INFO -     - accuracy: 0.1000
2025-07-28 10:53:27,162 - INFO -   kmmlu_hard_korean_history:
2025-07-28 10:53:27,162 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,163 - INFO -   kmmlu_hard_law:
2025-07-28 10:53:27,163 - INFO -     - accuracy: 0.2500
2025-07-28 10:53:27,163 - INFO -   kmmlu_hard_management:
2025-07-28 10:53:27,163 - INFO -     - accuracy: 0.2500
2025-07-28 10:53:27,163 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-28 10:53:27,163 - INFO -     - accuracy: 0.4000
2025-07-28 10:53:27,163 - INFO -   kmmlu_hard_psychology:
2025-07-28 10:53:27,163 - INFO -     - accuracy: 0.3000
2025-07-28 10:53:27,163 - INFO -   kmmlu_hard_social_welfare:
2025-07-28 10:53:27,164 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,164 - INFO -   kmmlu_hard_taxation:
2025-07-28 10:53:27,164 - INFO -     - accuracy: 0.3500
2025-07-28 10:53:27,164 - INFO -   kmmlu_hard_other:
2025-07-28 10:53:27,164 - INFO -     - accuracy: 0.1864
2025-07-28 10:53:27,164 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-28 10:53:27,164 - INFO -     - accuracy: 0.1000
2025-07-28 10:53:27,164 - INFO -   kmmlu_hard_construction:
2025-07-28 10:53:27,164 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,165 - INFO -   kmmlu_hard_fashion:
2025-07-28 10:53:27,165 - INFO -     - accuracy: 0.3500
2025-07-28 10:53:27,165 - INFO -   kmmlu_hard_food_processing:
2025-07-28 10:53:27,165 - INFO -     - accuracy: 0.1500
2025-07-28 10:53:27,165 - INFO -   kmmlu_hard_health:
2025-07-28 10:53:27,165 - INFO -     - accuracy: 0.1500
2025-07-28 10:53:27,165 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-28 10:53:27,165 - INFO -     - accuracy: 0.1000
2025-07-28 10:53:27,165 - INFO -   kmmlu_hard_marketing:
2025-07-28 10:53:27,165 - INFO -     - accuracy: 0.3500
2025-07-28 10:53:27,166 - INFO -   kmmlu_hard_patent:
2025-07-28 10:53:27,166 - INFO -     - accuracy: 0.1500
2025-07-28 10:53:27,167 - INFO -   kmmlu_hard_public_safety:
2025-07-28 10:53:27,167 - INFO -     - accuracy: 0.2500
2025-07-28 10:53:27,167 - INFO -   kmmlu_hard_real_estate:
2025-07-28 10:53:27,167 - INFO -     - accuracy: 0.1000
2025-07-28 10:53:27,167 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-28 10:53:27,167 - INFO -     - accuracy: 0.1500
2025-07-28 10:53:27,167 - INFO -   kmmlu_hard_stem:
2025-07-28 10:53:27,167 - INFO -     - accuracy: 0.1955
2025-07-28 10:53:27,168 - INFO -   kmmlu_hard_biology:
2025-07-28 10:53:27,168 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,168 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-28 10:53:27,168 - INFO -     - accuracy: 0.1000
2025-07-28 10:53:27,168 - INFO -   kmmlu_hard_chemistry:
2025-07-28 10:53:27,168 - INFO -     - accuracy: 0.2500
2025-07-28 10:53:27,168 - INFO -   kmmlu_hard_civil_engineering:
2025-07-28 10:53:27,168 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,168 - INFO -   kmmlu_hard_computer_science:
2025-07-28 10:53:27,168 - INFO -     - accuracy: 0.1500
2025-07-28 10:53:27,169 - INFO -   kmmlu_hard_ecology:
2025-07-28 10:53:27,169 - INFO -     - accuracy: 0.1000
2025-07-28 10:53:27,169 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-28 10:53:27,169 - INFO -     - accuracy: 0.3000
2025-07-28 10:53:27,169 - INFO -   kmmlu_hard_information_technology:
2025-07-28 10:53:27,169 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,169 - INFO -   kmmlu_hard_materials_engineering:
2025-07-28 10:53:27,169 - INFO -     - accuracy: 0.2500
2025-07-28 10:53:27,169 - INFO -   kmmlu_hard_math:
2025-07-28 10:53:27,170 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,170 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-28 10:53:27,170 - INFO -     - accuracy: 0.2000
2025-07-28 10:53:27,170 - INFO - ============================================================

2025-07-28 10:53:27,172 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 3/10: haerae
2025-07-28 10:53:27,172 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'haerae' will use num_fewshot=0
2025-07-28 10:53:27,173 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'haerae' with num_fewshot=0
2025-07-28 10:53:27,173 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:53:42,086 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 0
2025-07-28 10:53:42,086 - WARNING - Overwriting default num_fewshot of haerae_history from None to 0
2025-07-28 10:53:42,086 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 0
2025-07-28 10:53:42,086 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 0
2025-07-28 10:53:42,087 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 0
2025-07-28 10:55:53,538 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'haerae' with 6 subtasks
2025-07-28 10:55:53,539 - INFO - 
============================================================
2025-07-28 10:55:53,539 - INFO - Task 'haerae' Results:
2025-07-28 10:55:53,540 - INFO - ============================================================
2025-07-28 10:55:53,540 - INFO -   haerae:
2025-07-28 10:55:53,540 - INFO -     - accuracy: 0.3900
2025-07-28 10:55:53,540 - INFO -     - accuracy_norm: 0.3900
2025-07-28 10:55:53,540 - INFO -   haerae_general_knowledge:
2025-07-28 10:55:53,540 - INFO -     - accuracy: 0.5000
2025-07-28 10:55:53,540 - INFO -     - accuracy_norm: 0.5000
2025-07-28 10:55:53,540 - INFO -   haerae_history:
2025-07-28 10:55:53,540 - INFO -     - accuracy: 0.2000
2025-07-28 10:55:53,540 - INFO -     - accuracy_norm: 0.2000
2025-07-28 10:55:53,541 - INFO -   haerae_loan_word:
2025-07-28 10:55:53,541 - INFO -     - accuracy: 0.4500
2025-07-28 10:55:53,541 - INFO -     - accuracy_norm: 0.4500
2025-07-28 10:55:53,541 - INFO -   haerae_rare_word:
2025-07-28 10:55:53,541 - INFO -     - accuracy: 0.5000
2025-07-28 10:55:53,541 - INFO -     - accuracy_norm: 0.5000
2025-07-28 10:55:53,541 - INFO -   haerae_standard_nomenclature:
2025-07-28 10:55:53,541 - INFO -     - accuracy: 0.3000
2025-07-28 10:55:53,541 - INFO -     - accuracy_norm: 0.3000
2025-07-28 10:55:53,541 - INFO - ============================================================

2025-07-28 10:55:53,542 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 4/10: kobest
2025-07-28 10:55:53,543 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'kobest' will use num_fewshot=0
2025-07-28 10:55:53,543 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'kobest' with num_fewshot=0
2025-07-28 10:55:53,543 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:56:10,962 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 0
2025-07-28 10:56:10,963 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 0
2025-07-28 10:56:10,963 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 0
2025-07-28 10:56:10,963 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 0
2025-07-28 10:56:10,963 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 0
2025-07-28 10:57:15,705 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'kobest' with 6 subtasks
2025-07-28 10:57:15,707 - INFO - 
============================================================
2025-07-28 10:57:15,707 - INFO - Task 'kobest' Results:
2025-07-28 10:57:15,707 - INFO - ============================================================
2025-07-28 10:57:15,707 - INFO -   kobest:
2025-07-28 10:57:15,707 - INFO -     - accuracy: 0.5400
2025-07-28 10:57:15,707 - INFO -     - accuracy_norm: 0.6000
2025-07-28 10:57:15,707 - INFO -     - f1: 0.4449
2025-07-28 10:57:15,707 - INFO -   kobest_boolq:
2025-07-28 10:57:15,708 - INFO -     - accuracy: 0.6000
2025-07-28 10:57:15,708 - INFO -     - f1: 0.5238
2025-07-28 10:57:15,708 - INFO -   kobest_copa:
2025-07-28 10:57:15,708 - INFO -     - accuracy: 0.6000
2025-07-28 10:57:15,708 - INFO -     - f1: 0.6000
2025-07-28 10:57:15,708 - INFO -   kobest_hellaswag:
2025-07-28 10:57:15,708 - INFO -     - accuracy: 0.4000
2025-07-28 10:57:15,708 - INFO -     - accuracy_norm: 0.6000
2025-07-28 10:57:15,708 - INFO -     - f1: 0.3909
2025-07-28 10:57:15,709 - INFO -   kobest_sentineg:
2025-07-28 10:57:15,709 - INFO -     - accuracy: 0.5500
2025-07-28 10:57:15,709 - INFO -     - f1: 0.3548
2025-07-28 10:57:15,709 - INFO -   kobest_wic:
2025-07-28 10:57:15,709 - INFO -     - accuracy: 0.5500
2025-07-28 10:57:15,709 - INFO -     - f1: 0.3548
2025-07-28 10:57:15,709 - INFO - ============================================================

2025-07-28 10:57:15,711 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 5/10: csatqa
2025-07-28 10:57:15,711 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'csatqa' detected as zero-shot task
2025-07-28 10:57:15,711 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'csatqa' with num_fewshot=0
2025-07-28 10:57:15,711 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 10:57:26,066 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-28 10:57:26,066 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-28 10:57:26,066 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-28 10:57:26,066 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-28 10:57:26,066 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-28 10:57:26,067 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-28 11:05:36,546 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'csatqa' with 7 subtasks
2025-07-28 11:05:36,548 - INFO - 
============================================================
2025-07-28 11:05:36,548 - INFO - Task 'csatqa' Results:
2025-07-28 11:05:36,548 - INFO - ============================================================
2025-07-28 11:05:36,548 - INFO -   csatqa:
2025-07-28 11:05:36,548 - INFO -     - accuracy: 0.2523
2025-07-28 11:05:36,548 - INFO -     - accuracy_norm: 0.2523
2025-07-28 11:05:36,548 - INFO -   csatqa_gr:
2025-07-28 11:05:36,548 - INFO -     - accuracy: 0.1500
2025-07-28 11:05:36,549 - INFO -     - accuracy_norm: 0.1500
2025-07-28 11:05:36,549 - INFO -   csatqa_li:
2025-07-28 11:05:36,549 - INFO -     - accuracy: 0.2500
2025-07-28 11:05:36,549 - INFO -     - accuracy_norm: 0.2500
2025-07-28 11:05:36,549 - INFO -   csatqa_rch:
2025-07-28 11:05:36,549 - INFO -     - accuracy: 0.3000
2025-07-28 11:05:36,549 - INFO -     - accuracy_norm: 0.3000
2025-07-28 11:05:36,549 - INFO -   csatqa_rcs:
2025-07-28 11:05:36,549 - INFO -     - accuracy: 0.2500
2025-07-28 11:05:36,550 - INFO -     - accuracy_norm: 0.2500
2025-07-28 11:05:36,550 - INFO -   csatqa_rcss:
2025-07-28 11:05:36,550 - INFO -     - accuracy: 0.3000
2025-07-28 11:05:36,550 - INFO -     - accuracy_norm: 0.3000
2025-07-28 11:05:36,550 - INFO -   csatqa_wr:
2025-07-28 11:05:36,550 - INFO -     - accuracy: 0.2727
2025-07-28 11:05:36,550 - INFO -     - accuracy_norm: 0.2727
2025-07-28 11:05:36,550 - INFO - ============================================================

2025-07-28 11:05:36,560 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 6/10: kormedmcqa
2025-07-28 11:05:36,561 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'kormedmcqa' will use num_fewshot=0
2025-07-28 11:05:36,561 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'kormedmcqa' with num_fewshot=0
2025-07-28 11:05:36,561 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 11:05:53,491 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 0
2025-07-28 11:05:53,491 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 0
2025-07-28 11:05:53,491 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 0
2025-07-28 11:05:53,491 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 0
2025-07-28 11:07:00,448 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-28 11:07:00,449 - INFO - 
============================================================
2025-07-28 11:07:00,449 - INFO - Task 'kormedmcqa' Results:
2025-07-28 11:07:00,449 - INFO - ============================================================
2025-07-28 11:07:00,449 - INFO -   kormedmcqa:
2025-07-28 11:07:00,449 - INFO -     - exact_match: 0.4375
2025-07-28 11:07:00,450 - INFO -   kormedmcqa_dentist:
2025-07-28 11:07:00,450 - INFO -     - exact_match: 0.6000
2025-07-28 11:07:00,450 - INFO -   kormedmcqa_doctor:
2025-07-28 11:07:00,450 - INFO -     - exact_match: 0.3000
2025-07-28 11:07:00,450 - INFO -   kormedmcqa_nurse:
2025-07-28 11:07:00,450 - INFO -     - exact_match: 0.4000
2025-07-28 11:07:00,451 - INFO -   kormedmcqa_pharm:
2025-07-28 11:07:00,451 - INFO -     - exact_match: 0.4500
2025-07-28 11:07:00,451 - INFO - ============================================================

2025-07-28 11:07:00,456 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 7/10: mmlu
2025-07-28 11:07:00,457 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'mmlu' will use num_fewshot=0
2025-07-28 11:07:00,457 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'mmlu' with num_fewshot=0
2025-07-28 11:07:00,457 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 11:09:38,963 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 0
2025-07-28 11:09:38,964 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 0
2025-07-28 11:09:38,964 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 0
2025-07-28 11:09:38,964 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 0
2025-07-28 11:09:38,964 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 0
2025-07-28 11:09:38,964 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 0
2025-07-28 11:09:38,965 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 0
2025-07-28 11:09:38,965 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 0
2025-07-28 11:09:38,965 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 0
2025-07-28 11:09:38,965 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 0
2025-07-28 11:09:38,965 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 0
2025-07-28 11:09:38,965 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 0
2025-07-28 11:09:38,966 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 0
2025-07-28 11:09:38,966 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 0
2025-07-28 11:09:38,966 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 0
2025-07-28 11:09:38,966 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 0
2025-07-28 11:09:38,966 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 0
2025-07-28 11:09:38,966 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 0
2025-07-28 11:09:38,966 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 0
2025-07-28 11:09:38,967 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 0
2025-07-28 11:09:38,967 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 0
2025-07-28 11:09:38,967 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 0
2025-07-28 11:09:38,967 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 0
2025-07-28 11:09:38,967 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 0
2025-07-28 11:09:38,967 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 0
2025-07-28 11:09:38,967 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 0
2025-07-28 11:09:38,968 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 0
2025-07-28 11:09:38,968 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 0
2025-07-28 11:09:38,968 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 0
2025-07-28 11:09:38,968 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 0
2025-07-28 11:09:38,968 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 0
2025-07-28 11:09:38,968 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 0
2025-07-28 11:09:38,968 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 0
2025-07-28 11:09:38,969 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 0
2025-07-28 11:09:38,969 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 0
2025-07-28 11:09:38,969 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 0
2025-07-28 11:09:38,969 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 0
2025-07-28 11:09:38,969 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 0
2025-07-28 11:09:38,969 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 0
2025-07-28 11:09:38,970 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 0
2025-07-28 11:09:38,970 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 0
2025-07-28 11:09:38,970 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 0
2025-07-28 11:09:38,970 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 0
2025-07-28 11:09:38,970 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 0
2025-07-28 11:09:38,970 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 0
2025-07-28 11:09:38,970 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 0
2025-07-28 11:09:38,971 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 0
2025-07-28 11:09:38,971 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 0
2025-07-28 11:09:38,971 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 0
2025-07-28 11:09:38,971 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 0
2025-07-28 11:09:38,971 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 0
2025-07-28 11:09:38,971 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 0
2025-07-28 11:09:38,971 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 0
2025-07-28 11:09:38,971 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 0
2025-07-28 11:09:38,972 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 0
2025-07-28 11:09:38,972 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 0
2025-07-28 11:09:38,972 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 0
2025-07-28 11:14:26,296 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'mmlu' with 62 subtasks
2025-07-28 11:14:26,297 - INFO - 
============================================================
2025-07-28 11:14:26,297 - INFO - Task 'mmlu' Results:
2025-07-28 11:14:26,297 - INFO - ============================================================
2025-07-28 11:14:26,297 - INFO -   mmlu:
2025-07-28 11:14:26,297 - INFO -     - accuracy: 0.6482
2025-07-28 11:14:26,297 - INFO -   mmlu_humanities:
2025-07-28 11:14:26,297 - INFO -     - accuracy: 0.6846
2025-07-28 11:14:26,297 - INFO -   mmlu_formal_logic:
2025-07-28 11:14:26,298 - INFO -     - accuracy: 0.5500
2025-07-28 11:14:26,298 - INFO -   mmlu_high_school_european_history:
2025-07-28 11:14:26,298 - INFO -     - accuracy: 0.7500
2025-07-28 11:14:26,298 - INFO -   mmlu_high_school_us_history:
2025-07-28 11:14:26,298 - INFO -     - accuracy: 0.9000
2025-07-28 11:14:26,298 - INFO -   mmlu_high_school_world_history:
2025-07-28 11:14:26,298 - INFO -     - accuracy: 0.8500
2025-07-28 11:14:26,298 - INFO -   mmlu_international_law:
2025-07-28 11:14:26,299 - INFO -     - accuracy: 0.8000
2025-07-28 11:14:26,299 - INFO -   mmlu_jurisprudence:
2025-07-28 11:14:26,299 - INFO -     - accuracy: 0.8000
2025-07-28 11:14:26,299 - INFO -   mmlu_logical_fallacies:
2025-07-28 11:14:26,299 - INFO -     - accuracy: 0.7000
2025-07-28 11:14:26,299 - INFO -   mmlu_moral_disputes:
2025-07-28 11:14:26,299 - INFO -     - accuracy: 0.5500
2025-07-28 11:14:26,299 - INFO -   mmlu_moral_scenarios:
2025-07-28 11:14:26,299 - INFO -     - accuracy: 0.3500
2025-07-28 11:14:26,300 - INFO -   mmlu_philosophy:
2025-07-28 11:14:26,300 - INFO -     - accuracy: 0.7000
2025-07-28 11:14:26,300 - INFO -   mmlu_prehistory:
2025-07-28 11:14:26,300 - INFO -     - accuracy: 0.7000
2025-07-28 11:14:26,300 - INFO -   mmlu_professional_law:
2025-07-28 11:14:26,300 - INFO -     - accuracy: 0.5500
2025-07-28 11:14:26,300 - INFO -   mmlu_world_religions:
2025-07-28 11:14:26,300 - INFO -     - accuracy: 0.7000
2025-07-28 11:14:26,300 - INFO -   mmlu_other:
2025-07-28 11:14:26,300 - INFO -     - accuracy: 0.6423
2025-07-28 11:14:26,301 - INFO -   mmlu_business_ethics:
2025-07-28 11:14:26,301 - INFO -     - accuracy: 0.8500
2025-07-28 11:14:26,301 - INFO -   mmlu_clinical_knowledge:
2025-07-28 11:14:26,301 - INFO -     - accuracy: 0.7000
2025-07-28 11:14:26,301 - INFO -   mmlu_college_medicine:
2025-07-28 11:14:26,301 - INFO -     - accuracy: 0.7000
2025-07-28 11:14:26,301 - INFO -   mmlu_global_facts:
2025-07-28 11:14:26,301 - INFO -     - accuracy: 0.3000
2025-07-28 11:14:26,301 - INFO -   mmlu_human_aging:
2025-07-28 11:14:26,302 - INFO -     - accuracy: 0.8500
2025-07-28 11:14:26,302 - INFO -   mmlu_management:
2025-07-28 11:14:26,302 - INFO -     - accuracy: 0.7000
2025-07-28 11:14:26,302 - INFO -   mmlu_marketing:
2025-07-28 11:14:26,302 - INFO -     - accuracy: 0.7000
2025-07-28 11:14:26,302 - INFO -   mmlu_medical_genetics:
2025-07-28 11:14:26,302 - INFO -     - accuracy: 0.6500
2025-07-28 11:14:26,302 - INFO -   mmlu_miscellaneous:
2025-07-28 11:14:26,302 - INFO -     - accuracy: 0.7500
2025-07-28 11:14:26,303 - INFO -   mmlu_nutrition:
2025-07-28 11:14:26,303 - INFO -     - accuracy: 0.7500
2025-07-28 11:14:26,303 - INFO -   mmlu_professional_accounting:
2025-07-28 11:14:26,303 - INFO -     - accuracy: 0.4000
2025-07-28 11:14:26,303 - INFO -   mmlu_professional_medicine:
2025-07-28 11:14:26,303 - INFO -     - accuracy: 0.4500
2025-07-28 11:14:26,303 - INFO -   mmlu_virology:
2025-07-28 11:14:26,303 - INFO -     - accuracy: 0.5500
2025-07-28 11:14:26,305 - INFO -   mmlu_social_sciences:
2025-07-28 11:14:26,305 - INFO -     - accuracy: 0.7333
2025-07-28 11:14:26,305 - INFO -   mmlu_econometrics:
2025-07-28 11:14:26,305 - INFO -     - accuracy: 0.5500
2025-07-28 11:14:26,306 - INFO -   mmlu_high_school_geography:
2025-07-28 11:14:26,306 - INFO -     - accuracy: 0.9500
2025-07-28 11:14:26,306 - INFO -   mmlu_high_school_government_and_politics:
2025-07-28 11:14:26,306 - INFO -     - accuracy: 0.8500
2025-07-28 11:14:26,306 - INFO -   mmlu_high_school_macroeconomics:
2025-07-28 11:14:26,306 - INFO -     - accuracy: 0.5000
2025-07-28 11:14:26,307 - INFO -   mmlu_high_school_microeconomics:
2025-07-28 11:14:26,307 - INFO -     - accuracy: 0.6500
2025-07-28 11:14:26,307 - INFO -   mmlu_high_school_psychology:
2025-07-28 11:14:26,307 - INFO -     - accuracy: 0.9000
2025-07-28 11:14:26,307 - INFO -   mmlu_human_sexuality:
2025-07-28 11:14:26,307 - INFO -     - accuracy: 0.7500
2025-07-28 11:14:26,308 - INFO -   mmlu_professional_psychology:
2025-07-28 11:14:26,308 - INFO -     - accuracy: 0.8000
2025-07-28 11:14:26,308 - INFO -   mmlu_public_relations:
2025-07-28 11:14:26,308 - INFO -     - accuracy: 0.3500
2025-07-28 11:14:26,308 - INFO -   mmlu_security_studies:
2025-07-28 11:14:26,308 - INFO -     - accuracy: 0.8500
2025-07-28 11:14:26,308 - INFO -   mmlu_sociology:
2025-07-28 11:14:26,308 - INFO -     - accuracy: 0.8000
2025-07-28 11:14:26,308 - INFO -   mmlu_us_foreign_policy:
2025-07-28 11:14:26,308 - INFO -     - accuracy: 0.8500
2025-07-28 11:14:26,309 - INFO -   mmlu_stem:
2025-07-28 11:14:26,309 - INFO -     - accuracy: 0.5737
2025-07-28 11:14:26,309 - INFO -   mmlu_abstract_algebra:
2025-07-28 11:14:26,309 - INFO -     - accuracy: 0.3000
2025-07-28 11:14:26,309 - INFO -   mmlu_anatomy:
2025-07-28 11:14:26,309 - INFO -     - accuracy: 0.7500
2025-07-28 11:14:26,309 - INFO -   mmlu_astronomy:
2025-07-28 11:14:26,309 - INFO -     - accuracy: 0.8500
2025-07-28 11:14:26,310 - INFO -   mmlu_college_biology:
2025-07-28 11:14:26,310 - INFO -     - accuracy: 0.8500
2025-07-28 11:14:26,310 - INFO -   mmlu_college_chemistry:
2025-07-28 11:14:26,310 - INFO -     - accuracy: 0.5000
2025-07-28 11:14:26,310 - INFO -   mmlu_college_computer_science:
2025-07-28 11:14:26,310 - INFO -     - accuracy: 0.4000
2025-07-28 11:14:26,310 - INFO -   mmlu_college_mathematics:
2025-07-28 11:14:26,310 - INFO -     - accuracy: 0.4500
2025-07-28 11:14:26,310 - INFO -   mmlu_college_physics:
2025-07-28 11:14:26,310 - INFO -     - accuracy: 0.5000
2025-07-28 11:14:26,311 - INFO -   mmlu_computer_security:
2025-07-28 11:14:26,311 - INFO -     - accuracy: 0.8000
2025-07-28 11:14:26,311 - INFO -   mmlu_conceptual_physics:
2025-07-28 11:14:26,311 - INFO -     - accuracy: 0.7500
2025-07-28 11:14:26,311 - INFO -   mmlu_electrical_engineering:
2025-07-28 11:14:26,311 - INFO -     - accuracy: 0.3500
2025-07-28 11:14:26,311 - INFO -   mmlu_elementary_mathematics:
2025-07-28 11:14:26,311 - INFO -     - accuracy: 0.5000
2025-07-28 11:14:26,311 - INFO -   mmlu_high_school_biology:
2025-07-28 11:14:26,312 - INFO -     - accuracy: 0.8500
2025-07-28 11:14:26,312 - INFO -   mmlu_high_school_chemistry:
2025-07-28 11:14:26,312 - INFO -     - accuracy: 0.5500
2025-07-28 11:14:26,312 - INFO -   mmlu_high_school_computer_science:
2025-07-28 11:14:26,312 - INFO -     - accuracy: 0.8000
2025-07-28 11:14:26,312 - INFO -   mmlu_high_school_mathematics:
2025-07-28 11:14:26,312 - INFO -     - accuracy: 0.2500
2025-07-28 11:14:26,312 - INFO -   mmlu_high_school_physics:
2025-07-28 11:14:26,312 - INFO -     - accuracy: 0.4500
2025-07-28 11:14:26,313 - INFO -   mmlu_high_school_statistics:
2025-07-28 11:14:26,313 - INFO -     - accuracy: 0.4000
2025-07-28 11:14:26,313 - INFO -   mmlu_machine_learning:
2025-07-28 11:14:26,313 - INFO -     - accuracy: 0.6000
2025-07-28 11:14:26,313 - INFO - ============================================================

2025-07-28 11:14:26,315 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 8/10: arc_challenge
2025-07-28 11:14:26,315 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'arc_challenge' will use num_fewshot=0
2025-07-28 11:14:26,315 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'arc_challenge' with num_fewshot=0
2025-07-28 11:14:26,316 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 11:14:32,702 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 0
2025-07-28 11:14:54,483 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-28 11:14:54,484 - INFO - 
============================================================
2025-07-28 11:14:54,484 - INFO - Task 'arc_challenge' Results:
2025-07-28 11:14:54,484 - INFO - ============================================================
2025-07-28 11:14:54,484 - INFO -   arc_challenge:
2025-07-28 11:14:54,485 - INFO -     - accuracy: 0.6000
2025-07-28 11:14:54,485 - INFO -     - accuracy_norm: 0.6000
2025-07-28 11:14:54,485 - INFO - ============================================================

2025-07-28 11:14:54,486 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 9/10: arc_easy
2025-07-28 11:14:54,486 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'arc_easy' will use num_fewshot=0
2025-07-28 11:14:54,486 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'arc_easy' with num_fewshot=0
2025-07-28 11:14:54,486 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 11:15:00,928 - WARNING - Overwriting default num_fewshot of arc_easy from None to 0
2025-07-28 11:15:20,937 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-28 11:15:20,938 - INFO - 
============================================================
2025-07-28 11:15:20,938 - INFO - Task 'arc_easy' Results:
2025-07-28 11:15:20,938 - INFO - ============================================================
2025-07-28 11:15:20,939 - INFO -   arc_easy:
2025-07-28 11:15:20,939 - INFO -     - accuracy: 0.8000
2025-07-28 11:15:20,939 - INFO -     - accuracy_norm: 0.8000
2025-07-28 11:15:20,939 - INFO - ============================================================

2025-07-28 11:15:20,940 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Processing task 10/10: hellaswag
2025-07-28 11:15:20,940 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Task 'hellaswag' will use num_fewshot=0
2025-07-28 11:15:20,940 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Evaluating task 'hellaswag' with num_fewshot=0
2025-07-28 11:15:20,940 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-28 11:15:33,602 - WARNING - Overwriting default num_fewshot of hellaswag from None to 0
2025-07-28 11:15:56,253 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-28 11:15:56,254 - INFO - 
============================================================
2025-07-28 11:15:56,255 - INFO - Task 'hellaswag' Results:
2025-07-28 11:15:56,255 - INFO - ============================================================
2025-07-28 11:15:56,255 - INFO -   hellaswag:
2025-07-28 11:15:56,255 - INFO -     - accuracy: 0.6000
2025-07-28 11:15:56,255 - INFO -     - accuracy_norm: 0.6500
2025-07-28 11:15:56,255 - INFO - ============================================================

2025-07-28 11:15:56,256 - INFO - luxia-21.4b-alignment-v1.2_harness_13: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-28 11:15:56,258 - INFO - [Process 1865749] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/phase2_threshold_optimization_20250728_073925/model_results/luxia-21.4b-alignment-v1.2/luxia-21.4b-alignment-v1.2_harness_13.json
2025-07-28 11:15:56,259 - INFO - [Process 1865749] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/luxia-21.4b-alignment-v1.2/luxia-21.4b-alignment-v1.2_harness_13.json
2025-07-28 11:15:56,538 - INFO - Results uploaded to WandB as artifact
2025-07-28 11:15:56,547 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-28 11:15:56,549 - INFO - [Process 1865749] Successfully completed luxia-21.4b-alignment-v1.2_harness_13
2025-07-28 11:15:59,487 - INFO - Run luxia-21.4b-alignment-v1.2_harness_13 finished successfully
2025-07-28 11:15:59,489 - WARNING - No results directory found for model gemma-3-4b-it
2025-07-28 11:15:59,491 - WARNING - No results directory found for model EXAONE-3.5-2.4B-Instruct
2025-07-28 11:15:59,491 - WARNING - No results directory found for model HyperCLOVAX-SEED-Text-Instruct-1.5B
2025-07-28 11:15:59,491 - WARNING - No results directory found for model HyperCLOVAX-SEED-Text-Instruct-0.5B
2025-07-28 11:15:59,491 - WARNING - No results directory found for model kanana-1.5-2.1b-instruct-2505
2025-07-28 11:15:59,491 - WARNING - No results directory found for model eagle-3b-preview
