2025-07-18 04:08:20,933 - INFO - Using experiment directory: /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250718_040814
2025-07-18 04:08:20,934 - INFO - Performance Tracker initialized in main process - mode: baseline
2025-07-18 04:08:20,934 - INFO - ============================================================
2025-07-18 04:08:20,934 - INFO - BASELINE MODE - Traditional Execution
2025-07-18 04:08:20,934 - INFO - ============================================================
2025-07-18 04:08:20,934 - INFO - Processing 1 small models in parallel
2025-07-18 04:08:25,777 - INFO - Performance Tracker initialized in baseline mode
2025-07-18 04:08:25,777 - INFO - [Process 512446] HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_1 assigned to cuda:0
2025-07-18 04:08:25,777 - INFO - [Process 512446] HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_1 - full_run: True, limit: None
2025-07-18 04:08:27,648 - INFO - WandB run initialized: HyperCLOVAX-SEED-Text-Instruct-1.5B_20250718_040825 (ID: 1cfccf3a)
2025-07-18 04:08:27,998 - INFO - HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_1: Processing task 1/1: humaneval
2025-07-18 04:08:27,999 - INFO - HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_1: Task 'humaneval' detected as zero-shot task
2025-07-18 04:08:28,127 - INFO - HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_1: Evaluating task 'humaneval' with num_fewshot=0
2025-07-18 04:08:28,129 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-18 04:09:24,271 - INFO - Using experiment directory: /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250718_040922
2025-07-18 04:09:24,272 - INFO - Performance Tracker initialized in main process - mode: optimized
2025-07-18 04:09:24,272 - INFO - ============================================================
2025-07-18 04:09:24,272 - INFO - OPTIMIZED MODE - Using SchedulerManager
2025-07-18 04:09:24,272 - INFO - ============================================================
2025-07-18 04:09:24,888 - WARNING - Insufficient OOM samples for training classifier
2025-07-18 04:09:25,937 - INFO - Current Scheduler Mode: hybrid
2025-07-18 04:09:25,937 - INFO - Training Records: 1096
2025-07-18 04:09:25,937 - INFO - Using Hybrid Mode (ML + Rule-based)
2025-07-18 04:09:25,937 - INFO - Creating optimal schedule...
2025-07-18 04:09:27,602 - INFO - 
================================================================================
2025-07-18 04:09:27,602 - INFO - Optimal Execution Schedule (HYBRID mode):
2025-07-18 04:09:27,602 - INFO - ================================================================================
2025-07-18 04:09:27,602 - INFO - Priority   Model                          Task                 Est.Time   Est.Mem    GPU  
2025-07-18 04:09:27,602 - INFO - --------------------------------------------------------------------------------
2025-07-18 04:09:27,602 - INFO -    99.12   HyperCLOVAX-SEED-Text-Instru   humaneval               0.0h      1.4GB  GPU0
2025-07-18 04:09:27,602 - INFO - ================================================================================

2025-07-18 04:09:27,801 - INFO - Schedule exported to: /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250718_040922/config/schedule_hybrid.json
2025-07-18 04:09:27,801 - INFO - 
============================================================
2025-07-18 04:09:27,801 - INFO - Executing task 1/1
2025-07-18 04:09:27,801 - INFO - Model: HyperCLOVAX-SEED-Text-Instruct-0.5B
2025-07-18 04:09:27,801 - INFO - Task: humaneval
2025-07-18 04:09:27,801 - INFO - Mode: hybrid
2025-07-18 04:09:27,801 - INFO - Suggested batch_size: 8
2025-07-18 04:09:27,801 - INFO - Suggested num_fewshot: 0
2025-07-18 04:09:27,801 - INFO - Rationale: Hybrid (70.0% ML): Time: 0.0h, Memory: 1.4GB, Success: 80.0%
2025-07-18 04:09:27,802 - INFO - ============================================================
2025-07-18 04:09:28,165 - INFO - [Process 513282] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1 assigned to cuda:0
2025-07-18 04:09:28,165 - INFO - Using scheduler recommended batch_size: 8
2025-07-18 04:09:28,165 - INFO - [Process 513282] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1 - full_run: True, limit: None
2025-07-18 04:09:30,069 - INFO - WandB run initialized: HyperCLOVAX-SEED-Text-Instruct-0.5B_20250718_040928 (ID: 6a0da255)
2025-07-18 04:09:30,395 - INFO - Using scheduler recommended num_fewshot: 0
2025-07-18 04:09:30,395 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Processing task 1/1: humaneval
2025-07-18 04:09:30,395 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Task 'humaneval' detected as zero-shot task
2025-07-18 04:09:30,523 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Evaluating task 'humaneval' with num_fewshot=0
2025-07-18 04:09:30,524 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-18 04:17:20,321 - INFO - Using experiment directory: /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250718_041719
2025-07-18 04:17:20,322 - INFO - Performance Tracker initialized in main process - mode: baseline
2025-07-18 04:17:20,322 - INFO - ============================================================
2025-07-18 04:17:20,322 - INFO - BASELINE MODE - Traditional Execution
2025-07-18 04:17:20,322 - INFO - ============================================================
2025-07-18 04:17:20,322 - INFO - Processing 1 small models in parallel
2025-07-18 04:17:25,294 - INFO - Performance Tracker initialized in baseline mode
2025-07-18 04:17:25,294 - INFO - [Process 526479] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1 assigned to cuda:0
2025-07-18 04:17:25,294 - INFO - [Process 526479] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1 - full_run: True, limit: None
2025-07-18 04:17:27,058 - INFO - WandB run initialized: HyperCLOVAX-SEED-Text-Instruct-0.5B_20250718_041725 (ID: 6a0da255)
2025-07-18 04:17:27,414 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Processing task 1/1: humaneval
2025-07-18 04:17:27,414 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Task 'humaneval' detected as zero-shot task
2025-07-18 04:17:27,541 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Evaluating task 'humaneval' with num_fewshot=0
2025-07-18 04:17:27,543 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-18 04:51:32,129 - INFO - Using experiment directory: /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250718_045130
2025-07-18 04:51:32,129 - INFO - Performance Tracker initialized in main process - mode: baseline
2025-07-18 04:51:32,129 - INFO - ============================================================
2025-07-18 04:51:32,129 - INFO - BASELINE MODE - Traditional Execution
2025-07-18 04:51:32,129 - INFO - ============================================================
2025-07-18 04:51:32,129 - INFO - Processing 1 small models in parallel
2025-07-18 04:51:37,069 - INFO - Performance Tracker initialized in baseline mode
2025-07-18 04:51:37,069 - INFO - [Process 532972] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1 assigned to cuda:0
2025-07-18 04:51:37,069 - INFO - [Process 532972] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1 - full_run: True, limit: None
2025-07-18 04:51:38,937 - INFO - WandB run initialized: HyperCLOVAX-SEED-Text-Instruct-0.5B_20250718_045137 (ID: 48453a58)
2025-07-18 04:51:39,232 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Processing task 1/1: kmmlu
2025-07-18 04:51:39,233 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Task 'kmmlu' will use num_fewshot=5
2025-07-18 04:51:39,361 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-18 04:51:39,362 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-18 04:52:47,870 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-18 04:52:47,871 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-18 04:52:47,871 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-18 04:52:47,871 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-18 04:52:47,871 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-18 04:52:47,871 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-18 04:52:47,871 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-18 04:52:47,872 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-18 04:52:47,873 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-18 04:52:47,874 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-18 04:52:47,875 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-18 04:52:47,875 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-18 04:52:47,875 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-18 05:13:15,624 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-18 05:13:15,777 - INFO - 
============================================================
2025-07-18 05:13:15,777 - INFO - Task 'kmmlu' Results:
2025-07-18 05:13:15,777 - INFO - ============================================================
2025-07-18 05:13:15,778 - INFO -   kmmlu:
2025-07-18 05:13:15,779 - INFO -     - accuracy: 0.3789
2025-07-18 05:13:15,779 - INFO -   kmmlu_applied_science:
2025-07-18 05:13:15,779 - INFO -     - accuracy: 0.3753
2025-07-18 05:13:15,779 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-18 05:13:15,779 - INFO -     - accuracy: 0.3510
2025-07-18 05:13:15,779 - INFO -   kmmlu_electronics_engineering:
2025-07-18 05:13:15,780 - INFO -     - accuracy: 0.4410
2025-07-18 05:13:15,780 - INFO -   kmmlu_energy_management:
2025-07-18 05:13:15,780 - INFO -     - accuracy: 0.2940
2025-07-18 05:13:15,780 - INFO -   kmmlu_environmental_science:
2025-07-18 05:13:15,780 - INFO -     - accuracy: 0.3130
2025-07-18 05:13:15,780 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-18 05:13:15,780 - INFO -     - accuracy: 0.3550
2025-07-18 05:13:15,780 - INFO -   kmmlu_geomatics:
2025-07-18 05:13:15,780 - INFO -     - accuracy: 0.3740
2025-07-18 05:13:15,781 - INFO -   kmmlu_industrial_engineer:
2025-07-18 05:13:15,781 - INFO -     - accuracy: 0.3790
2025-07-18 05:13:15,781 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-18 05:13:15,781 - INFO -     - accuracy: 0.3950
2025-07-18 05:13:15,781 - INFO -   kmmlu_maritime_engineering:
2025-07-18 05:13:15,781 - INFO -     - accuracy: 0.3883
2025-07-18 05:13:15,781 - INFO -   kmmlu_nondestructive_testing:
2025-07-18 05:13:15,781 - INFO -     - accuracy: 0.4020
2025-07-18 05:13:15,782 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-18 05:13:15,782 - INFO -     - accuracy: 0.3150
2025-07-18 05:13:15,782 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-18 05:13:15,782 - INFO -     - accuracy: 0.5010
2025-07-18 05:13:15,782 - INFO -   kmmlu_humss:
2025-07-18 05:13:15,782 - INFO -     - accuracy: 0.3690
2025-07-18 05:13:15,782 - INFO -   kmmlu_accounting:
2025-07-18 05:13:15,782 - INFO -     - accuracy: 0.3200
2025-07-18 05:13:15,783 - INFO -   kmmlu_criminal_law:
2025-07-18 05:13:15,783 - INFO -     - accuracy: 0.3400
2025-07-18 05:13:15,783 - INFO -   kmmlu_economics:
2025-07-18 05:13:15,783 - INFO -     - accuracy: 0.3846
2025-07-18 05:13:15,783 - INFO -   kmmlu_education:
2025-07-18 05:13:15,783 - INFO -     - accuracy: 0.3700
2025-07-18 05:13:15,783 - INFO -   kmmlu_korean_history:
2025-07-18 05:13:15,783 - INFO -     - accuracy: 0.2800
2025-07-18 05:13:15,783 - INFO -   kmmlu_law:
2025-07-18 05:13:15,784 - INFO -     - accuracy: 0.3730
2025-07-18 05:13:15,784 - INFO -   kmmlu_management:
2025-07-18 05:13:15,784 - INFO -     - accuracy: 0.4050
2025-07-18 05:13:15,784 - INFO -   kmmlu_political_science_and_sociology:
2025-07-18 05:13:15,784 - INFO -     - accuracy: 0.4000
2025-07-18 05:13:15,784 - INFO -   kmmlu_psychology:
2025-07-18 05:13:15,784 - INFO -     - accuracy: 0.3240
2025-07-18 05:13:15,784 - INFO -   kmmlu_social_welfare:
2025-07-18 05:13:15,784 - INFO -     - accuracy: 0.3950
2025-07-18 05:13:15,785 - INFO -   kmmlu_taxation:
2025-07-18 05:13:15,785 - INFO -     - accuracy: 0.3050
2025-07-18 05:13:15,785 - INFO -   kmmlu_other:
2025-07-18 05:13:15,785 - INFO -     - accuracy: 0.3837
2025-07-18 05:13:15,785 - INFO -   kmmlu_agricultural_sciences:
2025-07-18 05:13:15,785 - INFO -     - accuracy: 0.3260
2025-07-18 05:13:15,785 - INFO -   kmmlu_construction:
2025-07-18 05:13:15,785 - INFO -     - accuracy: 0.3000
2025-07-18 05:13:15,786 - INFO -   kmmlu_fashion:
2025-07-18 05:13:15,786 - INFO -     - accuracy: 0.3940
2025-07-18 05:13:15,786 - INFO -   kmmlu_food_processing:
2025-07-18 05:13:15,786 - INFO -     - accuracy: 0.2980
2025-07-18 05:13:15,786 - INFO -   kmmlu_health:
2025-07-18 05:13:15,786 - INFO -     - accuracy: 0.4900
2025-07-18 05:13:15,786 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-18 05:13:15,786 - INFO -     - accuracy: 0.4820
2025-07-18 05:13:15,786 - INFO -   kmmlu_marketing:
2025-07-18 05:13:15,787 - INFO -     - accuracy: 0.6350
2025-07-18 05:13:15,787 - INFO -   kmmlu_patent:
2025-07-18 05:13:15,787 - INFO -     - accuracy: 0.3500
2025-07-18 05:13:15,787 - INFO -   kmmlu_public_safety:
2025-07-18 05:13:15,787 - INFO -     - accuracy: 0.3230
2025-07-18 05:13:15,787 - INFO -   kmmlu_real_estate:
2025-07-18 05:13:15,787 - INFO -     - accuracy: 0.3400
2025-07-18 05:13:15,787 - INFO -   kmmlu_refrigerating_machinery:
2025-07-18 05:13:15,787 - INFO -     - accuracy: 0.3130
2025-07-18 05:13:15,788 - INFO -   kmmlu_stem:
2025-07-18 05:13:15,788 - INFO -     - accuracy: 0.3841
2025-07-18 05:13:15,788 - INFO -   kmmlu_biology:
2025-07-18 05:13:15,788 - INFO -     - accuracy: 0.2880
2025-07-18 05:13:15,788 - INFO -   kmmlu_chemical_engineering:
2025-07-18 05:13:15,788 - INFO -     - accuracy: 0.3220
2025-07-18 05:13:15,788 - INFO -   kmmlu_chemistry:
2025-07-18 05:13:15,788 - INFO -     - accuracy: 0.3467
2025-07-18 05:13:15,789 - INFO -   kmmlu_civil_engineering:
2025-07-18 05:13:15,789 - INFO -     - accuracy: 0.3710
2025-07-18 05:13:15,789 - INFO -   kmmlu_computer_science:
2025-07-18 05:13:15,789 - INFO -     - accuracy: 0.5190
2025-07-18 05:13:15,789 - INFO -   kmmlu_ecology:
2025-07-18 05:13:15,789 - INFO -     - accuracy: 0.3930
2025-07-18 05:13:15,789 - INFO -   kmmlu_electrical_engineering:
2025-07-18 05:13:15,789 - INFO -     - accuracy: 0.3300
2025-07-18 05:13:15,789 - INFO -   kmmlu_information_technology:
2025-07-18 05:13:15,790 - INFO -     - accuracy: 0.5620
2025-07-18 05:13:15,790 - INFO -   kmmlu_materials_engineering:
2025-07-18 05:13:15,790 - INFO -     - accuracy: 0.3630
2025-07-18 05:13:15,790 - INFO -   kmmlu_math:
2025-07-18 05:13:15,790 - INFO -     - accuracy: 0.2833
2025-07-18 05:13:15,790 - INFO -   kmmlu_mechanical_engineering:
2025-07-18 05:13:15,790 - INFO -     - accuracy: 0.3620
2025-07-18 05:13:15,790 - INFO - ============================================================

2025-07-18 05:13:15,796 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1: Completed evaluation - 50 subtasks from 1 requested tasks
2025-07-18 05:13:15,798 - INFO - [Process 532972] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/HyperCLOVAX-SEED-Text-Instruct-0.5B/HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1.json
2025-07-18 05:13:16,092 - INFO - Results uploaded to WandB as artifact
2025-07-18 05:13:16,095 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-18 05:13:16,095 - INFO - [Process 532972] Successfully completed HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1
2025-07-18 05:13:18,929 - INFO - Run HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_1 finished successfully
2025-07-18 05:13:21,224 - INFO - 
============================================================
2025-07-18 05:13:21,224 - INFO - Performance Tracking Summary
2025-07-18 05:13:21,224 - INFO - ============================================================
2025-07-18 05:13:21,224 - INFO - Mode: baseline
2025-07-18 05:13:21,224 - INFO - Total runs: 122
2025-07-18 05:13:21,224 - INFO - Successful: 121
2025-07-18 05:13:21,224 - INFO - OOM failures: 0
2025-07-18 05:13:21,224 - INFO - Other failures: 1
2025-07-18 05:13:21,224 - INFO - Total execution time: 201792.25s (56.05 hours)
2025-07-18 05:13:21,224 - INFO - ============================================================

2025-07-29 04:11:18,615 - INFO - Using experiment directory: /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250729_041113
2025-07-29 04:11:18,626 - INFO - ConfigManager initialized successfully
2025-07-29 04:11:18,724 - INFO - PerformanceTracker initialized - mode: baseline
2025-07-29 04:11:18,724 - INFO - ============================================================
2025-07-29 04:11:18,725 - INFO - BASELINE MODE - Traditional Execution
2025-07-29 04:11:18,725 - INFO - ============================================================
2025-07-29 04:11:18,725 - INFO - Processing 4 medium models sequentially
2025-07-29 04:11:18,752 - INFO - [Process 1941996] Llama-3.1-8B_harness_1 assigned to cuda:0
2025-07-29 04:11:18,752 - INFO - [Process 1941996] Llama-3.1-8B_harness_1 - full_run: True, limit: None (full dataset)
2025-07-29 04:11:20,816 - INFO - WandB run initialized: Llama-3.1-8B_20250729_041118 (ID: fea3999e)
2025-07-29 04:11:21,127 - INFO - Llama-3.1-8B_harness_1: Processing task 1/10: kmmlu
2025-07-29 04:11:21,127 - INFO - Llama-3.1-8B_harness_1: Task 'kmmlu' will use num_fewshot=5
2025-07-29 04:11:21,258 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-29 04:11:21,260 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 04:12:39,851 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-29 04:12:39,851 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-29 04:12:39,851 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-29 04:12:39,851 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-29 04:12:39,851 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-29 04:12:39,852 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-29 04:12:39,852 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-29 04:12:39,852 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-29 04:12:39,852 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-29 04:12:39,852 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-29 04:12:39,852 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-29 04:12:39,852 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-29 04:12:39,853 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-29 04:12:39,853 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-29 04:12:39,853 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-29 04:12:39,853 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-29 04:12:39,853 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-29 04:12:39,853 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-29 04:12:39,853 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-29 04:12:39,853 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-29 04:12:39,854 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-29 04:12:39,854 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-29 04:12:39,854 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-29 04:12:39,854 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-29 04:12:39,854 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-29 04:12:39,854 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-29 04:12:39,854 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-29 04:12:39,855 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-29 04:12:39,855 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-29 04:12:39,855 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-29 04:12:39,855 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-29 04:12:39,855 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-29 04:12:39,855 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-29 04:12:39,855 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-29 04:12:39,855 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-29 04:12:39,856 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-29 04:12:39,856 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-29 04:12:39,856 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-29 04:12:39,856 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-29 04:12:39,856 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-29 04:12:39,856 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-29 04:12:39,856 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-29 04:12:39,856 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-29 04:12:39,857 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-29 04:12:39,857 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-29 04:58:06,868 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-29 04:58:07,099 - INFO - 
============================================================
2025-07-29 04:58:07,100 - INFO - Task 'kmmlu' Results:
2025-07-29 04:58:07,100 - INFO - ============================================================
2025-07-29 04:58:07,100 - INFO -   kmmlu:
2025-07-29 04:58:07,100 - INFO -     - accuracy: 0.4057
2025-07-29 04:58:07,100 - INFO -   kmmlu_applied_science:
2025-07-29 04:58:07,100 - INFO -     - accuracy: 0.3810
2025-07-29 04:58:07,100 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-29 04:58:07,101 - INFO -     - accuracy: 0.3570
2025-07-29 04:58:07,101 - INFO -   kmmlu_electronics_engineering:
2025-07-29 04:58:07,102 - INFO -     - accuracy: 0.4710
2025-07-29 04:58:07,102 - INFO -   kmmlu_energy_management:
2025-07-29 04:58:07,102 - INFO -     - accuracy: 0.3110
2025-07-29 04:58:07,102 - INFO -   kmmlu_environmental_science:
2025-07-29 04:58:07,102 - INFO -     - accuracy: 0.2930
2025-07-29 04:58:07,102 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-29 04:58:07,102 - INFO -     - accuracy: 0.2980
2025-07-29 04:58:07,103 - INFO -   kmmlu_geomatics:
2025-07-29 04:58:07,103 - INFO -     - accuracy: 0.3730
2025-07-29 04:58:07,103 - INFO -   kmmlu_industrial_engineer:
2025-07-29 04:58:07,103 - INFO -     - accuracy: 0.4020
2025-07-29 04:58:07,103 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-29 04:58:07,103 - INFO -     - accuracy: 0.4080
2025-07-29 04:58:07,103 - INFO -   kmmlu_maritime_engineering:
2025-07-29 04:58:07,103 - INFO -     - accuracy: 0.4167
2025-07-29 04:58:07,103 - INFO -   kmmlu_nondestructive_testing:
2025-07-29 04:58:07,104 - INFO -     - accuracy: 0.3940
2025-07-29 04:58:07,104 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-29 04:58:07,104 - INFO -     - accuracy: 0.3420
2025-07-29 04:58:07,104 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-29 04:58:07,104 - INFO -     - accuracy: 0.5210
2025-07-29 04:58:07,104 - INFO -   kmmlu_humss:
2025-07-29 04:58:07,104 - INFO -     - accuracy: 0.4117
2025-07-29 04:58:07,104 - INFO -   kmmlu_accounting:
2025-07-29 04:58:07,104 - INFO -     - accuracy: 0.3500
2025-07-29 04:58:07,105 - INFO -   kmmlu_criminal_law:
2025-07-29 04:58:07,105 - INFO -     - accuracy: 0.2750
2025-07-29 04:58:07,105 - INFO -   kmmlu_economics:
2025-07-29 04:58:07,105 - INFO -     - accuracy: 0.4462
2025-07-29 04:58:07,105 - INFO -   kmmlu_education:
2025-07-29 04:58:07,105 - INFO -     - accuracy: 0.5300
2025-07-29 04:58:07,105 - INFO -   kmmlu_korean_history:
2025-07-29 04:58:07,105 - INFO -     - accuracy: 0.3100
2025-07-29 04:58:07,105 - INFO -   kmmlu_law:
2025-07-29 04:58:07,106 - INFO -     - accuracy: 0.3770
2025-07-29 04:58:07,106 - INFO -   kmmlu_management:
2025-07-29 04:58:07,106 - INFO -     - accuracy: 0.4790
2025-07-29 04:58:07,106 - INFO -   kmmlu_political_science_and_sociology:
2025-07-29 04:58:07,106 - INFO -     - accuracy: 0.4367
2025-07-29 04:58:07,106 - INFO -   kmmlu_psychology:
2025-07-29 04:58:07,106 - INFO -     - accuracy: 0.3610
2025-07-29 04:58:07,106 - INFO -   kmmlu_social_welfare:
2025-07-29 04:58:07,106 - INFO -     - accuracy: 0.4680
2025-07-29 04:58:07,107 - INFO -   kmmlu_taxation:
2025-07-29 04:58:07,107 - INFO -     - accuracy: 0.3200
2025-07-29 04:58:07,107 - INFO -   kmmlu_other:
2025-07-29 04:58:07,107 - INFO -     - accuracy: 0.4060
2025-07-29 04:58:07,107 - INFO -   kmmlu_agricultural_sciences:
2025-07-29 04:58:07,107 - INFO -     - accuracy: 0.3160
2025-07-29 04:58:07,107 - INFO -   kmmlu_construction:
2025-07-29 04:58:07,107 - INFO -     - accuracy: 0.3390
2025-07-29 04:58:07,107 - INFO -   kmmlu_fashion:
2025-07-29 04:58:07,108 - INFO -     - accuracy: 0.4240
2025-07-29 04:58:07,108 - INFO -   kmmlu_food_processing:
2025-07-29 04:58:07,108 - INFO -     - accuracy: 0.3490
2025-07-29 04:58:07,108 - INFO -   kmmlu_health:
2025-07-29 04:58:07,108 - INFO -     - accuracy: 0.5200
2025-07-29 04:58:07,108 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-29 04:58:07,108 - INFO -     - accuracy: 0.4630
2025-07-29 04:58:07,108 - INFO -   kmmlu_marketing:
2025-07-29 04:58:07,108 - INFO -     - accuracy: 0.7020
2025-07-29 04:58:07,109 - INFO -   kmmlu_patent:
2025-07-29 04:58:07,109 - INFO -     - accuracy: 0.4200
2025-07-29 04:58:07,109 - INFO -   kmmlu_public_safety:
2025-07-29 04:58:07,109 - INFO -     - accuracy: 0.3240
2025-07-29 04:58:07,109 - INFO -   kmmlu_real_estate:
2025-07-29 04:58:07,109 - INFO -     - accuracy: 0.3900
2025-07-29 04:58:07,109 - INFO -   kmmlu_refrigerating_machinery:
2025-07-29 04:58:07,109 - INFO -     - accuracy: 0.3210
2025-07-29 04:58:07,109 - INFO -   kmmlu_stem:
2025-07-29 04:58:07,110 - INFO -     - accuracy: 0.4312
2025-07-29 04:58:07,110 - INFO -   kmmlu_biology:
2025-07-29 04:58:07,110 - INFO -     - accuracy: 0.3470
2025-07-29 04:58:07,110 - INFO -   kmmlu_chemical_engineering:
2025-07-29 04:58:07,110 - INFO -     - accuracy: 0.3980
2025-07-29 04:58:07,110 - INFO -   kmmlu_chemistry:
2025-07-29 04:58:07,110 - INFO -     - accuracy: 0.4267
2025-07-29 04:58:07,110 - INFO -   kmmlu_civil_engineering:
2025-07-29 04:58:07,110 - INFO -     - accuracy: 0.4000
2025-07-29 04:58:07,111 - INFO -   kmmlu_computer_science:
2025-07-29 04:58:07,111 - INFO -     - accuracy: 0.6690
2025-07-29 04:58:07,111 - INFO -   kmmlu_ecology:
2025-07-29 04:58:07,111 - INFO -     - accuracy: 0.4020
2025-07-29 04:58:07,111 - INFO -   kmmlu_electrical_engineering:
2025-07-29 04:58:07,111 - INFO -     - accuracy: 0.3210
2025-07-29 04:58:07,111 - INFO -   kmmlu_information_technology:
2025-07-29 04:58:07,111 - INFO -     - accuracy: 0.6390
2025-07-29 04:58:07,111 - INFO -   kmmlu_materials_engineering:
2025-07-29 04:58:07,112 - INFO -     - accuracy: 0.4070
2025-07-29 04:58:07,112 - INFO -   kmmlu_math:
2025-07-29 04:58:07,112 - INFO -     - accuracy: 0.2700
2025-07-29 04:58:07,112 - INFO -   kmmlu_mechanical_engineering:
2025-07-29 04:58:07,112 - INFO -     - accuracy: 0.3490
2025-07-29 04:58:07,112 - INFO - ============================================================

2025-07-29 04:58:07,151 - INFO - Llama-3.1-8B_harness_1: Processing task 2/10: kmmlu_hard
2025-07-29 04:58:07,152 - INFO - Llama-3.1-8B_harness_1: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-29 04:58:07,279 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-29 04:58:07,280 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 04:59:27,100 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-29 04:59:27,101 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-29 04:59:27,101 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-29 04:59:27,101 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-29 04:59:27,101 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-29 04:59:27,101 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-29 04:59:27,101 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-29 04:59:27,101 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-29 04:59:27,101 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-29 04:59:27,102 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-29 04:59:27,103 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-29 04:59:27,104 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-29 04:59:27,105 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-29 04:59:27,105 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-29 04:59:27,105 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-29 05:05:24,341 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-29 05:05:24,484 - INFO - 
============================================================
2025-07-29 05:05:24,485 - INFO - Task 'kmmlu_hard' Results:
2025-07-29 05:05:24,485 - INFO - ============================================================
2025-07-29 05:05:24,485 - INFO -   kmmlu_hard:
2025-07-29 05:05:24,485 - INFO -     - accuracy: 0.2083
2025-07-29 05:05:24,485 - INFO -   kmmlu_hard_applied_science:
2025-07-29 05:05:24,485 - INFO -     - accuracy: 0.2150
2025-07-29 05:05:24,485 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-29 05:05:24,485 - INFO -     - accuracy: 0.1700
2025-07-29 05:05:24,486 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-29 05:05:24,486 - INFO -     - accuracy: 0.2400
2025-07-29 05:05:24,486 - INFO -   kmmlu_hard_energy_management:
2025-07-29 05:05:24,486 - INFO -     - accuracy: 0.3100
2025-07-29 05:05:24,486 - INFO -   kmmlu_hard_environmental_science:
2025-07-29 05:05:24,486 - INFO -     - accuracy: 0.1500
2025-07-29 05:05:24,486 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-29 05:05:24,486 - INFO -     - accuracy: 0.1400
2025-07-29 05:05:24,487 - INFO -   kmmlu_hard_geomatics:
2025-07-29 05:05:24,487 - INFO -     - accuracy: 0.2200
2025-07-29 05:05:24,487 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-29 05:05:24,487 - INFO -     - accuracy: 0.1800
2025-07-29 05:05:24,487 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-29 05:05:24,487 - INFO -     - accuracy: 0.2300
2025-07-29 05:05:24,487 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-29 05:05:24,487 - INFO -     - accuracy: 0.2000
2025-07-29 05:05:24,487 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-29 05:05:24,487 - INFO -     - accuracy: 0.2700
2025-07-29 05:05:24,488 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-29 05:05:24,488 - INFO -     - accuracy: 0.2200
2025-07-29 05:05:24,488 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-29 05:05:24,488 - INFO -     - accuracy: 0.2500
2025-07-29 05:05:24,488 - INFO -   kmmlu_hard_humss:
2025-07-29 05:05:24,488 - INFO -     - accuracy: 0.2081
2025-07-29 05:05:24,518 - INFO -   kmmlu_hard_accounting:
2025-07-29 05:05:24,519 - INFO -     - accuracy: 0.1957
2025-07-29 05:05:24,519 - INFO -   kmmlu_hard_criminal_law:
2025-07-29 05:05:24,519 - INFO -     - accuracy: 0.2300
2025-07-29 05:05:24,519 - INFO -   kmmlu_hard_economics:
2025-07-29 05:05:24,519 - INFO -     - accuracy: 0.2143
2025-07-29 05:05:24,519 - INFO -   kmmlu_hard_education:
2025-07-29 05:05:24,519 - INFO -     - accuracy: 0.0870
2025-07-29 05:05:24,519 - INFO -   kmmlu_hard_korean_history:
2025-07-29 05:05:24,519 - INFO -     - accuracy: 0.1591
2025-07-29 05:05:24,520 - INFO -   kmmlu_hard_law:
2025-07-29 05:05:24,520 - INFO -     - accuracy: 0.2200
2025-07-29 05:05:24,520 - INFO -   kmmlu_hard_management:
2025-07-29 05:05:24,520 - INFO -     - accuracy: 0.2600
2025-07-29 05:05:24,520 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-29 05:05:24,520 - INFO -     - accuracy: 0.1889
2025-07-29 05:05:24,520 - INFO -   kmmlu_hard_psychology:
2025-07-29 05:05:24,520 - INFO -     - accuracy: 0.1500
2025-07-29 05:05:24,521 - INFO -   kmmlu_hard_social_welfare:
2025-07-29 05:05:24,521 - INFO -     - accuracy: 0.2300
2025-07-29 05:05:24,521 - INFO -   kmmlu_hard_taxation:
2025-07-29 05:05:24,521 - INFO -     - accuracy: 0.2292
2025-07-29 05:05:24,521 - INFO -   kmmlu_hard_other:
2025-07-29 05:05:24,521 - INFO -     - accuracy: 0.2035
2025-07-29 05:05:24,521 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-29 05:05:24,521 - INFO -     - accuracy: 0.2000
2025-07-29 05:05:24,521 - INFO -   kmmlu_hard_construction:
2025-07-29 05:05:24,522 - INFO -     - accuracy: 0.1900
2025-07-29 05:05:24,522 - INFO -   kmmlu_hard_fashion:
2025-07-29 05:05:24,522 - INFO -     - accuracy: 0.2700
2025-07-29 05:05:24,522 - INFO -   kmmlu_hard_food_processing:
2025-07-29 05:05:24,522 - INFO -     - accuracy: 0.1400
2025-07-29 05:05:24,522 - INFO -   kmmlu_hard_health:
2025-07-29 05:05:24,522 - INFO -     - accuracy: 0.0435
2025-07-29 05:05:24,522 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-29 05:05:24,522 - INFO -     - accuracy: 0.2500
2025-07-29 05:05:24,523 - INFO -   kmmlu_hard_marketing:
2025-07-29 05:05:24,523 - INFO -     - accuracy: 0.2000
2025-07-29 05:05:24,523 - INFO -   kmmlu_hard_patent:
2025-07-29 05:05:24,523 - INFO -     - accuracy: 0.2157
2025-07-29 05:05:24,523 - INFO -   kmmlu_hard_public_safety:
2025-07-29 05:05:24,523 - INFO -     - accuracy: 0.1600
2025-07-29 05:05:24,523 - INFO -   kmmlu_hard_real_estate:
2025-07-29 05:05:24,523 - INFO -     - accuracy: 0.2584
2025-07-29 05:05:24,523 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-29 05:05:24,524 - INFO -     - accuracy: 0.2000
2025-07-29 05:05:24,524 - INFO -   kmmlu_hard_stem:
2025-07-29 05:05:24,524 - INFO -     - accuracy: 0.2055
2025-07-29 05:05:24,524 - INFO -   kmmlu_hard_biology:
2025-07-29 05:05:24,524 - INFO -     - accuracy: 0.1900
2025-07-29 05:05:24,524 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-29 05:05:24,524 - INFO -     - accuracy: 0.1700
2025-07-29 05:05:24,524 - INFO -   kmmlu_hard_chemistry:
2025-07-29 05:05:24,524 - INFO -     - accuracy: 0.2900
2025-07-29 05:05:24,525 - INFO -   kmmlu_hard_civil_engineering:
2025-07-29 05:05:24,525 - INFO -     - accuracy: 0.2200
2025-07-29 05:05:24,525 - INFO -   kmmlu_hard_computer_science:
2025-07-29 05:05:24,525 - INFO -     - accuracy: 0.2300
2025-07-29 05:05:24,525 - INFO -   kmmlu_hard_ecology:
2025-07-29 05:05:24,525 - INFO -     - accuracy: 0.1600
2025-07-29 05:05:24,525 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-29 05:05:24,525 - INFO -     - accuracy: 0.1700
2025-07-29 05:05:24,525 - INFO -   kmmlu_hard_information_technology:
2025-07-29 05:05:24,526 - INFO -     - accuracy: 0.2000
2025-07-29 05:05:24,526 - INFO -   kmmlu_hard_materials_engineering:
2025-07-29 05:05:24,526 - INFO -     - accuracy: 0.1800
2025-07-29 05:05:24,526 - INFO -   kmmlu_hard_math:
2025-07-29 05:05:24,526 - INFO -     - accuracy: 0.2200
2025-07-29 05:05:24,526 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-29 05:05:24,526 - INFO -     - accuracy: 0.2300
2025-07-29 05:05:24,526 - INFO - ============================================================

2025-07-29 05:05:24,567 - INFO - Llama-3.1-8B_harness_1: Processing task 3/10: haerae
2025-07-29 05:05:24,569 - INFO - Llama-3.1-8B_harness_1: Task 'haerae' will use num_fewshot=5
2025-07-29 05:05:24,695 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'haerae' with num_fewshot=5
2025-07-29 05:05:24,696 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 05:05:46,432 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-29 05:05:46,433 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-29 05:05:46,433 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-29 05:05:46,433 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-29 05:05:46,433 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-29 05:11:48,907 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'haerae' with 6 subtasks
2025-07-29 05:11:49,053 - INFO - 
============================================================
2025-07-29 05:11:49,053 - INFO - Task 'haerae' Results:
2025-07-29 05:11:49,053 - INFO - ============================================================
2025-07-29 05:11:49,053 - INFO -   haerae:
2025-07-29 05:11:49,053 - INFO -     - accuracy: 0.6104
2025-07-29 05:11:49,054 - INFO -     - accuracy_norm: 0.6104
2025-07-29 05:11:49,054 - INFO -   haerae_general_knowledge:
2025-07-29 05:11:49,054 - INFO -     - accuracy: 0.3807
2025-07-29 05:11:49,054 - INFO -     - accuracy_norm: 0.3807
2025-07-29 05:11:49,054 - INFO -   haerae_history:
2025-07-29 05:11:49,054 - INFO -     - accuracy: 0.5426
2025-07-29 05:11:49,054 - INFO -     - accuracy_norm: 0.5426
2025-07-29 05:11:49,054 - INFO -   haerae_loan_word:
2025-07-29 05:11:49,055 - INFO -     - accuracy: 0.6627
2025-07-29 05:11:49,055 - INFO -     - accuracy_norm: 0.6627
2025-07-29 05:11:49,055 - INFO -   haerae_rare_word:
2025-07-29 05:11:49,055 - INFO -     - accuracy: 0.6741
2025-07-29 05:11:49,055 - INFO -     - accuracy_norm: 0.6741
2025-07-29 05:11:49,055 - INFO -   haerae_standard_nomenclature:
2025-07-29 05:11:49,055 - INFO -     - accuracy: 0.7320
2025-07-29 05:11:49,055 - INFO -     - accuracy_norm: 0.7320
2025-07-29 05:11:49,055 - INFO - ============================================================

2025-07-29 05:11:49,093 - INFO - Llama-3.1-8B_harness_1: Processing task 4/10: kobest
2025-07-29 05:11:49,095 - INFO - Llama-3.1-8B_harness_1: Task 'kobest' will use num_fewshot=5
2025-07-29 05:11:49,223 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kobest' with num_fewshot=5
2025-07-29 05:11:49,223 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 05:12:13,616 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-29 05:12:13,616 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-29 05:12:13,617 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-29 05:12:13,617 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-29 05:12:13,617 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-29 05:22:40,488 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kobest' with 6 subtasks
2025-07-29 05:22:40,636 - INFO - 
============================================================
2025-07-29 05:22:40,636 - INFO - Task 'kobest' Results:
2025-07-29 05:22:40,636 - INFO - ============================================================
2025-07-29 05:22:40,636 - INFO -   kobest:
2025-07-29 05:22:40,636 - INFO -     - accuracy: 0.7003
2025-07-29 05:22:40,636 - INFO -     - accuracy_norm: 0.5900
2025-07-29 05:22:40,637 - INFO -     - f1: 0.6901
2025-07-29 05:22:40,637 - INFO -   kobest_boolq:
2025-07-29 05:22:40,637 - INFO -     - accuracy: 0.8241
2025-07-29 05:22:40,637 - INFO -     - f1: 0.8241
2025-07-29 05:22:40,637 - INFO -   kobest_copa:
2025-07-29 05:22:40,637 - INFO -     - accuracy: 0.7120
2025-07-29 05:22:40,637 - INFO -     - f1: 0.7112
2025-07-29 05:22:40,637 - INFO -   kobest_hellaswag:
2025-07-29 05:22:40,638 - INFO -     - accuracy: 0.4520
2025-07-29 05:22:40,638 - INFO -     - accuracy_norm: 0.5900
2025-07-29 05:22:40,638 - INFO -     - f1: 0.4488
2025-07-29 05:22:40,638 - INFO -   kobest_sentineg:
2025-07-29 05:22:40,638 - INFO -     - accuracy: 0.9496
2025-07-29 05:22:40,638 - INFO -     - f1: 0.9496
2025-07-29 05:22:40,638 - INFO -   kobest_wic:
2025-07-29 05:22:40,638 - INFO -     - accuracy: 0.5730
2025-07-29 05:22:40,638 - INFO -     - f1: 0.5382
2025-07-29 05:22:40,639 - INFO - ============================================================

2025-07-29 05:22:40,677 - INFO - Llama-3.1-8B_harness_1: Processing task 5/10: csatqa
2025-07-29 05:22:40,679 - INFO - Llama-3.1-8B_harness_1: Task 'csatqa' detected as zero-shot task
2025-07-29 05:22:40,806 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'csatqa' with num_fewshot=0
2025-07-29 05:22:40,806 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 05:22:57,761 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-29 05:22:57,762 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-29 05:22:57,762 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-29 05:22:57,762 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-29 05:22:57,762 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-29 05:22:57,763 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-29 05:25:07,246 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'csatqa' with 7 subtasks
2025-07-29 05:25:07,397 - INFO - 
============================================================
2025-07-29 05:25:07,397 - INFO - Task 'csatqa' Results:
2025-07-29 05:25:07,397 - INFO - ============================================================
2025-07-29 05:25:07,397 - INFO -   csatqa:
2025-07-29 05:25:07,397 - INFO -     - accuracy: 0.2834
2025-07-29 05:25:07,397 - INFO -     - accuracy_norm: 0.2834
2025-07-29 05:25:07,397 - INFO -   csatqa_gr:
2025-07-29 05:25:07,398 - INFO -     - accuracy: 0.0800
2025-07-29 05:25:07,398 - INFO -     - accuracy_norm: 0.0800
2025-07-29 05:25:07,398 - INFO -   csatqa_li:
2025-07-29 05:25:07,398 - INFO -     - accuracy: 0.3243
2025-07-29 05:25:07,398 - INFO -     - accuracy_norm: 0.3243
2025-07-29 05:25:07,398 - INFO -   csatqa_rch:
2025-07-29 05:25:07,398 - INFO -     - accuracy: 0.3429
2025-07-29 05:25:07,398 - INFO -     - accuracy_norm: 0.3429
2025-07-29 05:25:07,399 - INFO -   csatqa_rcs:
2025-07-29 05:25:07,399 - INFO -     - accuracy: 0.2973
2025-07-29 05:25:07,399 - INFO -     - accuracy_norm: 0.2973
2025-07-29 05:25:07,399 - INFO -   csatqa_rcss:
2025-07-29 05:25:07,399 - INFO -     - accuracy: 0.3095
2025-07-29 05:25:07,399 - INFO -     - accuracy_norm: 0.3095
2025-07-29 05:25:07,399 - INFO -   csatqa_wr:
2025-07-29 05:25:07,399 - INFO -     - accuracy: 0.2727
2025-07-29 05:25:07,399 - INFO -     - accuracy_norm: 0.2727
2025-07-29 05:25:07,400 - INFO - ============================================================

2025-07-29 05:25:07,441 - INFO - Llama-3.1-8B_harness_1: Processing task 6/10: kormedmcqa
2025-07-29 05:25:07,442 - INFO - Llama-3.1-8B_harness_1: Task 'kormedmcqa' will use num_fewshot=5
2025-07-29 05:25:07,568 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-29 05:25:07,568 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 05:25:32,310 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-29 05:25:32,310 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-29 05:25:32,310 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-29 05:25:32,310 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
2025-07-29 05:31:31,992 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-29 05:31:32,150 - INFO - 
============================================================
2025-07-29 05:31:32,150 - INFO - Task 'kormedmcqa' Results:
2025-07-29 05:31:32,150 - INFO - ============================================================
2025-07-29 05:31:32,151 - INFO -   kormedmcqa:
2025-07-29 05:31:32,151 - INFO -     - exact_match: 0.4789
2025-07-29 05:31:32,151 - INFO -   kormedmcqa_dentist:
2025-07-29 05:31:32,151 - INFO -     - exact_match: 0.3872
2025-07-29 05:31:32,152 - INFO -   kormedmcqa_doctor:
2025-07-29 05:31:32,152 - INFO -     - exact_match: 0.4138
2025-07-29 05:31:32,152 - INFO -   kormedmcqa_nurse:
2025-07-29 05:31:32,152 - INFO -     - exact_match: 0.5661
2025-07-29 05:31:32,152 - INFO -   kormedmcqa_pharm:
2025-07-29 05:31:32,153 - INFO -     - exact_match: 0.5085
2025-07-29 05:31:32,155 - INFO - ============================================================

2025-07-29 05:31:32,193 - INFO - Llama-3.1-8B_harness_1: Processing task 7/10: mmlu
2025-07-29 05:31:32,194 - INFO - Llama-3.1-8B_harness_1: Task 'mmlu' will use num_fewshot=5
2025-07-29 05:31:32,322 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'mmlu' with num_fewshot=5
2025-07-29 05:31:32,322 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 05:34:37,756 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5
2025-07-29 05:34:37,756 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5
2025-07-29 05:34:37,757 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 5
2025-07-29 05:34:37,757 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5
2025-07-29 05:34:37,757 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5
2025-07-29 05:34:37,757 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 5
2025-07-29 05:34:37,757 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 5
2025-07-29 05:34:37,757 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5
2025-07-29 05:34:37,757 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 5
2025-07-29 05:34:37,757 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 5
2025-07-29 05:34:37,757 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 5
2025-07-29 05:34:37,758 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 5
2025-07-29 05:34:37,758 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 5
2025-07-29 05:34:37,758 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5
2025-07-29 05:34:37,758 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5
2025-07-29 05:34:37,758 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 5
2025-07-29 05:34:37,758 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 5
2025-07-29 05:34:37,758 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5
2025-07-29 05:34:37,758 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 5
2025-07-29 05:34:37,758 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 5
2025-07-29 05:34:37,758 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 5
2025-07-29 05:34:37,759 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 5
2025-07-29 05:34:37,760 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5
2025-07-29 05:34:37,761 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5
2025-07-29 05:34:37,761 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 5
2025-07-29 05:34:37,761 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 5
2025-07-29 05:34:37,761 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5
2025-07-29 05:34:37,761 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5
2025-07-29 05:34:37,761 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 5
2025-07-29 05:34:37,761 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 5
2025-07-29 05:34:37,761 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5
2025-07-29 05:34:37,761 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 5
2025-07-29 05:34:37,761 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 5
2025-07-29 05:34:37,762 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5
2025-07-29 05:34:37,762 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 5
2025-07-29 05:34:37,762 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 5
2025-07-29 05:34:37,762 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5
2025-07-29 05:56:53,948 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'mmlu' with 62 subtasks
2025-07-29 05:56:54,097 - INFO - 
============================================================
2025-07-29 05:56:54,097 - INFO - Task 'mmlu' Results:
2025-07-29 05:56:54,097 - INFO - ============================================================
2025-07-29 05:56:54,098 - INFO -   mmlu:
2025-07-29 05:56:54,098 - INFO -     - accuracy: 0.6525
2025-07-29 05:56:54,098 - INFO -   mmlu_humanities:
2025-07-29 05:56:54,098 - INFO -     - accuracy: 0.6011
2025-07-29 05:56:54,098 - INFO -   mmlu_formal_logic:
2025-07-29 05:56:54,098 - INFO -     - accuracy: 0.4841
2025-07-29 05:56:54,098 - INFO -   mmlu_high_school_european_history:
2025-07-29 05:56:54,099 - INFO -     - accuracy: 0.7758
2025-07-29 05:56:54,099 - INFO -   mmlu_high_school_us_history:
2025-07-29 05:56:54,099 - INFO -     - accuracy: 0.8137
2025-07-29 05:56:54,099 - INFO -   mmlu_high_school_world_history:
2025-07-29 05:56:54,099 - INFO -     - accuracy: 0.8186
2025-07-29 05:56:54,099 - INFO -   mmlu_international_law:
2025-07-29 05:56:54,099 - INFO -     - accuracy: 0.8182
2025-07-29 05:56:54,099 - INFO -   mmlu_jurisprudence:
2025-07-29 05:56:54,099 - INFO -     - accuracy: 0.7315
2025-07-29 05:56:54,100 - INFO -   mmlu_logical_fallacies:
2025-07-29 05:56:54,100 - INFO -     - accuracy: 0.7362
2025-07-29 05:56:54,100 - INFO -   mmlu_moral_disputes:
2025-07-29 05:56:54,100 - INFO -     - accuracy: 0.7283
2025-07-29 05:56:54,100 - INFO -   mmlu_moral_scenarios:
2025-07-29 05:56:54,100 - INFO -     - accuracy: 0.4156
2025-07-29 05:56:54,100 - INFO -   mmlu_philosophy:
2025-07-29 05:56:54,100 - INFO -     - accuracy: 0.7363
2025-07-29 05:56:54,100 - INFO -   mmlu_prehistory:
2025-07-29 05:56:54,101 - INFO -     - accuracy: 0.7191
2025-07-29 05:56:54,101 - INFO -   mmlu_professional_law:
2025-07-29 05:56:54,101 - INFO -     - accuracy: 0.4935
2025-07-29 05:56:54,101 - INFO -   mmlu_world_religions:
2025-07-29 05:56:54,101 - INFO -     - accuracy: 0.8070
2025-07-29 05:56:54,101 - INFO -   mmlu_other:
2025-07-29 05:56:54,101 - INFO -     - accuracy: 0.7200
2025-07-29 05:56:54,101 - INFO -   mmlu_business_ethics:
2025-07-29 05:56:54,101 - INFO -     - accuracy: 0.6300
2025-07-29 05:56:54,102 - INFO -   mmlu_clinical_knowledge:
2025-07-29 05:56:54,102 - INFO -     - accuracy: 0.7472
2025-07-29 05:56:54,102 - INFO -   mmlu_college_medicine:
2025-07-29 05:56:54,102 - INFO -     - accuracy: 0.6474
2025-07-29 05:56:54,102 - INFO -   mmlu_global_facts:
2025-07-29 05:56:54,102 - INFO -     - accuracy: 0.3400
2025-07-29 05:56:54,102 - INFO -   mmlu_human_aging:
2025-07-29 05:56:54,102 - INFO -     - accuracy: 0.6906
2025-07-29 05:56:54,102 - INFO -   mmlu_management:
2025-07-29 05:56:54,103 - INFO -     - accuracy: 0.8447
2025-07-29 05:56:54,103 - INFO -   mmlu_marketing:
2025-07-29 05:56:54,103 - INFO -     - accuracy: 0.8632
2025-07-29 05:56:54,103 - INFO -   mmlu_medical_genetics:
2025-07-29 05:56:54,103 - INFO -     - accuracy: 0.8100
2025-07-29 05:56:54,103 - INFO -   mmlu_miscellaneous:
2025-07-29 05:56:54,103 - INFO -     - accuracy: 0.8135
2025-07-29 05:56:54,103 - INFO -   mmlu_nutrition:
2025-07-29 05:56:54,103 - INFO -     - accuracy: 0.8039
2025-07-29 05:56:54,104 - INFO -   mmlu_professional_accounting:
2025-07-29 05:56:54,104 - INFO -     - accuracy: 0.4965
2025-07-29 05:56:54,104 - INFO -   mmlu_professional_medicine:
2025-07-29 05:56:54,104 - INFO -     - accuracy: 0.6949
2025-07-29 05:56:54,104 - INFO -   mmlu_virology:
2025-07-29 05:56:54,104 - INFO -     - accuracy: 0.5663
2025-07-29 05:56:54,104 - INFO -   mmlu_social_sciences:
2025-07-29 05:56:54,104 - INFO -     - accuracy: 0.7628
2025-07-29 05:56:54,104 - INFO -   mmlu_econometrics:
2025-07-29 05:56:54,104 - INFO -     - accuracy: 0.4912
2025-07-29 05:56:54,105 - INFO -   mmlu_high_school_geography:
2025-07-29 05:56:54,105 - INFO -     - accuracy: 0.8182
2025-07-29 05:56:54,105 - INFO -   mmlu_high_school_government_and_politics:
2025-07-29 05:56:54,105 - INFO -     - accuracy: 0.8860
2025-07-29 05:56:54,105 - INFO -   mmlu_high_school_macroeconomics:
2025-07-29 05:56:54,105 - INFO -     - accuracy: 0.6462
2025-07-29 05:56:54,105 - INFO -   mmlu_high_school_microeconomics:
2025-07-29 05:56:54,105 - INFO -     - accuracy: 0.7437
2025-07-29 05:56:54,106 - INFO -   mmlu_high_school_psychology:
2025-07-29 05:56:54,106 - INFO -     - accuracy: 0.8495
2025-07-29 05:56:54,106 - INFO -   mmlu_human_sexuality:
2025-07-29 05:56:54,106 - INFO -     - accuracy: 0.7786
2025-07-29 05:56:54,106 - INFO -   mmlu_professional_psychology:
2025-07-29 05:56:54,106 - INFO -     - accuracy: 0.7173
2025-07-29 05:56:54,106 - INFO -   mmlu_public_relations:
2025-07-29 05:56:54,106 - INFO -     - accuracy: 0.7273
2025-07-29 05:56:54,106 - INFO -   mmlu_security_studies:
2025-07-29 05:56:54,106 - INFO -     - accuracy: 0.7347
2025-07-29 05:56:54,107 - INFO -   mmlu_sociology:
2025-07-29 05:56:54,107 - INFO -     - accuracy: 0.8806
2025-07-29 05:56:54,107 - INFO -   mmlu_us_foreign_policy:
2025-07-29 05:56:54,107 - INFO -     - accuracy: 0.8800
2025-07-29 05:56:54,107 - INFO -   mmlu_stem:
2025-07-29 05:56:54,107 - INFO -     - accuracy: 0.5550
2025-07-29 05:56:54,107 - INFO -   mmlu_abstract_algebra:
2025-07-29 05:56:54,107 - INFO -     - accuracy: 0.3000
2025-07-29 05:56:54,107 - INFO -   mmlu_anatomy:
2025-07-29 05:56:54,108 - INFO -     - accuracy: 0.6222
2025-07-29 05:56:54,108 - INFO -   mmlu_astronomy:
2025-07-29 05:56:54,108 - INFO -     - accuracy: 0.7237
2025-07-29 05:56:54,108 - INFO -   mmlu_college_biology:
2025-07-29 05:56:54,108 - INFO -     - accuracy: 0.7778
2025-07-29 05:56:54,108 - INFO -   mmlu_college_chemistry:
2025-07-29 05:56:54,108 - INFO -     - accuracy: 0.4400
2025-07-29 05:56:54,108 - INFO -   mmlu_college_computer_science:
2025-07-29 05:56:54,108 - INFO -     - accuracy: 0.4800
2025-07-29 05:56:54,109 - INFO -   mmlu_college_mathematics:
2025-07-29 05:56:54,109 - INFO -     - accuracy: 0.3500
2025-07-29 05:56:54,109 - INFO -   mmlu_college_physics:
2025-07-29 05:56:54,109 - INFO -     - accuracy: 0.4804
2025-07-29 05:56:54,109 - INFO -   mmlu_computer_security:
2025-07-29 05:56:54,109 - INFO -     - accuracy: 0.8300
2025-07-29 05:56:54,109 - INFO -   mmlu_conceptual_physics:
2025-07-29 05:56:54,109 - INFO -     - accuracy: 0.6000
2025-07-29 05:56:54,109 - INFO -   mmlu_electrical_engineering:
2025-07-29 05:56:54,110 - INFO -     - accuracy: 0.6207
2025-07-29 05:56:54,110 - INFO -   mmlu_elementary_mathematics:
2025-07-29 05:56:54,110 - INFO -     - accuracy: 0.4233
2025-07-29 05:56:54,110 - INFO -   mmlu_high_school_biology:
2025-07-29 05:56:54,110 - INFO -     - accuracy: 0.7710
2025-07-29 05:56:54,110 - INFO -   mmlu_high_school_chemistry:
2025-07-29 05:56:54,110 - INFO -     - accuracy: 0.5419
2025-07-29 05:56:54,110 - INFO -   mmlu_high_school_computer_science:
2025-07-29 05:56:54,110 - INFO -     - accuracy: 0.6500
2025-07-29 05:56:54,111 - INFO -   mmlu_high_school_mathematics:
2025-07-29 05:56:54,111 - INFO -     - accuracy: 0.4259
2025-07-29 05:56:54,111 - INFO -   mmlu_high_school_physics:
2025-07-29 05:56:54,111 - INFO -     - accuracy: 0.4371
2025-07-29 05:56:54,111 - INFO -   mmlu_high_school_statistics:
2025-07-29 05:56:54,111 - INFO -     - accuracy: 0.5463
2025-07-29 05:56:54,111 - INFO -   mmlu_machine_learning:
2025-07-29 05:56:54,111 - INFO -     - accuracy: 0.4554
2025-07-29 05:56:54,111 - INFO - ============================================================

2025-07-29 05:56:54,156 - INFO - Llama-3.1-8B_harness_1: Processing task 8/10: arc_challenge
2025-07-29 05:56:54,161 - INFO - Llama-3.1-8B_harness_1: Task 'arc_challenge' will use num_fewshot=5
2025-07-29 05:56:54,287 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'arc_challenge' with num_fewshot=5
2025-07-29 05:56:54,288 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 05:57:06,212 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 5
2025-07-29 05:59:50,970 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-29 05:59:51,115 - INFO - 
============================================================
2025-07-29 05:59:51,115 - INFO - Task 'arc_challenge' Results:
2025-07-29 05:59:51,115 - INFO - ============================================================
2025-07-29 05:59:51,115 - INFO -   arc_challenge:
2025-07-29 05:59:51,115 - INFO -     - accuracy: 0.5435
2025-07-29 05:59:51,115 - INFO -     - accuracy_norm: 0.5811
2025-07-29 05:59:51,115 - INFO - ============================================================

2025-07-29 05:59:51,152 - INFO - Llama-3.1-8B_harness_1: Processing task 9/10: arc_easy
2025-07-29 05:59:51,154 - INFO - Llama-3.1-8B_harness_1: Task 'arc_easy' will use num_fewshot=5
2025-07-29 05:59:51,278 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'arc_easy' with num_fewshot=5
2025-07-29 05:59:51,279 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 06:00:01,719 - WARNING - Overwriting default num_fewshot of arc_easy from None to 5
2025-07-29 06:04:59,548 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-29 06:04:59,698 - INFO - 
============================================================
2025-07-29 06:04:59,699 - INFO - Task 'arc_easy' Results:
2025-07-29 06:04:59,699 - INFO - ============================================================
2025-07-29 06:04:59,699 - INFO -   arc_easy:
2025-07-29 06:04:59,699 - INFO -     - accuracy: 0.8409
2025-07-29 06:04:59,699 - INFO -     - accuracy_norm: 0.8489
2025-07-29 06:04:59,700 - INFO - ============================================================

2025-07-29 06:04:59,739 - INFO - Llama-3.1-8B_harness_1: Processing task 10/10: hellaswag
2025-07-29 06:04:59,741 - INFO - Llama-3.1-8B_harness_1: Task 'hellaswag' will use num_fewshot=5
2025-07-29 06:04:59,868 - INFO - Llama-3.1-8B_harness_1: Evaluating task 'hellaswag' with num_fewshot=5
2025-07-29 06:04:59,869 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 06:05:19,292 - WARNING - Overwriting default num_fewshot of hellaswag from None to 5
2025-07-29 06:44:02,841 - INFO - Llama-3.1-8B_harness_1: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-29 06:44:02,987 - INFO - 
============================================================
2025-07-29 06:44:02,987 - INFO - Task 'hellaswag' Results:
2025-07-29 06:44:02,987 - INFO - ============================================================
2025-07-29 06:44:02,987 - INFO -   hellaswag:
2025-07-29 06:44:02,988 - INFO -     - accuracy: 0.6117
2025-07-29 06:44:02,988 - INFO -     - accuracy_norm: 0.8095
2025-07-29 06:44:02,988 - INFO - ============================================================

2025-07-29 06:44:03,027 - INFO - Llama-3.1-8B_harness_1: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-29 06:44:03,031 - INFO - [Process 1941996] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250729_041113/model_results/Llama-3.1-8B/Llama-3.1-8B_harness_1.json
2025-07-29 06:44:03,033 - INFO - [Process 1941996] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Llama-3.1-8B/Llama-3.1-8B_harness_1.json
2025-07-29 06:44:03,335 - INFO - Results uploaded to WandB as artifact
2025-07-29 06:44:03,344 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-29 06:44:03,346 - INFO - [Process 1941996] Successfully completed Llama-3.1-8B_harness_1
2025-07-29 06:44:05,756 - INFO - Run Llama-3.1-8B_harness_1 finished successfully
2025-07-29 06:44:05,757 - INFO - [Process 1941996] Mistral-7B-v0.3_harness_4 assigned to cuda:0
2025-07-29 06:44:05,757 - INFO - [Process 1941996] Mistral-7B-v0.3_harness_4 - full_run: True, limit: None (full dataset)
2025-07-29 06:44:07,099 - INFO - WandB run initialized: Mistral-7B-v0.3_20250729_064405 (ID: 8881a0b4)
2025-07-29 06:44:07,403 - INFO - Mistral-7B-v0.3_harness_4: Processing task 1/10: kmmlu
2025-07-29 06:44:07,403 - INFO - Mistral-7B-v0.3_harness_4: Task 'kmmlu' will use num_fewshot=5
2025-07-29 06:44:07,531 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-29 06:44:07,531 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 06:45:23,471 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-29 06:45:23,471 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-29 06:45:23,471 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-29 06:45:23,471 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-29 06:45:23,471 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-29 06:45:23,472 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-29 06:45:23,472 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-29 06:45:23,472 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-29 06:45:23,472 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-29 06:45:23,472 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-29 06:45:23,472 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-29 06:45:23,472 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-29 06:45:23,472 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-29 06:45:23,472 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-29 06:45:23,472 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-29 06:45:23,473 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-29 06:45:23,473 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-29 06:45:23,473 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-29 06:45:23,473 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-29 06:45:23,473 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-29 06:45:23,473 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-29 06:45:23,473 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-29 06:45:23,473 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-29 06:45:23,473 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-29 06:45:23,473 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-29 06:45:23,474 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-29 06:45:23,474 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-29 06:45:23,474 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-29 06:45:23,474 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-29 06:45:23,474 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-29 06:45:23,474 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-29 06:45:23,474 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-29 06:45:23,474 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-29 06:45:23,474 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-29 06:45:23,475 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-29 06:45:23,475 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-29 06:45:23,475 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-29 06:45:23,475 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-29 06:45:23,475 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-29 06:45:23,475 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-29 06:45:23,475 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-29 06:45:23,475 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-29 06:45:23,475 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-29 06:45:23,475 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-29 06:45:23,476 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-29 07:44:56,371 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-29 07:44:56,515 - INFO - 
============================================================
2025-07-29 07:44:56,515 - INFO - Task 'kmmlu' Results:
2025-07-29 07:44:56,515 - INFO - ============================================================
2025-07-29 07:44:56,515 - INFO -   kmmlu:
2025-07-29 07:44:56,515 - INFO -     - accuracy: 0.3727
2025-07-29 07:44:56,515 - INFO -   kmmlu_applied_science:
2025-07-29 07:44:56,515 - INFO -     - accuracy: 0.3581
2025-07-29 07:44:56,516 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-29 07:44:56,516 - INFO -     - accuracy: 0.3300
2025-07-29 07:44:56,516 - INFO -   kmmlu_electronics_engineering:
2025-07-29 07:44:56,516 - INFO -     - accuracy: 0.4630
2025-07-29 07:44:56,516 - INFO -   kmmlu_energy_management:
2025-07-29 07:44:56,516 - INFO -     - accuracy: 0.3120
2025-07-29 07:44:56,516 - INFO -   kmmlu_environmental_science:
2025-07-29 07:44:56,516 - INFO -     - accuracy: 0.2970
2025-07-29 07:44:56,517 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-29 07:44:56,517 - INFO -     - accuracy: 0.3220
2025-07-29 07:44:56,517 - INFO -   kmmlu_geomatics:
2025-07-29 07:44:56,517 - INFO -     - accuracy: 0.3720
2025-07-29 07:44:56,517 - INFO -   kmmlu_industrial_engineer:
2025-07-29 07:44:56,517 - INFO -     - accuracy: 0.3750
2025-07-29 07:44:56,517 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-29 07:44:56,517 - INFO -     - accuracy: 0.3550
2025-07-29 07:44:56,517 - INFO -   kmmlu_maritime_engineering:
2025-07-29 07:44:56,517 - INFO -     - accuracy: 0.3583
2025-07-29 07:44:56,518 - INFO -   kmmlu_nondestructive_testing:
2025-07-29 07:44:56,518 - INFO -     - accuracy: 0.3390
2025-07-29 07:44:56,518 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-29 07:44:56,518 - INFO -     - accuracy: 0.3030
2025-07-29 07:44:56,518 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-29 07:44:56,518 - INFO -     - accuracy: 0.4710
2025-07-29 07:44:56,518 - INFO -   kmmlu_humss:
2025-07-29 07:44:56,518 - INFO -     - accuracy: 0.3540
2025-07-29 07:44:56,519 - INFO -   kmmlu_accounting:
2025-07-29 07:44:56,519 - INFO -     - accuracy: 0.3200
2025-07-29 07:44:56,519 - INFO -   kmmlu_criminal_law:
2025-07-29 07:44:56,519 - INFO -     - accuracy: 0.2650
2025-07-29 07:44:56,519 - INFO -   kmmlu_economics:
2025-07-29 07:44:56,519 - INFO -     - accuracy: 0.3231
2025-07-29 07:44:56,520 - INFO -   kmmlu_education:
2025-07-29 07:44:56,520 - INFO -     - accuracy: 0.4800
2025-07-29 07:44:56,520 - INFO -   kmmlu_korean_history:
2025-07-29 07:44:56,520 - INFO -     - accuracy: 0.2900
2025-07-29 07:44:56,520 - INFO -   kmmlu_law:
2025-07-29 07:44:56,520 - INFO -     - accuracy: 0.3350
2025-07-29 07:44:56,520 - INFO -   kmmlu_management:
2025-07-29 07:44:56,520 - INFO -     - accuracy: 0.4030
2025-07-29 07:44:56,520 - INFO -   kmmlu_political_science_and_sociology:
2025-07-29 07:44:56,521 - INFO -     - accuracy: 0.3933
2025-07-29 07:44:56,521 - INFO -   kmmlu_psychology:
2025-07-29 07:44:56,521 - INFO -     - accuracy: 0.2970
2025-07-29 07:44:56,521 - INFO -   kmmlu_social_welfare:
2025-07-29 07:44:56,521 - INFO -     - accuracy: 0.3910
2025-07-29 07:44:56,521 - INFO -   kmmlu_taxation:
2025-07-29 07:44:56,521 - INFO -     - accuracy: 0.3400
2025-07-29 07:44:56,521 - INFO -   kmmlu_other:
2025-07-29 07:44:56,521 - INFO -     - accuracy: 0.3650
2025-07-29 07:44:56,522 - INFO -   kmmlu_agricultural_sciences:
2025-07-29 07:44:56,522 - INFO -     - accuracy: 0.3030
2025-07-29 07:44:56,522 - INFO -   kmmlu_construction:
2025-07-29 07:44:56,522 - INFO -     - accuracy: 0.3280
2025-07-29 07:44:56,522 - INFO -   kmmlu_fashion:
2025-07-29 07:44:56,522 - INFO -     - accuracy: 0.3590
2025-07-29 07:44:56,522 - INFO -   kmmlu_food_processing:
2025-07-29 07:44:56,522 - INFO -     - accuracy: 0.3240
2025-07-29 07:44:56,522 - INFO -   kmmlu_health:
2025-07-29 07:44:56,523 - INFO -     - accuracy: 0.4200
2025-07-29 07:44:56,523 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-29 07:44:56,523 - INFO -     - accuracy: 0.3880
2025-07-29 07:44:56,523 - INFO -   kmmlu_marketing:
2025-07-29 07:44:56,523 - INFO -     - accuracy: 0.6180
2025-07-29 07:44:56,523 - INFO -   kmmlu_patent:
2025-07-29 07:44:56,523 - INFO -     - accuracy: 0.3000
2025-07-29 07:44:56,523 - INFO -   kmmlu_public_safety:
2025-07-29 07:44:56,523 - INFO -     - accuracy: 0.3190
2025-07-29 07:44:56,524 - INFO -   kmmlu_real_estate:
2025-07-29 07:44:56,524 - INFO -     - accuracy: 0.2800
2025-07-29 07:44:56,524 - INFO -   kmmlu_refrigerating_machinery:
2025-07-29 07:44:56,524 - INFO -     - accuracy: 0.2990
2025-07-29 07:44:56,524 - INFO -   kmmlu_stem:
2025-07-29 07:44:56,524 - INFO -     - accuracy: 0.4062
2025-07-29 07:44:56,524 - INFO -   kmmlu_biology:
2025-07-29 07:44:56,524 - INFO -     - accuracy: 0.3070
2025-07-29 07:44:56,524 - INFO -   kmmlu_chemical_engineering:
2025-07-29 07:44:56,525 - INFO -     - accuracy: 0.3750
2025-07-29 07:44:56,525 - INFO -   kmmlu_chemistry:
2025-07-29 07:44:56,525 - INFO -     - accuracy: 0.3717
2025-07-29 07:44:56,525 - INFO -   kmmlu_civil_engineering:
2025-07-29 07:44:56,525 - INFO -     - accuracy: 0.4010
2025-07-29 07:44:56,525 - INFO -   kmmlu_computer_science:
2025-07-29 07:44:56,525 - INFO -     - accuracy: 0.6220
2025-07-29 07:44:56,525 - INFO -   kmmlu_ecology:
2025-07-29 07:44:56,525 - INFO -     - accuracy: 0.3910
2025-07-29 07:44:56,526 - INFO -   kmmlu_electrical_engineering:
2025-07-29 07:44:56,526 - INFO -     - accuracy: 0.3380
2025-07-29 07:44:56,526 - INFO -   kmmlu_information_technology:
2025-07-29 07:44:56,526 - INFO -     - accuracy: 0.5860
2025-07-29 07:44:56,526 - INFO -   kmmlu_materials_engineering:
2025-07-29 07:44:56,526 - INFO -     - accuracy: 0.3630
2025-07-29 07:44:56,526 - INFO -   kmmlu_math:
2025-07-29 07:44:56,526 - INFO -     - accuracy: 0.2700
2025-07-29 07:44:56,526 - INFO -   kmmlu_mechanical_engineering:
2025-07-29 07:44:56,527 - INFO -     - accuracy: 0.3340
2025-07-29 07:44:56,527 - INFO - ============================================================

2025-07-29 07:44:56,566 - INFO - Mistral-7B-v0.3_harness_4: Processing task 2/10: kmmlu_hard
2025-07-29 07:44:56,572 - INFO - Mistral-7B-v0.3_harness_4: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-29 07:44:56,700 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-29 07:44:56,701 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 07:46:13,679 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-29 07:46:13,680 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-29 07:46:13,680 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-29 07:46:13,680 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-29 07:46:13,680 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-29 07:46:13,680 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-29 07:46:13,681 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-29 07:46:13,682 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-29 07:46:13,683 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-29 07:46:13,684 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-29 07:46:13,684 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-29 07:46:13,684 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-29 07:46:13,684 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-29 07:46:13,684 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-29 07:54:01,908 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-29 07:54:02,059 - INFO - 
============================================================
2025-07-29 07:54:02,060 - INFO - Task 'kmmlu_hard' Results:
2025-07-29 07:54:02,060 - INFO - ============================================================
2025-07-29 07:54:02,060 - INFO -   kmmlu_hard:
2025-07-29 07:54:02,060 - INFO -     - accuracy: 0.2205
2025-07-29 07:54:02,060 - INFO -   kmmlu_hard_applied_science:
2025-07-29 07:54:02,060 - INFO -     - accuracy: 0.2283
2025-07-29 07:54:02,060 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-29 07:54:02,061 - INFO -     - accuracy: 0.1900
2025-07-29 07:54:02,061 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-29 07:54:02,061 - INFO -     - accuracy: 0.3000
2025-07-29 07:54:02,061 - INFO -   kmmlu_hard_energy_management:
2025-07-29 07:54:02,061 - INFO -     - accuracy: 0.2300
2025-07-29 07:54:02,061 - INFO -   kmmlu_hard_environmental_science:
2025-07-29 07:54:02,061 - INFO -     - accuracy: 0.2600
2025-07-29 07:54:02,061 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-29 07:54:02,061 - INFO -     - accuracy: 0.1500
2025-07-29 07:54:02,062 - INFO -   kmmlu_hard_geomatics:
2025-07-29 07:54:02,062 - INFO -     - accuracy: 0.2700
2025-07-29 07:54:02,062 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-29 07:54:02,062 - INFO -     - accuracy: 0.2100
2025-07-29 07:54:02,062 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-29 07:54:02,062 - INFO -     - accuracy: 0.2400
2025-07-29 07:54:02,062 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-29 07:54:02,062 - INFO -     - accuracy: 0.1700
2025-07-29 07:54:02,063 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-29 07:54:02,063 - INFO -     - accuracy: 0.2000
2025-07-29 07:54:02,063 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-29 07:54:02,063 - INFO -     - accuracy: 0.2400
2025-07-29 07:54:02,063 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-29 07:54:02,063 - INFO -     - accuracy: 0.2800
2025-07-29 07:54:02,063 - INFO -   kmmlu_hard_humss:
2025-07-29 07:54:02,063 - INFO -     - accuracy: 0.2033
2025-07-29 07:54:02,063 - INFO -   kmmlu_hard_accounting:
2025-07-29 07:54:02,063 - INFO -     - accuracy: 0.1522
2025-07-29 07:54:02,063 - INFO -   kmmlu_hard_criminal_law:
2025-07-29 07:54:02,064 - INFO -     - accuracy: 0.2300
2025-07-29 07:54:02,064 - INFO -   kmmlu_hard_economics:
2025-07-29 07:54:02,064 - INFO -     - accuracy: 0.1905
2025-07-29 07:54:02,064 - INFO -   kmmlu_hard_education:
2025-07-29 07:54:02,064 - INFO -     - accuracy: 0.1304
2025-07-29 07:54:02,064 - INFO -   kmmlu_hard_korean_history:
2025-07-29 07:54:02,064 - INFO -     - accuracy: 0.3182
2025-07-29 07:54:02,064 - INFO -   kmmlu_hard_law:
2025-07-29 07:54:02,064 - INFO -     - accuracy: 0.2000
2025-07-29 07:54:02,065 - INFO -   kmmlu_hard_management:
2025-07-29 07:54:02,065 - INFO -     - accuracy: 0.1700
2025-07-29 07:54:02,065 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-29 07:54:02,065 - INFO -     - accuracy: 0.2000
2025-07-29 07:54:02,065 - INFO -   kmmlu_hard_psychology:
2025-07-29 07:54:02,065 - INFO -     - accuracy: 0.1600
2025-07-29 07:54:02,065 - INFO -   kmmlu_hard_social_welfare:
2025-07-29 07:54:02,065 - INFO -     - accuracy: 0.2300
2025-07-29 07:54:02,066 - INFO -   kmmlu_hard_taxation:
2025-07-29 07:54:02,066 - INFO -     - accuracy: 0.2292
2025-07-29 07:54:02,066 - INFO -   kmmlu_hard_other:
2025-07-29 07:54:02,066 - INFO -     - accuracy: 0.2222
2025-07-29 07:54:02,066 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-29 07:54:02,066 - INFO -     - accuracy: 0.1800
2025-07-29 07:54:02,066 - INFO -   kmmlu_hard_construction:
2025-07-29 07:54:02,067 - INFO -     - accuracy: 0.2100
2025-07-29 07:54:02,067 - INFO -   kmmlu_hard_fashion:
2025-07-29 07:54:02,067 - INFO -     - accuracy: 0.2400
2025-07-29 07:54:02,067 - INFO -   kmmlu_hard_food_processing:
2025-07-29 07:54:02,067 - INFO -     - accuracy: 0.1900
2025-07-29 07:54:02,067 - INFO -   kmmlu_hard_health:
2025-07-29 07:54:02,067 - INFO -     - accuracy: 0.1739
2025-07-29 07:54:02,067 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-29 07:54:02,067 - INFO -     - accuracy: 0.3300
2025-07-29 07:54:02,068 - INFO -   kmmlu_hard_marketing:
2025-07-29 07:54:02,068 - INFO -     - accuracy: 0.2600
2025-07-29 07:54:02,068 - INFO -   kmmlu_hard_patent:
2025-07-29 07:54:02,068 - INFO -     - accuracy: 0.2941
2025-07-29 07:54:02,068 - INFO -   kmmlu_hard_public_safety:
2025-07-29 07:54:02,068 - INFO -     - accuracy: 0.2400
2025-07-29 07:54:02,068 - INFO -   kmmlu_hard_real_estate:
2025-07-29 07:54:02,068 - INFO -     - accuracy: 0.1573
2025-07-29 07:54:02,068 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-29 07:54:02,069 - INFO -     - accuracy: 0.1600
2025-07-29 07:54:02,069 - INFO -   kmmlu_hard_stem:
2025-07-29 07:54:02,069 - INFO -     - accuracy: 0.2236
2025-07-29 07:54:02,069 - INFO -   kmmlu_hard_biology:
2025-07-29 07:54:02,069 - INFO -     - accuracy: 0.2000
2025-07-29 07:54:02,069 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-29 07:54:02,069 - INFO -     - accuracy: 0.1600
2025-07-29 07:54:02,069 - INFO -   kmmlu_hard_chemistry:
2025-07-29 07:54:02,069 - INFO -     - accuracy: 0.3100
2025-07-29 07:54:02,070 - INFO -   kmmlu_hard_civil_engineering:
2025-07-29 07:54:02,070 - INFO -     - accuracy: 0.2400
2025-07-29 07:54:02,070 - INFO -   kmmlu_hard_computer_science:
2025-07-29 07:54:02,070 - INFO -     - accuracy: 0.2300
2025-07-29 07:54:02,070 - INFO -   kmmlu_hard_ecology:
2025-07-29 07:54:02,070 - INFO -     - accuracy: 0.1500
2025-07-29 07:54:02,070 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-29 07:54:02,071 - INFO -     - accuracy: 0.1900
2025-07-29 07:54:02,071 - INFO -   kmmlu_hard_information_technology:
2025-07-29 07:54:02,071 - INFO -     - accuracy: 0.2400
2025-07-29 07:54:02,071 - INFO -   kmmlu_hard_materials_engineering:
2025-07-29 07:54:02,071 - INFO -     - accuracy: 0.2600
2025-07-29 07:54:02,071 - INFO -   kmmlu_hard_math:
2025-07-29 07:54:02,071 - INFO -     - accuracy: 0.2600
2025-07-29 07:54:02,071 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-29 07:54:02,072 - INFO -     - accuracy: 0.2200
2025-07-29 07:54:02,072 - INFO - ============================================================

2025-07-29 07:54:02,110 - INFO - Mistral-7B-v0.3_harness_4: Processing task 3/10: haerae
2025-07-29 07:54:02,112 - INFO - Mistral-7B-v0.3_harness_4: Task 'haerae' will use num_fewshot=5
2025-07-29 07:54:02,238 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'haerae' with num_fewshot=5
2025-07-29 07:54:02,238 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 07:54:21,911 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-29 07:54:21,911 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-29 07:54:21,911 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-29 07:54:21,911 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-29 07:54:21,912 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-29 08:03:19,080 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'haerae' with 6 subtasks
2025-07-29 08:03:19,230 - INFO - 
============================================================
2025-07-29 08:03:19,230 - INFO - Task 'haerae' Results:
2025-07-29 08:03:19,231 - INFO - ============================================================
2025-07-29 08:03:19,231 - INFO -   haerae:
2025-07-29 08:03:19,231 - INFO -     - accuracy: 0.4977
2025-07-29 08:03:19,231 - INFO -     - accuracy_norm: 0.4977
2025-07-29 08:03:19,231 - INFO -   haerae_general_knowledge:
2025-07-29 08:03:19,231 - INFO -     - accuracy: 0.3750
2025-07-29 08:03:19,231 - INFO -     - accuracy_norm: 0.3750
2025-07-29 08:03:19,231 - INFO -   haerae_history:
2025-07-29 08:03:19,232 - INFO -     - accuracy: 0.3191
2025-07-29 08:03:19,232 - INFO -     - accuracy_norm: 0.3191
2025-07-29 08:03:19,232 - INFO -   haerae_loan_word:
2025-07-29 08:03:19,232 - INFO -     - accuracy: 0.5740
2025-07-29 08:03:19,232 - INFO -     - accuracy_norm: 0.5740
2025-07-29 08:03:19,232 - INFO -   haerae_rare_word:
2025-07-29 08:03:19,232 - INFO -     - accuracy: 0.5926
2025-07-29 08:03:19,232 - INFO -     - accuracy_norm: 0.5926
2025-07-29 08:03:19,232 - INFO -   haerae_standard_nomenclature:
2025-07-29 08:03:19,233 - INFO -     - accuracy: 0.5229
2025-07-29 08:03:19,233 - INFO -     - accuracy_norm: 0.5229
2025-07-29 08:03:19,233 - INFO - ============================================================

2025-07-29 08:03:19,266 - INFO - Mistral-7B-v0.3_harness_4: Processing task 4/10: kobest
2025-07-29 08:03:19,269 - INFO - Mistral-7B-v0.3_harness_4: Task 'kobest' will use num_fewshot=5
2025-07-29 08:03:19,396 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kobest' with num_fewshot=5
2025-07-29 08:03:19,397 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 08:03:41,384 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-29 08:03:41,385 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-29 08:03:41,385 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-29 08:03:41,385 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-29 08:03:41,385 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-29 08:18:41,666 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kobest' with 6 subtasks
2025-07-29 08:18:41,813 - INFO - 
============================================================
2025-07-29 08:18:41,813 - INFO - Task 'kobest' Results:
2025-07-29 08:18:41,813 - INFO - ============================================================
2025-07-29 08:18:41,813 - INFO -   kobest:
2025-07-29 08:18:41,813 - INFO -     - accuracy: 0.6345
2025-07-29 08:18:41,814 - INFO -     - accuracy_norm: 0.5240
2025-07-29 08:18:41,814 - INFO -     - f1: 0.6134
2025-07-29 08:18:41,814 - INFO -   kobest_boolq:
2025-07-29 08:18:41,814 - INFO -     - accuracy: 0.7635
2025-07-29 08:18:41,814 - INFO -     - f1: 0.7617
2025-07-29 08:18:41,814 - INFO -   kobest_copa:
2025-07-29 08:18:41,814 - INFO -     - accuracy: 0.6140
2025-07-29 08:18:41,814 - INFO -     - f1: 0.6133
2025-07-29 08:18:41,815 - INFO -   kobest_hellaswag:
2025-07-29 08:18:41,815 - INFO -     - accuracy: 0.4280
2025-07-29 08:18:41,815 - INFO -     - accuracy_norm: 0.5240
2025-07-29 08:18:41,815 - INFO -     - f1: 0.4233
2025-07-29 08:18:41,815 - INFO -   kobest_sentineg:
2025-07-29 08:18:41,815 - INFO -     - accuracy: 0.8791
2025-07-29 08:18:41,815 - INFO -     - f1: 0.8784
2025-07-29 08:18:41,815 - INFO -   kobest_wic:
2025-07-29 08:18:41,815 - INFO -     - accuracy: 0.5119
2025-07-29 08:18:41,816 - INFO -     - f1: 0.4402
2025-07-29 08:18:41,816 - INFO - ============================================================

2025-07-29 08:18:41,853 - INFO - Mistral-7B-v0.3_harness_4: Processing task 5/10: csatqa
2025-07-29 08:18:41,857 - INFO - Mistral-7B-v0.3_harness_4: Task 'csatqa' detected as zero-shot task
2025-07-29 08:18:41,985 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'csatqa' with num_fewshot=0
2025-07-29 08:18:41,985 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 08:18:58,533 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-29 08:18:58,533 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-29 08:18:58,534 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-29 08:18:58,534 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-29 08:18:58,534 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-29 08:18:58,534 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-29 08:22:17,523 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'csatqa' with 7 subtasks
2025-07-29 08:22:17,674 - INFO - 
============================================================
2025-07-29 08:22:17,675 - INFO - Task 'csatqa' Results:
2025-07-29 08:22:17,675 - INFO - ============================================================
2025-07-29 08:22:17,675 - INFO -   csatqa:
2025-07-29 08:22:17,675 - INFO -     - accuracy: 0.2674
2025-07-29 08:22:17,675 - INFO -     - accuracy_norm: 0.2674
2025-07-29 08:22:17,675 - INFO -   csatqa_gr:
2025-07-29 08:22:17,675 - INFO -     - accuracy: 0.1200
2025-07-29 08:22:17,675 - INFO -     - accuracy_norm: 0.1200
2025-07-29 08:22:17,676 - INFO -   csatqa_li:
2025-07-29 08:22:17,676 - INFO -     - accuracy: 0.4595
2025-07-29 08:22:17,676 - INFO -     - accuracy_norm: 0.4595
2025-07-29 08:22:17,676 - INFO -   csatqa_rch:
2025-07-29 08:22:17,676 - INFO -     - accuracy: 0.3429
2025-07-29 08:22:17,676 - INFO -     - accuracy_norm: 0.3429
2025-07-29 08:22:17,676 - INFO -   csatqa_rcs:
2025-07-29 08:22:17,676 - INFO -     - accuracy: 0.2162
2025-07-29 08:22:17,676 - INFO -     - accuracy_norm: 0.2162
2025-07-29 08:22:17,698 - INFO -   csatqa_rcss:
2025-07-29 08:22:17,698 - INFO -     - accuracy: 0.1905
2025-07-29 08:22:17,698 - INFO -     - accuracy_norm: 0.1905
2025-07-29 08:22:17,699 - INFO -   csatqa_wr:
2025-07-29 08:22:17,699 - INFO -     - accuracy: 0.1818
2025-07-29 08:22:17,699 - INFO -     - accuracy_norm: 0.1818
2025-07-29 08:22:17,699 - INFO - ============================================================

2025-07-29 08:22:17,736 - INFO - Mistral-7B-v0.3_harness_4: Processing task 6/10: kormedmcqa
2025-07-29 08:22:17,739 - INFO - Mistral-7B-v0.3_harness_4: Task 'kormedmcqa' will use num_fewshot=5
2025-07-29 08:22:17,866 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-29 08:22:17,866 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 08:22:39,764 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-29 08:22:39,764 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-29 08:22:39,764 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-29 08:22:39,765 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
2025-07-29 08:31:31,831 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-29 08:31:32,020 - INFO - 
============================================================
2025-07-29 08:31:32,021 - INFO - Task 'kormedmcqa' Results:
2025-07-29 08:31:32,021 - INFO - ============================================================
2025-07-29 08:31:32,021 - INFO -   kormedmcqa:
2025-07-29 08:31:32,021 - INFO -     - exact_match: 0.3735
2025-07-29 08:31:32,022 - INFO -   kormedmcqa_dentist:
2025-07-29 08:31:32,022 - INFO -     - exact_match: 0.3046
2025-07-29 08:31:32,022 - INFO -   kormedmcqa_doctor:
2025-07-29 08:31:32,022 - INFO -     - exact_match: 0.3011
2025-07-29 08:31:32,022 - INFO -   kormedmcqa_nurse:
2025-07-29 08:31:32,023 - INFO -     - exact_match: 0.4487
2025-07-29 08:31:32,023 - INFO -   kormedmcqa_pharm:
2025-07-29 08:31:32,023 - INFO -     - exact_match: 0.3977
2025-07-29 08:31:32,023 - INFO - ============================================================

2025-07-29 08:31:32,058 - INFO - Mistral-7B-v0.3_harness_4: Processing task 7/10: mmlu
2025-07-29 08:31:32,061 - INFO - Mistral-7B-v0.3_harness_4: Task 'mmlu' will use num_fewshot=5
2025-07-29 08:31:32,188 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'mmlu' with num_fewshot=5
2025-07-29 08:31:32,188 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 08:34:21,988 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5
2025-07-29 08:34:21,988 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 5
2025-07-29 08:34:21,989 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 5
2025-07-29 08:34:21,990 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5
2025-07-29 08:34:21,991 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 5
2025-07-29 08:34:21,992 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5
2025-07-29 08:34:21,993 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5
2025-07-29 08:34:21,993 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 5
2025-07-29 08:34:21,993 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 5
2025-07-29 08:34:21,993 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5
2025-07-29 08:34:21,993 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 5
2025-07-29 08:34:21,993 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 5
2025-07-29 08:34:21,993 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5
2025-07-29 08:34:21,993 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 5
2025-07-29 08:34:21,993 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 5
2025-07-29 08:34:21,993 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5
2025-07-29 08:57:25,199 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'mmlu' with 62 subtasks
2025-07-29 08:57:25,345 - INFO - 
============================================================
2025-07-29 08:57:25,346 - INFO - Task 'mmlu' Results:
2025-07-29 08:57:25,346 - INFO - ============================================================
2025-07-29 08:57:25,346 - INFO -   mmlu:
2025-07-29 08:57:25,346 - INFO -     - accuracy: 0.6235
2025-07-29 08:57:25,346 - INFO -   mmlu_humanities:
2025-07-29 08:57:25,346 - INFO -     - accuracy: 0.5792
2025-07-29 08:57:25,346 - INFO -   mmlu_formal_logic:
2025-07-29 08:57:25,347 - INFO -     - accuracy: 0.3810
2025-07-29 08:57:25,347 - INFO -   mmlu_high_school_european_history:
2025-07-29 08:57:25,347 - INFO -     - accuracy: 0.7515
2025-07-29 08:57:25,347 - INFO -   mmlu_high_school_us_history:
2025-07-29 08:57:25,347 - INFO -     - accuracy: 0.8088
2025-07-29 08:57:25,347 - INFO -   mmlu_high_school_world_history:
2025-07-29 08:57:25,347 - INFO -     - accuracy: 0.7848
2025-07-29 08:57:25,347 - INFO -   mmlu_international_law:
2025-07-29 08:57:25,347 - INFO -     - accuracy: 0.8017
2025-07-29 08:57:25,348 - INFO -   mmlu_jurisprudence:
2025-07-29 08:57:25,348 - INFO -     - accuracy: 0.7685
2025-07-29 08:57:25,348 - INFO -   mmlu_logical_fallacies:
2025-07-29 08:57:25,348 - INFO -     - accuracy: 0.7669
2025-07-29 08:57:25,348 - INFO -   mmlu_moral_disputes:
2025-07-29 08:57:25,348 - INFO -     - accuracy: 0.7023
2025-07-29 08:57:25,348 - INFO -   mmlu_moral_scenarios:
2025-07-29 08:57:25,348 - INFO -     - accuracy: 0.4045
2025-07-29 08:57:25,349 - INFO -   mmlu_philosophy:
2025-07-29 08:57:25,349 - INFO -     - accuracy: 0.7170
2025-07-29 08:57:25,349 - INFO -   mmlu_prehistory:
2025-07-29 08:57:25,349 - INFO -     - accuracy: 0.6914
2025-07-29 08:57:25,349 - INFO -   mmlu_professional_law:
2025-07-29 08:57:25,349 - INFO -     - accuracy: 0.4609
2025-07-29 08:57:25,349 - INFO -   mmlu_world_religions:
2025-07-29 08:57:25,349 - INFO -     - accuracy: 0.8070
2025-07-29 08:57:25,349 - INFO -   mmlu_other:
2025-07-29 08:57:25,349 - INFO -     - accuracy: 0.6984
2025-07-29 08:57:25,350 - INFO -   mmlu_business_ethics:
2025-07-29 08:57:25,350 - INFO -     - accuracy: 0.6000
2025-07-29 08:57:25,350 - INFO -   mmlu_clinical_knowledge:
2025-07-29 08:57:25,350 - INFO -     - accuracy: 0.6755
2025-07-29 08:57:25,350 - INFO -   mmlu_college_medicine:
2025-07-29 08:57:25,350 - INFO -     - accuracy: 0.6127
2025-07-29 08:57:25,350 - INFO -   mmlu_global_facts:
2025-07-29 08:57:25,350 - INFO -     - accuracy: 0.3800
2025-07-29 08:57:25,351 - INFO -   mmlu_human_aging:
2025-07-29 08:57:25,351 - INFO -     - accuracy: 0.6996
2025-07-29 08:57:25,351 - INFO -   mmlu_management:
2025-07-29 08:57:25,351 - INFO -     - accuracy: 0.8058
2025-07-29 08:57:25,351 - INFO -   mmlu_marketing:
2025-07-29 08:57:25,351 - INFO -     - accuracy: 0.8846
2025-07-29 08:57:25,351 - INFO -   mmlu_medical_genetics:
2025-07-29 08:57:25,351 - INFO -     - accuracy: 0.7000
2025-07-29 08:57:25,351 - INFO -   mmlu_miscellaneous:
2025-07-29 08:57:25,352 - INFO -     - accuracy: 0.7995
2025-07-29 08:57:25,352 - INFO -   mmlu_nutrition:
2025-07-29 08:57:25,352 - INFO -     - accuracy: 0.7516
2025-07-29 08:57:25,352 - INFO -   mmlu_professional_accounting:
2025-07-29 08:57:25,352 - INFO -     - accuracy: 0.5035
2025-07-29 08:57:25,352 - INFO -   mmlu_professional_medicine:
2025-07-29 08:57:25,352 - INFO -     - accuracy: 0.6838
2025-07-29 08:57:25,352 - INFO -   mmlu_virology:
2025-07-29 08:57:25,352 - INFO -     - accuracy: 0.5241
2025-07-29 08:57:25,353 - INFO -   mmlu_social_sciences:
2025-07-29 08:57:25,353 - INFO -     - accuracy: 0.7163
2025-07-29 08:57:25,353 - INFO -   mmlu_econometrics:
2025-07-29 08:57:25,353 - INFO -     - accuracy: 0.4298
2025-07-29 08:57:25,353 - INFO -   mmlu_high_school_geography:
2025-07-29 08:57:25,353 - INFO -     - accuracy: 0.7677
2025-07-29 08:57:25,353 - INFO -   mmlu_high_school_government_and_politics:
2025-07-29 08:57:25,353 - INFO -     - accuracy: 0.8860
2025-07-29 08:57:25,353 - INFO -   mmlu_high_school_macroeconomics:
2025-07-29 08:57:25,354 - INFO -     - accuracy: 0.6077
2025-07-29 08:57:25,354 - INFO -   mmlu_high_school_microeconomics:
2025-07-29 08:57:25,354 - INFO -     - accuracy: 0.6261
2025-07-29 08:57:25,354 - INFO -   mmlu_high_school_psychology:
2025-07-29 08:57:25,354 - INFO -     - accuracy: 0.8018
2025-07-29 08:57:25,354 - INFO -   mmlu_human_sexuality:
2025-07-29 08:57:25,354 - INFO -     - accuracy: 0.7557
2025-07-29 08:57:25,354 - INFO -   mmlu_professional_psychology:
2025-07-29 08:57:25,354 - INFO -     - accuracy: 0.6618
2025-07-29 08:57:25,355 - INFO -   mmlu_public_relations:
2025-07-29 08:57:25,355 - INFO -     - accuracy: 0.6727
2025-07-29 08:57:25,355 - INFO -   mmlu_security_studies:
2025-07-29 08:57:25,355 - INFO -     - accuracy: 0.7306
2025-07-29 08:57:25,355 - INFO -   mmlu_sociology:
2025-07-29 08:57:25,355 - INFO -     - accuracy: 0.8209
2025-07-29 08:57:25,355 - INFO -   mmlu_us_foreign_policy:
2025-07-29 08:57:25,355 - INFO -     - accuracy: 0.8700
2025-07-29 08:57:25,355 - INFO -   mmlu_stem:
2025-07-29 08:57:25,356 - INFO -     - accuracy: 0.5252
2025-07-29 08:57:25,356 - INFO -   mmlu_abstract_algebra:
2025-07-29 08:57:25,356 - INFO -     - accuracy: 0.3000
2025-07-29 08:57:25,356 - INFO -   mmlu_anatomy:
2025-07-29 08:57:25,356 - INFO -     - accuracy: 0.6000
2025-07-29 08:57:25,356 - INFO -   mmlu_astronomy:
2025-07-29 08:57:25,356 - INFO -     - accuracy: 0.6513
2025-07-29 08:57:25,356 - INFO -   mmlu_college_biology:
2025-07-29 08:57:25,356 - INFO -     - accuracy: 0.7222
2025-07-29 08:57:25,356 - INFO -   mmlu_college_chemistry:
2025-07-29 08:57:25,357 - INFO -     - accuracy: 0.4700
2025-07-29 08:57:25,357 - INFO -   mmlu_college_computer_science:
2025-07-29 08:57:25,357 - INFO -     - accuracy: 0.5300
2025-07-29 08:57:25,357 - INFO -   mmlu_college_mathematics:
2025-07-29 08:57:25,357 - INFO -     - accuracy: 0.3900
2025-07-29 08:57:25,357 - INFO -   mmlu_college_physics:
2025-07-29 08:57:25,357 - INFO -     - accuracy: 0.3333
2025-07-29 08:57:25,357 - INFO -   mmlu_computer_security:
2025-07-29 08:57:25,357 - INFO -     - accuracy: 0.7700
2025-07-29 08:57:25,358 - INFO -   mmlu_conceptual_physics:
2025-07-29 08:57:25,358 - INFO -     - accuracy: 0.5702
2025-07-29 08:57:25,358 - INFO -   mmlu_electrical_engineering:
2025-07-29 08:57:25,358 - INFO -     - accuracy: 0.5862
2025-07-29 08:57:25,358 - INFO -   mmlu_elementary_mathematics:
2025-07-29 08:57:25,358 - INFO -     - accuracy: 0.4048
2025-07-29 08:57:25,358 - INFO -   mmlu_high_school_biology:
2025-07-29 08:57:25,358 - INFO -     - accuracy: 0.7548
2025-07-29 08:57:25,359 - INFO -   mmlu_high_school_chemistry:
2025-07-29 08:57:25,359 - INFO -     - accuracy: 0.5320
2025-07-29 08:57:25,359 - INFO -   mmlu_high_school_computer_science:
2025-07-29 08:57:25,359 - INFO -     - accuracy: 0.6300
2025-07-29 08:57:25,359 - INFO -   mmlu_high_school_mathematics:
2025-07-29 08:57:25,359 - INFO -     - accuracy: 0.3481
2025-07-29 08:57:25,359 - INFO -   mmlu_high_school_physics:
2025-07-29 08:57:25,359 - INFO -     - accuracy: 0.3576
2025-07-29 08:57:25,359 - INFO -   mmlu_high_school_statistics:
2025-07-29 08:57:25,359 - INFO -     - accuracy: 0.5093
2025-07-29 08:57:25,360 - INFO -   mmlu_machine_learning:
2025-07-29 08:57:25,360 - INFO -     - accuracy: 0.5089
2025-07-29 08:57:25,360 - INFO - ============================================================

2025-07-29 08:57:25,398 - INFO - Mistral-7B-v0.3_harness_4: Processing task 8/10: arc_challenge
2025-07-29 08:57:25,404 - INFO - Mistral-7B-v0.3_harness_4: Task 'arc_challenge' will use num_fewshot=5
2025-07-29 08:57:25,530 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'arc_challenge' with num_fewshot=5
2025-07-29 08:57:25,531 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 08:57:36,362 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 5
2025-07-29 09:00:31,112 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-29 09:00:31,260 - INFO - 
============================================================
2025-07-29 09:00:31,260 - INFO - Task 'arc_challenge' Results:
2025-07-29 09:00:31,260 - INFO - ============================================================
2025-07-29 09:00:31,260 - INFO -   arc_challenge:
2025-07-29 09:00:31,260 - INFO -     - accuracy: 0.5529
2025-07-29 09:00:31,260 - INFO -     - accuracy_norm: 0.5904
2025-07-29 09:00:31,261 - INFO - ============================================================

2025-07-29 09:00:31,295 - INFO - Mistral-7B-v0.3_harness_4: Processing task 9/10: arc_easy
2025-07-29 09:00:31,297 - INFO - Mistral-7B-v0.3_harness_4: Task 'arc_easy' will use num_fewshot=5
2025-07-29 09:00:31,424 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'arc_easy' with num_fewshot=5
2025-07-29 09:00:31,425 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 09:00:41,468 - WARNING - Overwriting default num_fewshot of arc_easy from None to 5
2025-07-29 09:06:04,451 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-29 09:06:04,600 - INFO - 
============================================================
2025-07-29 09:06:04,600 - INFO - Task 'arc_easy' Results:
2025-07-29 09:06:04,600 - INFO - ============================================================
2025-07-29 09:06:04,600 - INFO -   arc_easy:
2025-07-29 09:06:04,600 - INFO -     - accuracy: 0.8342
2025-07-29 09:06:04,600 - INFO -     - accuracy_norm: 0.8434
2025-07-29 09:06:04,603 - INFO - ============================================================

2025-07-29 09:06:04,639 - INFO - Mistral-7B-v0.3_harness_4: Processing task 10/10: hellaswag
2025-07-29 09:06:04,642 - INFO - Mistral-7B-v0.3_harness_4: Task 'hellaswag' will use num_fewshot=5
2025-07-29 09:06:04,769 - INFO - Mistral-7B-v0.3_harness_4: Evaluating task 'hellaswag' with num_fewshot=5
2025-07-29 09:06:04,769 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 09:06:31,625 - WARNING - Overwriting default num_fewshot of hellaswag from None to 5
2025-07-29 09:46:03,011 - INFO - Mistral-7B-v0.3_harness_4: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-29 09:46:03,161 - INFO - 
============================================================
2025-07-29 09:46:03,161 - INFO - Task 'hellaswag' Results:
2025-07-29 09:46:03,161 - INFO - ============================================================
2025-07-29 09:46:03,161 - INFO -   hellaswag:
2025-07-29 09:46:03,161 - INFO -     - accuracy: 0.6231
2025-07-29 09:46:03,162 - INFO -     - accuracy_norm: 0.8231
2025-07-29 09:46:03,162 - INFO - ============================================================

2025-07-29 09:46:03,200 - INFO - Mistral-7B-v0.3_harness_4: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-29 09:46:03,203 - INFO - [Process 1941996] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250729_041113/model_results/Mistral-7B-v0.3/Mistral-7B-v0.3_harness_4.json
2025-07-29 09:46:03,204 - INFO - [Process 1941996] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Mistral-7B-v0.3/Mistral-7B-v0.3_harness_4.json
2025-07-29 09:46:03,488 - INFO - Results uploaded to WandB as artifact
2025-07-29 09:46:03,497 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-29 09:46:03,499 - INFO - [Process 1941996] Successfully completed Mistral-7B-v0.3_harness_4
2025-07-29 09:46:05,798 - INFO - Run Mistral-7B-v0.3_harness_4 finished successfully
2025-07-29 09:46:05,798 - INFO - [Process 1941996] Qwen3-8B_harness_5 assigned to cuda:0
2025-07-29 09:46:05,799 - INFO - [Process 1941996] Qwen3-8B_harness_5 - full_run: True, limit: None (full dataset)
2025-07-29 09:46:08,060 - INFO - WandB run initialized: Qwen3-8B_20250729_094605 (ID: 2d5a7535)
2025-07-29 09:46:08,427 - INFO - Qwen3-8B_harness_5: Processing task 1/10: kmmlu
2025-07-29 09:46:08,427 - INFO - Qwen3-8B_harness_5: Task 'kmmlu' will use num_fewshot=5
2025-07-29 09:46:08,556 - INFO - Qwen3-8B_harness_5: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-29 09:46:08,557 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 09:47:25,773 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-29 09:47:25,774 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-29 09:47:25,774 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-29 09:47:25,774 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-29 09:47:25,774 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-29 09:47:25,774 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-29 09:47:25,774 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-29 09:47:25,775 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-29 09:47:25,775 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-29 09:47:25,775 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-29 09:47:25,775 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-29 09:47:25,775 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-29 09:47:25,775 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-29 09:47:25,775 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-29 09:47:25,775 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-29 09:47:25,775 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-29 09:47:25,776 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-29 09:47:25,777 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-29 09:47:25,777 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-29 09:47:25,777 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-29 09:47:25,777 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-29 09:47:25,777 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-29 09:47:25,777 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-29 09:47:25,777 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-29 09:47:25,777 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-29 09:47:25,777 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-29 09:47:25,777 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-29 09:47:25,823 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-29 09:47:25,823 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-29 09:47:25,823 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-29 09:47:25,823 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-29 09:47:25,823 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-29 09:47:25,824 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-29 09:47:25,824 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-29 09:47:25,824 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-29 10:40:03,102 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-29 10:40:03,250 - INFO - 
============================================================
2025-07-29 10:40:03,250 - INFO - Task 'kmmlu' Results:
2025-07-29 10:40:03,250 - INFO - ============================================================
2025-07-29 10:40:03,250 - INFO -   kmmlu:
2025-07-29 10:40:03,250 - INFO -     - accuracy: 0.5556
2025-07-29 10:40:03,250 - INFO -   kmmlu_applied_science:
2025-07-29 10:40:03,251 - INFO -     - accuracy: 0.5363
2025-07-29 10:40:03,251 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-29 10:40:03,251 - INFO -     - accuracy: 0.5540
2025-07-29 10:40:03,251 - INFO -   kmmlu_electronics_engineering:
2025-07-29 10:40:03,251 - INFO -     - accuracy: 0.6570
2025-07-29 10:40:03,251 - INFO -   kmmlu_energy_management:
2025-07-29 10:40:03,251 - INFO -     - accuracy: 0.4220
2025-07-29 10:40:03,251 - INFO -   kmmlu_environmental_science:
2025-07-29 10:40:03,252 - INFO -     - accuracy: 0.4520
2025-07-29 10:40:03,252 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-29 10:40:03,252 - INFO -     - accuracy: 0.4610
2025-07-29 10:40:03,252 - INFO -   kmmlu_geomatics:
2025-07-29 10:40:03,252 - INFO -     - accuracy: 0.5080
2025-07-29 10:40:03,252 - INFO -   kmmlu_industrial_engineer:
2025-07-29 10:40:03,252 - INFO -     - accuracy: 0.5400
2025-07-29 10:40:03,252 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-29 10:40:03,252 - INFO -     - accuracy: 0.5790
2025-07-29 10:40:03,253 - INFO -   kmmlu_maritime_engineering:
2025-07-29 10:40:03,253 - INFO -     - accuracy: 0.5783
2025-07-29 10:40:03,253 - INFO -   kmmlu_nondestructive_testing:
2025-07-29 10:40:03,253 - INFO -     - accuracy: 0.5560
2025-07-29 10:40:03,253 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-29 10:40:03,253 - INFO -     - accuracy: 0.4710
2025-07-29 10:40:03,253 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-29 10:40:03,253 - INFO -     - accuracy: 0.6740
2025-07-29 10:40:03,253 - INFO -   kmmlu_humss:
2025-07-29 10:40:03,254 - INFO -     - accuracy: 0.5772
2025-07-29 10:40:03,254 - INFO -   kmmlu_accounting:
2025-07-29 10:40:03,254 - INFO -     - accuracy: 0.4400
2025-07-29 10:40:03,254 - INFO -   kmmlu_criminal_law:
2025-07-29 10:40:03,254 - INFO -     - accuracy: 0.4300
2025-07-29 10:40:03,254 - INFO -   kmmlu_economics:
2025-07-29 10:40:03,254 - INFO -     - accuracy: 0.6077
2025-07-29 10:40:03,254 - INFO -   kmmlu_education:
2025-07-29 10:40:03,254 - INFO -     - accuracy: 0.7200
2025-07-29 10:40:03,255 - INFO -   kmmlu_korean_history:
2025-07-29 10:40:03,255 - INFO -     - accuracy: 0.3300
2025-07-29 10:40:03,255 - INFO -   kmmlu_law:
2025-07-29 10:40:03,255 - INFO -     - accuracy: 0.5050
2025-07-29 10:40:03,255 - INFO -   kmmlu_management:
2025-07-29 10:40:03,255 - INFO -     - accuracy: 0.6420
2025-07-29 10:40:03,255 - INFO -   kmmlu_political_science_and_sociology:
2025-07-29 10:40:03,255 - INFO -     - accuracy: 0.6033
2025-07-29 10:40:03,256 - INFO -   kmmlu_psychology:
2025-07-29 10:40:03,256 - INFO -     - accuracy: 0.5130
2025-07-29 10:40:03,256 - INFO -   kmmlu_social_welfare:
2025-07-29 10:40:03,256 - INFO -     - accuracy: 0.7210
2025-07-29 10:40:03,256 - INFO -   kmmlu_taxation:
2025-07-29 10:40:03,256 - INFO -     - accuracy: 0.4250
2025-07-29 10:40:03,256 - INFO -   kmmlu_other:
2025-07-29 10:40:03,256 - INFO -     - accuracy: 0.5344
2025-07-29 10:40:03,256 - INFO -   kmmlu_agricultural_sciences:
2025-07-29 10:40:03,256 - INFO -     - accuracy: 0.4010
2025-07-29 10:40:03,257 - INFO -   kmmlu_construction:
2025-07-29 10:40:03,257 - INFO -     - accuracy: 0.4550
2025-07-29 10:40:03,257 - INFO -   kmmlu_fashion:
2025-07-29 10:40:03,257 - INFO -     - accuracy: 0.5470
2025-07-29 10:40:03,257 - INFO -   kmmlu_food_processing:
2025-07-29 10:40:03,257 - INFO -     - accuracy: 0.4950
2025-07-29 10:40:03,257 - INFO -   kmmlu_health:
2025-07-29 10:40:03,257 - INFO -     - accuracy: 0.6600
2025-07-29 10:40:03,258 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-29 10:40:03,258 - INFO -     - accuracy: 0.6050
2025-07-29 10:40:03,258 - INFO -   kmmlu_marketing:
2025-07-29 10:40:03,258 - INFO -     - accuracy: 0.8370
2025-07-29 10:40:03,258 - INFO -   kmmlu_patent:
2025-07-29 10:40:03,258 - INFO -     - accuracy: 0.3800
2025-07-29 10:40:03,258 - INFO -   kmmlu_public_safety:
2025-07-29 10:40:03,258 - INFO -     - accuracy: 0.4660
2025-07-29 10:40:03,258 - INFO -   kmmlu_real_estate:
2025-07-29 10:40:03,258 - INFO -     - accuracy: 0.5000
2025-07-29 10:40:03,259 - INFO -   kmmlu_refrigerating_machinery:
2025-07-29 10:40:03,259 - INFO -     - accuracy: 0.4790
2025-07-29 10:40:03,259 - INFO -   kmmlu_stem:
2025-07-29 10:40:03,259 - INFO -     - accuracy: 0.5852
2025-07-29 10:40:03,259 - INFO -   kmmlu_biology:
2025-07-29 10:40:03,259 - INFO -     - accuracy: 0.4490
2025-07-29 10:40:03,259 - INFO -   kmmlu_chemical_engineering:
2025-07-29 10:40:03,259 - INFO -     - accuracy: 0.6060
2025-07-29 10:40:03,259 - INFO -   kmmlu_chemistry:
2025-07-29 10:40:03,259 - INFO -     - accuracy: 0.5833
2025-07-29 10:40:03,260 - INFO -   kmmlu_civil_engineering:
2025-07-29 10:40:03,260 - INFO -     - accuracy: 0.5060
2025-07-29 10:40:03,260 - INFO -   kmmlu_computer_science:
2025-07-29 10:40:03,260 - INFO -     - accuracy: 0.8070
2025-07-29 10:40:03,260 - INFO -   kmmlu_ecology:
2025-07-29 10:40:03,260 - INFO -     - accuracy: 0.5730
2025-07-29 10:40:03,260 - INFO -   kmmlu_electrical_engineering:
2025-07-29 10:40:03,260 - INFO -     - accuracy: 0.4520
2025-07-29 10:40:03,260 - INFO -   kmmlu_information_technology:
2025-07-29 10:40:03,260 - INFO -     - accuracy: 0.8010
2025-07-29 10:40:03,261 - INFO -   kmmlu_materials_engineering:
2025-07-29 10:40:03,261 - INFO -     - accuracy: 0.6070
2025-07-29 10:40:03,261 - INFO -   kmmlu_math:
2025-07-29 10:40:03,261 - INFO -     - accuracy: 0.3267
2025-07-29 10:40:03,261 - INFO -   kmmlu_mechanical_engineering:
2025-07-29 10:40:03,261 - INFO -     - accuracy: 0.5440
2025-07-29 10:40:03,261 - INFO - ============================================================

2025-07-29 10:40:03,307 - INFO - Qwen3-8B_harness_5: Processing task 2/10: kmmlu_hard
2025-07-29 10:40:03,314 - INFO - Qwen3-8B_harness_5: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-29 10:40:03,443 - INFO - Qwen3-8B_harness_5: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-29 10:40:03,443 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 10:41:18,715 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-29 10:41:18,715 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-29 10:41:18,715 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-29 10:41:18,716 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-29 10:41:18,716 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-29 10:41:18,716 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-29 10:41:18,716 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-29 10:41:18,716 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-29 10:41:18,716 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-29 10:41:18,716 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-29 10:41:18,716 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-29 10:41:18,716 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-29 10:41:18,716 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-29 10:41:18,717 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-29 10:41:18,717 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-29 10:41:18,717 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-29 10:41:18,717 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-29 10:41:18,717 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-29 10:41:18,717 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-29 10:41:18,717 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-29 10:41:18,717 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-29 10:41:18,717 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-29 10:41:18,718 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-29 10:41:18,718 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-29 10:41:18,718 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-29 10:41:18,718 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-29 10:41:18,718 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-29 10:41:18,718 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-29 10:41:18,718 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-29 10:41:18,718 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-29 10:41:18,718 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-29 10:41:18,718 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-29 10:41:18,719 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-29 10:41:18,719 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-29 10:41:18,719 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-29 10:41:18,719 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-29 10:41:18,719 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-29 10:41:18,719 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-29 10:41:18,719 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-29 10:41:18,719 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-29 10:41:18,719 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-29 10:41:18,719 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-29 10:41:18,720 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-29 10:41:18,720 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-29 10:41:18,720 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-29 10:48:06,110 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-29 10:48:06,268 - INFO - 
============================================================
2025-07-29 10:48:06,268 - INFO - Task 'kmmlu_hard' Results:
2025-07-29 10:48:06,268 - INFO - ============================================================
2025-07-29 10:48:06,269 - INFO -   kmmlu_hard:
2025-07-29 10:48:06,269 - INFO -     - accuracy: 0.2926
2025-07-29 10:48:06,269 - INFO -   kmmlu_hard_applied_science:
2025-07-29 10:48:06,269 - INFO -     - accuracy: 0.2950
2025-07-29 10:48:06,270 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-29 10:48:06,270 - INFO -     - accuracy: 0.3800
2025-07-29 10:48:06,270 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-29 10:48:06,270 - INFO -     - accuracy: 0.4200
2025-07-29 10:48:06,270 - INFO -   kmmlu_hard_energy_management:
2025-07-29 10:48:06,270 - INFO -     - accuracy: 0.2200
2025-07-29 10:48:06,271 - INFO -   kmmlu_hard_environmental_science:
2025-07-29 10:48:06,271 - INFO -     - accuracy: 0.2800
2025-07-29 10:48:06,273 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-29 10:48:06,274 - INFO -     - accuracy: 0.3300
2025-07-29 10:48:06,274 - INFO -   kmmlu_hard_geomatics:
2025-07-29 10:48:06,274 - INFO -     - accuracy: 0.3000
2025-07-29 10:48:06,275 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-29 10:48:06,275 - INFO -     - accuracy: 0.2200
2025-07-29 10:48:06,275 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-29 10:48:06,275 - INFO -     - accuracy: 0.2400
2025-07-29 10:48:06,275 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-29 10:48:06,275 - INFO -     - accuracy: 0.3000
2025-07-29 10:48:06,275 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-29 10:48:06,275 - INFO -     - accuracy: 0.3100
2025-07-29 10:48:06,276 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-29 10:48:06,276 - INFO -     - accuracy: 0.2500
2025-07-29 10:48:06,276 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-29 10:48:06,276 - INFO -     - accuracy: 0.2900
2025-07-29 10:48:06,276 - INFO -   kmmlu_hard_humss:
2025-07-29 10:48:06,276 - INFO -     - accuracy: 0.2652
2025-07-29 10:48:06,276 - INFO -   kmmlu_hard_accounting:
2025-07-29 10:48:06,276 - INFO -     - accuracy: 0.2174
2025-07-29 10:48:06,276 - INFO -   kmmlu_hard_criminal_law:
2025-07-29 10:48:06,277 - INFO -     - accuracy: 0.2500
2025-07-29 10:48:06,277 - INFO -   kmmlu_hard_economics:
2025-07-29 10:48:06,277 - INFO -     - accuracy: 0.3095
2025-07-29 10:48:06,277 - INFO -   kmmlu_hard_education:
2025-07-29 10:48:06,277 - INFO -     - accuracy: 0.3043
2025-07-29 10:48:06,277 - INFO -   kmmlu_hard_korean_history:
2025-07-29 10:48:06,277 - INFO -     - accuracy: 0.1818
2025-07-29 10:48:06,277 - INFO -   kmmlu_hard_law:
2025-07-29 10:48:06,277 - INFO -     - accuracy: 0.1800
2025-07-29 10:48:06,278 - INFO -   kmmlu_hard_management:
2025-07-29 10:48:06,278 - INFO -     - accuracy: 0.3200
2025-07-29 10:48:06,278 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-29 10:48:06,278 - INFO -     - accuracy: 0.2778
2025-07-29 10:48:06,278 - INFO -   kmmlu_hard_psychology:
2025-07-29 10:48:06,278 - INFO -     - accuracy: 0.2200
2025-07-29 10:48:06,278 - INFO -   kmmlu_hard_social_welfare:
2025-07-29 10:48:06,278 - INFO -     - accuracy: 0.4400
2025-07-29 10:48:06,279 - INFO -   kmmlu_hard_taxation:
2025-07-29 10:48:06,279 - INFO -     - accuracy: 0.1979
2025-07-29 10:48:06,279 - INFO -   kmmlu_hard_other:
2025-07-29 10:48:06,279 - INFO -     - accuracy: 0.2856
2025-07-29 10:48:06,279 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-29 10:48:06,279 - INFO -     - accuracy: 0.2100
2025-07-29 10:48:06,279 - INFO -   kmmlu_hard_construction:
2025-07-29 10:48:06,279 - INFO -     - accuracy: 0.3500
2025-07-29 10:48:06,279 - INFO -   kmmlu_hard_fashion:
2025-07-29 10:48:06,280 - INFO -     - accuracy: 0.2100
2025-07-29 10:48:06,280 - INFO -   kmmlu_hard_food_processing:
2025-07-29 10:48:06,280 - INFO -     - accuracy: 0.2500
2025-07-29 10:48:06,280 - INFO -   kmmlu_hard_health:
2025-07-29 10:48:06,280 - INFO -     - accuracy: 0.0870
2025-07-29 10:48:06,280 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-29 10:48:06,280 - INFO -     - accuracy: 0.3300
2025-07-29 10:48:06,280 - INFO -   kmmlu_hard_marketing:
2025-07-29 10:48:06,280 - INFO -     - accuracy: 0.3700
2025-07-29 10:48:06,281 - INFO -   kmmlu_hard_patent:
2025-07-29 10:48:06,281 - INFO -     - accuracy: 0.1961
2025-07-29 10:48:06,281 - INFO -   kmmlu_hard_public_safety:
2025-07-29 10:48:06,281 - INFO -     - accuracy: 0.2800
2025-07-29 10:48:06,281 - INFO -   kmmlu_hard_real_estate:
2025-07-29 10:48:06,281 - INFO -     - accuracy: 0.2584
2025-07-29 10:48:06,281 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-29 10:48:06,281 - INFO -     - accuracy: 0.4000
2025-07-29 10:48:06,281 - INFO -   kmmlu_hard_stem:
2025-07-29 10:48:06,281 - INFO -     - accuracy: 0.3173
2025-07-29 10:48:06,282 - INFO -   kmmlu_hard_biology:
2025-07-29 10:48:06,282 - INFO -     - accuracy: 0.2300
2025-07-29 10:48:06,282 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-29 10:48:06,282 - INFO -     - accuracy: 0.3400
2025-07-29 10:48:06,282 - INFO -   kmmlu_hard_chemistry:
2025-07-29 10:48:06,282 - INFO -     - accuracy: 0.3000
2025-07-29 10:48:06,282 - INFO -   kmmlu_hard_civil_engineering:
2025-07-29 10:48:06,282 - INFO -     - accuracy: 0.3800
2025-07-29 10:48:06,283 - INFO -   kmmlu_hard_computer_science:
2025-07-29 10:48:06,283 - INFO -     - accuracy: 0.3300
2025-07-29 10:48:06,283 - INFO -   kmmlu_hard_ecology:
2025-07-29 10:48:06,283 - INFO -     - accuracy: 0.1800
2025-07-29 10:48:06,283 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-29 10:48:06,283 - INFO -     - accuracy: 0.3500
2025-07-29 10:48:06,283 - INFO -   kmmlu_hard_information_technology:
2025-07-29 10:48:06,283 - INFO -     - accuracy: 0.4300
2025-07-29 10:48:06,283 - INFO -   kmmlu_hard_materials_engineering:
2025-07-29 10:48:06,284 - INFO -     - accuracy: 0.2900
2025-07-29 10:48:06,284 - INFO -   kmmlu_hard_math:
2025-07-29 10:48:06,284 - INFO -     - accuracy: 0.3200
2025-07-29 10:48:06,284 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-29 10:48:06,284 - INFO -     - accuracy: 0.3400
2025-07-29 10:48:06,284 - INFO - ============================================================

2025-07-29 10:48:06,331 - INFO - Qwen3-8B_harness_5: Processing task 3/10: haerae
2025-07-29 10:48:06,332 - INFO - Qwen3-8B_harness_5: Task 'haerae' will use num_fewshot=5
2025-07-29 10:48:06,460 - INFO - Qwen3-8B_harness_5: Evaluating task 'haerae' with num_fewshot=5
2025-07-29 10:48:06,461 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 10:48:25,738 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-29 10:48:25,738 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-29 10:48:25,739 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-29 10:48:25,739 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-29 10:48:25,739 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-29 10:55:17,357 - INFO - Qwen3-8B_harness_5: Successfully completed task 'haerae' with 6 subtasks
2025-07-29 10:55:17,509 - INFO - 
============================================================
2025-07-29 10:55:17,510 - INFO - Task 'haerae' Results:
2025-07-29 10:55:17,510 - INFO - ============================================================
2025-07-29 10:55:17,511 - INFO -   haerae:
2025-07-29 10:55:17,511 - INFO -     - accuracy: 0.6700
2025-07-29 10:55:17,511 - INFO -     - accuracy_norm: 0.6700
2025-07-29 10:55:17,511 - INFO -   haerae_general_knowledge:
2025-07-29 10:55:17,511 - INFO -     - accuracy: 0.4318
2025-07-29 10:55:17,511 - INFO -     - accuracy_norm: 0.4318
2025-07-29 10:55:17,512 - INFO -   haerae_history:
2025-07-29 10:55:17,512 - INFO -     - accuracy: 0.4840
2025-07-29 10:55:17,512 - INFO -     - accuracy_norm: 0.4840
2025-07-29 10:55:17,512 - INFO -   haerae_loan_word:
2025-07-29 10:55:17,514 - INFO -     - accuracy: 0.7692
2025-07-29 10:55:17,515 - INFO -     - accuracy_norm: 0.7692
2025-07-29 10:55:17,515 - INFO -   haerae_rare_word:
2025-07-29 10:55:17,515 - INFO -     - accuracy: 0.7704
2025-07-29 10:55:17,515 - INFO -     - accuracy_norm: 0.7704
2025-07-29 10:55:17,515 - INFO -   haerae_standard_nomenclature:
2025-07-29 10:55:17,515 - INFO -     - accuracy: 0.7974
2025-07-29 10:55:17,515 - INFO -     - accuracy_norm: 0.7974
2025-07-29 10:55:17,516 - INFO - ============================================================

2025-07-29 10:55:17,557 - INFO - Qwen3-8B_harness_5: Processing task 4/10: kobest
2025-07-29 10:55:17,559 - INFO - Qwen3-8B_harness_5: Task 'kobest' will use num_fewshot=5
2025-07-29 10:55:17,689 - INFO - Qwen3-8B_harness_5: Evaluating task 'kobest' with num_fewshot=5
2025-07-29 10:55:17,689 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 10:55:40,689 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-29 10:55:40,689 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-29 10:55:40,689 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-29 10:55:40,689 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-29 10:55:40,689 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-29 11:08:11,461 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kobest' with 6 subtasks
2025-07-29 11:08:11,653 - INFO - 
============================================================
2025-07-29 11:08:11,653 - INFO - Task 'kobest' Results:
2025-07-29 11:08:11,653 - INFO - ============================================================
2025-07-29 11:08:11,654 - INFO -   kobest:
2025-07-29 11:08:11,654 - INFO -     - accuracy: 0.7891
2025-07-29 11:08:11,654 - INFO -     - accuracy_norm: 0.5920
2025-07-29 11:08:11,654 - INFO -     - f1: 0.7874
2025-07-29 11:08:11,654 - INFO -   kobest_boolq:
2025-07-29 11:08:11,654 - INFO -     - accuracy: 0.9174
2025-07-29 11:08:11,654 - INFO -     - f1: 0.9173
2025-07-29 11:08:11,654 - INFO -   kobest_copa:
2025-07-29 11:08:11,655 - INFO -     - accuracy: 0.7290
2025-07-29 11:08:11,655 - INFO -     - f1: 0.7289
2025-07-29 11:08:11,655 - INFO -   kobest_hellaswag:
2025-07-29 11:08:11,655 - INFO -     - accuracy: 0.4660
2025-07-29 11:08:11,655 - INFO -     - accuracy_norm: 0.5920
2025-07-29 11:08:11,655 - INFO -     - f1: 0.4643
2025-07-29 11:08:11,655 - INFO -   kobest_sentineg:
2025-07-29 11:08:11,655 - INFO -     - accuracy: 0.9647
2025-07-29 11:08:11,655 - INFO -     - f1: 0.9647
2025-07-29 11:08:11,655 - INFO -   kobest_wic:
2025-07-29 11:08:11,656 - INFO -     - accuracy: 0.7667
2025-07-29 11:08:11,656 - INFO -     - f1: 0.7615
2025-07-29 11:08:11,656 - INFO - ============================================================

2025-07-29 11:08:11,698 - INFO - Qwen3-8B_harness_5: Processing task 5/10: csatqa
2025-07-29 11:08:11,700 - INFO - Qwen3-8B_harness_5: Task 'csatqa' detected as zero-shot task
2025-07-29 11:08:11,827 - INFO - Qwen3-8B_harness_5: Evaluating task 'csatqa' with num_fewshot=0
2025-07-29 11:08:11,827 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 11:08:28,573 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-29 11:08:28,574 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-29 11:08:28,574 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-29 11:08:28,574 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-29 11:08:28,574 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-29 11:08:28,574 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-29 11:10:59,913 - INFO - Qwen3-8B_harness_5: Successfully completed task 'csatqa' with 7 subtasks
2025-07-29 11:11:00,059 - INFO - 
============================================================
2025-07-29 11:11:00,060 - INFO - Task 'csatqa' Results:
2025-07-29 11:11:00,060 - INFO - ============================================================
2025-07-29 11:11:00,060 - INFO -   csatqa:
2025-07-29 11:11:00,060 - INFO -     - accuracy: 0.5134
2025-07-29 11:11:00,060 - INFO -     - accuracy_norm: 0.5134
2025-07-29 11:11:00,060 - INFO -   csatqa_gr:
2025-07-29 11:11:00,060 - INFO -     - accuracy: 0.2400
2025-07-29 11:11:00,060 - INFO -     - accuracy_norm: 0.2400
2025-07-29 11:11:00,061 - INFO -   csatqa_li:
2025-07-29 11:11:00,061 - INFO -     - accuracy: 0.5405
2025-07-29 11:11:00,061 - INFO -     - accuracy_norm: 0.5405
2025-07-29 11:11:00,061 - INFO -   csatqa_rch:
2025-07-29 11:11:00,061 - INFO -     - accuracy: 0.6286
2025-07-29 11:11:00,061 - INFO -     - accuracy_norm: 0.6286
2025-07-29 11:11:00,061 - INFO -   csatqa_rcs:
2025-07-29 11:11:00,061 - INFO -     - accuracy: 0.5676
2025-07-29 11:11:00,061 - INFO -     - accuracy_norm: 0.5676
2025-07-29 11:11:00,062 - INFO -   csatqa_rcss:
2025-07-29 11:11:00,062 - INFO -     - accuracy: 0.5476
2025-07-29 11:11:00,062 - INFO -     - accuracy_norm: 0.5476
2025-07-29 11:11:00,062 - INFO -   csatqa_wr:
2025-07-29 11:11:00,062 - INFO -     - accuracy: 0.3636
2025-07-29 11:11:00,062 - INFO -     - accuracy_norm: 0.3636
2025-07-29 11:11:00,062 - INFO - ============================================================

2025-07-29 11:11:00,108 - INFO - Qwen3-8B_harness_5: Processing task 6/10: kormedmcqa
2025-07-29 11:11:00,111 - INFO - Qwen3-8B_harness_5: Task 'kormedmcqa' will use num_fewshot=5
2025-07-29 11:11:00,237 - INFO - Qwen3-8B_harness_5: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-29 11:11:00,238 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 11:11:20,342 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-29 11:11:20,342 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-29 11:11:20,343 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-29 11:11:20,343 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
2025-07-29 11:18:36,282 - INFO - Qwen3-8B_harness_5: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-29 11:18:36,437 - INFO - 
============================================================
2025-07-29 11:18:36,437 - INFO - Task 'kormedmcqa' Results:
2025-07-29 11:18:36,437 - INFO - ============================================================
2025-07-29 11:18:36,438 - INFO -   kormedmcqa:
2025-07-29 11:18:36,438 - INFO -     - exact_match: 0.6471
2025-07-29 11:18:36,438 - INFO -   kormedmcqa_dentist:
2025-07-29 11:18:36,438 - INFO -     - exact_match: 0.5376
2025-07-29 11:18:36,438 - INFO -   kormedmcqa_doctor:
2025-07-29 11:18:36,439 - INFO -     - exact_match: 0.5218
2025-07-29 11:18:36,439 - INFO -   kormedmcqa_nurse:
2025-07-29 11:18:36,439 - INFO -     - exact_match: 0.7631
2025-07-29 11:18:36,441 - INFO -   kormedmcqa_pharm:
2025-07-29 11:18:36,441 - INFO -     - exact_match: 0.6938
2025-07-29 11:18:36,442 - INFO - ============================================================

2025-07-29 11:18:36,482 - INFO - Qwen3-8B_harness_5: Processing task 7/10: mmlu
2025-07-29 11:18:36,484 - INFO - Qwen3-8B_harness_5: Task 'mmlu' will use num_fewshot=5
2025-07-29 11:18:36,611 - INFO - Qwen3-8B_harness_5: Evaluating task 'mmlu' with num_fewshot=5
2025-07-29 11:18:36,612 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 11:21:22,061 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5
2025-07-29 11:21:22,062 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5
2025-07-29 11:21:22,062 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 5
2025-07-29 11:21:22,062 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5
2025-07-29 11:21:22,062 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5
2025-07-29 11:21:22,062 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 5
2025-07-29 11:21:22,062 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 5
2025-07-29 11:21:22,062 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 5
2025-07-29 11:21:22,063 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 5
2025-07-29 11:21:22,064 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 5
2025-07-29 11:21:22,065 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 5
2025-07-29 11:21:22,066 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5
2025-07-29 11:21:22,067 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 5
2025-07-29 11:21:22,067 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 5
2025-07-29 11:21:22,067 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5
2025-07-29 11:46:05,443 - INFO - Qwen3-8B_harness_5: Successfully completed task 'mmlu' with 62 subtasks
2025-07-29 11:46:05,596 - INFO - 
============================================================
2025-07-29 11:46:05,596 - INFO - Task 'mmlu' Results:
2025-07-29 11:46:05,596 - INFO - ============================================================
2025-07-29 11:46:05,597 - INFO -   mmlu:
2025-07-29 11:46:05,597 - INFO -     - accuracy: 0.7490
2025-07-29 11:46:05,597 - INFO -   mmlu_humanities:
2025-07-29 11:46:05,597 - INFO -     - accuracy: 0.6623
2025-07-29 11:46:05,597 - INFO -   mmlu_formal_logic:
2025-07-29 11:46:05,598 - INFO -     - accuracy: 0.6587
2025-07-29 11:46:05,598 - INFO -   mmlu_high_school_european_history:
2025-07-29 11:46:05,598 - INFO -     - accuracy: 0.8606
2025-07-29 11:46:05,598 - INFO -   mmlu_high_school_us_history:
2025-07-29 11:46:05,601 - INFO -     - accuracy: 0.8627
2025-07-29 11:46:05,601 - INFO -   mmlu_high_school_world_history:
2025-07-29 11:46:05,602 - INFO -     - accuracy: 0.8608
2025-07-29 11:46:05,602 - INFO -   mmlu_international_law:
2025-07-29 11:46:05,602 - INFO -     - accuracy: 0.7355
2025-07-29 11:46:05,602 - INFO -   mmlu_jurisprudence:
2025-07-29 11:46:05,602 - INFO -     - accuracy: 0.8148
2025-07-29 11:46:05,602 - INFO -   mmlu_logical_fallacies:
2025-07-29 11:46:05,602 - INFO -     - accuracy: 0.8282
2025-07-29 11:46:05,603 - INFO -   mmlu_moral_disputes:
2025-07-29 11:46:05,603 - INFO -     - accuracy: 0.7630
2025-07-29 11:46:05,603 - INFO -   mmlu_moral_scenarios:
2025-07-29 11:46:05,603 - INFO -     - accuracy: 0.5497
2025-07-29 11:46:05,603 - INFO -   mmlu_philosophy:
2025-07-29 11:46:05,603 - INFO -     - accuracy: 0.7781
2025-07-29 11:46:05,603 - INFO -   mmlu_prehistory:
2025-07-29 11:46:05,603 - INFO -     - accuracy: 0.8395
2025-07-29 11:46:05,603 - INFO -   mmlu_professional_law:
2025-07-29 11:46:05,604 - INFO -     - accuracy: 0.5085
2025-07-29 11:46:05,604 - INFO -   mmlu_world_religions:
2025-07-29 11:46:05,604 - INFO -     - accuracy: 0.8713
2025-07-29 11:46:05,604 - INFO -   mmlu_other:
2025-07-29 11:46:05,604 - INFO -     - accuracy: 0.7834
2025-07-29 11:46:05,604 - INFO -   mmlu_business_ethics:
2025-07-29 11:46:05,604 - INFO -     - accuracy: 0.7700
2025-07-29 11:46:05,604 - INFO -   mmlu_clinical_knowledge:
2025-07-29 11:46:05,604 - INFO -     - accuracy: 0.7849
2025-07-29 11:46:05,605 - INFO -   mmlu_college_medicine:
2025-07-29 11:46:05,605 - INFO -     - accuracy: 0.8035
2025-07-29 11:46:05,605 - INFO -   mmlu_global_facts:
2025-07-29 11:46:05,605 - INFO -     - accuracy: 0.5300
2025-07-29 11:46:05,605 - INFO -   mmlu_human_aging:
2025-07-29 11:46:05,605 - INFO -     - accuracy: 0.7489
2025-07-29 11:46:05,605 - INFO -   mmlu_management:
2025-07-29 11:46:05,605 - INFO -     - accuracy: 0.8738
2025-07-29 11:46:05,605 - INFO -   mmlu_marketing:
2025-07-29 11:46:05,606 - INFO -     - accuracy: 0.9359
2025-07-29 11:46:05,606 - INFO -   mmlu_medical_genetics:
2025-07-29 11:46:05,606 - INFO -     - accuracy: 0.8400
2025-07-29 11:46:05,606 - INFO -   mmlu_miscellaneous:
2025-07-29 11:46:05,606 - INFO -     - accuracy: 0.8582
2025-07-29 11:46:05,606 - INFO -   mmlu_nutrition:
2025-07-29 11:46:05,606 - INFO -     - accuracy: 0.8105
2025-07-29 11:46:05,606 - INFO -   mmlu_professional_accounting:
2025-07-29 11:46:05,606 - INFO -     - accuracy: 0.5780
2025-07-29 11:46:05,607 - INFO -   mmlu_professional_medicine:
2025-07-29 11:46:05,607 - INFO -     - accuracy: 0.8125
2025-07-29 11:46:05,607 - INFO -   mmlu_virology:
2025-07-29 11:46:05,607 - INFO -     - accuracy: 0.5602
2025-07-29 11:46:05,607 - INFO -   mmlu_social_sciences:
2025-07-29 11:46:05,607 - INFO -     - accuracy: 0.8388
2025-07-29 11:46:05,607 - INFO -   mmlu_econometrics:
2025-07-29 11:46:05,607 - INFO -     - accuracy: 0.6579
2025-07-29 11:46:05,608 - INFO -   mmlu_high_school_geography:
2025-07-29 11:46:05,608 - INFO -     - accuracy: 0.8636
2025-07-29 11:46:05,608 - INFO -   mmlu_high_school_government_and_politics:
2025-07-29 11:46:05,608 - INFO -     - accuracy: 0.9326
2025-07-29 11:46:05,608 - INFO -   mmlu_high_school_macroeconomics:
2025-07-29 11:46:05,608 - INFO -     - accuracy: 0.8103
2025-07-29 11:46:05,608 - INFO -   mmlu_high_school_microeconomics:
2025-07-29 11:46:05,608 - INFO -     - accuracy: 0.9370
2025-07-29 11:46:05,608 - INFO -   mmlu_high_school_psychology:
2025-07-29 11:46:05,608 - INFO -     - accuracy: 0.9138
2025-07-29 11:46:05,609 - INFO -   mmlu_human_sexuality:
2025-07-29 11:46:05,609 - INFO -     - accuracy: 0.8321
2025-07-29 11:46:05,609 - INFO -   mmlu_professional_psychology:
2025-07-29 11:46:05,609 - INFO -     - accuracy: 0.7827
2025-07-29 11:46:05,609 - INFO -   mmlu_public_relations:
2025-07-29 11:46:05,609 - INFO -     - accuracy: 0.7091
2025-07-29 11:46:05,609 - INFO -   mmlu_security_studies:
2025-07-29 11:46:05,609 - INFO -     - accuracy: 0.7918
2025-07-29 11:46:05,610 - INFO -   mmlu_sociology:
2025-07-29 11:46:05,610 - INFO -     - accuracy: 0.8657
2025-07-29 11:46:05,610 - INFO -   mmlu_us_foreign_policy:
2025-07-29 11:46:05,610 - INFO -     - accuracy: 0.8400
2025-07-29 11:46:05,610 - INFO -   mmlu_stem:
2025-07-29 11:46:05,610 - INFO -     - accuracy: 0.7571
2025-07-29 11:46:05,610 - INFO -   mmlu_abstract_algebra:
2025-07-29 11:46:05,610 - INFO -     - accuracy: 0.5800
2025-07-29 11:46:05,610 - INFO -   mmlu_anatomy:
2025-07-29 11:46:05,611 - INFO -     - accuracy: 0.7037
2025-07-29 11:46:05,611 - INFO -   mmlu_astronomy:
2025-07-29 11:46:05,611 - INFO -     - accuracy: 0.9013
2025-07-29 11:46:05,611 - INFO -   mmlu_college_biology:
2025-07-29 11:46:05,611 - INFO -     - accuracy: 0.8889
2025-07-29 11:46:05,611 - INFO -   mmlu_college_chemistry:
2025-07-29 11:46:05,611 - INFO -     - accuracy: 0.5600
2025-07-29 11:46:05,611 - INFO -   mmlu_college_computer_science:
2025-07-29 11:46:05,611 - INFO -     - accuracy: 0.7300
2025-07-29 11:46:05,612 - INFO -   mmlu_college_mathematics:
2025-07-29 11:46:05,612 - INFO -     - accuracy: 0.5900
2025-07-29 11:46:05,612 - INFO -   mmlu_college_physics:
2025-07-29 11:46:05,612 - INFO -     - accuracy: 0.6569
2025-07-29 11:46:05,612 - INFO -   mmlu_computer_security:
2025-07-29 11:46:05,612 - INFO -     - accuracy: 0.8100
2025-07-29 11:46:05,612 - INFO -   mmlu_conceptual_physics:
2025-07-29 11:46:05,612 - INFO -     - accuracy: 0.8553
2025-07-29 11:46:05,612 - INFO -   mmlu_electrical_engineering:
2025-07-29 11:46:05,613 - INFO -     - accuracy: 0.8069
2025-07-29 11:46:05,613 - INFO -   mmlu_elementary_mathematics:
2025-07-29 11:46:05,613 - INFO -     - accuracy: 0.7884
2025-07-29 11:46:05,613 - INFO -   mmlu_high_school_biology:
2025-07-29 11:46:05,613 - INFO -     - accuracy: 0.9129
2025-07-29 11:46:05,613 - INFO -   mmlu_high_school_chemistry:
2025-07-29 11:46:05,613 - INFO -     - accuracy: 0.7586
2025-07-29 11:46:05,613 - INFO -   mmlu_high_school_computer_science:
2025-07-29 11:46:05,613 - INFO -     - accuracy: 0.8600
2025-07-29 11:46:05,614 - INFO -   mmlu_high_school_mathematics:
2025-07-29 11:46:05,614 - INFO -     - accuracy: 0.5407
2025-07-29 11:46:05,614 - INFO -   mmlu_high_school_physics:
2025-07-29 11:46:05,614 - INFO -     - accuracy: 0.7285
2025-07-29 11:46:05,614 - INFO -   mmlu_high_school_statistics:
2025-07-29 11:46:05,614 - INFO -     - accuracy: 0.7824
2025-07-29 11:46:05,614 - INFO -   mmlu_machine_learning:
2025-07-29 11:46:05,614 - INFO -     - accuracy: 0.6161
2025-07-29 11:46:05,615 - INFO - ============================================================

2025-07-29 11:46:05,663 - INFO - Qwen3-8B_harness_5: Processing task 8/10: arc_challenge
2025-07-29 11:46:05,673 - INFO - Qwen3-8B_harness_5: Task 'arc_challenge' will use num_fewshot=5
2025-07-29 11:46:05,799 - INFO - Qwen3-8B_harness_5: Evaluating task 'arc_challenge' with num_fewshot=5
2025-07-29 11:46:05,800 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 11:46:16,671 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 5
2025-07-29 11:49:24,448 - INFO - Qwen3-8B_harness_5: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-29 11:49:24,602 - INFO - 
============================================================
2025-07-29 11:49:24,602 - INFO - Task 'arc_challenge' Results:
2025-07-29 11:49:24,602 - INFO - ============================================================
2025-07-29 11:49:24,602 - INFO -   arc_challenge:
2025-07-29 11:49:24,602 - INFO -     - accuracy: 0.6485
2025-07-29 11:49:24,603 - INFO -     - accuracy_norm: 0.6621
2025-07-29 11:49:24,603 - INFO - ============================================================

2025-07-29 11:49:24,640 - INFO - Qwen3-8B_harness_5: Processing task 9/10: arc_easy
2025-07-29 11:49:24,642 - INFO - Qwen3-8B_harness_5: Task 'arc_easy' will use num_fewshot=5
2025-07-29 11:49:24,768 - INFO - Qwen3-8B_harness_5: Evaluating task 'arc_easy' with num_fewshot=5
2025-07-29 11:49:24,768 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 11:49:35,331 - WARNING - Overwriting default num_fewshot of arc_easy from None to 5
2025-07-29 11:55:27,718 - INFO - Qwen3-8B_harness_5: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-29 11:55:27,866 - INFO - 
============================================================
2025-07-29 11:55:27,866 - INFO - Task 'arc_easy' Results:
2025-07-29 11:55:27,866 - INFO - ============================================================
2025-07-29 11:55:27,866 - INFO -   arc_easy:
2025-07-29 11:55:27,866 - INFO -     - accuracy: 0.8742
2025-07-29 11:55:27,867 - INFO -     - accuracy_norm: 0.8712
2025-07-29 11:55:27,867 - INFO - ============================================================

2025-07-29 11:55:27,909 - INFO - Qwen3-8B_harness_5: Processing task 10/10: hellaswag
2025-07-29 11:55:27,913 - INFO - Qwen3-8B_harness_5: Task 'hellaswag' will use num_fewshot=5
2025-07-29 11:55:28,040 - INFO - Qwen3-8B_harness_5: Evaluating task 'hellaswag' with num_fewshot=5
2025-07-29 11:55:28,041 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 11:55:45,502 - WARNING - Overwriting default num_fewshot of hellaswag from None to 5
2025-07-29 12:37:20,934 - INFO - Qwen3-8B_harness_5: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-29 12:37:21,081 - INFO - 
============================================================
2025-07-29 12:37:21,081 - INFO - Task 'hellaswag' Results:
2025-07-29 12:37:21,081 - INFO - ============================================================
2025-07-29 12:37:21,081 - INFO -   hellaswag:
2025-07-29 12:37:21,081 - INFO -     - accuracy: 0.5770
2025-07-29 12:37:21,081 - INFO -     - accuracy_norm: 0.7595
2025-07-29 12:37:21,082 - INFO - ============================================================

2025-07-29 12:37:21,124 - INFO - Qwen3-8B_harness_5: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-29 12:37:21,128 - INFO - [Process 1941996] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250729_041113/model_results/Qwen3-8B/Qwen3-8B_harness_5.json
2025-07-29 12:37:21,130 - INFO - [Process 1941996] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Qwen3-8B/Qwen3-8B_harness_5.json
2025-07-29 12:37:21,425 - INFO - Results uploaded to WandB as artifact
2025-07-29 12:37:21,434 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-29 12:37:21,436 - INFO - [Process 1941996] Successfully completed Qwen3-8B_harness_5
2025-07-29 12:37:23,913 - INFO - Run Qwen3-8B_harness_5 finished successfully
2025-07-29 12:37:23,914 - INFO - [Process 1941996] Llama-DNA-1.0-8B-Instruct_harness_6 assigned to cuda:0
2025-07-29 12:37:23,914 - INFO - [Process 1941996] Llama-DNA-1.0-8B-Instruct_harness_6 - full_run: True, limit: None (full dataset)
2025-07-29 12:37:25,316 - INFO - WandB run initialized: Llama-DNA-1.0-8B-Instruct_20250729_123723 (ID: 03094734)
2025-07-29 12:37:25,619 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 1/10: kmmlu
2025-07-29 12:37:25,620 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kmmlu' will use num_fewshot=5
2025-07-29 12:37:25,748 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-29 12:37:25,749 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 12:38:37,562 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-29 12:38:37,562 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-29 12:38:37,562 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-29 12:38:37,562 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-29 12:38:37,563 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-29 12:38:37,564 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-29 12:38:37,565 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-29 12:38:37,566 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-29 12:38:37,566 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-29 12:38:37,566 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-29 12:38:37,566 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-29 12:38:37,566 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-29 12:38:37,566 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-29 13:25:07,313 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-29 13:25:07,478 - INFO - 
============================================================
2025-07-29 13:25:07,479 - INFO - Task 'kmmlu' Results:
2025-07-29 13:25:07,479 - INFO - ============================================================
2025-07-29 13:25:07,479 - INFO -   kmmlu:
2025-07-29 13:25:07,479 - INFO -     - accuracy: 0.5321
2025-07-29 13:25:07,479 - INFO -   kmmlu_applied_science:
2025-07-29 13:25:07,479 - INFO -     - accuracy: 0.5161
2025-07-29 13:25:07,479 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-29 13:25:07,479 - INFO -     - accuracy: 0.5120
2025-07-29 13:25:07,480 - INFO -   kmmlu_electronics_engineering:
2025-07-29 13:25:07,480 - INFO -     - accuracy: 0.6100
2025-07-29 13:25:07,480 - INFO -   kmmlu_energy_management:
2025-07-29 13:25:07,480 - INFO -     - accuracy: 0.4130
2025-07-29 13:25:07,480 - INFO -   kmmlu_environmental_science:
2025-07-29 13:25:07,480 - INFO -     - accuracy: 0.4290
2025-07-29 13:25:07,480 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-29 13:25:07,480 - INFO -     - accuracy: 0.4280
2025-07-29 13:25:07,481 - INFO -   kmmlu_geomatics:
2025-07-29 13:25:07,481 - INFO -     - accuracy: 0.4800
2025-07-29 13:25:07,481 - INFO -   kmmlu_industrial_engineer:
2025-07-29 13:25:07,481 - INFO -     - accuracy: 0.5130
2025-07-29 13:25:07,481 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-29 13:25:07,481 - INFO -     - accuracy: 0.5860
2025-07-29 13:25:07,481 - INFO -   kmmlu_maritime_engineering:
2025-07-29 13:25:07,481 - INFO -     - accuracy: 0.5250
2025-07-29 13:25:07,481 - INFO -   kmmlu_nondestructive_testing:
2025-07-29 13:25:07,482 - INFO -     - accuracy: 0.5700
2025-07-29 13:25:07,482 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-29 13:25:07,482 - INFO -     - accuracy: 0.4610
2025-07-29 13:25:07,482 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-29 13:25:07,482 - INFO -     - accuracy: 0.6700
2025-07-29 13:25:07,482 - INFO -   kmmlu_humss:
2025-07-29 13:25:07,482 - INFO -     - accuracy: 0.5164
2025-07-29 13:25:07,482 - INFO -   kmmlu_accounting:
2025-07-29 13:25:07,482 - INFO -     - accuracy: 0.5200
2025-07-29 13:25:07,483 - INFO -   kmmlu_criminal_law:
2025-07-29 13:25:07,483 - INFO -     - accuracy: 0.3500
2025-07-29 13:25:07,483 - INFO -   kmmlu_economics:
2025-07-29 13:25:07,483 - INFO -     - accuracy: 0.4769
2025-07-29 13:25:07,483 - INFO -   kmmlu_education:
2025-07-29 13:25:07,483 - INFO -     - accuracy: 0.6000
2025-07-29 13:25:07,483 - INFO -   kmmlu_korean_history:
2025-07-29 13:25:07,483 - INFO -     - accuracy: 0.3600
2025-07-29 13:25:07,483 - INFO -   kmmlu_law:
2025-07-29 13:25:07,484 - INFO -     - accuracy: 0.4760
2025-07-29 13:25:07,484 - INFO -   kmmlu_management:
2025-07-29 13:25:07,484 - INFO -     - accuracy: 0.5610
2025-07-29 13:25:07,484 - INFO -   kmmlu_political_science_and_sociology:
2025-07-29 13:25:07,484 - INFO -     - accuracy: 0.5400
2025-07-29 13:25:07,484 - INFO -   kmmlu_psychology:
2025-07-29 13:25:07,484 - INFO -     - accuracy: 0.4820
2025-07-29 13:25:07,484 - INFO -   kmmlu_social_welfare:
2025-07-29 13:25:07,484 - INFO -     - accuracy: 0.6030
2025-07-29 13:25:07,485 - INFO -   kmmlu_taxation:
2025-07-29 13:25:07,485 - INFO -     - accuracy: 0.4250
2025-07-29 13:25:07,485 - INFO -   kmmlu_other:
2025-07-29 13:25:07,485 - INFO -     - accuracy: 0.5382
2025-07-29 13:25:07,485 - INFO -   kmmlu_agricultural_sciences:
2025-07-29 13:25:07,485 - INFO -     - accuracy: 0.4500
2025-07-29 13:25:07,485 - INFO -   kmmlu_construction:
2025-07-29 13:25:07,485 - INFO -     - accuracy: 0.4600
2025-07-29 13:25:07,486 - INFO -   kmmlu_fashion:
2025-07-29 13:25:07,486 - INFO -     - accuracy: 0.4740
2025-07-29 13:25:07,486 - INFO -   kmmlu_food_processing:
2025-07-29 13:25:07,486 - INFO -     - accuracy: 0.5090
2025-07-29 13:25:07,486 - INFO -   kmmlu_health:
2025-07-29 13:25:07,486 - INFO -     - accuracy: 0.6400
2025-07-29 13:25:07,486 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-29 13:25:07,486 - INFO -     - accuracy: 0.6870
2025-07-29 13:25:07,486 - INFO -   kmmlu_marketing:
2025-07-29 13:25:07,487 - INFO -     - accuracy: 0.7740
2025-07-29 13:25:07,487 - INFO -   kmmlu_patent:
2025-07-29 13:25:07,487 - INFO -     - accuracy: 0.3800
2025-07-29 13:25:07,487 - INFO -   kmmlu_public_safety:
2025-07-29 13:25:07,487 - INFO -     - accuracy: 0.4960
2025-07-29 13:25:07,487 - INFO -   kmmlu_real_estate:
2025-07-29 13:25:07,487 - INFO -     - accuracy: 0.4800
2025-07-29 13:25:07,487 - INFO -   kmmlu_refrigerating_machinery:
2025-07-29 13:25:07,487 - INFO -     - accuracy: 0.4730
2025-07-29 13:25:07,488 - INFO -   kmmlu_stem:
2025-07-29 13:25:07,488 - INFO -     - accuracy: 0.5538
2025-07-29 13:25:07,488 - INFO -   kmmlu_biology:
2025-07-29 13:25:07,488 - INFO -     - accuracy: 0.4820
2025-07-29 13:25:07,488 - INFO -   kmmlu_chemical_engineering:
2025-07-29 13:25:07,488 - INFO -     - accuracy: 0.4930
2025-07-29 13:25:07,488 - INFO -   kmmlu_chemistry:
2025-07-29 13:25:07,488 - INFO -     - accuracy: 0.4933
2025-07-29 13:25:07,489 - INFO -   kmmlu_civil_engineering:
2025-07-29 13:25:07,589 - INFO -     - accuracy: 0.5200
2025-07-29 13:25:07,590 - INFO -   kmmlu_computer_science:
2025-07-29 13:25:07,590 - INFO -     - accuracy: 0.7840
2025-07-29 13:25:07,590 - INFO -   kmmlu_ecology:
2025-07-29 13:25:07,590 - INFO -     - accuracy: 0.5890
2025-07-29 13:25:07,590 - INFO -   kmmlu_electrical_engineering:
2025-07-29 13:25:07,590 - INFO -     - accuracy: 0.4490
2025-07-29 13:25:07,590 - INFO -   kmmlu_information_technology:
2025-07-29 13:25:07,590 - INFO -     - accuracy: 0.7190
2025-07-29 13:25:07,591 - INFO -   kmmlu_materials_engineering:
2025-07-29 13:25:07,591 - INFO -     - accuracy: 0.5660
2025-07-29 13:25:07,591 - INFO -   kmmlu_math:
2025-07-29 13:25:07,591 - INFO -     - accuracy: 0.2800
2025-07-29 13:25:07,591 - INFO -   kmmlu_mechanical_engineering:
2025-07-29 13:25:07,591 - INFO -     - accuracy: 0.5010
2025-07-29 13:25:07,591 - INFO - ============================================================

2025-07-29 13:25:07,635 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 2/10: kmmlu_hard
2025-07-29 13:25:07,642 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-29 13:25:07,772 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-29 13:25:07,773 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 13:26:30,440 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-29 13:26:30,441 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-29 13:26:30,441 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-29 13:26:30,441 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-29 13:26:30,441 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-29 13:26:30,441 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-29 13:26:30,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-29 13:26:30,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-29 13:26:30,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-29 13:26:30,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-29 13:26:30,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-29 13:26:30,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-29 13:26:30,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-29 13:26:30,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-29 13:32:29,754 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-29 13:32:29,900 - INFO - 
============================================================
2025-07-29 13:32:29,900 - INFO - Task 'kmmlu_hard' Results:
2025-07-29 13:32:29,900 - INFO - ============================================================
2025-07-29 13:32:29,901 - INFO -   kmmlu_hard:
2025-07-29 13:32:29,901 - INFO -     - accuracy: 0.2951
2025-07-29 13:32:29,901 - INFO -   kmmlu_hard_applied_science:
2025-07-29 13:32:29,901 - INFO -     - accuracy: 0.3017
2025-07-29 13:32:29,901 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-29 13:32:29,901 - INFO -     - accuracy: 0.3000
2025-07-29 13:32:29,901 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-29 13:32:29,902 - INFO -     - accuracy: 0.3100
2025-07-29 13:32:29,902 - INFO -   kmmlu_hard_energy_management:
2025-07-29 13:32:29,902 - INFO -     - accuracy: 0.2300
2025-07-29 13:32:29,902 - INFO -   kmmlu_hard_environmental_science:
2025-07-29 13:32:29,902 - INFO -     - accuracy: 0.3200
2025-07-29 13:32:29,902 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-29 13:32:29,902 - INFO -     - accuracy: 0.2800
2025-07-29 13:32:29,902 - INFO -   kmmlu_hard_geomatics:
2025-07-29 13:32:29,903 - INFO -     - accuracy: 0.3100
2025-07-29 13:32:29,903 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-29 13:32:29,903 - INFO -     - accuracy: 0.2500
2025-07-29 13:32:29,903 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-29 13:32:29,903 - INFO -     - accuracy: 0.3500
2025-07-29 13:32:29,903 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-29 13:32:29,903 - INFO -     - accuracy: 0.3300
2025-07-29 13:32:29,903 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-29 13:32:29,903 - INFO -     - accuracy: 0.3000
2025-07-29 13:32:29,904 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-29 13:32:29,904 - INFO -     - accuracy: 0.2400
2025-07-29 13:32:29,904 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-29 13:32:29,904 - INFO -     - accuracy: 0.4000
2025-07-29 13:32:29,904 - INFO -   kmmlu_hard_humss:
2025-07-29 13:32:29,904 - INFO -     - accuracy: 0.2449
2025-07-29 13:32:29,904 - INFO -   kmmlu_hard_accounting:
2025-07-29 13:32:29,904 - INFO -     - accuracy: 0.3261
2025-07-29 13:32:29,904 - INFO -   kmmlu_hard_criminal_law:
2025-07-29 13:32:29,905 - INFO -     - accuracy: 0.1500
2025-07-29 13:32:29,905 - INFO -   kmmlu_hard_economics:
2025-07-29 13:32:29,905 - INFO -     - accuracy: 0.1905
2025-07-29 13:32:29,905 - INFO -   kmmlu_hard_education:
2025-07-29 13:32:29,905 - INFO -     - accuracy: 0.2609
2025-07-29 13:32:29,905 - INFO -   kmmlu_hard_korean_history:
2025-07-29 13:32:29,905 - INFO -     - accuracy: 0.1364
2025-07-29 13:32:29,905 - INFO -   kmmlu_hard_law:
2025-07-29 13:32:29,905 - INFO -     - accuracy: 0.2500
2025-07-29 13:32:29,906 - INFO -   kmmlu_hard_management:
2025-07-29 13:32:29,906 - INFO -     - accuracy: 0.2500
2025-07-29 13:32:29,906 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-29 13:32:29,906 - INFO -     - accuracy: 0.2778
2025-07-29 13:32:29,906 - INFO -   kmmlu_hard_psychology:
2025-07-29 13:32:29,906 - INFO -     - accuracy: 0.2800
2025-07-29 13:32:29,906 - INFO -   kmmlu_hard_social_welfare:
2025-07-29 13:32:29,906 - INFO -     - accuracy: 0.2500
2025-07-29 13:32:29,907 - INFO -   kmmlu_hard_taxation:
2025-07-29 13:32:29,907 - INFO -     - accuracy: 0.2917
2025-07-29 13:32:29,907 - INFO -   kmmlu_hard_other:
2025-07-29 13:32:29,907 - INFO -     - accuracy: 0.2887
2025-07-29 13:32:29,907 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-29 13:32:29,907 - INFO -     - accuracy: 0.3300
2025-07-29 13:32:29,907 - INFO -   kmmlu_hard_construction:
2025-07-29 13:32:29,907 - INFO -     - accuracy: 0.3100
2025-07-29 13:32:29,907 - INFO -   kmmlu_hard_fashion:
2025-07-29 13:32:29,908 - INFO -     - accuracy: 0.2300
2025-07-29 13:32:29,908 - INFO -   kmmlu_hard_food_processing:
2025-07-29 13:32:29,908 - INFO -     - accuracy: 0.3200
2025-07-29 13:32:29,908 - INFO -   kmmlu_hard_health:
2025-07-29 13:32:29,908 - INFO -     - accuracy: 0.2609
2025-07-29 13:32:29,908 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-29 13:32:29,908 - INFO -     - accuracy: 0.4200
2025-07-29 13:32:29,908 - INFO -   kmmlu_hard_marketing:
2025-07-29 13:32:29,908 - INFO -     - accuracy: 0.2700
2025-07-29 13:32:29,909 - INFO -   kmmlu_hard_patent:
2025-07-29 13:32:29,909 - INFO -     - accuracy: 0.2157
2025-07-29 13:32:29,909 - INFO -   kmmlu_hard_public_safety:
2025-07-29 13:32:29,909 - INFO -     - accuracy: 0.2200
2025-07-29 13:32:29,909 - INFO -   kmmlu_hard_real_estate:
2025-07-29 13:32:29,909 - INFO -     - accuracy: 0.2360
2025-07-29 13:32:29,909 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-29 13:32:29,909 - INFO -     - accuracy: 0.3000
2025-07-29 13:32:29,909 - INFO -   kmmlu_hard_stem:
2025-07-29 13:32:29,910 - INFO -     - accuracy: 0.3318
2025-07-29 13:32:29,910 - INFO -   kmmlu_hard_biology:
2025-07-29 13:32:29,910 - INFO -     - accuracy: 0.4000
2025-07-29 13:32:29,910 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-29 13:32:29,910 - INFO -     - accuracy: 0.2600
2025-07-29 13:32:29,910 - INFO -   kmmlu_hard_chemistry:
2025-07-29 13:32:29,910 - INFO -     - accuracy: 0.1800
2025-07-29 13:32:29,910 - INFO -   kmmlu_hard_civil_engineering:
2025-07-29 13:32:29,910 - INFO -     - accuracy: 0.3500
2025-07-29 13:32:29,911 - INFO -   kmmlu_hard_computer_science:
2025-07-29 13:32:29,911 - INFO -     - accuracy: 0.4600
2025-07-29 13:32:29,911 - INFO -   kmmlu_hard_ecology:
2025-07-29 13:32:29,911 - INFO -     - accuracy: 0.2900
2025-07-29 13:32:29,911 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-29 13:32:29,911 - INFO -     - accuracy: 0.3900
2025-07-29 13:32:29,911 - INFO -   kmmlu_hard_information_technology:
2025-07-29 13:32:29,911 - INFO -     - accuracy: 0.3500
2025-07-29 13:32:29,911 - INFO -   kmmlu_hard_materials_engineering:
2025-07-29 13:32:29,912 - INFO -     - accuracy: 0.3200
2025-07-29 13:32:29,912 - INFO -   kmmlu_hard_math:
2025-07-29 13:32:29,912 - INFO -     - accuracy: 0.3200
2025-07-29 13:32:29,912 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-29 13:32:29,912 - INFO -     - accuracy: 0.3300
2025-07-29 13:32:29,912 - INFO - ============================================================

2025-07-29 13:32:29,954 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 3/10: haerae
2025-07-29 13:32:29,957 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'haerae' will use num_fewshot=5
2025-07-29 13:32:30,084 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'haerae' with num_fewshot=5
2025-07-29 13:32:30,085 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 13:32:49,906 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-29 13:32:49,907 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-29 13:32:49,907 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-29 13:32:49,907 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-29 13:32:49,907 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-29 13:38:53,105 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'haerae' with 6 subtasks
2025-07-29 13:38:53,256 - INFO - 
============================================================
2025-07-29 13:38:53,256 - INFO - Task 'haerae' Results:
2025-07-29 13:38:53,256 - INFO - ============================================================
2025-07-29 13:38:53,256 - INFO -   haerae:
2025-07-29 13:38:53,256 - INFO -     - accuracy: 0.6609
2025-07-29 13:38:53,256 - INFO -     - accuracy_norm: 0.6609
2025-07-29 13:38:53,256 - INFO -   haerae_general_knowledge:
2025-07-29 13:38:53,257 - INFO -     - accuracy: 0.4318
2025-07-29 13:38:53,257 - INFO -     - accuracy_norm: 0.4318
2025-07-29 13:38:53,257 - INFO -   haerae_history:
2025-07-29 13:38:53,257 - INFO -     - accuracy: 0.6170
2025-07-29 13:38:53,257 - INFO -     - accuracy_norm: 0.6170
2025-07-29 13:38:53,257 - INFO -   haerae_loan_word:
2025-07-29 13:38:53,257 - INFO -     - accuracy: 0.7574
2025-07-29 13:38:53,257 - INFO -     - accuracy_norm: 0.7574
2025-07-29 13:38:53,258 - INFO -   haerae_rare_word:
2025-07-29 13:38:53,258 - INFO -     - accuracy: 0.7136
2025-07-29 13:38:53,258 - INFO -     - accuracy_norm: 0.7136
2025-07-29 13:38:53,258 - INFO -   haerae_standard_nomenclature:
2025-07-29 13:38:53,258 - INFO -     - accuracy: 0.7320
2025-07-29 13:38:53,258 - INFO -     - accuracy_norm: 0.7320
2025-07-29 13:38:53,258 - INFO - ============================================================

2025-07-29 13:38:53,297 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 4/10: kobest
2025-07-29 13:38:53,301 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kobest' will use num_fewshot=5
2025-07-29 13:38:53,428 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kobest' with num_fewshot=5
2025-07-29 13:38:53,429 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 13:39:15,624 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-29 13:39:15,624 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-29 13:39:15,624 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-29 13:39:15,625 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-29 13:39:15,625 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-29 13:49:44,601 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kobest' with 6 subtasks
2025-07-29 13:49:44,752 - INFO - 
============================================================
2025-07-29 13:49:44,753 - INFO - Task 'kobest' Results:
2025-07-29 13:49:44,753 - INFO - ============================================================
2025-07-29 13:49:44,753 - INFO -   kobest:
2025-07-29 13:49:44,753 - INFO -     - accuracy: 0.8312
2025-07-29 13:49:44,753 - INFO -     - accuracy_norm: 0.6180
2025-07-29 13:49:44,753 - INFO -     - f1: 0.8304
2025-07-29 13:49:44,753 - INFO -   kobest_boolq:
2025-07-29 13:49:44,753 - INFO -     - accuracy: 0.9195
2025-07-29 13:49:44,754 - INFO -     - f1: 0.9194
2025-07-29 13:49:44,754 - INFO -   kobest_copa:
2025-07-29 13:49:44,754 - INFO -     - accuracy: 0.8310
2025-07-29 13:49:44,754 - INFO -     - f1: 0.8309
2025-07-29 13:49:44,754 - INFO -   kobest_hellaswag:
2025-07-29 13:49:44,754 - INFO -     - accuracy: 0.5060
2025-07-29 13:49:44,754 - INFO -     - accuracy_norm: 0.6180
2025-07-29 13:49:44,754 - INFO -     - f1: 0.5007
2025-07-29 13:49:44,754 - INFO -   kobest_sentineg:
2025-07-29 13:49:44,755 - INFO -     - accuracy: 0.9521
2025-07-29 13:49:44,755 - INFO -     - f1: 0.9521
2025-07-29 13:49:44,755 - INFO -   kobest_wic:
2025-07-29 13:49:44,755 - INFO -     - accuracy: 0.8238
2025-07-29 13:49:44,755 - INFO -     - f1: 0.8233
2025-07-29 13:49:44,755 - INFO - ============================================================

2025-07-29 13:49:44,796 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 5/10: csatqa
2025-07-29 13:49:44,798 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'csatqa' detected as zero-shot task
2025-07-29 13:49:44,925 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'csatqa' with num_fewshot=0
2025-07-29 13:49:44,925 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 13:50:00,947 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-29 13:50:00,947 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-29 13:50:00,948 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-29 13:50:00,948 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-29 13:50:00,948 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-29 13:50:00,948 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-29 13:52:10,594 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'csatqa' with 7 subtasks
2025-07-29 13:52:10,736 - INFO - 
============================================================
2025-07-29 13:52:10,736 - INFO - Task 'csatqa' Results:
2025-07-29 13:52:10,737 - INFO - ============================================================
2025-07-29 13:52:10,737 - INFO -   csatqa:
2025-07-29 13:52:10,737 - INFO -     - accuracy: 0.4225
2025-07-29 13:52:10,737 - INFO -     - accuracy_norm: 0.4225
2025-07-29 13:52:10,737 - INFO -   csatqa_gr:
2025-07-29 13:52:10,737 - INFO -     - accuracy: 0.2000
2025-07-29 13:52:10,737 - INFO -     - accuracy_norm: 0.2000
2025-07-29 13:52:10,737 - INFO -   csatqa_li:
2025-07-29 13:52:10,738 - INFO -     - accuracy: 0.4595
2025-07-29 13:52:10,738 - INFO -     - accuracy_norm: 0.4595
2025-07-29 13:52:10,738 - INFO -   csatqa_rch:
2025-07-29 13:52:10,738 - INFO -     - accuracy: 0.5714
2025-07-29 13:52:10,738 - INFO -     - accuracy_norm: 0.5714
2025-07-29 13:52:10,738 - INFO -   csatqa_rcs:
2025-07-29 13:52:10,738 - INFO -     - accuracy: 0.4054
2025-07-29 13:52:10,738 - INFO -     - accuracy_norm: 0.4054
2025-07-29 13:52:10,738 - INFO -   csatqa_rcss:
2025-07-29 13:52:10,739 - INFO -     - accuracy: 0.4524
2025-07-29 13:52:10,739 - INFO -     - accuracy_norm: 0.4524
2025-07-29 13:52:10,739 - INFO -   csatqa_wr:
2025-07-29 13:52:10,739 - INFO -     - accuracy: 0.2727
2025-07-29 13:52:10,739 - INFO -     - accuracy_norm: 0.2727
2025-07-29 13:52:10,739 - INFO - ============================================================

2025-07-29 13:52:10,782 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 6/10: kormedmcqa
2025-07-29 13:52:10,785 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'kormedmcqa' will use num_fewshot=5
2025-07-29 13:52:10,913 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-29 13:52:10,913 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 13:52:31,488 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-29 13:52:31,489 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-29 13:52:31,489 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-29 13:52:31,489 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
2025-07-29 13:58:34,178 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-29 13:58:34,332 - INFO - 
============================================================
2025-07-29 13:58:34,332 - INFO - Task 'kormedmcqa' Results:
2025-07-29 13:58:34,333 - INFO - ============================================================
2025-07-29 13:58:34,333 - INFO -   kormedmcqa:
2025-07-29 13:58:34,333 - INFO -     - exact_match: 0.5424
2025-07-29 13:58:34,333 - INFO -   kormedmcqa_dentist:
2025-07-29 13:58:34,333 - INFO -     - exact_match: 0.4575
2025-07-29 13:58:34,333 - INFO -   kormedmcqa_doctor:
2025-07-29 13:58:34,333 - INFO -     - exact_match: 0.4069
2025-07-29 13:58:34,334 - INFO -   kormedmcqa_nurse:
2025-07-29 13:58:34,334 - INFO -     - exact_match: 0.6412
2025-07-29 13:58:34,334 - INFO -   kormedmcqa_pharm:
2025-07-29 13:58:34,334 - INFO -     - exact_match: 0.5887
2025-07-29 13:58:34,334 - INFO - ============================================================

2025-07-29 13:58:34,373 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 7/10: mmlu
2025-07-29 13:58:34,375 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'mmlu' will use num_fewshot=5
2025-07-29 13:58:34,504 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'mmlu' with num_fewshot=5
2025-07-29 13:58:34,505 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 14:01:21,486 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5
2025-07-29 14:01:21,486 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5
2025-07-29 14:01:21,486 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 5
2025-07-29 14:01:21,487 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5
2025-07-29 14:01:21,487 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5
2025-07-29 14:01:21,487 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 5
2025-07-29 14:01:21,487 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 5
2025-07-29 14:01:21,487 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5
2025-07-29 14:01:21,487 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 5
2025-07-29 14:01:21,487 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 5
2025-07-29 14:01:21,487 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 5
2025-07-29 14:01:21,487 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 5
2025-07-29 14:01:21,487 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 5
2025-07-29 14:01:21,488 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5
2025-07-29 14:01:21,489 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 5
2025-07-29 14:01:21,490 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5
2025-07-29 14:01:21,491 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5
2025-07-29 14:01:21,491 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 5
2025-07-29 14:01:21,491 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 5
2025-07-29 14:01:21,491 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5
2025-07-29 14:01:21,491 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 5
2025-07-29 14:01:21,491 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 5
2025-07-29 14:01:21,491 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5
2025-07-29 14:01:21,491 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 5
2025-07-29 14:01:21,491 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 5
2025-07-29 14:01:21,491 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5
2025-07-29 14:23:40,904 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'mmlu' with 62 subtasks
2025-07-29 14:23:41,054 - INFO - 
============================================================
2025-07-29 14:23:41,054 - INFO - Task 'mmlu' Results:
2025-07-29 14:23:41,055 - INFO - ============================================================
2025-07-29 14:23:41,055 - INFO -   mmlu:
2025-07-29 14:23:41,055 - INFO -     - accuracy: 0.6654
2025-07-29 14:23:41,055 - INFO -   mmlu_humanities:
2025-07-29 14:23:41,055 - INFO -     - accuracy: 0.6130
2025-07-29 14:23:41,055 - INFO -   mmlu_formal_logic:
2025-07-29 14:23:41,055 - INFO -     - accuracy: 0.4921
2025-07-29 14:23:41,055 - INFO -   mmlu_high_school_european_history:
2025-07-29 14:23:41,056 - INFO -     - accuracy: 0.7818
2025-07-29 14:23:41,056 - INFO -   mmlu_high_school_us_history:
2025-07-29 14:23:41,056 - INFO -     - accuracy: 0.8284
2025-07-29 14:23:41,056 - INFO -   mmlu_high_school_world_history:
2025-07-29 14:23:41,056 - INFO -     - accuracy: 0.8692
2025-07-29 14:23:41,056 - INFO -   mmlu_international_law:
2025-07-29 14:23:41,056 - INFO -     - accuracy: 0.7934
2025-07-29 14:23:41,056 - INFO -   mmlu_jurisprudence:
2025-07-29 14:23:41,057 - INFO -     - accuracy: 0.7870
2025-07-29 14:23:41,057 - INFO -   mmlu_logical_fallacies:
2025-07-29 14:23:41,057 - INFO -     - accuracy: 0.7362
2025-07-29 14:23:41,057 - INFO -   mmlu_moral_disputes:
2025-07-29 14:23:41,057 - INFO -     - accuracy: 0.7052
2025-07-29 14:23:41,057 - INFO -   mmlu_moral_scenarios:
2025-07-29 14:23:41,057 - INFO -     - accuracy: 0.4302
2025-07-29 14:23:41,057 - INFO -   mmlu_philosophy:
2025-07-29 14:23:41,057 - INFO -     - accuracy: 0.7492
2025-07-29 14:23:41,058 - INFO -   mmlu_prehistory:
2025-07-29 14:23:41,058 - INFO -     - accuracy: 0.7377
2025-07-29 14:23:41,058 - INFO -   mmlu_professional_law:
2025-07-29 14:23:41,058 - INFO -     - accuracy: 0.5052
2025-07-29 14:23:41,058 - INFO -   mmlu_world_religions:
2025-07-29 14:23:41,058 - INFO -     - accuracy: 0.8246
2025-07-29 14:23:41,058 - INFO -   mmlu_other:
2025-07-29 14:23:41,058 - INFO -     - accuracy: 0.7197
2025-07-29 14:23:41,059 - INFO -   mmlu_business_ethics:
2025-07-29 14:23:41,059 - INFO -     - accuracy: 0.7200
2025-07-29 14:23:41,059 - INFO -   mmlu_clinical_knowledge:
2025-07-29 14:23:41,059 - INFO -     - accuracy: 0.7396
2025-07-29 14:23:41,059 - INFO -   mmlu_college_medicine:
2025-07-29 14:23:41,059 - INFO -     - accuracy: 0.6879
2025-07-29 14:23:41,059 - INFO -   mmlu_global_facts:
2025-07-29 14:23:41,059 - INFO -     - accuracy: 0.4100
2025-07-29 14:23:41,059 - INFO -   mmlu_human_aging:
2025-07-29 14:23:41,060 - INFO -     - accuracy: 0.6816
2025-07-29 14:23:41,060 - INFO -   mmlu_management:
2025-07-29 14:23:41,060 - INFO -     - accuracy: 0.8155
2025-07-29 14:23:41,060 - INFO -   mmlu_marketing:
2025-07-29 14:23:41,060 - INFO -     - accuracy: 0.8675
2025-07-29 14:23:41,060 - INFO -   mmlu_medical_genetics:
2025-07-29 14:23:41,060 - INFO -     - accuracy: 0.7800
2025-07-29 14:23:41,060 - INFO -   mmlu_miscellaneous:
2025-07-29 14:23:41,060 - INFO -     - accuracy: 0.8238
2025-07-29 14:23:41,061 - INFO -   mmlu_nutrition:
2025-07-29 14:23:41,061 - INFO -     - accuracy: 0.7353
2025-07-29 14:23:41,061 - INFO -   mmlu_professional_accounting:
2025-07-29 14:23:41,061 - INFO -     - accuracy: 0.5106
2025-07-29 14:23:41,061 - INFO -   mmlu_professional_medicine:
2025-07-29 14:23:41,061 - INFO -     - accuracy: 0.7169
2025-07-29 14:23:41,061 - INFO -   mmlu_virology:
2025-07-29 14:23:41,061 - INFO -     - accuracy: 0.4940
2025-07-29 14:23:41,061 - INFO -   mmlu_social_sciences:
2025-07-29 14:23:41,062 - INFO -     - accuracy: 0.7754
2025-07-29 14:23:41,062 - INFO -   mmlu_econometrics:
2025-07-29 14:23:41,062 - INFO -     - accuracy: 0.5877
2025-07-29 14:23:41,062 - INFO -   mmlu_high_school_geography:
2025-07-29 14:23:41,062 - INFO -     - accuracy: 0.8485
2025-07-29 14:23:41,062 - INFO -   mmlu_high_school_government_and_politics:
2025-07-29 14:23:41,062 - INFO -     - accuracy: 0.8912
2025-07-29 14:23:41,062 - INFO -   mmlu_high_school_macroeconomics:
2025-07-29 14:23:41,062 - INFO -     - accuracy: 0.7026
2025-07-29 14:23:41,062 - INFO -   mmlu_high_school_microeconomics:
2025-07-29 14:23:41,063 - INFO -     - accuracy: 0.7395
2025-07-29 14:23:41,063 - INFO -   mmlu_high_school_psychology:
2025-07-29 14:23:41,063 - INFO -     - accuracy: 0.8624
2025-07-29 14:23:41,063 - INFO -   mmlu_human_sexuality:
2025-07-29 14:23:41,063 - INFO -     - accuracy: 0.7557
2025-07-29 14:23:41,063 - INFO -   mmlu_professional_psychology:
2025-07-29 14:23:41,063 - INFO -     - accuracy: 0.7124
2025-07-29 14:23:41,063 - INFO -   mmlu_public_relations:
2025-07-29 14:23:41,063 - INFO -     - accuracy: 0.7273
2025-07-29 14:23:41,064 - INFO -   mmlu_security_studies:
2025-07-29 14:23:41,064 - INFO -     - accuracy: 0.7592
2025-07-29 14:23:41,064 - INFO -   mmlu_sociology:
2025-07-29 14:23:41,064 - INFO -     - accuracy: 0.8607
2025-07-29 14:23:41,064 - INFO -   mmlu_us_foreign_policy:
2025-07-29 14:23:41,064 - INFO -     - accuracy: 0.8500
2025-07-29 14:23:41,064 - INFO -   mmlu_stem:
2025-07-29 14:23:41,064 - INFO -     - accuracy: 0.5829
2025-07-29 14:23:41,064 - INFO -   mmlu_abstract_algebra:
2025-07-29 14:23:41,064 - INFO -     - accuracy: 0.3300
2025-07-29 14:23:41,065 - INFO -   mmlu_anatomy:
2025-07-29 14:23:41,065 - INFO -     - accuracy: 0.5926
2025-07-29 14:23:41,065 - INFO -   mmlu_astronomy:
2025-07-29 14:23:41,065 - INFO -     - accuracy: 0.7829
2025-07-29 14:23:41,065 - INFO -   mmlu_college_biology:
2025-07-29 14:23:41,065 - INFO -     - accuracy: 0.8194
2025-07-29 14:23:41,065 - INFO -   mmlu_college_chemistry:
2025-07-29 14:23:41,065 - INFO -     - accuracy: 0.4900
2025-07-29 14:23:41,066 - INFO -   mmlu_college_computer_science:
2025-07-29 14:23:41,066 - INFO -     - accuracy: 0.5700
2025-07-29 14:23:41,066 - INFO -   mmlu_college_mathematics:
2025-07-29 14:23:41,066 - INFO -     - accuracy: 0.3700
2025-07-29 14:23:41,066 - INFO -   mmlu_college_physics:
2025-07-29 14:23:41,066 - INFO -     - accuracy: 0.4412
2025-07-29 14:23:41,066 - INFO -   mmlu_computer_security:
2025-07-29 14:23:41,066 - INFO -     - accuracy: 0.7100
2025-07-29 14:23:41,066 - INFO -   mmlu_conceptual_physics:
2025-07-29 14:23:41,067 - INFO -     - accuracy: 0.6340
2025-07-29 14:23:41,067 - INFO -   mmlu_electrical_engineering:
2025-07-29 14:23:41,067 - INFO -     - accuracy: 0.5931
2025-07-29 14:23:41,067 - INFO -   mmlu_elementary_mathematics:
2025-07-29 14:23:41,067 - INFO -     - accuracy: 0.4921
2025-07-29 14:23:41,067 - INFO -   mmlu_high_school_biology:
2025-07-29 14:23:41,067 - INFO -     - accuracy: 0.8258
2025-07-29 14:23:41,067 - INFO -   mmlu_high_school_chemistry:
2025-07-29 14:23:41,067 - INFO -     - accuracy: 0.5222
2025-07-29 14:23:41,068 - INFO -   mmlu_high_school_computer_science:
2025-07-29 14:23:41,068 - INFO -     - accuracy: 0.7200
2025-07-29 14:23:41,068 - INFO -   mmlu_high_school_mathematics:
2025-07-29 14:23:41,068 - INFO -     - accuracy: 0.3778
2025-07-29 14:23:41,068 - INFO -   mmlu_high_school_physics:
2025-07-29 14:23:41,068 - INFO -     - accuracy: 0.5033
2025-07-29 14:23:41,068 - INFO -   mmlu_high_school_statistics:
2025-07-29 14:23:41,068 - INFO -     - accuracy: 0.6481
2025-07-29 14:23:41,068 - INFO -   mmlu_machine_learning:
2025-07-29 14:23:41,069 - INFO -     - accuracy: 0.5000
2025-07-29 14:23:41,069 - INFO - ============================================================

2025-07-29 14:23:41,114 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 8/10: arc_challenge
2025-07-29 14:23:41,124 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'arc_challenge' will use num_fewshot=5
2025-07-29 14:23:41,260 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'arc_challenge' with num_fewshot=5
2025-07-29 14:23:41,260 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 14:23:51,759 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 5
2025-07-29 14:26:37,950 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-29 14:26:38,112 - INFO - 
============================================================
2025-07-29 14:26:38,112 - INFO - Task 'arc_challenge' Results:
2025-07-29 14:26:38,112 - INFO - ============================================================
2025-07-29 14:26:38,112 - INFO -   arc_challenge:
2025-07-29 14:26:38,112 - INFO -     - accuracy: 0.6220
2025-07-29 14:26:38,113 - INFO -     - accuracy_norm: 0.6374
2025-07-29 14:26:38,113 - INFO - ============================================================

2025-07-29 14:26:38,150 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 9/10: arc_easy
2025-07-29 14:26:38,152 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'arc_easy' will use num_fewshot=5
2025-07-29 14:26:38,279 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'arc_easy' with num_fewshot=5
2025-07-29 14:26:38,279 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 14:26:49,018 - WARNING - Overwriting default num_fewshot of arc_easy from None to 5
2025-07-29 14:31:48,555 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-29 14:31:48,705 - INFO - 
============================================================
2025-07-29 14:31:48,705 - INFO - Task 'arc_easy' Results:
2025-07-29 14:31:48,705 - INFO - ============================================================
2025-07-29 14:31:48,705 - INFO -   arc_easy:
2025-07-29 14:31:48,705 - INFO -     - accuracy: 0.8737
2025-07-29 14:31:48,705 - INFO -     - accuracy_norm: 0.8674
2025-07-29 14:31:48,706 - INFO - ============================================================

2025-07-29 14:31:48,744 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Processing task 10/10: hellaswag
2025-07-29 14:31:48,745 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Task 'hellaswag' will use num_fewshot=5
2025-07-29 14:31:48,873 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Evaluating task 'hellaswag' with num_fewshot=5
2025-07-29 14:31:48,873 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 14:32:05,158 - WARNING - Overwriting default num_fewshot of hellaswag from None to 5
2025-07-29 15:10:53,438 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-29 15:10:53,601 - INFO - 
============================================================
2025-07-29 15:10:53,601 - INFO - Task 'hellaswag' Results:
2025-07-29 15:10:53,601 - INFO - ============================================================
2025-07-29 15:10:53,601 - INFO -   hellaswag:
2025-07-29 15:10:53,602 - INFO -     - accuracy: 0.6250
2025-07-29 15:10:53,602 - INFO -     - accuracy_norm: 0.8086
2025-07-29 15:10:53,602 - INFO - ============================================================

2025-07-29 15:10:53,644 - INFO - Llama-DNA-1.0-8B-Instruct_harness_6: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-29 15:10:53,648 - INFO - [Process 1941996] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250729_041113/model_results/Llama-DNA-1.0-8B-Instruct/Llama-DNA-1.0-8B-Instruct_harness_6.json
2025-07-29 15:10:53,650 - INFO - [Process 1941996] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/Llama-DNA-1.0-8B-Instruct/Llama-DNA-1.0-8B-Instruct_harness_6.json
2025-07-29 15:10:53,921 - INFO - Results uploaded to WandB as artifact
2025-07-29 15:10:53,931 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-29 15:10:53,932 - INFO - [Process 1941996] Successfully completed Llama-DNA-1.0-8B-Instruct_harness_6
2025-07-29 15:10:56,293 - INFO - Run Llama-DNA-1.0-8B-Instruct_harness_6 finished successfully
2025-07-29 15:10:56,294 - INFO - Processing 6 small models in parallel
2025-07-29 15:11:01,282 - INFO - [Process 2120894] gemma-3-4b-it_harness_2 assigned to cuda:0
2025-07-29 15:11:01,283 - INFO - [Process 2120894] gemma-3-4b-it_harness_2 - full_run: True, limit: None (full dataset)
2025-07-29 15:11:03,029 - INFO - WandB run initialized: gemma-3-4b-it_20250729_151101 (ID: 03c308d0)
2025-07-29 15:11:05,237 - INFO - gemma-3-4b-it_harness_2: Gemma settings applied - max_gen_toks=256
2025-07-29 15:11:05,238 - INFO - gemma-3-4b-it_harness_2: Gemma model detected, adjusting settings
2025-07-29 15:11:05,238 - INFO - gemma-3-4b-it_harness_2: Processing task 1/10: kmmlu
2025-07-29 15:11:05,238 - INFO - gemma-3-4b-it_harness_2: Task 'kmmlu' will use num_fewshot=5
2025-07-29 15:11:05,238 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-29 15:11:05,239 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 15:12:18,963 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-29 15:12:18,964 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-29 15:12:18,964 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-29 15:12:18,964 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-29 15:12:18,964 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-29 15:12:18,964 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-29 15:12:18,964 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-29 15:12:18,964 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-29 15:12:18,965 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-29 15:12:18,965 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-29 15:12:18,965 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-29 15:12:18,965 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-29 15:12:18,965 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-29 15:12:18,965 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-29 15:12:18,965 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-29 15:12:18,965 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-29 15:12:18,965 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-29 15:12:18,965 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-29 15:12:18,966 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-29 15:12:18,966 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-29 15:12:18,966 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-29 15:12:18,966 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-29 15:12:18,966 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-29 15:12:18,966 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-29 15:12:18,966 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-29 15:12:18,966 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-29 15:12:18,966 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-29 15:12:18,967 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-29 15:12:18,967 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-29 15:12:18,967 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-29 15:12:18,967 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-29 15:12:18,967 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-29 15:12:18,967 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-29 15:12:18,967 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-29 15:12:18,967 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-29 15:12:18,967 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-29 15:12:18,967 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-29 15:12:18,968 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-29 15:12:18,968 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-29 15:12:18,968 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-29 15:12:18,968 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-29 15:12:18,968 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-29 15:12:18,968 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-29 15:12:18,968 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-29 15:12:18,968 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-29 16:08:00,299 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-29 16:08:00,302 - INFO - 
============================================================
2025-07-29 16:08:00,304 - INFO - Task 'kmmlu' Results:
2025-07-29 16:08:00,307 - INFO - ============================================================
2025-07-29 16:08:00,316 - INFO -   kmmlu:
2025-07-29 16:08:00,316 - INFO -     - accuracy: 0.3907
2025-07-29 16:08:00,316 - INFO -   kmmlu_applied_science:
2025-07-29 16:08:00,316 - INFO -     - accuracy: 0.3722
2025-07-29 16:08:00,316 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-29 16:08:00,316 - INFO -     - accuracy: 0.3970
2025-07-29 16:08:00,316 - INFO -   kmmlu_electronics_engineering:
2025-07-29 16:08:00,317 - INFO -     - accuracy: 0.4710
2025-07-29 16:08:00,317 - INFO -   kmmlu_energy_management:
2025-07-29 16:08:00,317 - INFO -     - accuracy: 0.3280
2025-07-29 16:08:00,317 - INFO -   kmmlu_environmental_science:
2025-07-29 16:08:00,317 - INFO -     - accuracy: 0.2790
2025-07-29 16:08:00,317 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-29 16:08:00,317 - INFO -     - accuracy: 0.3140
2025-07-29 16:08:00,317 - INFO -   kmmlu_geomatics:
2025-07-29 16:08:00,317 - INFO -     - accuracy: 0.3410
2025-07-29 16:08:00,317 - INFO -   kmmlu_industrial_engineer:
2025-07-29 16:08:00,318 - INFO -     - accuracy: 0.3760
2025-07-29 16:08:00,318 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-29 16:08:00,318 - INFO -     - accuracy: 0.3960
2025-07-29 16:08:00,318 - INFO -   kmmlu_maritime_engineering:
2025-07-29 16:08:00,318 - INFO -     - accuracy: 0.4417
2025-07-29 16:08:00,318 - INFO -   kmmlu_nondestructive_testing:
2025-07-29 16:08:00,318 - INFO -     - accuracy: 0.3840
2025-07-29 16:08:00,318 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-29 16:08:00,318 - INFO -     - accuracy: 0.2970
2025-07-29 16:08:00,318 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-29 16:08:00,318 - INFO -     - accuracy: 0.4690
2025-07-29 16:08:00,319 - INFO -   kmmlu_humss:
2025-07-29 16:08:00,319 - INFO -     - accuracy: 0.3897
2025-07-29 16:08:00,319 - INFO -   kmmlu_accounting:
2025-07-29 16:08:00,319 - INFO -     - accuracy: 0.4100
2025-07-29 16:08:00,319 - INFO -   kmmlu_criminal_law:
2025-07-29 16:08:00,319 - INFO -     - accuracy: 0.3200
2025-07-29 16:08:00,319 - INFO -   kmmlu_economics:
2025-07-29 16:08:00,319 - INFO -     - accuracy: 0.3923
2025-07-29 16:08:00,319 - INFO -   kmmlu_education:
2025-07-29 16:08:00,319 - INFO -     - accuracy: 0.4200
2025-07-29 16:08:00,320 - INFO -   kmmlu_korean_history:
2025-07-29 16:08:00,320 - INFO -     - accuracy: 0.2700
2025-07-29 16:08:00,320 - INFO -   kmmlu_law:
2025-07-29 16:08:00,320 - INFO -     - accuracy: 0.3510
2025-07-29 16:08:00,320 - INFO -   kmmlu_management:
2025-07-29 16:08:00,320 - INFO -     - accuracy: 0.4280
2025-07-29 16:08:00,320 - INFO -   kmmlu_political_science_and_sociology:
2025-07-29 16:08:00,320 - INFO -     - accuracy: 0.4167
2025-07-29 16:08:00,320 - INFO -   kmmlu_psychology:
2025-07-29 16:08:00,320 - INFO -     - accuracy: 0.3600
2025-07-29 16:08:00,321 - INFO -   kmmlu_social_welfare:
2025-07-29 16:08:00,321 - INFO -     - accuracy: 0.4450
2025-07-29 16:08:00,321 - INFO -   kmmlu_taxation:
2025-07-29 16:08:00,321 - INFO -     - accuracy: 0.3250
2025-07-29 16:08:00,321 - INFO -   kmmlu_other:
2025-07-29 16:08:00,321 - INFO -     - accuracy: 0.3985
2025-07-29 16:08:00,321 - INFO -   kmmlu_agricultural_sciences:
2025-07-29 16:08:00,321 - INFO -     - accuracy: 0.3110
2025-07-29 16:08:00,321 - INFO -   kmmlu_construction:
2025-07-29 16:08:00,321 - INFO -     - accuracy: 0.3010
2025-07-29 16:08:00,321 - INFO -   kmmlu_fashion:
2025-07-29 16:08:00,322 - INFO -     - accuracy: 0.3980
2025-07-29 16:08:00,322 - INFO -   kmmlu_food_processing:
2025-07-29 16:08:00,322 - INFO -     - accuracy: 0.3570
2025-07-29 16:08:00,322 - INFO -   kmmlu_health:
2025-07-29 16:08:00,322 - INFO -     - accuracy: 0.4900
2025-07-29 16:08:00,322 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-29 16:08:00,322 - INFO -     - accuracy: 0.4820
2025-07-29 16:08:00,322 - INFO -   kmmlu_marketing:
2025-07-29 16:08:00,322 - INFO -     - accuracy: 0.7140
2025-07-29 16:08:00,322 - INFO -   kmmlu_patent:
2025-07-29 16:08:00,323 - INFO -     - accuracy: 0.4000
2025-07-29 16:08:00,323 - INFO -   kmmlu_public_safety:
2025-07-29 16:08:00,323 - INFO -     - accuracy: 0.3370
2025-07-29 16:08:00,323 - INFO -   kmmlu_real_estate:
2025-07-29 16:08:00,323 - INFO -     - accuracy: 0.4000
2025-07-29 16:08:00,323 - INFO -   kmmlu_refrigerating_machinery:
2025-07-29 16:08:00,323 - INFO -     - accuracy: 0.2780
2025-07-29 16:08:00,323 - INFO -   kmmlu_stem:
2025-07-29 16:08:00,323 - INFO -     - accuracy: 0.4064
2025-07-29 16:08:00,323 - INFO -   kmmlu_biology:
2025-07-29 16:08:00,323 - INFO -     - accuracy: 0.3200
2025-07-29 16:08:00,324 - INFO -   kmmlu_chemical_engineering:
2025-07-29 16:08:00,324 - INFO -     - accuracy: 0.3900
2025-07-29 16:08:00,324 - INFO -   kmmlu_chemistry:
2025-07-29 16:08:00,324 - INFO -     - accuracy: 0.3917
2025-07-29 16:08:00,324 - INFO -   kmmlu_civil_engineering:
2025-07-29 16:08:00,324 - INFO -     - accuracy: 0.3490
2025-07-29 16:08:00,324 - INFO -   kmmlu_computer_science:
2025-07-29 16:08:00,324 - INFO -     - accuracy: 0.5980
2025-07-29 16:08:00,324 - INFO -   kmmlu_ecology:
2025-07-29 16:08:00,324 - INFO -     - accuracy: 0.4230
2025-07-29 16:08:00,325 - INFO -   kmmlu_electrical_engineering:
2025-07-29 16:08:00,325 - INFO -     - accuracy: 0.2920
2025-07-29 16:08:00,325 - INFO -   kmmlu_information_technology:
2025-07-29 16:08:00,325 - INFO -     - accuracy: 0.6010
2025-07-29 16:08:00,325 - INFO -   kmmlu_materials_engineering:
2025-07-29 16:08:00,325 - INFO -     - accuracy: 0.3900
2025-07-29 16:08:00,325 - INFO -   kmmlu_math:
2025-07-29 16:08:00,325 - INFO -     - accuracy: 0.2667
2025-07-29 16:08:00,325 - INFO -   kmmlu_mechanical_engineering:
2025-07-29 16:08:00,325 - INFO -     - accuracy: 0.3450
2025-07-29 16:08:00,326 - INFO - ============================================================

2025-07-29 16:08:00,358 - INFO - gemma-3-4b-it_harness_2: Processing task 2/10: kmmlu_hard
2025-07-29 16:08:00,363 - INFO - gemma-3-4b-it_harness_2: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-29 16:08:00,363 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-29 16:08:00,364 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 16:09:20,026 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-29 16:09:20,027 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-29 16:09:20,027 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-29 16:09:20,027 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-29 16:09:20,027 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-29 16:09:20,027 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-29 16:09:20,027 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-29 16:09:20,027 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-29 16:09:20,027 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-29 16:09:20,028 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-29 16:09:20,028 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-29 16:09:20,028 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-29 16:09:20,028 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-29 16:09:20,028 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-29 16:09:20,028 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-29 16:09:20,028 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-29 16:09:20,028 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-29 16:09:20,028 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-29 16:09:20,028 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-29 16:09:20,029 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-29 16:09:20,029 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-29 16:09:20,029 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-29 16:09:20,029 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-29 16:09:20,029 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-29 16:09:20,029 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-29 16:09:20,029 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-29 16:09:20,029 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-29 16:09:20,029 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-29 16:09:20,029 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-29 16:09:20,030 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-29 16:09:20,030 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-29 16:09:20,030 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-29 16:09:20,030 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-29 16:09:20,030 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-29 16:09:20,030 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-29 16:09:20,030 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-29 16:09:20,030 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-29 16:09:20,030 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-29 16:09:20,030 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-29 16:09:20,031 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-29 16:09:20,031 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-29 16:09:20,031 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-29 16:09:20,031 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-29 16:09:20,031 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-29 16:09:20,031 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-29 16:16:14,218 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-29 16:16:14,221 - INFO - 
============================================================
2025-07-29 16:16:14,225 - INFO - Task 'kmmlu_hard' Results:
2025-07-29 16:16:14,225 - INFO - ============================================================
2025-07-29 16:16:14,226 - INFO -   kmmlu_hard:
2025-07-29 16:16:14,227 - INFO -     - accuracy: 0.2152
2025-07-29 16:16:14,227 - INFO -   kmmlu_hard_applied_science:
2025-07-29 16:16:14,228 - INFO -     - accuracy: 0.2242
2025-07-29 16:16:14,229 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-29 16:16:14,233 - INFO -     - accuracy: 0.2100
2025-07-29 16:16:14,233 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-29 16:16:14,233 - INFO -     - accuracy: 0.2700
2025-07-29 16:16:14,233 - INFO -   kmmlu_hard_energy_management:
2025-07-29 16:16:14,233 - INFO -     - accuracy: 0.3200
2025-07-29 16:16:14,234 - INFO -   kmmlu_hard_environmental_science:
2025-07-29 16:16:14,234 - INFO -     - accuracy: 0.1600
2025-07-29 16:16:14,234 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-29 16:16:14,234 - INFO -     - accuracy: 0.2300
2025-07-29 16:16:14,234 - INFO -   kmmlu_hard_geomatics:
2025-07-29 16:16:14,234 - INFO -     - accuracy: 0.2100
2025-07-29 16:16:14,234 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-29 16:16:14,234 - INFO -     - accuracy: 0.1500
2025-07-29 16:16:14,234 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-29 16:16:14,235 - INFO -     - accuracy: 0.2200
2025-07-29 16:16:14,235 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-29 16:16:14,235 - INFO -     - accuracy: 0.2600
2025-07-29 16:16:14,235 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-29 16:16:14,235 - INFO -     - accuracy: 0.2600
2025-07-29 16:16:14,235 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-29 16:16:14,235 - INFO -     - accuracy: 0.1800
2025-07-29 16:16:14,235 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-29 16:16:14,235 - INFO -     - accuracy: 0.2200
2025-07-29 16:16:14,235 - INFO -   kmmlu_hard_humss:
2025-07-29 16:16:14,235 - INFO -     - accuracy: 0.2105
2025-07-29 16:16:14,236 - INFO -   kmmlu_hard_accounting:
2025-07-29 16:16:14,236 - INFO -     - accuracy: 0.3261
2025-07-29 16:16:14,236 - INFO -   kmmlu_hard_criminal_law:
2025-07-29 16:16:14,236 - INFO -     - accuracy: 0.2600
2025-07-29 16:16:14,236 - INFO -   kmmlu_hard_economics:
2025-07-29 16:16:14,236 - INFO -     - accuracy: 0.1190
2025-07-29 16:16:14,236 - INFO -   kmmlu_hard_education:
2025-07-29 16:16:14,236 - INFO -     - accuracy: 0.2174
2025-07-29 16:16:14,236 - INFO -   kmmlu_hard_korean_history:
2025-07-29 16:16:14,236 - INFO -     - accuracy: 0.2045
2025-07-29 16:16:14,237 - INFO -   kmmlu_hard_law:
2025-07-29 16:16:14,237 - INFO -     - accuracy: 0.1700
2025-07-29 16:16:14,237 - INFO -   kmmlu_hard_management:
2025-07-29 16:16:14,237 - INFO -     - accuracy: 0.2100
2025-07-29 16:16:14,237 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-29 16:16:14,237 - INFO -     - accuracy: 0.1889
2025-07-29 16:16:14,237 - INFO -   kmmlu_hard_psychology:
2025-07-29 16:16:14,237 - INFO -     - accuracy: 0.1600
2025-07-29 16:16:14,237 - INFO -   kmmlu_hard_social_welfare:
2025-07-29 16:16:14,237 - INFO -     - accuracy: 0.2400
2025-07-29 16:16:14,238 - INFO -   kmmlu_hard_taxation:
2025-07-29 16:16:14,238 - INFO -     - accuracy: 0.2292
2025-07-29 16:16:14,238 - INFO -   kmmlu_hard_other:
2025-07-29 16:16:14,238 - INFO -     - accuracy: 0.2191
2025-07-29 16:16:14,238 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-29 16:16:14,238 - INFO -     - accuracy: 0.1700
2025-07-29 16:16:14,238 - INFO -   kmmlu_hard_construction:
2025-07-29 16:16:14,238 - INFO -     - accuracy: 0.1700
2025-07-29 16:16:14,238 - INFO -   kmmlu_hard_fashion:
2025-07-29 16:16:14,238 - INFO -     - accuracy: 0.2900
2025-07-29 16:16:14,239 - INFO -   kmmlu_hard_food_processing:
2025-07-29 16:16:14,239 - INFO -     - accuracy: 0.2200
2025-07-29 16:16:14,239 - INFO -   kmmlu_hard_health:
2025-07-29 16:16:14,239 - INFO -     - accuracy: 0.1739
2025-07-29 16:16:14,239 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-29 16:16:14,239 - INFO -     - accuracy: 0.2700
2025-07-29 16:16:14,239 - INFO -   kmmlu_hard_marketing:
2025-07-29 16:16:14,239 - INFO -     - accuracy: 0.1900
2025-07-29 16:16:14,239 - INFO -   kmmlu_hard_patent:
2025-07-29 16:16:14,239 - INFO -     - accuracy: 0.3333
2025-07-29 16:16:14,239 - INFO -   kmmlu_hard_public_safety:
2025-07-29 16:16:14,240 - INFO -     - accuracy: 0.1700
2025-07-29 16:16:14,240 - INFO -   kmmlu_hard_real_estate:
2025-07-29 16:16:14,240 - INFO -     - accuracy: 0.2584
2025-07-29 16:16:14,240 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-29 16:16:14,240 - INFO -     - accuracy: 0.1900
2025-07-29 16:16:14,240 - INFO -   kmmlu_hard_stem:
2025-07-29 16:16:14,240 - INFO -     - accuracy: 0.2055
2025-07-29 16:16:14,240 - INFO -   kmmlu_hard_biology:
2025-07-29 16:16:14,240 - INFO -     - accuracy: 0.1800
2025-07-29 16:16:14,240 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-29 16:16:14,241 - INFO -     - accuracy: 0.1800
2025-07-29 16:16:14,241 - INFO -   kmmlu_hard_chemistry:
2025-07-29 16:16:14,241 - INFO -     - accuracy: 0.2100
2025-07-29 16:16:14,241 - INFO -   kmmlu_hard_civil_engineering:
2025-07-29 16:16:14,241 - INFO -     - accuracy: 0.1800
2025-07-29 16:16:14,241 - INFO -   kmmlu_hard_computer_science:
2025-07-29 16:16:14,241 - INFO -     - accuracy: 0.1900
2025-07-29 16:16:14,241 - INFO -   kmmlu_hard_ecology:
2025-07-29 16:16:14,241 - INFO -     - accuracy: 0.1800
2025-07-29 16:16:14,241 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-29 16:16:14,241 - INFO -     - accuracy: 0.1600
2025-07-29 16:16:14,242 - INFO -   kmmlu_hard_information_technology:
2025-07-29 16:16:14,242 - INFO -     - accuracy: 0.2200
2025-07-29 16:16:14,242 - INFO -   kmmlu_hard_materials_engineering:
2025-07-29 16:16:14,242 - INFO -     - accuracy: 0.2500
2025-07-29 16:16:14,242 - INFO -   kmmlu_hard_math:
2025-07-29 16:16:14,242 - INFO -     - accuracy: 0.2900
2025-07-29 16:16:14,242 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-29 16:16:14,242 - INFO -     - accuracy: 0.2200
2025-07-29 16:16:14,242 - INFO - ============================================================

2025-07-29 16:16:14,271 - INFO - gemma-3-4b-it_harness_2: Processing task 3/10: haerae
2025-07-29 16:16:14,272 - INFO - gemma-3-4b-it_harness_2: Task 'haerae' will use num_fewshot=5
2025-07-29 16:16:14,275 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'haerae' with num_fewshot=5
2025-07-29 16:16:14,275 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 16:16:36,282 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-29 16:16:36,283 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-29 16:16:36,283 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-29 16:16:36,283 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-29 16:16:36,283 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-29 16:24:32,834 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'haerae' with 6 subtasks
2025-07-29 16:24:32,839 - INFO - 
============================================================
2025-07-29 16:24:32,843 - INFO - Task 'haerae' Results:
2025-07-29 16:24:32,843 - INFO - ============================================================
2025-07-29 16:24:32,844 - INFO -   haerae:
2025-07-29 16:24:32,844 - INFO -     - accuracy: 0.5949
2025-07-29 16:24:32,845 - INFO -     - accuracy_norm: 0.5949
2025-07-29 16:24:32,845 - INFO -   haerae_general_knowledge:
2025-07-29 16:24:32,845 - INFO -     - accuracy: 0.3750
2025-07-29 16:24:32,848 - INFO -     - accuracy_norm: 0.3750
2025-07-29 16:24:32,849 - INFO -   haerae_history:
2025-07-29 16:24:32,849 - INFO -     - accuracy: 0.5213
2025-07-29 16:24:32,849 - INFO -     - accuracy_norm: 0.5213
2025-07-29 16:24:32,849 - INFO -   haerae_loan_word:
2025-07-29 16:24:32,849 - INFO -     - accuracy: 0.6154
2025-07-29 16:24:32,849 - INFO -     - accuracy_norm: 0.6154
2025-07-29 16:24:32,849 - INFO -   haerae_rare_word:
2025-07-29 16:24:32,849 - INFO -     - accuracy: 0.6790
2025-07-29 16:24:32,849 - INFO -     - accuracy_norm: 0.6790
2025-07-29 16:24:32,850 - INFO -   haerae_standard_nomenclature:
2025-07-29 16:24:32,850 - INFO -     - accuracy: 0.6928
2025-07-29 16:24:32,850 - INFO -     - accuracy_norm: 0.6928
2025-07-29 16:24:32,850 - INFO - ============================================================

2025-07-29 16:24:32,878 - INFO - gemma-3-4b-it_harness_2: Processing task 4/10: kobest
2025-07-29 16:24:32,879 - INFO - gemma-3-4b-it_harness_2: Task 'kobest' will use num_fewshot=5
2025-07-29 16:24:32,880 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kobest' with num_fewshot=5
2025-07-29 16:24:32,881 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 16:24:57,266 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-29 16:24:57,267 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-29 16:24:57,267 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-29 16:24:57,267 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-29 16:24:57,267 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-29 16:39:03,201 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kobest' with 6 subtasks
2025-07-29 16:39:03,204 - INFO - 
============================================================
2025-07-29 16:39:03,206 - INFO - Task 'kobest' Results:
2025-07-29 16:39:03,207 - INFO - ============================================================
2025-07-29 16:39:03,209 - INFO -   kobest:
2025-07-29 16:39:03,209 - INFO -     - accuracy: 0.7259
2025-07-29 16:39:03,209 - INFO -     - accuracy_norm: 0.5320
2025-07-29 16:39:03,210 - INFO -     - f1: 0.7244
2025-07-29 16:39:03,211 - INFO -   kobest_boolq:
2025-07-29 16:39:03,211 - INFO -     - accuracy: 0.8568
2025-07-29 16:39:03,212 - INFO -     - f1: 0.8568
2025-07-29 16:39:03,212 - INFO -   kobest_copa:
2025-07-29 16:39:03,212 - INFO -     - accuracy: 0.7540
2025-07-29 16:39:03,212 - INFO -     - f1: 0.7539
2025-07-29 16:39:03,215 - INFO -   kobest_hellaswag:
2025-07-29 16:39:03,215 - INFO -     - accuracy: 0.4400
2025-07-29 16:39:03,215 - INFO -     - accuracy_norm: 0.5320
2025-07-29 16:39:03,215 - INFO -     - f1: 0.4365
2025-07-29 16:39:03,215 - INFO -   kobest_sentineg:
2025-07-29 16:39:03,215 - INFO -     - accuracy: 0.9597
2025-07-29 16:39:03,215 - INFO -     - f1: 0.9597
2025-07-29 16:39:03,215 - INFO -   kobest_wic:
2025-07-29 16:39:03,216 - INFO -     - accuracy: 0.5976
2025-07-29 16:39:03,216 - INFO -     - f1: 0.5936
2025-07-29 16:39:03,216 - INFO - ============================================================

2025-07-29 16:39:03,242 - INFO - gemma-3-4b-it_harness_2: Processing task 5/10: csatqa
2025-07-29 16:39:03,244 - INFO - gemma-3-4b-it_harness_2: Task 'csatqa' detected as zero-shot task
2025-07-29 16:39:03,245 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'csatqa' with num_fewshot=0
2025-07-29 16:39:03,245 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 16:39:22,072 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-29 16:39:22,072 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-29 16:39:22,072 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-29 16:39:22,072 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-29 16:39:22,072 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-29 16:39:22,072 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-29 16:41:16,750 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'csatqa' with 7 subtasks
2025-07-29 16:41:16,753 - INFO - 
============================================================
2025-07-29 16:41:16,756 - INFO - Task 'csatqa' Results:
2025-07-29 16:41:16,759 - INFO - ============================================================
2025-07-29 16:41:16,761 - INFO -   csatqa:
2025-07-29 16:41:16,762 - INFO -     - accuracy: 0.3262
2025-07-29 16:41:16,763 - INFO -     - accuracy_norm: 0.3262
2025-07-29 16:41:16,763 - INFO -   csatqa_gr:
2025-07-29 16:41:16,763 - INFO -     - accuracy: 0.1200
2025-07-29 16:41:16,763 - INFO -     - accuracy_norm: 0.1200
2025-07-29 16:41:16,763 - INFO -   csatqa_li:
2025-07-29 16:41:16,763 - INFO -     - accuracy: 0.4324
2025-07-29 16:41:16,763 - INFO -     - accuracy_norm: 0.4324
2025-07-29 16:41:16,764 - INFO -   csatqa_rch:
2025-07-29 16:41:16,764 - INFO -     - accuracy: 0.3714
2025-07-29 16:41:16,764 - INFO -     - accuracy_norm: 0.3714
2025-07-29 16:41:16,764 - INFO -   csatqa_rcs:
2025-07-29 16:41:16,764 - INFO -     - accuracy: 0.2973
2025-07-29 16:41:16,764 - INFO -     - accuracy_norm: 0.2973
2025-07-29 16:41:16,764 - INFO -   csatqa_rcss:
2025-07-29 16:41:16,764 - INFO -     - accuracy: 0.3571
2025-07-29 16:41:16,764 - INFO -     - accuracy_norm: 0.3571
2025-07-29 16:41:16,764 - INFO -   csatqa_wr:
2025-07-29 16:41:16,764 - INFO -     - accuracy: 0.2727
2025-07-29 16:41:16,764 - INFO -     - accuracy_norm: 0.2727
2025-07-29 16:41:16,765 - INFO - ============================================================

2025-07-29 16:41:16,799 - INFO - gemma-3-4b-it_harness_2: Processing task 6/10: kormedmcqa
2025-07-29 16:41:16,800 - INFO - gemma-3-4b-it_harness_2: Task 'kormedmcqa' will use num_fewshot=5
2025-07-29 16:41:16,802 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-29 16:41:16,803 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 16:41:39,878 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-29 16:41:39,878 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-29 16:41:39,878 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-29 16:41:39,879 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
2025-07-29 16:48:21,139 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-29 16:48:21,141 - INFO - 
============================================================
2025-07-29 16:48:21,144 - INFO - Task 'kormedmcqa' Results:
2025-07-29 16:48:21,145 - INFO - ============================================================
2025-07-29 16:48:21,145 - INFO -   kormedmcqa:
2025-07-29 16:48:21,145 - INFO -     - exact_match: 0.4453
2025-07-29 16:48:21,146 - INFO -   kormedmcqa_dentist:
2025-07-29 16:48:21,146 - INFO -     - exact_match: 0.3798
2025-07-29 16:48:21,146 - INFO -   kormedmcqa_doctor:
2025-07-29 16:48:21,147 - INFO -     - exact_match: 0.3655
2025-07-29 16:48:21,147 - INFO -   kormedmcqa_nurse:
2025-07-29 16:48:21,147 - INFO -     - exact_match: 0.5592
2025-07-29 16:48:21,148 - INFO -   kormedmcqa_pharm:
2025-07-29 16:48:21,148 - INFO -     - exact_match: 0.4316
2025-07-29 16:48:21,148 - INFO - ============================================================

2025-07-29 16:48:21,170 - INFO - gemma-3-4b-it_harness_2: Processing task 7/10: mmlu
2025-07-29 16:48:21,171 - INFO - gemma-3-4b-it_harness_2: Task 'mmlu' will use num_fewshot=5
2025-07-29 16:48:21,171 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'mmlu' with num_fewshot=5
2025-07-29 16:48:21,172 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 16:51:22,327 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5
2025-07-29 16:51:22,327 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5
2025-07-29 16:51:22,327 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 5
2025-07-29 16:51:22,327 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5
2025-07-29 16:51:22,327 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5
2025-07-29 16:51:22,327 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 5
2025-07-29 16:51:22,328 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 5
2025-07-29 16:51:22,328 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5
2025-07-29 16:51:22,328 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 5
2025-07-29 16:51:22,328 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 5
2025-07-29 16:51:22,328 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 5
2025-07-29 16:51:22,328 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 5
2025-07-29 16:51:22,328 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 5
2025-07-29 16:51:22,328 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5
2025-07-29 16:51:22,328 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5
2025-07-29 16:51:22,328 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 5
2025-07-29 16:51:22,329 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 5
2025-07-29 16:51:22,329 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5
2025-07-29 16:51:22,329 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 5
2025-07-29 16:51:22,329 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 5
2025-07-29 16:51:22,329 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 5
2025-07-29 16:51:22,329 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 5
2025-07-29 16:51:22,329 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 5
2025-07-29 16:51:22,329 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 5
2025-07-29 16:51:22,329 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 5
2025-07-29 16:51:22,329 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 5
2025-07-29 16:51:22,330 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 5
2025-07-29 16:51:22,330 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 5
2025-07-29 16:51:22,330 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 5
2025-07-29 16:51:22,330 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 5
2025-07-29 16:51:22,330 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 5
2025-07-29 16:51:22,330 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5
2025-07-29 16:51:22,330 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5
2025-07-29 16:51:22,330 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5
2025-07-29 16:51:22,330 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5
2025-07-29 16:51:22,330 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 5
2025-07-29 16:51:22,331 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 5
2025-07-29 16:51:22,331 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 5
2025-07-29 16:51:22,331 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 5
2025-07-29 16:51:22,331 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 5
2025-07-29 16:51:22,331 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 5
2025-07-29 16:51:22,331 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 5
2025-07-29 16:51:22,331 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5
2025-07-29 16:51:22,331 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5
2025-07-29 16:51:22,331 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 5
2025-07-29 16:51:22,332 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 5
2025-07-29 16:51:22,332 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5
2025-07-29 16:51:22,332 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5
2025-07-29 16:51:22,332 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 5
2025-07-29 16:51:22,332 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 5
2025-07-29 16:51:22,332 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5
2025-07-29 16:51:22,332 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 5
2025-07-29 16:51:22,332 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 5
2025-07-29 16:51:22,332 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5
2025-07-29 16:51:22,333 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 5
2025-07-29 16:51:22,333 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 5
2025-07-29 16:51:22,333 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5
2025-07-29 17:18:00,646 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'mmlu' with 62 subtasks
2025-07-29 17:18:00,650 - INFO - 
============================================================
2025-07-29 17:18:00,652 - INFO - Task 'mmlu' Results:
2025-07-29 17:18:00,656 - INFO - ============================================================
2025-07-29 17:18:00,658 - INFO -   mmlu:
2025-07-29 17:18:00,658 - INFO -     - accuracy: 0.5839
2025-07-29 17:18:00,659 - INFO -   mmlu_humanities:
2025-07-29 17:18:00,659 - INFO -     - accuracy: 0.5228
2025-07-29 17:18:00,659 - INFO -   mmlu_formal_logic:
2025-07-29 17:18:00,659 - INFO -     - accuracy: 0.4048
2025-07-29 17:18:00,659 - INFO -   mmlu_high_school_european_history:
2025-07-29 17:18:00,660 - INFO -     - accuracy: 0.7273
2025-07-29 17:18:00,660 - INFO -   mmlu_high_school_us_history:
2025-07-29 17:18:00,660 - INFO -     - accuracy: 0.7451
2025-07-29 17:18:00,660 - INFO -   mmlu_high_school_world_history:
2025-07-29 17:18:00,660 - INFO -     - accuracy: 0.7595
2025-07-29 17:18:00,661 - INFO -   mmlu_international_law:
2025-07-29 17:18:00,661 - INFO -     - accuracy: 0.7521
2025-07-29 17:18:00,661 - INFO -   mmlu_jurisprudence:
2025-07-29 17:18:00,661 - INFO -     - accuracy: 0.6944
2025-07-29 17:18:00,661 - INFO -   mmlu_logical_fallacies:
2025-07-29 17:18:00,662 - INFO -     - accuracy: 0.7178
2025-07-29 17:18:00,662 - INFO -   mmlu_moral_disputes:
2025-07-29 17:18:00,662 - INFO -     - accuracy: 0.6705
2025-07-29 17:18:00,662 - INFO -   mmlu_moral_scenarios:
2025-07-29 17:18:00,662 - INFO -     - accuracy: 0.2492
2025-07-29 17:18:00,662 - INFO -   mmlu_philosophy:
2025-07-29 17:18:00,662 - INFO -     - accuracy: 0.6688
2025-07-29 17:18:00,663 - INFO -   mmlu_prehistory:
2025-07-29 17:18:00,663 - INFO -     - accuracy: 0.6698
2025-07-29 17:18:00,663 - INFO -   mmlu_professional_law:
2025-07-29 17:18:00,663 - INFO -     - accuracy: 0.4270
2025-07-29 17:18:00,663 - INFO -   mmlu_world_religions:
2025-07-29 17:18:00,663 - INFO -     - accuracy: 0.8129
2025-07-29 17:18:00,664 - INFO -   mmlu_other:
2025-07-29 17:18:00,664 - INFO -     - accuracy: 0.6444
2025-07-29 17:18:00,664 - INFO -   mmlu_business_ethics:
2025-07-29 17:18:00,664 - INFO -     - accuracy: 0.6100
2025-07-29 17:18:00,664 - INFO -   mmlu_clinical_knowledge:
2025-07-29 17:18:00,664 - INFO -     - accuracy: 0.6679
2025-07-29 17:18:00,665 - INFO -   mmlu_college_medicine:
2025-07-29 17:18:00,665 - INFO -     - accuracy: 0.5838
2025-07-29 17:18:00,665 - INFO -   mmlu_global_facts:
2025-07-29 17:18:00,665 - INFO -     - accuracy: 0.3200
2025-07-29 17:18:00,665 - INFO -   mmlu_human_aging:
2025-07-29 17:18:00,665 - INFO -     - accuracy: 0.6771
2025-07-29 17:18:00,666 - INFO -   mmlu_management:
2025-07-29 17:18:00,666 - INFO -     - accuracy: 0.7767
2025-07-29 17:18:00,666 - INFO -   mmlu_marketing:
2025-07-29 17:18:00,666 - INFO -     - accuracy: 0.8761
2025-07-29 17:18:00,666 - INFO -   mmlu_medical_genetics:
2025-07-29 17:18:00,666 - INFO -     - accuracy: 0.6200
2025-07-29 17:18:00,667 - INFO -   mmlu_miscellaneous:
2025-07-29 17:18:00,667 - INFO -     - accuracy: 0.7522
2025-07-29 17:18:00,667 - INFO -   mmlu_nutrition:
2025-07-29 17:18:00,667 - INFO -     - accuracy: 0.6732
2025-07-29 17:18:00,667 - INFO -   mmlu_professional_accounting:
2025-07-29 17:18:00,668 - INFO -     - accuracy: 0.3830
2025-07-29 17:18:00,668 - INFO -   mmlu_professional_medicine:
2025-07-29 17:18:00,668 - INFO -     - accuracy: 0.5515
2025-07-29 17:18:00,668 - INFO -   mmlu_virology:
2025-07-29 17:18:00,668 - INFO -     - accuracy: 0.4819
2025-07-29 17:18:00,668 - INFO -   mmlu_social_sciences:
2025-07-29 17:18:00,669 - INFO -     - accuracy: 0.6909
2025-07-29 17:18:00,669 - INFO -   mmlu_econometrics:
2025-07-29 17:18:00,669 - INFO -     - accuracy: 0.4386
2025-07-29 17:18:00,669 - INFO -   mmlu_high_school_geography:
2025-07-29 17:18:00,669 - INFO -     - accuracy: 0.8030
2025-07-29 17:18:00,669 - INFO -   mmlu_high_school_government_and_politics:
2025-07-29 17:18:00,670 - INFO -     - accuracy: 0.8446
2025-07-29 17:18:00,670 - INFO -   mmlu_high_school_macroeconomics:
2025-07-29 17:18:00,670 - INFO -     - accuracy: 0.5872
2025-07-29 17:18:00,670 - INFO -   mmlu_high_school_microeconomics:
2025-07-29 17:18:00,670 - INFO -     - accuracy: 0.6261
2025-07-29 17:18:00,671 - INFO -   mmlu_high_school_psychology:
2025-07-29 17:18:00,671 - INFO -     - accuracy: 0.7853
2025-07-29 17:18:00,671 - INFO -   mmlu_human_sexuality:
2025-07-29 17:18:00,671 - INFO -     - accuracy: 0.6947
2025-07-29 17:18:00,671 - INFO -   mmlu_professional_psychology:
2025-07-29 17:18:00,671 - INFO -     - accuracy: 0.6029
2025-07-29 17:18:00,672 - INFO -   mmlu_public_relations:
2025-07-29 17:18:00,672 - INFO -     - accuracy: 0.6455
2025-07-29 17:18:00,672 - INFO -   mmlu_security_studies:
2025-07-29 17:18:00,672 - INFO -     - accuracy: 0.7265
2025-07-29 17:18:00,672 - INFO -   mmlu_sociology:
2025-07-29 17:18:00,672 - INFO -     - accuracy: 0.7711
2025-07-29 17:18:00,673 - INFO -   mmlu_us_foreign_policy:
2025-07-29 17:18:00,673 - INFO -     - accuracy: 0.8400
2025-07-29 17:18:00,673 - INFO -   mmlu_stem:
2025-07-29 17:18:00,673 - INFO -     - accuracy: 0.5109
2025-07-29 17:18:00,673 - INFO -   mmlu_abstract_algebra:
2025-07-29 17:18:00,673 - INFO -     - accuracy: 0.3500
2025-07-29 17:18:00,673 - INFO -   mmlu_anatomy:
2025-07-29 17:18:00,674 - INFO -     - accuracy: 0.5778
2025-07-29 17:18:00,674 - INFO -   mmlu_astronomy:
2025-07-29 17:18:00,674 - INFO -     - accuracy: 0.6645
2025-07-29 17:18:00,674 - INFO -   mmlu_college_biology:
2025-07-29 17:18:00,674 - INFO -     - accuracy: 0.7153
2025-07-29 17:18:00,675 - INFO -   mmlu_college_chemistry:
2025-07-29 17:18:00,675 - INFO -     - accuracy: 0.4200
2025-07-29 17:18:00,675 - INFO -   mmlu_college_computer_science:
2025-07-29 17:18:00,675 - INFO -     - accuracy: 0.4500
2025-07-29 17:18:00,675 - INFO -   mmlu_college_mathematics:
2025-07-29 17:18:00,675 - INFO -     - accuracy: 0.3700
2025-07-29 17:18:00,675 - INFO -   mmlu_college_physics:
2025-07-29 17:18:00,676 - INFO -     - accuracy: 0.3137
2025-07-29 17:18:00,676 - INFO -   mmlu_computer_security:
2025-07-29 17:18:00,676 - INFO -     - accuracy: 0.7500
2025-07-29 17:18:00,676 - INFO -   mmlu_conceptual_physics:
2025-07-29 17:18:00,676 - INFO -     - accuracy: 0.5489
2025-07-29 17:18:00,676 - INFO -   mmlu_electrical_engineering:
2025-07-29 17:18:00,676 - INFO -     - accuracy: 0.6000
2025-07-29 17:18:00,677 - INFO -   mmlu_elementary_mathematics:
2025-07-29 17:18:00,677 - INFO -     - accuracy: 0.4365
2025-07-29 17:18:00,677 - INFO -   mmlu_high_school_biology:
2025-07-29 17:18:00,677 - INFO -     - accuracy: 0.7065
2025-07-29 17:18:00,677 - INFO -   mmlu_high_school_chemistry:
2025-07-29 17:18:00,678 - INFO -     - accuracy: 0.5320
2025-07-29 17:18:00,678 - INFO -   mmlu_high_school_computer_science:
2025-07-29 17:18:00,678 - INFO -     - accuracy: 0.7000
2025-07-29 17:18:00,678 - INFO -   mmlu_high_school_mathematics:
2025-07-29 17:18:00,678 - INFO -     - accuracy: 0.3778
2025-07-29 17:18:00,679 - INFO -   mmlu_high_school_physics:
2025-07-29 17:18:00,679 - INFO -     - accuracy: 0.3311
2025-07-29 17:18:00,679 - INFO -   mmlu_high_school_statistics:
2025-07-29 17:18:00,679 - INFO -     - accuracy: 0.4074
2025-07-29 17:18:00,679 - INFO -   mmlu_machine_learning:
2025-07-29 17:18:00,679 - INFO -     - accuracy: 0.4018
2025-07-29 17:18:00,680 - INFO - ============================================================

2025-07-29 17:18:00,715 - INFO - gemma-3-4b-it_harness_2: Processing task 8/10: arc_challenge
2025-07-29 17:18:00,730 - INFO - gemma-3-4b-it_harness_2: Task 'arc_challenge' will use num_fewshot=5
2025-07-29 17:18:00,730 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'arc_challenge' with num_fewshot=5
2025-07-29 17:18:00,730 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 17:18:12,645 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 5
2025-07-29 17:23:28,693 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-29 17:23:28,697 - INFO - 
============================================================
2025-07-29 17:23:28,699 - INFO - Task 'arc_challenge' Results:
2025-07-29 17:23:28,702 - INFO - ============================================================
2025-07-29 17:23:28,702 - INFO -   arc_challenge:
2025-07-29 17:23:28,702 - INFO -     - accuracy: 0.5631
2025-07-29 17:23:28,703 - INFO -     - accuracy_norm: 0.6075
2025-07-29 17:23:28,707 - INFO - ============================================================

2025-07-29 17:23:28,730 - INFO - gemma-3-4b-it_harness_2: Processing task 9/10: arc_easy
2025-07-29 17:23:28,732 - INFO - gemma-3-4b-it_harness_2: Task 'arc_easy' will use num_fewshot=5
2025-07-29 17:23:28,733 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'arc_easy' with num_fewshot=5
2025-07-29 17:23:28,733 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 17:23:39,911 - WARNING - Overwriting default num_fewshot of arc_easy from None to 5
2025-07-29 17:33:29,736 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-29 17:33:29,738 - INFO - 
============================================================
2025-07-29 17:33:29,742 - INFO - Task 'arc_easy' Results:
2025-07-29 17:33:29,746 - INFO - ============================================================
2025-07-29 17:33:29,749 - INFO -   arc_easy:
2025-07-29 17:33:29,749 - INFO -     - accuracy: 0.8396
2025-07-29 17:33:29,749 - INFO -     - accuracy_norm: 0.8544
2025-07-29 17:33:29,750 - INFO - ============================================================

2025-07-29 17:33:29,774 - INFO - gemma-3-4b-it_harness_2: Processing task 10/10: hellaswag
2025-07-29 17:33:29,776 - INFO - gemma-3-4b-it_harness_2: Task 'hellaswag' will use num_fewshot=5
2025-07-29 17:33:29,776 - INFO - gemma-3-4b-it_harness_2: Evaluating task 'hellaswag' with num_fewshot=5
2025-07-29 17:33:29,777 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 17:33:48,925 - WARNING - Overwriting default num_fewshot of hellaswag from None to 5
2025-07-29 18:31:28,509 - INFO - gemma-3-4b-it_harness_2: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-29 18:31:28,513 - INFO - 
============================================================
2025-07-29 18:31:28,517 - INFO - Task 'hellaswag' Results:
2025-07-29 18:31:28,521 - INFO - ============================================================
2025-07-29 18:31:28,525 - INFO -   hellaswag:
2025-07-29 18:31:28,531 - INFO -     - accuracy: 0.5599
2025-07-29 18:31:28,532 - INFO -     - accuracy_norm: 0.7495
2025-07-29 18:31:28,532 - INFO - ============================================================

2025-07-29 18:31:28,560 - INFO - gemma-3-4b-it_harness_2: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-29 18:31:28,563 - INFO - [Process 2120894] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/gemma-3-4b-it/gemma-3-4b-it_harness_2.json
2025-07-29 18:31:28,925 - INFO - Results uploaded to WandB as artifact
2025-07-29 18:31:28,935 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-29 18:31:28,937 - INFO - [Process 2120894] Successfully completed gemma-3-4b-it_harness_2
2025-07-29 18:31:32,621 - INFO - Run gemma-3-4b-it_harness_2 finished successfully
2025-07-29 18:31:32,622 - INFO - [Process 2120894] EXAONE-3.5-2.4B-Instruct_harness_7 assigned to cuda:0
2025-07-29 18:31:32,622 - INFO - [Process 2120894] EXAONE-3.5-2.4B-Instruct_harness_7 - full_run: True, limit: None (full dataset)
2025-07-29 18:31:33,962 - INFO - WandB run initialized: EXAONE-3.5-2.4B-Instruct_20250729_183132 (ID: 9dadbb1c)
2025-07-29 18:31:34,326 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 1/10: kmmlu
2025-07-29 18:31:34,326 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kmmlu' will use num_fewshot=5
2025-07-29 18:31:34,327 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-29 18:31:34,327 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 18:32:46,328 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-29 18:32:46,328 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-29 18:32:46,328 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-29 18:32:46,328 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-29 18:32:46,328 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-29 18:32:46,328 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-29 18:32:46,329 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-29 18:32:46,330 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-29 18:32:46,331 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-29 18:32:46,332 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-29 18:32:46,332 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-29 18:32:46,332 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-29 18:32:46,332 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-29 18:32:46,332 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-29 18:32:46,332 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-29 18:42:45,849 - WARNING - We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
2025-07-29 20:26:21,345 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-29 20:26:21,347 - INFO - 
============================================================
2025-07-29 20:26:21,349 - INFO - Task 'kmmlu' Results:
2025-07-29 20:26:21,351 - INFO - ============================================================
2025-07-29 20:26:21,351 - INFO -   kmmlu:
2025-07-29 20:26:21,351 - INFO -     - accuracy: 0.4379
2025-07-29 20:26:21,351 - INFO -   kmmlu_applied_science:
2025-07-29 20:26:21,352 - INFO -     - accuracy: 0.4216
2025-07-29 20:26:21,352 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-29 20:26:21,352 - INFO -     - accuracy: 0.4190
2025-07-29 20:26:21,352 - INFO -   kmmlu_electronics_engineering:
2025-07-29 20:26:21,352 - INFO -     - accuracy: 0.5450
2025-07-29 20:26:21,352 - INFO -   kmmlu_energy_management:
2025-07-29 20:26:21,352 - INFO -     - accuracy: 0.3220
2025-07-29 20:26:21,353 - INFO -   kmmlu_environmental_science:
2025-07-29 20:26:21,353 - INFO -     - accuracy: 0.3440
2025-07-29 20:26:21,353 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-29 20:26:21,353 - INFO -     - accuracy: 0.3700
2025-07-29 20:26:21,353 - INFO -   kmmlu_geomatics:
2025-07-29 20:26:21,353 - INFO -     - accuracy: 0.4020
2025-07-29 20:26:21,353 - INFO -   kmmlu_industrial_engineer:
2025-07-29 20:26:21,353 - INFO -     - accuracy: 0.4330
2025-07-29 20:26:21,353 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-29 20:26:21,354 - INFO -     - accuracy: 0.4290
2025-07-29 20:26:21,354 - INFO -   kmmlu_maritime_engineering:
2025-07-29 20:26:21,354 - INFO -     - accuracy: 0.4250
2025-07-29 20:26:21,354 - INFO -   kmmlu_nondestructive_testing:
2025-07-29 20:26:21,354 - INFO -     - accuracy: 0.4290
2025-07-29 20:26:21,354 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-29 20:26:21,354 - INFO -     - accuracy: 0.3560
2025-07-29 20:26:21,354 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-29 20:26:21,354 - INFO -     - accuracy: 0.5870
2025-07-29 20:26:21,355 - INFO -   kmmlu_humss:
2025-07-29 20:26:21,355 - INFO -     - accuracy: 0.4415
2025-07-29 20:26:21,355 - INFO -   kmmlu_accounting:
2025-07-29 20:26:21,355 - INFO -     - accuracy: 0.3600
2025-07-29 20:26:21,355 - INFO -   kmmlu_criminal_law:
2025-07-29 20:26:21,355 - INFO -     - accuracy: 0.2650
2025-07-29 20:26:21,355 - INFO -   kmmlu_economics:
2025-07-29 20:26:21,355 - INFO -     - accuracy: 0.4385
2025-07-29 20:26:21,356 - INFO -   kmmlu_education:
2025-07-29 20:26:21,356 - INFO -     - accuracy: 0.5300
2025-07-29 20:26:21,356 - INFO -   kmmlu_korean_history:
2025-07-29 20:26:21,356 - INFO -     - accuracy: 0.3100
2025-07-29 20:26:21,356 - INFO -   kmmlu_law:
2025-07-29 20:26:21,356 - INFO -     - accuracy: 0.4190
2025-07-29 20:26:21,356 - INFO -   kmmlu_management:
2025-07-29 20:26:21,356 - INFO -     - accuracy: 0.4940
2025-07-29 20:26:21,356 - INFO -   kmmlu_political_science_and_sociology:
2025-07-29 20:26:21,356 - INFO -     - accuracy: 0.4933
2025-07-29 20:26:21,357 - INFO -   kmmlu_psychology:
2025-07-29 20:26:21,357 - INFO -     - accuracy: 0.4060
2025-07-29 20:26:21,357 - INFO -   kmmlu_social_welfare:
2025-07-29 20:26:21,357 - INFO -     - accuracy: 0.4990
2025-07-29 20:26:21,357 - INFO -   kmmlu_taxation:
2025-07-29 20:26:21,357 - INFO -     - accuracy: 0.3450
2025-07-29 20:26:21,357 - INFO -   kmmlu_other:
2025-07-29 20:26:21,357 - INFO -     - accuracy: 0.4433
2025-07-29 20:26:21,357 - INFO -   kmmlu_agricultural_sciences:
2025-07-29 20:26:21,358 - INFO -     - accuracy: 0.3680
2025-07-29 20:26:21,358 - INFO -   kmmlu_construction:
2025-07-29 20:26:21,358 - INFO -     - accuracy: 0.3750
2025-07-29 20:26:21,358 - INFO -   kmmlu_fashion:
2025-07-29 20:26:21,358 - INFO -     - accuracy: 0.4280
2025-07-29 20:26:21,358 - INFO -   kmmlu_food_processing:
2025-07-29 20:26:21,358 - INFO -     - accuracy: 0.3810
2025-07-29 20:26:21,358 - INFO -   kmmlu_health:
2025-07-29 20:26:21,358 - INFO -     - accuracy: 0.5200
2025-07-29 20:26:21,358 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-29 20:26:21,358 - INFO -     - accuracy: 0.5510
2025-07-29 20:26:21,359 - INFO -   kmmlu_marketing:
2025-07-29 20:26:21,359 - INFO -     - accuracy: 0.7130
2025-07-29 20:26:21,359 - INFO -   kmmlu_patent:
2025-07-29 20:26:21,359 - INFO -     - accuracy: 0.3600
2025-07-29 20:26:21,359 - INFO -   kmmlu_public_safety:
2025-07-29 20:26:21,359 - INFO -     - accuracy: 0.3870
2025-07-29 20:26:21,359 - INFO -   kmmlu_real_estate:
2025-07-29 20:26:21,359 - INFO -     - accuracy: 0.3950
2025-07-29 20:26:21,359 - INFO -   kmmlu_refrigerating_machinery:
2025-07-29 20:26:21,359 - INFO -     - accuracy: 0.3540
2025-07-29 20:26:21,360 - INFO -   kmmlu_stem:
2025-07-29 20:26:21,360 - INFO -     - accuracy: 0.4506
2025-07-29 20:26:21,360 - INFO -   kmmlu_biology:
2025-07-29 20:26:21,360 - INFO -     - accuracy: 0.3500
2025-07-29 20:26:21,360 - INFO -   kmmlu_chemical_engineering:
2025-07-29 20:26:21,360 - INFO -     - accuracy: 0.4530
2025-07-29 20:26:21,360 - INFO -   kmmlu_chemistry:
2025-07-29 20:26:21,360 - INFO -     - accuracy: 0.4200
2025-07-29 20:26:21,360 - INFO -   kmmlu_civil_engineering:
2025-07-29 20:26:21,361 - INFO -     - accuracy: 0.4040
2025-07-29 20:26:21,361 - INFO -   kmmlu_computer_science:
2025-07-29 20:26:21,361 - INFO -     - accuracy: 0.6480
2025-07-29 20:26:21,361 - INFO -   kmmlu_ecology:
2025-07-29 20:26:21,361 - INFO -     - accuracy: 0.4750
2025-07-29 20:26:21,361 - INFO -   kmmlu_electrical_engineering:
2025-07-29 20:26:21,361 - INFO -     - accuracy: 0.3520
2025-07-29 20:26:21,361 - INFO -   kmmlu_information_technology:
2025-07-29 20:26:21,361 - INFO -     - accuracy: 0.6370
2025-07-29 20:26:21,362 - INFO -   kmmlu_materials_engineering:
2025-07-29 20:26:21,362 - INFO -     - accuracy: 0.4240
2025-07-29 20:26:21,362 - INFO -   kmmlu_math:
2025-07-29 20:26:21,362 - INFO -     - accuracy: 0.2700
2025-07-29 20:26:21,362 - INFO -   kmmlu_mechanical_engineering:
2025-07-29 20:26:21,362 - INFO -     - accuracy: 0.3850
2025-07-29 20:26:21,362 - INFO - ============================================================

2025-07-29 20:26:21,392 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 2/10: kmmlu_hard
2025-07-29 20:26:21,396 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-29 20:26:21,399 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-29 20:26:21,399 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 20:27:36,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-29 20:27:36,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-29 20:27:36,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-29 20:27:36,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-29 20:27:36,090 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-29 20:27:36,091 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-29 20:27:36,092 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-29 20:27:36,093 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-29 20:27:36,094 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-29 20:27:36,094 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-29 20:27:36,094 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-29 20:27:36,094 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-29 20:27:36,094 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-29 20:27:36,094 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-29 20:27:36,094 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-29 20:42:15,126 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-29 20:42:15,128 - INFO - 
============================================================
2025-07-29 20:42:15,129 - INFO - Task 'kmmlu_hard' Results:
2025-07-29 20:42:15,130 - INFO - ============================================================
2025-07-29 20:42:15,130 - INFO -   kmmlu_hard:
2025-07-29 20:42:15,131 - INFO -     - accuracy: 0.2110
2025-07-29 20:42:15,131 - INFO -   kmmlu_hard_applied_science:
2025-07-29 20:42:15,133 - INFO -     - accuracy: 0.2117
2025-07-29 20:42:15,134 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-29 20:42:15,134 - INFO -     - accuracy: 0.1700
2025-07-29 20:42:15,134 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-29 20:42:15,134 - INFO -     - accuracy: 0.2100
2025-07-29 20:42:15,135 - INFO -   kmmlu_hard_energy_management:
2025-07-29 20:42:15,135 - INFO -     - accuracy: 0.2300
2025-07-29 20:42:15,135 - INFO -   kmmlu_hard_environmental_science:
2025-07-29 20:42:15,135 - INFO -     - accuracy: 0.1700
2025-07-29 20:42:15,135 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-29 20:42:15,135 - INFO -     - accuracy: 0.2100
2025-07-29 20:42:15,135 - INFO -   kmmlu_hard_geomatics:
2025-07-29 20:42:15,135 - INFO -     - accuracy: 0.2600
2025-07-29 20:42:15,135 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-29 20:42:15,135 - INFO -     - accuracy: 0.1700
2025-07-29 20:42:15,136 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-29 20:42:15,136 - INFO -     - accuracy: 0.2500
2025-07-29 20:42:15,136 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-29 20:42:15,136 - INFO -     - accuracy: 0.1800
2025-07-29 20:42:15,136 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-29 20:42:15,136 - INFO -     - accuracy: 0.2400
2025-07-29 20:42:15,136 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-29 20:42:15,136 - INFO -     - accuracy: 0.2000
2025-07-29 20:42:15,136 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-29 20:42:15,136 - INFO -     - accuracy: 0.2500
2025-07-29 20:42:15,137 - INFO -   kmmlu_hard_humss:
2025-07-29 20:42:15,137 - INFO -     - accuracy: 0.1986
2025-07-29 20:42:15,137 - INFO -   kmmlu_hard_accounting:
2025-07-29 20:42:15,137 - INFO -     - accuracy: 0.1522
2025-07-29 20:42:15,137 - INFO -   kmmlu_hard_criminal_law:
2025-07-29 20:42:15,137 - INFO -     - accuracy: 0.1400
2025-07-29 20:42:15,137 - INFO -   kmmlu_hard_economics:
2025-07-29 20:42:15,137 - INFO -     - accuracy: 0.2381
2025-07-29 20:42:15,137 - INFO -   kmmlu_hard_education:
2025-07-29 20:42:15,137 - INFO -     - accuracy: 0.2609
2025-07-29 20:42:15,137 - INFO -   kmmlu_hard_korean_history:
2025-07-29 20:42:15,138 - INFO -     - accuracy: 0.1591
2025-07-29 20:42:15,138 - INFO -   kmmlu_hard_law:
2025-07-29 20:42:15,138 - INFO -     - accuracy: 0.1900
2025-07-29 20:42:15,138 - INFO -   kmmlu_hard_management:
2025-07-29 20:42:15,138 - INFO -     - accuracy: 0.2400
2025-07-29 20:42:15,138 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-29 20:42:15,138 - INFO -     - accuracy: 0.1889
2025-07-29 20:42:15,138 - INFO -   kmmlu_hard_psychology:
2025-07-29 20:42:15,138 - INFO -     - accuracy: 0.1100
2025-07-29 20:42:15,138 - INFO -   kmmlu_hard_social_welfare:
2025-07-29 20:42:15,139 - INFO -     - accuracy: 0.3800
2025-07-29 20:42:15,139 - INFO -   kmmlu_hard_taxation:
2025-07-29 20:42:15,139 - INFO -     - accuracy: 0.1458
2025-07-29 20:42:15,139 - INFO -   kmmlu_hard_other:
2025-07-29 20:42:15,139 - INFO -     - accuracy: 0.2150
2025-07-29 20:42:15,139 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-29 20:42:15,139 - INFO -     - accuracy: 0.2100
2025-07-29 20:42:15,139 - INFO -   kmmlu_hard_construction:
2025-07-29 20:42:15,139 - INFO -     - accuracy: 0.2100
2025-07-29 20:42:15,139 - INFO -   kmmlu_hard_fashion:
2025-07-29 20:42:15,139 - INFO -     - accuracy: 0.2300
2025-07-29 20:42:15,140 - INFO -   kmmlu_hard_food_processing:
2025-07-29 20:42:15,140 - INFO -     - accuracy: 0.2000
2025-07-29 20:42:15,140 - INFO -   kmmlu_hard_health:
2025-07-29 20:42:15,140 - INFO -     - accuracy: 0.1304
2025-07-29 20:42:15,140 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-29 20:42:15,140 - INFO -     - accuracy: 0.2700
2025-07-29 20:42:15,140 - INFO -   kmmlu_hard_marketing:
2025-07-29 20:42:15,140 - INFO -     - accuracy: 0.2300
2025-07-29 20:42:15,140 - INFO -   kmmlu_hard_patent:
2025-07-29 20:42:15,140 - INFO -     - accuracy: 0.2353
2025-07-29 20:42:15,141 - INFO -   kmmlu_hard_public_safety:
2025-07-29 20:42:15,141 - INFO -     - accuracy: 0.2100
2025-07-29 20:42:15,141 - INFO -   kmmlu_hard_real_estate:
2025-07-29 20:42:15,141 - INFO -     - accuracy: 0.1685
2025-07-29 20:42:15,141 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-29 20:42:15,141 - INFO -     - accuracy: 0.2100
2025-07-29 20:42:15,141 - INFO -   kmmlu_hard_stem:
2025-07-29 20:42:15,141 - INFO -     - accuracy: 0.2164
2025-07-29 20:42:15,141 - INFO -   kmmlu_hard_biology:
2025-07-29 20:42:15,141 - INFO -     - accuracy: 0.1500
2025-07-29 20:42:15,141 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-29 20:42:15,142 - INFO -     - accuracy: 0.2300
2025-07-29 20:42:15,142 - INFO -   kmmlu_hard_chemistry:
2025-07-29 20:42:15,142 - INFO -     - accuracy: 0.2100
2025-07-29 20:42:15,142 - INFO -   kmmlu_hard_civil_engineering:
2025-07-29 20:42:15,142 - INFO -     - accuracy: 0.2000
2025-07-29 20:42:15,142 - INFO -   kmmlu_hard_computer_science:
2025-07-29 20:42:15,142 - INFO -     - accuracy: 0.1900
2025-07-29 20:42:15,142 - INFO -   kmmlu_hard_ecology:
2025-07-29 20:42:15,142 - INFO -     - accuracy: 0.2100
2025-07-29 20:42:15,142 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-29 20:42:15,143 - INFO -     - accuracy: 0.2300
2025-07-29 20:42:15,143 - INFO -   kmmlu_hard_information_technology:
2025-07-29 20:42:15,143 - INFO -     - accuracy: 0.2700
2025-07-29 20:42:15,143 - INFO -   kmmlu_hard_materials_engineering:
2025-07-29 20:42:15,143 - INFO -     - accuracy: 0.2400
2025-07-29 20:42:15,143 - INFO -   kmmlu_hard_math:
2025-07-29 20:42:15,143 - INFO -     - accuracy: 0.2100
2025-07-29 20:42:15,143 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-29 20:42:15,143 - INFO -     - accuracy: 0.2400
2025-07-29 20:42:15,143 - INFO - ============================================================

2025-07-29 20:42:15,172 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 3/10: haerae
2025-07-29 20:42:15,173 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'haerae' will use num_fewshot=5
2025-07-29 20:42:15,174 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'haerae' with num_fewshot=5
2025-07-29 20:42:15,175 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 20:42:34,572 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-29 20:42:34,573 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-29 20:42:34,573 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-29 20:42:34,573 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-29 20:42:34,573 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-29 21:00:10,457 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'haerae' with 6 subtasks
2025-07-29 21:00:10,459 - INFO - 
============================================================
2025-07-29 21:00:10,461 - INFO - Task 'haerae' Results:
2025-07-29 21:00:10,462 - INFO - ============================================================
2025-07-29 21:00:10,463 - INFO -   haerae:
2025-07-29 21:00:10,463 - INFO -     - accuracy: 0.6618
2025-07-29 21:00:10,463 - INFO -     - accuracy_norm: 0.6618
2025-07-29 21:00:10,463 - INFO -   haerae_general_knowledge:
2025-07-29 21:00:10,464 - INFO -     - accuracy: 0.3864
2025-07-29 21:00:10,464 - INFO -     - accuracy_norm: 0.3864
2025-07-29 21:00:10,464 - INFO -   haerae_history:
2025-07-29 21:00:10,464 - INFO -     - accuracy: 0.6543
2025-07-29 21:00:10,464 - INFO -     - accuracy_norm: 0.6543
2025-07-29 21:00:10,464 - INFO -   haerae_loan_word:
2025-07-29 21:00:10,465 - INFO -     - accuracy: 0.7870
2025-07-29 21:00:10,465 - INFO -     - accuracy_norm: 0.7870
2025-07-29 21:00:10,466 - INFO -   haerae_rare_word:
2025-07-29 21:00:10,466 - INFO -     - accuracy: 0.7012
2025-07-29 21:00:10,466 - INFO -     - accuracy_norm: 0.7012
2025-07-29 21:00:10,466 - INFO -   haerae_standard_nomenclature:
2025-07-29 21:00:10,466 - INFO -     - accuracy: 0.7451
2025-07-29 21:00:10,466 - INFO -     - accuracy_norm: 0.7451
2025-07-29 21:00:10,466 - INFO - ============================================================

2025-07-29 21:00:10,492 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 4/10: kobest
2025-07-29 21:00:10,494 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kobest' will use num_fewshot=5
2025-07-29 21:00:10,494 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kobest' with num_fewshot=5
2025-07-29 21:00:10,495 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 21:00:31,520 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-29 21:00:31,521 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-29 21:00:31,521 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-29 21:00:31,521 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-29 21:00:31,521 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-29 21:25:01,596 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kobest' with 6 subtasks
2025-07-29 21:25:01,599 - INFO - 
============================================================
2025-07-29 21:25:01,601 - INFO - Task 'kobest' Results:
2025-07-29 21:25:01,602 - INFO - ============================================================
2025-07-29 21:25:01,602 - INFO -   kobest:
2025-07-29 21:25:01,602 - INFO -     - accuracy: 0.7492
2025-07-29 21:25:01,602 - INFO -     - accuracy_norm: 0.5780
2025-07-29 21:25:01,603 - INFO -     - f1: 0.7485
2025-07-29 21:25:01,603 - INFO -   kobest_boolq:
2025-07-29 21:25:01,603 - INFO -     - accuracy: 0.8754
2025-07-29 21:25:01,603 - INFO -     - f1: 0.8753
2025-07-29 21:25:01,603 - INFO -   kobest_copa:
2025-07-29 21:25:01,603 - INFO -     - accuracy: 0.7700
2025-07-29 21:25:01,603 - INFO -     - f1: 0.7696
2025-07-29 21:25:01,604 - INFO -   kobest_hellaswag:
2025-07-29 21:25:01,604 - INFO -     - accuracy: 0.4540
2025-07-29 21:25:01,604 - INFO -     - accuracy_norm: 0.5780
2025-07-29 21:25:01,604 - INFO -     - f1: 0.4518
2025-07-29 21:25:01,604 - INFO -   kobest_sentineg:
2025-07-29 21:25:01,604 - INFO -     - accuracy: 0.9849
2025-07-29 21:25:01,604 - INFO -     - f1: 0.9849
2025-07-29 21:25:01,604 - INFO -   kobest_wic:
2025-07-29 21:25:01,604 - INFO -     - accuracy: 0.6349
2025-07-29 21:25:01,604 - INFO -     - f1: 0.6339
2025-07-29 21:25:01,605 - INFO - ============================================================

2025-07-29 21:25:01,631 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 5/10: csatqa
2025-07-29 21:25:01,633 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'csatqa' detected as zero-shot task
2025-07-29 21:25:01,633 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'csatqa' with num_fewshot=0
2025-07-29 21:25:01,634 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 21:25:16,412 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-29 21:25:16,412 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-29 21:25:16,412 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-29 21:25:16,412 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-29 21:25:16,412 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-29 21:25:16,412 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-29 21:31:14,964 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'csatqa' with 7 subtasks
2025-07-29 21:31:14,967 - INFO - 
============================================================
2025-07-29 21:31:14,968 - INFO - Task 'csatqa' Results:
2025-07-29 21:31:14,970 - INFO - ============================================================
2025-07-29 21:31:14,970 - INFO -   csatqa:
2025-07-29 21:31:14,970 - INFO -     - accuracy: 0.3743
2025-07-29 21:31:14,971 - INFO -     - accuracy_norm: 0.3743
2025-07-29 21:31:14,971 - INFO -   csatqa_gr:
2025-07-29 21:31:14,971 - INFO -     - accuracy: 0.0800
2025-07-29 21:31:14,971 - INFO -     - accuracy_norm: 0.0800
2025-07-29 21:31:14,971 - INFO -   csatqa_li:
2025-07-29 21:31:14,971 - INFO -     - accuracy: 0.4054
2025-07-29 21:31:14,971 - INFO -     - accuracy_norm: 0.4054
2025-07-29 21:31:14,972 - INFO -   csatqa_rch:
2025-07-29 21:31:14,972 - INFO -     - accuracy: 0.5714
2025-07-29 21:31:14,972 - INFO -     - accuracy_norm: 0.5714
2025-07-29 21:31:14,972 - INFO -   csatqa_rcs:
2025-07-29 21:31:14,972 - INFO -     - accuracy: 0.3243
2025-07-29 21:31:14,972 - INFO -     - accuracy_norm: 0.3243
2025-07-29 21:31:14,972 - INFO -   csatqa_rcss:
2025-07-29 21:31:14,972 - INFO -     - accuracy: 0.4286
2025-07-29 21:31:14,972 - INFO -     - accuracy_norm: 0.4286
2025-07-29 21:31:14,972 - INFO -   csatqa_wr:
2025-07-29 21:31:14,972 - INFO -     - accuracy: 0.2727
2025-07-29 21:31:14,973 - INFO -     - accuracy_norm: 0.2727
2025-07-29 21:31:14,973 - INFO - ============================================================

2025-07-29 21:31:15,005 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 6/10: kormedmcqa
2025-07-29 21:31:15,006 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'kormedmcqa' will use num_fewshot=5
2025-07-29 21:31:15,007 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-29 21:31:15,007 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 21:31:43,375 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-29 21:31:43,375 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-29 21:31:43,375 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-29 21:31:43,375 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
2025-07-29 21:46:07,000 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-29 21:46:07,002 - INFO - 
============================================================
2025-07-29 21:46:07,004 - INFO - Task 'kormedmcqa' Results:
2025-07-29 21:46:07,005 - INFO - ============================================================
2025-07-29 21:46:07,006 - INFO -   kormedmcqa:
2025-07-29 21:46:07,006 - INFO -     - exact_match: 0.4842
2025-07-29 21:46:07,007 - INFO -   kormedmcqa_dentist:
2025-07-29 21:46:07,008 - INFO -     - exact_match: 0.4057
2025-07-29 21:46:07,008 - INFO -   kormedmcqa_doctor:
2025-07-29 21:46:07,008 - INFO -     - exact_match: 0.4345
2025-07-29 21:46:07,008 - INFO -   kormedmcqa_nurse:
2025-07-29 21:46:07,009 - INFO -     - exact_match: 0.6002
2025-07-29 21:46:07,009 - INFO -   kormedmcqa_pharm:
2025-07-29 21:46:07,009 - INFO -     - exact_match: 0.4655
2025-07-29 21:46:07,009 - INFO - ============================================================

2025-07-29 21:46:07,034 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 7/10: mmlu
2025-07-29 21:46:07,036 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'mmlu' will use num_fewshot=5
2025-07-29 21:46:07,036 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'mmlu' with num_fewshot=5
2025-07-29 21:46:07,037 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 21:48:49,710 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5
2025-07-29 21:48:49,710 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5
2025-07-29 21:48:49,711 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 5
2025-07-29 21:48:49,711 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5
2025-07-29 21:48:49,711 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5
2025-07-29 21:48:49,711 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 5
2025-07-29 21:48:49,711 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 5
2025-07-29 21:48:49,711 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5
2025-07-29 21:48:49,711 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 5
2025-07-29 21:48:49,712 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 5
2025-07-29 21:48:49,712 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 5
2025-07-29 21:48:49,712 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 5
2025-07-29 21:48:49,712 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 5
2025-07-29 21:48:49,712 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5
2025-07-29 21:48:49,712 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5
2025-07-29 21:48:49,712 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 5
2025-07-29 21:48:49,712 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 5
2025-07-29 21:48:49,713 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5
2025-07-29 21:48:49,713 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 5
2025-07-29 21:48:49,713 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 5
2025-07-29 21:48:49,713 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 5
2025-07-29 21:48:49,713 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 5
2025-07-29 21:48:49,713 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 5
2025-07-29 21:48:49,713 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 5
2025-07-29 21:48:49,713 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 5
2025-07-29 21:48:49,714 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 5
2025-07-29 21:48:49,714 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 5
2025-07-29 21:48:49,714 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 5
2025-07-29 21:48:49,714 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 5
2025-07-29 21:48:49,714 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 5
2025-07-29 21:48:49,714 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 5
2025-07-29 21:48:49,714 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5
2025-07-29 21:48:49,714 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5
2025-07-29 21:48:49,715 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5
2025-07-29 21:48:49,715 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5
2025-07-29 21:48:49,715 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 5
2025-07-29 21:48:49,715 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 5
2025-07-29 21:48:49,715 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 5
2025-07-29 21:48:49,715 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 5
2025-07-29 21:48:49,715 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 5
2025-07-29 21:48:49,715 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 5
2025-07-29 21:48:49,716 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 5
2025-07-29 21:48:49,716 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5
2025-07-29 21:48:49,716 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5
2025-07-29 21:48:49,716 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 5
2025-07-29 21:48:49,716 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 5
2025-07-29 21:48:49,716 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5
2025-07-29 21:48:49,716 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5
2025-07-29 21:48:49,716 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 5
2025-07-29 21:48:49,717 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 5
2025-07-29 21:48:49,717 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5
2025-07-29 21:48:49,717 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 5
2025-07-29 21:48:49,717 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 5
2025-07-29 21:48:49,717 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5
2025-07-29 21:48:49,717 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 5
2025-07-29 21:48:49,717 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 5
2025-07-29 21:48:49,717 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5
2025-07-29 22:51:03,508 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'mmlu' with 62 subtasks
2025-07-29 22:51:03,509 - INFO - 
============================================================
2025-07-29 22:51:03,511 - INFO - Task 'mmlu' Results:
2025-07-29 22:51:03,514 - INFO - ============================================================
2025-07-29 22:51:03,514 - INFO -   mmlu:
2025-07-29 22:51:03,514 - INFO -     - accuracy: 0.5914
2025-07-29 22:51:03,514 - INFO -   mmlu_humanities:
2025-07-29 22:51:03,514 - INFO -     - accuracy: 0.5356
2025-07-29 22:51:03,514 - INFO -   mmlu_formal_logic:
2025-07-29 22:51:03,515 - INFO -     - accuracy: 0.3889
2025-07-29 22:51:03,515 - INFO -   mmlu_high_school_european_history:
2025-07-29 22:51:03,515 - INFO -     - accuracy: 0.7273
2025-07-29 22:51:03,515 - INFO -   mmlu_high_school_us_history:
2025-07-29 22:51:03,515 - INFO -     - accuracy: 0.7157
2025-07-29 22:51:03,515 - INFO -   mmlu_high_school_world_history:
2025-07-29 22:51:03,515 - INFO -     - accuracy: 0.7679
2025-07-29 22:51:03,515 - INFO -   mmlu_international_law:
2025-07-29 22:51:03,515 - INFO -     - accuracy: 0.7521
2025-07-29 22:51:03,516 - INFO -   mmlu_jurisprudence:
2025-07-29 22:51:03,516 - INFO -     - accuracy: 0.7130
2025-07-29 22:51:03,516 - INFO -   mmlu_logical_fallacies:
2025-07-29 22:51:03,516 - INFO -     - accuracy: 0.6933
2025-07-29 22:51:03,516 - INFO -   mmlu_moral_disputes:
2025-07-29 22:51:03,516 - INFO -     - accuracy: 0.6243
2025-07-29 22:51:03,516 - INFO -   mmlu_moral_scenarios:
2025-07-29 22:51:03,516 - INFO -     - accuracy: 0.3464
2025-07-29 22:51:03,516 - INFO -   mmlu_philosophy:
2025-07-29 22:51:03,516 - INFO -     - accuracy: 0.6399
2025-07-29 22:51:03,517 - INFO -   mmlu_prehistory:
2025-07-29 22:51:03,517 - INFO -     - accuracy: 0.6605
2025-07-29 22:51:03,517 - INFO -   mmlu_professional_law:
2025-07-29 22:51:03,517 - INFO -     - accuracy: 0.4452
2025-07-29 22:51:03,517 - INFO -   mmlu_world_religions:
2025-07-29 22:51:03,517 - INFO -     - accuracy: 0.7018
2025-07-29 22:51:03,517 - INFO -   mmlu_other:
2025-07-29 22:51:03,517 - INFO -     - accuracy: 0.6373
2025-07-29 22:51:03,517 - INFO -   mmlu_business_ethics:
2025-07-29 22:51:03,517 - INFO -     - accuracy: 0.6000
2025-07-29 22:51:03,518 - INFO -   mmlu_clinical_knowledge:
2025-07-29 22:51:03,518 - INFO -     - accuracy: 0.6830
2025-07-29 22:51:03,518 - INFO -   mmlu_college_medicine:
2025-07-29 22:51:03,518 - INFO -     - accuracy: 0.5838
2025-07-29 22:51:03,518 - INFO -   mmlu_global_facts:
2025-07-29 22:51:03,518 - INFO -     - accuracy: 0.3300
2025-07-29 22:51:03,518 - INFO -   mmlu_human_aging:
2025-07-29 22:51:03,518 - INFO -     - accuracy: 0.6771
2025-07-29 22:51:03,518 - INFO -   mmlu_management:
2025-07-29 22:51:03,518 - INFO -     - accuracy: 0.7573
2025-07-29 22:51:03,519 - INFO -   mmlu_marketing:
2025-07-29 22:51:03,519 - INFO -     - accuracy: 0.8248
2025-07-29 22:51:03,519 - INFO -   mmlu_medical_genetics:
2025-07-29 22:51:03,519 - INFO -     - accuracy: 0.6600
2025-07-29 22:51:03,519 - INFO -   mmlu_miscellaneous:
2025-07-29 22:51:03,519 - INFO -     - accuracy: 0.7420
2025-07-29 22:51:03,519 - INFO -   mmlu_nutrition:
2025-07-29 22:51:03,519 - INFO -     - accuracy: 0.6373
2025-07-29 22:51:03,519 - INFO -   mmlu_professional_accounting:
2025-07-29 22:51:03,519 - INFO -     - accuracy: 0.4574
2025-07-29 22:51:03,519 - INFO -   mmlu_professional_medicine:
2025-07-29 22:51:03,520 - INFO -     - accuracy: 0.4816
2025-07-29 22:51:03,520 - INFO -   mmlu_virology:
2025-07-29 22:51:03,520 - INFO -     - accuracy: 0.4880
2025-07-29 22:51:03,520 - INFO -   mmlu_social_sciences:
2025-07-29 22:51:03,520 - INFO -     - accuracy: 0.6841
2025-07-29 22:51:03,520 - INFO -   mmlu_econometrics:
2025-07-29 22:51:03,520 - INFO -     - accuracy: 0.3860
2025-07-29 22:51:03,520 - INFO -   mmlu_high_school_geography:
2025-07-29 22:51:03,520 - INFO -     - accuracy: 0.7424
2025-07-29 22:51:03,521 - INFO -   mmlu_high_school_government_and_politics:
2025-07-29 22:51:03,521 - INFO -     - accuracy: 0.7720
2025-07-29 22:51:03,521 - INFO -   mmlu_high_school_macroeconomics:
2025-07-29 22:51:03,521 - INFO -     - accuracy: 0.6308
2025-07-29 22:51:03,521 - INFO -   mmlu_high_school_microeconomics:
2025-07-29 22:51:03,521 - INFO -     - accuracy: 0.6807
2025-07-29 22:51:03,521 - INFO -   mmlu_high_school_psychology:
2025-07-29 22:51:03,521 - INFO -     - accuracy: 0.7743
2025-07-29 22:51:03,521 - INFO -   mmlu_human_sexuality:
2025-07-29 22:51:03,522 - INFO -     - accuracy: 0.7023
2025-07-29 22:51:03,522 - INFO -   mmlu_professional_psychology:
2025-07-29 22:51:03,522 - INFO -     - accuracy: 0.5964
2025-07-29 22:51:03,522 - INFO -   mmlu_public_relations:
2025-07-29 22:51:03,522 - INFO -     - accuracy: 0.5636
2025-07-29 22:51:03,522 - INFO -   mmlu_security_studies:
2025-07-29 22:51:03,522 - INFO -     - accuracy: 0.7510
2025-07-29 22:51:03,522 - INFO -   mmlu_sociology:
2025-07-29 22:51:03,522 - INFO -     - accuracy: 0.7662
2025-07-29 22:51:03,523 - INFO -   mmlu_us_foreign_policy:
2025-07-29 22:51:03,523 - INFO -     - accuracy: 0.7800
2025-07-29 22:51:03,523 - INFO -   mmlu_stem:
2025-07-29 22:51:03,523 - INFO -     - accuracy: 0.5389
2025-07-29 22:51:03,523 - INFO -   mmlu_abstract_algebra:
2025-07-29 22:51:03,523 - INFO -     - accuracy: 0.3500
2025-07-29 22:51:03,523 - INFO -   mmlu_anatomy:
2025-07-29 22:51:03,523 - INFO -     - accuracy: 0.4963
2025-07-29 22:51:03,593 - INFO -   mmlu_astronomy:
2025-07-29 22:51:03,593 - INFO -     - accuracy: 0.6711
2025-07-29 22:51:03,593 - INFO -   mmlu_college_biology:
2025-07-29 22:51:03,593 - INFO -     - accuracy: 0.6736
2025-07-29 22:51:03,593 - INFO -   mmlu_college_chemistry:
2025-07-29 22:51:03,593 - INFO -     - accuracy: 0.4400
2025-07-29 22:51:03,593 - INFO -   mmlu_college_computer_science:
2025-07-29 22:51:03,593 - INFO -     - accuracy: 0.4700
2025-07-29 22:51:03,593 - INFO -   mmlu_college_mathematics:
2025-07-29 22:51:03,594 - INFO -     - accuracy: 0.3800
2025-07-29 22:51:03,594 - INFO -   mmlu_college_physics:
2025-07-29 22:51:03,594 - INFO -     - accuracy: 0.3333
2025-07-29 22:51:03,594 - INFO -   mmlu_computer_security:
2025-07-29 22:51:03,594 - INFO -     - accuracy: 0.7100
2025-07-29 22:51:03,594 - INFO -   mmlu_conceptual_physics:
2025-07-29 22:51:03,594 - INFO -     - accuracy: 0.5489
2025-07-29 22:51:03,594 - INFO -   mmlu_electrical_engineering:
2025-07-29 22:51:03,594 - INFO -     - accuracy: 0.5655
2025-07-29 22:51:03,595 - INFO -   mmlu_elementary_mathematics:
2025-07-29 22:51:03,595 - INFO -     - accuracy: 0.5026
2025-07-29 22:51:03,595 - INFO -   mmlu_high_school_biology:
2025-07-29 22:51:03,595 - INFO -     - accuracy: 0.7516
2025-07-29 22:51:03,595 - INFO -   mmlu_high_school_chemistry:
2025-07-29 22:51:03,595 - INFO -     - accuracy: 0.5517
2025-07-29 22:51:03,595 - INFO -   mmlu_high_school_computer_science:
2025-07-29 22:51:03,595 - INFO -     - accuracy: 0.6900
2025-07-29 22:51:03,595 - INFO -   mmlu_high_school_mathematics:
2025-07-29 22:51:03,596 - INFO -     - accuracy: 0.4259
2025-07-29 22:51:03,596 - INFO -   mmlu_high_school_physics:
2025-07-29 22:51:03,596 - INFO -     - accuracy: 0.3974
2025-07-29 22:51:03,596 - INFO -   mmlu_high_school_statistics:
2025-07-29 22:51:03,596 - INFO -     - accuracy: 0.5741
2025-07-29 22:51:03,596 - INFO -   mmlu_machine_learning:
2025-07-29 22:51:03,596 - INFO -     - accuracy: 0.4464
2025-07-29 22:51:03,596 - INFO - ============================================================

2025-07-29 22:51:03,632 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 8/10: arc_challenge
2025-07-29 22:51:03,636 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'arc_challenge' will use num_fewshot=5
2025-07-29 22:51:03,636 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'arc_challenge' with num_fewshot=5
2025-07-29 22:51:03,637 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 22:51:13,075 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 5
2025-07-29 22:57:37,159 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-29 22:57:37,160 - INFO - 
============================================================
2025-07-29 22:57:37,161 - INFO - Task 'arc_challenge' Results:
2025-07-29 22:57:37,162 - INFO - ============================================================
2025-07-29 22:57:37,163 - INFO -   arc_challenge:
2025-07-29 22:57:37,163 - INFO -     - accuracy: 0.5068
2025-07-29 22:57:37,163 - INFO -     - accuracy_norm: 0.5427
2025-07-29 22:57:37,164 - INFO - ============================================================

2025-07-29 22:57:37,189 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 9/10: arc_easy
2025-07-29 22:57:37,191 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'arc_easy' will use num_fewshot=5
2025-07-29 22:57:37,192 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'arc_easy' with num_fewshot=5
2025-07-29 22:57:37,193 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 22:57:46,402 - WARNING - Overwriting default num_fewshot of arc_easy from None to 5
2025-07-29 23:08:16,253 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-29 23:08:16,255 - INFO - 
============================================================
2025-07-29 23:08:16,257 - INFO - Task 'arc_easy' Results:
2025-07-29 23:08:16,258 - INFO - ============================================================
2025-07-29 23:08:16,258 - INFO -   arc_easy:
2025-07-29 23:08:16,258 - INFO -     - accuracy: 0.7727
2025-07-29 23:08:16,259 - INFO -     - accuracy_norm: 0.7664
2025-07-29 23:08:16,259 - INFO - ============================================================

2025-07-29 23:08:16,285 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Processing task 10/10: hellaswag
2025-07-29 23:08:16,286 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Task 'hellaswag' will use num_fewshot=5
2025-07-29 23:08:16,287 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Evaluating task 'hellaswag' with num_fewshot=5
2025-07-29 23:08:16,287 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-29 23:08:31,365 - WARNING - Overwriting default num_fewshot of hellaswag from None to 5
2025-07-30 01:02:14,078 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-30 01:02:14,080 - INFO - 
============================================================
2025-07-30 01:02:14,081 - INFO - Task 'hellaswag' Results:
2025-07-30 01:02:14,083 - INFO - ============================================================
2025-07-30 01:02:14,085 - INFO -   hellaswag:
2025-07-30 01:02:14,085 - INFO -     - accuracy: 0.5403
2025-07-30 01:02:14,085 - INFO -     - accuracy_norm: 0.7225
2025-07-30 01:02:14,085 - INFO - ============================================================

2025-07-30 01:02:14,110 - INFO - EXAONE-3.5-2.4B-Instruct_harness_7: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-30 01:02:14,114 - INFO - [Process 2120894] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/EXAONE-3.5-2.4B-Instruct/EXAONE-3.5-2.4B-Instruct_harness_7.json
2025-07-30 01:02:14,382 - INFO - Results uploaded to WandB as artifact
2025-07-30 01:02:14,391 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-30 01:02:14,393 - INFO - [Process 2120894] Successfully completed EXAONE-3.5-2.4B-Instruct_harness_7
2025-07-30 01:02:17,711 - INFO - Run EXAONE-3.5-2.4B-Instruct_harness_7 finished successfully
2025-07-30 01:02:17,712 - INFO - [Process 2120894] HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9 assigned to cuda:0
2025-07-30 01:02:17,712 - INFO - [Process 2120894] HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9 - full_run: True, limit: None (full dataset)
2025-07-30 01:02:18,760 - INFO - WandB run initialized: HyperCLOVAX-SEED-Text-Instruct-1.5B_20250730_010217 (ID: 71bd7739)
2025-07-30 01:02:19,631 - ERROR - [Process 2120894] Error in HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9: 401 Client Error. (Request ID: Root=1-68896f1b-59b01f6005fdf22e1732506e;430e6fdc-103b-4a0d-833f-5ea4969ef9c9)

Cannot access gated repo for url https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes.
Access to model naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B is restricted. You must have access to it and be authenticated to access it. Please log in.
Traceback (most recent call last):
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/gwlee/Benchmark/AIDE_Benchmark/code/core/evaluation_lm.py", line 630, in evaluate_single
    local_path = ensure_model_local(model_id)
  File "/home/gwlee/Benchmark/AIDE_Benchmark/code/core/evaluation_lm.py", line 149, in ensure_model_local
    local_path = snapshot_download(repo_id=repo_id, cache_dir=cache_dir, local_files_only=False)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py", line 296, in snapshot_download
    thread_map(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/tqdm/contrib/concurrent.py", line 69, in thread_map
    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/tqdm/contrib/concurrent.py", line 51, in _executor_map
    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 621, in result_iterator
    yield _result_or_cancel(fs.pop())
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 319, in _result_or_cancel
    return fut.result(timeout)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/_snapshot_download.py", line 270, in _inner_hf_hub_download
    return hf_hub_download(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "/home/gwlee/miniconda3/envs/science/lib/python3.10/site-packages/huggingface_hub/utils/_http.py", line 426, in hf_raise_for_status
    raise _format(GatedRepoError, message, response) from e
huggingface_hub.errors.GatedRepoError: 401 Client Error. (Request ID: Root=1-68896f1b-59b01f6005fdf22e1732506e;430e6fdc-103b-4a0d-833f-5ea4969ef9c9)

Cannot access gated repo for url https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes.
Access to model naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-07-30 01:02:20,854 - ERROR - Run HyperCLOVAX-SEED-Text-Instruct-1.5B_harness_9 failed: 401 Client Error. (Request ID: Root=1-68896f1b-59b01f6005fdf22e1732506e;430e6fdc-103b-4a0d-833f-5ea4969ef9c9)

Cannot access gated repo for url https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B/resolve/1ae9d346994979a4a1b58b7d312008dce449ba40/.gitattributes.
Access to model naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-1.5B is restricted. You must have access to it and be authenticated to access it. Please log in.
2025-07-30 01:02:20,855 - INFO - [Process 2120894] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10 assigned to cuda:0
2025-07-30 01:02:20,855 - INFO - [Process 2120894] HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10 - full_run: True, limit: None (full dataset)
2025-07-30 01:02:22,259 - INFO - WandB run initialized: HyperCLOVAX-SEED-Text-Instruct-0.5B_20250730_010220 (ID: f06132cd)
2025-07-30 01:02:22,468 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 1/10: kmmlu
2025-07-30 01:02:22,469 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kmmlu' will use num_fewshot=5
2025-07-30 01:02:22,469 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-30 01:02:22,469 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 01:03:30,775 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-30 01:03:30,776 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-30 01:03:30,776 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-30 01:03:30,776 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-30 01:03:30,776 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-30 01:03:30,776 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-30 01:03:30,776 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-30 01:03:30,776 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-30 01:03:30,777 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-30 01:03:30,778 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-30 01:03:30,779 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-30 01:03:30,780 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-30 01:03:30,780 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-30 01:03:30,780 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-30 01:03:30,780 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-30 01:26:24,715 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-30 01:26:24,717 - INFO - 
============================================================
2025-07-30 01:26:24,718 - INFO - Task 'kmmlu' Results:
2025-07-30 01:26:24,718 - INFO - ============================================================
2025-07-30 01:26:24,719 - INFO -   kmmlu:
2025-07-30 01:26:24,721 - INFO -     - accuracy: 0.3789
2025-07-30 01:26:24,721 - INFO -   kmmlu_applied_science:
2025-07-30 01:26:24,721 - INFO -     - accuracy: 0.3753
2025-07-30 01:26:24,721 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-30 01:26:24,721 - INFO -     - accuracy: 0.3510
2025-07-30 01:26:24,722 - INFO -   kmmlu_electronics_engineering:
2025-07-30 01:26:24,722 - INFO -     - accuracy: 0.4410
2025-07-30 01:26:24,722 - INFO -   kmmlu_energy_management:
2025-07-30 01:26:24,722 - INFO -     - accuracy: 0.2940
2025-07-30 01:26:24,722 - INFO -   kmmlu_environmental_science:
2025-07-30 01:26:24,722 - INFO -     - accuracy: 0.3130
2025-07-30 01:26:24,722 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-30 01:26:24,722 - INFO -     - accuracy: 0.3550
2025-07-30 01:26:24,722 - INFO -   kmmlu_geomatics:
2025-07-30 01:26:24,722 - INFO -     - accuracy: 0.3740
2025-07-30 01:26:24,723 - INFO -   kmmlu_industrial_engineer:
2025-07-30 01:26:24,723 - INFO -     - accuracy: 0.3790
2025-07-30 01:26:24,723 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-30 01:26:24,723 - INFO -     - accuracy: 0.3950
2025-07-30 01:26:24,723 - INFO -   kmmlu_maritime_engineering:
2025-07-30 01:26:24,723 - INFO -     - accuracy: 0.3883
2025-07-30 01:26:24,723 - INFO -   kmmlu_nondestructive_testing:
2025-07-30 01:26:24,723 - INFO -     - accuracy: 0.4020
2025-07-30 01:26:24,723 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-30 01:26:24,723 - INFO -     - accuracy: 0.3150
2025-07-30 01:26:24,724 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-30 01:26:24,724 - INFO -     - accuracy: 0.5010
2025-07-30 01:26:24,724 - INFO -   kmmlu_humss:
2025-07-30 01:26:24,724 - INFO -     - accuracy: 0.3690
2025-07-30 01:26:24,724 - INFO -   kmmlu_accounting:
2025-07-30 01:26:24,724 - INFO -     - accuracy: 0.3200
2025-07-30 01:26:24,724 - INFO -   kmmlu_criminal_law:
2025-07-30 01:26:24,724 - INFO -     - accuracy: 0.3400
2025-07-30 01:26:24,724 - INFO -   kmmlu_economics:
2025-07-30 01:26:24,724 - INFO -     - accuracy: 0.3846
2025-07-30 01:26:24,725 - INFO -   kmmlu_education:
2025-07-30 01:26:24,725 - INFO -     - accuracy: 0.3700
2025-07-30 01:26:24,725 - INFO -   kmmlu_korean_history:
2025-07-30 01:26:24,725 - INFO -     - accuracy: 0.2800
2025-07-30 01:26:24,725 - INFO -   kmmlu_law:
2025-07-30 01:26:24,725 - INFO -     - accuracy: 0.3730
2025-07-30 01:26:24,725 - INFO -   kmmlu_management:
2025-07-30 01:26:24,725 - INFO -     - accuracy: 0.4050
2025-07-30 01:26:24,725 - INFO -   kmmlu_political_science_and_sociology:
2025-07-30 01:26:24,725 - INFO -     - accuracy: 0.4000
2025-07-30 01:26:24,725 - INFO -   kmmlu_psychology:
2025-07-30 01:26:24,726 - INFO -     - accuracy: 0.3240
2025-07-30 01:26:24,726 - INFO -   kmmlu_social_welfare:
2025-07-30 01:26:24,726 - INFO -     - accuracy: 0.3950
2025-07-30 01:26:24,726 - INFO -   kmmlu_taxation:
2025-07-30 01:26:24,726 - INFO -     - accuracy: 0.3050
2025-07-30 01:26:24,726 - INFO -   kmmlu_other:
2025-07-30 01:26:24,726 - INFO -     - accuracy: 0.3837
2025-07-30 01:26:24,726 - INFO -   kmmlu_agricultural_sciences:
2025-07-30 01:26:24,726 - INFO -     - accuracy: 0.3260
2025-07-30 01:26:24,726 - INFO -   kmmlu_construction:
2025-07-30 01:26:24,727 - INFO -     - accuracy: 0.3000
2025-07-30 01:26:24,727 - INFO -   kmmlu_fashion:
2025-07-30 01:26:24,727 - INFO -     - accuracy: 0.3940
2025-07-30 01:26:24,727 - INFO -   kmmlu_food_processing:
2025-07-30 01:26:24,727 - INFO -     - accuracy: 0.2980
2025-07-30 01:26:24,727 - INFO -   kmmlu_health:
2025-07-30 01:26:24,727 - INFO -     - accuracy: 0.4900
2025-07-30 01:26:24,727 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-30 01:26:24,727 - INFO -     - accuracy: 0.4820
2025-07-30 01:26:24,727 - INFO -   kmmlu_marketing:
2025-07-30 01:26:24,728 - INFO -     - accuracy: 0.6350
2025-07-30 01:26:24,728 - INFO -   kmmlu_patent:
2025-07-30 01:26:24,728 - INFO -     - accuracy: 0.3500
2025-07-30 01:26:24,728 - INFO -   kmmlu_public_safety:
2025-07-30 01:26:24,728 - INFO -     - accuracy: 0.3230
2025-07-30 01:26:24,728 - INFO -   kmmlu_real_estate:
2025-07-30 01:26:24,728 - INFO -     - accuracy: 0.3400
2025-07-30 01:26:24,728 - INFO -   kmmlu_refrigerating_machinery:
2025-07-30 01:26:24,728 - INFO -     - accuracy: 0.3130
2025-07-30 01:26:24,728 - INFO -   kmmlu_stem:
2025-07-30 01:26:24,728 - INFO -     - accuracy: 0.3841
2025-07-30 01:26:24,729 - INFO -   kmmlu_biology:
2025-07-30 01:26:24,729 - INFO -     - accuracy: 0.2880
2025-07-30 01:26:24,729 - INFO -   kmmlu_chemical_engineering:
2025-07-30 01:26:24,729 - INFO -     - accuracy: 0.3220
2025-07-30 01:26:24,729 - INFO -   kmmlu_chemistry:
2025-07-30 01:26:24,729 - INFO -     - accuracy: 0.3467
2025-07-30 01:26:24,729 - INFO -   kmmlu_civil_engineering:
2025-07-30 01:26:24,729 - INFO -     - accuracy: 0.3710
2025-07-30 01:26:24,729 - INFO -   kmmlu_computer_science:
2025-07-30 01:26:24,729 - INFO -     - accuracy: 0.5190
2025-07-30 01:26:24,730 - INFO -   kmmlu_ecology:
2025-07-30 01:26:24,730 - INFO -     - accuracy: 0.3930
2025-07-30 01:26:24,730 - INFO -   kmmlu_electrical_engineering:
2025-07-30 01:26:24,730 - INFO -     - accuracy: 0.3300
2025-07-30 01:26:24,730 - INFO -   kmmlu_information_technology:
2025-07-30 01:26:24,730 - INFO -     - accuracy: 0.5620
2025-07-30 01:26:24,730 - INFO -   kmmlu_materials_engineering:
2025-07-30 01:26:24,730 - INFO -     - accuracy: 0.3630
2025-07-30 01:26:24,730 - INFO -   kmmlu_math:
2025-07-30 01:26:24,730 - INFO -     - accuracy: 0.2833
2025-07-30 01:26:24,731 - INFO -   kmmlu_mechanical_engineering:
2025-07-30 01:26:24,731 - INFO -     - accuracy: 0.3620
2025-07-30 01:26:24,731 - INFO - ============================================================

2025-07-30 01:26:24,737 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 2/10: kmmlu_hard
2025-07-30 01:26:24,738 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-30 01:26:24,739 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-30 01:26:24,740 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 01:27:35,287 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-30 01:27:35,288 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-30 01:27:35,288 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-30 01:27:35,288 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-30 01:27:35,288 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-30 01:27:35,288 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-30 01:27:35,288 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-30 01:27:35,288 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-30 01:27:35,288 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-30 01:27:35,289 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-30 01:27:35,290 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-30 01:27:35,291 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-30 01:27:35,292 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-30 01:27:35,292 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-30 01:30:27,982 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-30 01:30:27,984 - INFO - 
============================================================
2025-07-30 01:30:27,985 - INFO - Task 'kmmlu_hard' Results:
2025-07-30 01:30:27,985 - INFO - ============================================================
2025-07-30 01:30:27,986 - INFO -   kmmlu_hard:
2025-07-30 01:30:27,987 - INFO -     - accuracy: 0.2256
2025-07-30 01:30:27,989 - INFO -   kmmlu_hard_applied_science:
2025-07-30 01:30:27,989 - INFO -     - accuracy: 0.2333
2025-07-30 01:30:27,989 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-30 01:30:27,989 - INFO -     - accuracy: 0.1700
2025-07-30 01:30:27,989 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-30 01:30:27,989 - INFO -     - accuracy: 0.2500
2025-07-30 01:30:27,989 - INFO -   kmmlu_hard_energy_management:
2025-07-30 01:30:27,989 - INFO -     - accuracy: 0.2800
2025-07-30 01:30:27,989 - INFO -   kmmlu_hard_environmental_science:
2025-07-30 01:30:27,990 - INFO -     - accuracy: 0.1700
2025-07-30 01:30:27,990 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-30 01:30:27,990 - INFO -     - accuracy: 0.2300
2025-07-30 01:30:27,990 - INFO -   kmmlu_hard_geomatics:
2025-07-30 01:30:27,990 - INFO -     - accuracy: 0.2700
2025-07-30 01:30:27,990 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-30 01:30:27,990 - INFO -     - accuracy: 0.1600
2025-07-30 01:30:27,990 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-30 01:30:27,990 - INFO -     - accuracy: 0.1800
2025-07-30 01:30:27,990 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-30 01:30:27,991 - INFO -     - accuracy: 0.2500
2025-07-30 01:30:27,991 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-30 01:30:27,991 - INFO -     - accuracy: 0.3200
2025-07-30 01:30:27,991 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-30 01:30:27,991 - INFO -     - accuracy: 0.2500
2025-07-30 01:30:27,991 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-30 01:30:27,991 - INFO -     - accuracy: 0.2700
2025-07-30 01:30:27,991 - INFO -   kmmlu_hard_humss:
2025-07-30 01:30:27,991 - INFO -     - accuracy: 0.2307
2025-07-30 01:30:27,991 - INFO -   kmmlu_hard_accounting:
2025-07-30 01:30:27,992 - INFO -     - accuracy: 0.1304
2025-07-30 01:30:27,992 - INFO -   kmmlu_hard_criminal_law:
2025-07-30 01:30:27,992 - INFO -     - accuracy: 0.2600
2025-07-30 01:30:27,992 - INFO -   kmmlu_hard_economics:
2025-07-30 01:30:27,992 - INFO -     - accuracy: 0.1905
2025-07-30 01:30:27,992 - INFO -   kmmlu_hard_education:
2025-07-30 01:30:27,992 - INFO -     - accuracy: 0.0870
2025-07-30 01:30:27,992 - INFO -   kmmlu_hard_korean_history:
2025-07-30 01:30:27,992 - INFO -     - accuracy: 0.2500
2025-07-30 01:30:27,992 - INFO -   kmmlu_hard_law:
2025-07-30 01:30:27,993 - INFO -     - accuracy: 0.2700
2025-07-30 01:30:27,993 - INFO -   kmmlu_hard_management:
2025-07-30 01:30:27,993 - INFO -     - accuracy: 0.2500
2025-07-30 01:30:27,993 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-30 01:30:27,993 - INFO -     - accuracy: 0.2444
2025-07-30 01:30:27,993 - INFO -   kmmlu_hard_psychology:
2025-07-30 01:30:27,993 - INFO -     - accuracy: 0.1700
2025-07-30 01:30:27,993 - INFO -   kmmlu_hard_social_welfare:
2025-07-30 01:30:27,993 - INFO -     - accuracy: 0.2700
2025-07-30 01:30:27,993 - INFO -   kmmlu_hard_taxation:
2025-07-30 01:30:27,993 - INFO -     - accuracy: 0.2396
2025-07-30 01:30:27,994 - INFO -   kmmlu_hard_other:
2025-07-30 01:30:27,994 - INFO -     - accuracy: 0.2129
2025-07-30 01:30:27,994 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-30 01:30:27,994 - INFO -     - accuracy: 0.1900
2025-07-30 01:30:27,994 - INFO -   kmmlu_hard_construction:
2025-07-30 01:30:27,994 - INFO -     - accuracy: 0.1300
2025-07-30 01:30:27,994 - INFO -   kmmlu_hard_fashion:
2025-07-30 01:30:27,994 - INFO -     - accuracy: 0.1700
2025-07-30 01:30:27,994 - INFO -   kmmlu_hard_food_processing:
2025-07-30 01:30:27,994 - INFO -     - accuracy: 0.1800
2025-07-30 01:30:27,995 - INFO -   kmmlu_hard_health:
2025-07-30 01:30:27,995 - INFO -     - accuracy: 0.2174
2025-07-30 01:30:27,995 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-30 01:30:27,995 - INFO -     - accuracy: 0.2300
2025-07-30 01:30:27,995 - INFO -   kmmlu_hard_marketing:
2025-07-30 01:30:27,995 - INFO -     - accuracy: 0.2900
2025-07-30 01:30:27,995 - INFO -   kmmlu_hard_patent:
2025-07-30 01:30:27,995 - INFO -     - accuracy: 0.3529
2025-07-30 01:30:27,995 - INFO -   kmmlu_hard_public_safety:
2025-07-30 01:30:27,995 - INFO -     - accuracy: 0.1900
2025-07-30 01:30:27,996 - INFO -   kmmlu_hard_real_estate:
2025-07-30 01:30:27,996 - INFO -     - accuracy: 0.1798
2025-07-30 01:30:27,996 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-30 01:30:27,996 - INFO -     - accuracy: 0.2800
2025-07-30 01:30:27,996 - INFO -   kmmlu_hard_stem:
2025-07-30 01:30:27,996 - INFO -     - accuracy: 0.2245
2025-07-30 01:30:27,996 - INFO -   kmmlu_hard_biology:
2025-07-30 01:30:27,996 - INFO -     - accuracy: 0.1900
2025-07-30 01:30:27,996 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-30 01:30:27,996 - INFO -     - accuracy: 0.1700
2025-07-30 01:30:27,997 - INFO -   kmmlu_hard_chemistry:
2025-07-30 01:30:27,997 - INFO -     - accuracy: 0.2300
2025-07-30 01:30:27,997 - INFO -   kmmlu_hard_civil_engineering:
2025-07-30 01:30:27,997 - INFO -     - accuracy: 0.3100
2025-07-30 01:30:27,997 - INFO -   kmmlu_hard_computer_science:
2025-07-30 01:30:27,997 - INFO -     - accuracy: 0.2400
2025-07-30 01:30:27,997 - INFO -   kmmlu_hard_ecology:
2025-07-30 01:30:27,997 - INFO -     - accuracy: 0.1700
2025-07-30 01:30:27,997 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-30 01:30:27,997 - INFO -     - accuracy: 0.2800
2025-07-30 01:30:27,998 - INFO -   kmmlu_hard_information_technology:
2025-07-30 01:30:27,998 - INFO -     - accuracy: 0.1800
2025-07-30 01:30:27,998 - INFO -   kmmlu_hard_materials_engineering:
2025-07-30 01:30:27,998 - INFO -     - accuracy: 0.2000
2025-07-30 01:30:27,998 - INFO -   kmmlu_hard_math:
2025-07-30 01:30:27,998 - INFO -     - accuracy: 0.2700
2025-07-30 01:30:27,998 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-30 01:30:27,998 - INFO -     - accuracy: 0.2300
2025-07-30 01:30:27,999 - INFO - ============================================================

2025-07-30 01:30:28,004 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 3/10: haerae
2025-07-30 01:30:28,005 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'haerae' will use num_fewshot=5
2025-07-30 01:30:28,005 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'haerae' with num_fewshot=5
2025-07-30 01:30:28,006 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 01:30:45,265 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-30 01:30:45,265 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-30 01:30:45,265 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-30 01:30:45,266 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-30 01:30:45,266 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-30 01:32:56,782 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'haerae' with 6 subtasks
2025-07-30 01:32:56,784 - INFO - 
============================================================
2025-07-30 01:32:56,785 - INFO - Task 'haerae' Results:
2025-07-30 01:32:56,786 - INFO - ============================================================
2025-07-30 01:32:56,787 - INFO -   haerae:
2025-07-30 01:32:56,788 - INFO -     - accuracy: 0.5628
2025-07-30 01:32:56,788 - INFO -     - accuracy_norm: 0.5628
2025-07-30 01:32:56,789 - INFO -   haerae_general_knowledge:
2025-07-30 01:32:56,789 - INFO -     - accuracy: 0.2273
2025-07-30 01:32:56,789 - INFO -     - accuracy_norm: 0.2273
2025-07-30 01:32:56,789 - INFO -   haerae_history:
2025-07-30 01:32:56,789 - INFO -     - accuracy: 0.5213
2025-07-30 01:32:56,789 - INFO -     - accuracy_norm: 0.5213
2025-07-30 01:32:56,789 - INFO -   haerae_loan_word:
2025-07-30 01:32:56,789 - INFO -     - accuracy: 0.6864
2025-07-30 01:32:56,789 - INFO -     - accuracy_norm: 0.6864
2025-07-30 01:32:56,790 - INFO -   haerae_rare_word:
2025-07-30 01:32:56,790 - INFO -     - accuracy: 0.6568
2025-07-30 01:32:56,790 - INFO -     - accuracy_norm: 0.6568
2025-07-30 01:32:56,790 - INFO -   haerae_standard_nomenclature:
2025-07-30 01:32:56,790 - INFO -     - accuracy: 0.6144
2025-07-30 01:32:56,790 - INFO -     - accuracy_norm: 0.6144
2025-07-30 01:32:56,791 - INFO - ============================================================

2025-07-30 01:32:56,796 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 4/10: kobest
2025-07-30 01:32:56,796 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kobest' will use num_fewshot=5
2025-07-30 01:32:56,797 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kobest' with num_fewshot=5
2025-07-30 01:32:56,797 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 01:33:15,788 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-30 01:33:15,789 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-30 01:33:15,789 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-30 01:33:15,789 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-30 01:33:15,789 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-30 01:37:16,346 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kobest' with 6 subtasks
2025-07-30 01:37:16,348 - INFO - 
============================================================
2025-07-30 01:37:16,348 - INFO - Task 'kobest' Results:
2025-07-30 01:37:16,349 - INFO - ============================================================
2025-07-30 01:37:16,349 - INFO -   kobest:
2025-07-30 01:37:16,349 - INFO -     - accuracy: 0.6301
2025-07-30 01:37:16,349 - INFO -     - accuracy_norm: 0.5180
2025-07-30 01:37:16,350 - INFO -     - f1: 0.6269
2025-07-30 01:37:16,351 - INFO -   kobest_boolq:
2025-07-30 01:37:16,353 - INFO -     - accuracy: 0.6916
2025-07-30 01:37:16,353 - INFO -     - f1: 0.6847
2025-07-30 01:37:16,353 - INFO -   kobest_copa:
2025-07-30 01:37:16,353 - INFO -     - accuracy: 0.6910
2025-07-30 01:37:16,353 - INFO -     - f1: 0.6906
2025-07-30 01:37:16,354 - INFO -   kobest_hellaswag:
2025-07-30 01:37:16,354 - INFO -     - accuracy: 0.4240
2025-07-30 01:37:16,354 - INFO -     - accuracy_norm: 0.5180
2025-07-30 01:37:16,354 - INFO -     - f1: 0.4202
2025-07-30 01:37:16,354 - INFO -   kobest_sentineg:
2025-07-30 01:37:16,354 - INFO -     - accuracy: 0.8086
2025-07-30 01:37:16,354 - INFO -     - f1: 0.8067
2025-07-30 01:37:16,354 - INFO -   kobest_wic:
2025-07-30 01:37:16,354 - INFO -     - accuracy: 0.5389
2025-07-30 01:37:16,354 - INFO -     - f1: 0.5372
2025-07-30 01:37:16,355 - INFO - ============================================================

2025-07-30 01:37:16,359 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 5/10: csatqa
2025-07-30 01:37:16,360 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'csatqa' detected as zero-shot task
2025-07-30 01:37:16,360 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'csatqa' with num_fewshot=0
2025-07-30 01:37:16,360 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 01:37:28,517 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-30 01:37:28,517 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-30 01:37:28,518 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-30 01:37:28,518 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-30 01:37:28,518 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-30 01:37:28,518 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-30 01:37:58,547 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'csatqa' with 7 subtasks
2025-07-30 01:37:58,549 - INFO - 
============================================================
2025-07-30 01:37:58,549 - INFO - Task 'csatqa' Results:
2025-07-30 01:37:58,550 - INFO - ============================================================
2025-07-30 01:37:58,551 - INFO -   csatqa:
2025-07-30 01:37:58,552 - INFO -     - accuracy: 0.3316
2025-07-30 01:37:58,552 - INFO -     - accuracy_norm: 0.3316
2025-07-30 01:37:58,553 - INFO -   csatqa_gr:
2025-07-30 01:37:58,553 - INFO -     - accuracy: 0.2000
2025-07-30 01:37:58,554 - INFO -     - accuracy_norm: 0.2000
2025-07-30 01:37:58,554 - INFO -   csatqa_li:
2025-07-30 01:37:58,554 - INFO -     - accuracy: 0.4865
2025-07-30 01:37:58,554 - INFO -     - accuracy_norm: 0.4865
2025-07-30 01:37:58,554 - INFO -   csatqa_rch:
2025-07-30 01:37:58,555 - INFO -     - accuracy: 0.3429
2025-07-30 01:37:58,555 - INFO -     - accuracy_norm: 0.3429
2025-07-30 01:37:58,555 - INFO -   csatqa_rcs:
2025-07-30 01:37:58,555 - INFO -     - accuracy: 0.1622
2025-07-30 01:37:58,555 - INFO -     - accuracy_norm: 0.1622
2025-07-30 01:37:58,555 - INFO -   csatqa_rcss:
2025-07-30 01:37:58,555 - INFO -     - accuracy: 0.4286
2025-07-30 01:37:58,555 - INFO -     - accuracy_norm: 0.4286
2025-07-30 01:37:58,555 - INFO -   csatqa_wr:
2025-07-30 01:37:58,556 - INFO -     - accuracy: 0.2727
2025-07-30 01:37:58,556 - INFO -     - accuracy_norm: 0.2727
2025-07-30 01:37:58,556 - INFO - ============================================================

2025-07-30 01:37:58,562 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 6/10: kormedmcqa
2025-07-30 01:37:58,563 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'kormedmcqa' will use num_fewshot=5
2025-07-30 01:37:58,563 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-30 01:37:58,564 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 01:38:16,608 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-30 01:38:16,608 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-30 01:38:16,608 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-30 01:38:16,608 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
2025-07-30 01:41:09,933 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-30 01:41:09,935 - INFO - 
============================================================
2025-07-30 01:41:09,936 - INFO - Task 'kormedmcqa' Results:
2025-07-30 01:41:09,936 - INFO - ============================================================
2025-07-30 01:41:09,937 - INFO -   kormedmcqa:
2025-07-30 01:41:09,939 - INFO -     - exact_match: 0.3383
2025-07-30 01:41:09,939 - INFO -   kormedmcqa_dentist:
2025-07-30 01:41:09,940 - INFO -     - exact_match: 0.3144
2025-07-30 01:41:09,940 - INFO -   kormedmcqa_doctor:
2025-07-30 01:41:09,940 - INFO -     - exact_match: 0.2805
2025-07-30 01:41:09,941 - INFO -   kormedmcqa_nurse:
2025-07-30 01:41:09,941 - INFO -     - exact_match: 0.4374
2025-07-30 01:41:09,941 - INFO -   kormedmcqa_pharm:
2025-07-30 01:41:09,941 - INFO -     - exact_match: 0.2904
2025-07-30 01:41:09,941 - INFO - ============================================================

2025-07-30 01:41:09,946 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 7/10: mmlu
2025-07-30 01:41:09,946 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'mmlu' will use num_fewshot=5
2025-07-30 01:41:09,946 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'mmlu' with num_fewshot=5
2025-07-30 01:41:09,947 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 01:43:57,100 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5
2025-07-30 01:43:57,100 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5
2025-07-30 01:43:57,100 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 5
2025-07-30 01:43:57,100 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5
2025-07-30 01:43:57,101 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 5
2025-07-30 01:43:57,102 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 5
2025-07-30 01:43:57,103 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5
2025-07-30 01:43:57,104 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 5
2025-07-30 01:43:57,105 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 5
2025-07-30 01:43:57,105 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5
2025-07-30 01:43:57,105 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 5
2025-07-30 01:43:57,105 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 5
2025-07-30 01:43:57,105 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5
2025-07-30 01:43:57,105 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 5
2025-07-30 01:43:57,105 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 5
2025-07-30 01:43:57,105 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5
2025-07-30 01:54:57,060 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'mmlu' with 62 subtasks
2025-07-30 01:54:57,061 - INFO - 
============================================================
2025-07-30 01:54:57,061 - INFO - Task 'mmlu' Results:
2025-07-30 01:54:57,062 - INFO - ============================================================
2025-07-30 01:54:57,063 - INFO -   mmlu:
2025-07-30 01:54:57,064 - INFO -     - accuracy: 0.4418
2025-07-30 01:54:57,065 - INFO -   mmlu_humanities:
2025-07-30 01:54:57,066 - INFO -     - accuracy: 0.4172
2025-07-30 01:54:57,066 - INFO -   mmlu_formal_logic:
2025-07-30 01:54:57,066 - INFO -     - accuracy: 0.2698
2025-07-30 01:54:57,066 - INFO -   mmlu_high_school_european_history:
2025-07-30 01:54:57,066 - INFO -     - accuracy: 0.5697
2025-07-30 01:54:57,066 - INFO -   mmlu_high_school_us_history:
2025-07-30 01:54:57,066 - INFO -     - accuracy: 0.5049
2025-07-30 01:54:57,066 - INFO -   mmlu_high_school_world_history:
2025-07-30 01:54:57,067 - INFO -     - accuracy: 0.5865
2025-07-30 01:54:57,067 - INFO -   mmlu_international_law:
2025-07-30 01:54:57,067 - INFO -     - accuracy: 0.6612
2025-07-30 01:54:57,067 - INFO -   mmlu_jurisprudence:
2025-07-30 01:54:57,067 - INFO -     - accuracy: 0.4722
2025-07-30 01:54:57,067 - INFO -   mmlu_logical_fallacies:
2025-07-30 01:54:57,067 - INFO -     - accuracy: 0.5092
2025-07-30 01:54:57,067 - INFO -   mmlu_moral_disputes:
2025-07-30 01:54:57,067 - INFO -     - accuracy: 0.4769
2025-07-30 01:54:57,067 - INFO -   mmlu_moral_scenarios:
2025-07-30 01:54:57,068 - INFO -     - accuracy: 0.2682
2025-07-30 01:54:57,068 - INFO -   mmlu_philosophy:
2025-07-30 01:54:57,068 - INFO -     - accuracy: 0.4502
2025-07-30 01:54:57,068 - INFO -   mmlu_prehistory:
2025-07-30 01:54:57,068 - INFO -     - accuracy: 0.4938
2025-07-30 01:54:57,068 - INFO -   mmlu_professional_law:
2025-07-30 01:54:57,068 - INFO -     - accuracy: 0.3807
2025-07-30 01:54:57,068 - INFO -   mmlu_world_religions:
2025-07-30 01:54:57,068 - INFO -     - accuracy: 0.5263
2025-07-30 01:54:57,068 - INFO -   mmlu_other:
2025-07-30 01:54:57,069 - INFO -     - accuracy: 0.4818
2025-07-30 01:54:57,069 - INFO -   mmlu_business_ethics:
2025-07-30 01:54:57,069 - INFO -     - accuracy: 0.5100
2025-07-30 01:54:57,069 - INFO -   mmlu_clinical_knowledge:
2025-07-30 01:54:57,069 - INFO -     - accuracy: 0.5019
2025-07-30 01:54:57,069 - INFO -   mmlu_college_medicine:
2025-07-30 01:54:57,069 - INFO -     - accuracy: 0.4162
2025-07-30 01:54:57,069 - INFO -   mmlu_global_facts:
2025-07-30 01:54:57,069 - INFO -     - accuracy: 0.2500
2025-07-30 01:54:57,069 - INFO -   mmlu_human_aging:
2025-07-30 01:54:57,070 - INFO -     - accuracy: 0.4529
2025-07-30 01:54:57,070 - INFO -   mmlu_management:
2025-07-30 01:54:57,070 - INFO -     - accuracy: 0.5825
2025-07-30 01:54:57,070 - INFO -   mmlu_marketing:
2025-07-30 01:54:57,070 - INFO -     - accuracy: 0.7137
2025-07-30 01:54:57,070 - INFO -   mmlu_medical_genetics:
2025-07-30 01:54:57,070 - INFO -     - accuracy: 0.4600
2025-07-30 01:54:57,070 - INFO -   mmlu_miscellaneous:
2025-07-30 01:54:57,070 - INFO -     - accuracy: 0.5466
2025-07-30 01:54:57,070 - INFO -   mmlu_nutrition:
2025-07-30 01:54:57,070 - INFO -     - accuracy: 0.4902
2025-07-30 01:54:57,071 - INFO -   mmlu_professional_accounting:
2025-07-30 01:54:57,071 - INFO -     - accuracy: 0.3262
2025-07-30 01:54:57,071 - INFO -   mmlu_professional_medicine:
2025-07-30 01:54:57,071 - INFO -     - accuracy: 0.3529
2025-07-30 01:54:57,071 - INFO -   mmlu_virology:
2025-07-30 01:54:57,071 - INFO -     - accuracy: 0.4578
2025-07-30 01:54:57,071 - INFO -   mmlu_social_sciences:
2025-07-30 01:54:57,071 - INFO -     - accuracy: 0.5102
2025-07-30 01:54:57,071 - INFO -   mmlu_econometrics:
2025-07-30 01:54:57,071 - INFO -     - accuracy: 0.2719
2025-07-30 01:54:57,072 - INFO -   mmlu_high_school_geography:
2025-07-30 01:54:57,072 - INFO -     - accuracy: 0.5758
2025-07-30 01:54:57,072 - INFO -   mmlu_high_school_government_and_politics:
2025-07-30 01:54:57,072 - INFO -     - accuracy: 0.6010
2025-07-30 01:54:57,072 - INFO -   mmlu_high_school_macroeconomics:
2025-07-30 01:54:57,072 - INFO -     - accuracy: 0.3974
2025-07-30 01:54:57,072 - INFO -   mmlu_high_school_microeconomics:
2025-07-30 01:54:57,072 - INFO -     - accuracy: 0.4328
2025-07-30 01:54:57,072 - INFO -   mmlu_high_school_psychology:
2025-07-30 01:54:57,072 - INFO -     - accuracy: 0.6404
2025-07-30 01:54:57,073 - INFO -   mmlu_human_sexuality:
2025-07-30 01:54:57,073 - INFO -     - accuracy: 0.5267
2025-07-30 01:54:57,073 - INFO -   mmlu_professional_psychology:
2025-07-30 01:54:57,073 - INFO -     - accuracy: 0.4461
2025-07-30 01:54:57,073 - INFO -   mmlu_public_relations:
2025-07-30 01:54:57,073 - INFO -     - accuracy: 0.5455
2025-07-30 01:54:57,073 - INFO -   mmlu_security_studies:
2025-07-30 01:54:57,073 - INFO -     - accuracy: 0.4449
2025-07-30 01:54:57,073 - INFO -   mmlu_sociology:
2025-07-30 01:54:57,073 - INFO -     - accuracy: 0.6468
2025-07-30 01:54:57,074 - INFO -   mmlu_us_foreign_policy:
2025-07-30 01:54:57,074 - INFO -     - accuracy: 0.6100
2025-07-30 01:54:57,074 - INFO -   mmlu_stem:
2025-07-30 01:54:57,074 - INFO -     - accuracy: 0.3723
2025-07-30 01:54:57,074 - INFO -   mmlu_abstract_algebra:
2025-07-30 01:54:57,074 - INFO -     - accuracy: 0.3200
2025-07-30 01:54:57,074 - INFO -   mmlu_anatomy:
2025-07-30 01:54:57,074 - INFO -     - accuracy: 0.3778
2025-07-30 01:54:57,074 - INFO -   mmlu_astronomy:
2025-07-30 01:54:57,074 - INFO -     - accuracy: 0.4276
2025-07-30 01:54:57,075 - INFO -   mmlu_college_biology:
2025-07-30 01:54:57,075 - INFO -     - accuracy: 0.4722
2025-07-30 01:54:57,075 - INFO -   mmlu_college_chemistry:
2025-07-30 01:54:57,075 - INFO -     - accuracy: 0.3000
2025-07-30 01:54:57,075 - INFO -   mmlu_college_computer_science:
2025-07-30 01:54:57,075 - INFO -     - accuracy: 0.2800
2025-07-30 01:54:57,075 - INFO -   mmlu_college_mathematics:
2025-07-30 01:54:57,075 - INFO -     - accuracy: 0.3100
2025-07-30 01:54:57,075 - INFO -   mmlu_college_physics:
2025-07-30 01:54:57,075 - INFO -     - accuracy: 0.3235
2025-07-30 01:54:57,075 - INFO -   mmlu_computer_security:
2025-07-30 01:54:57,076 - INFO -     - accuracy: 0.5700
2025-07-30 01:54:57,076 - INFO -   mmlu_conceptual_physics:
2025-07-30 01:54:57,076 - INFO -     - accuracy: 0.4000
2025-07-30 01:54:57,076 - INFO -   mmlu_electrical_engineering:
2025-07-30 01:54:57,076 - INFO -     - accuracy: 0.4552
2025-07-30 01:54:57,076 - INFO -   mmlu_elementary_mathematics:
2025-07-30 01:54:57,076 - INFO -     - accuracy: 0.3280
2025-07-30 01:54:57,076 - INFO -   mmlu_high_school_biology:
2025-07-30 01:54:57,076 - INFO -     - accuracy: 0.5097
2025-07-30 01:54:57,076 - INFO -   mmlu_high_school_chemistry:
2025-07-30 01:54:57,077 - INFO -     - accuracy: 0.3744
2025-07-30 01:54:57,077 - INFO -   mmlu_high_school_computer_science:
2025-07-30 01:54:57,077 - INFO -     - accuracy: 0.4300
2025-07-30 01:54:57,077 - INFO -   mmlu_high_school_mathematics:
2025-07-30 01:54:57,077 - INFO -     - accuracy: 0.3074
2025-07-30 01:54:57,077 - INFO -   mmlu_high_school_physics:
2025-07-30 01:54:57,077 - INFO -     - accuracy: 0.2119
2025-07-30 01:54:57,077 - INFO -   mmlu_high_school_statistics:
2025-07-30 01:54:57,077 - INFO -     - accuracy: 0.2917
2025-07-30 01:54:57,077 - INFO -   mmlu_machine_learning:
2025-07-30 01:54:57,078 - INFO -     - accuracy: 0.3571
2025-07-30 01:54:57,078 - INFO - ============================================================

2025-07-30 01:54:57,085 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 8/10: arc_challenge
2025-07-30 01:54:57,088 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'arc_challenge' will use num_fewshot=5
2025-07-30 01:54:57,088 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'arc_challenge' with num_fewshot=5
2025-07-30 01:54:57,088 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 01:55:05,597 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 5
2025-07-30 01:56:50,296 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-30 01:56:50,298 - INFO - 
============================================================
2025-07-30 01:56:50,299 - INFO - Task 'arc_challenge' Results:
2025-07-30 01:56:50,300 - INFO - ============================================================
2025-07-30 01:56:50,301 - INFO -   arc_challenge:
2025-07-30 01:56:50,302 - INFO -     - accuracy: 0.3908
2025-07-30 01:56:50,302 - INFO -     - accuracy_norm: 0.4317
2025-07-30 01:56:50,302 - INFO - ============================================================

2025-07-30 01:56:50,306 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 9/10: arc_easy
2025-07-30 01:56:50,307 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'arc_easy' will use num_fewshot=5
2025-07-30 01:56:50,307 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'arc_easy' with num_fewshot=5
2025-07-30 01:56:50,307 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 01:56:58,514 - WARNING - Overwriting default num_fewshot of arc_easy from None to 5
2025-07-30 02:00:13,714 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-30 02:00:13,715 - INFO - 
============================================================
2025-07-30 02:00:13,715 - INFO - Task 'arc_easy' Results:
2025-07-30 02:00:13,717 - INFO - ============================================================
2025-07-30 02:00:13,718 - INFO -   arc_easy:
2025-07-30 02:00:13,720 - INFO -     - accuracy: 0.7201
2025-07-30 02:00:13,720 - INFO -     - accuracy_norm: 0.7104
2025-07-30 02:00:13,721 - INFO - ============================================================

2025-07-30 02:00:13,724 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Processing task 10/10: hellaswag
2025-07-30 02:00:13,725 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Task 'hellaswag' will use num_fewshot=5
2025-07-30 02:00:13,725 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Evaluating task 'hellaswag' with num_fewshot=5
2025-07-30 02:00:13,726 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 02:00:28,484 - WARNING - Overwriting default num_fewshot of hellaswag from None to 5
2025-07-30 02:17:05,027 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-30 02:17:05,029 - INFO - 
============================================================
2025-07-30 02:17:05,030 - INFO - Task 'hellaswag' Results:
2025-07-30 02:17:05,032 - INFO - ============================================================
2025-07-30 02:17:05,034 - INFO -   hellaswag:
2025-07-30 02:17:05,034 - INFO -     - accuracy: 0.4187
2025-07-30 02:17:05,034 - INFO -     - accuracy_norm: 0.5330
2025-07-30 02:17:05,035 - INFO - ============================================================

2025-07-30 02:17:05,039 - INFO - HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-30 02:17:05,041 - INFO - [Process 2120894] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/HyperCLOVAX-SEED-Text-Instruct-0.5B/HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10.json
2025-07-30 02:17:05,315 - INFO - Results uploaded to WandB as artifact
2025-07-30 02:17:05,325 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-30 02:17:05,327 - INFO - [Process 2120894] Successfully completed HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10
2025-07-30 02:17:08,361 - INFO - Run HyperCLOVAX-SEED-Text-Instruct-0.5B_harness_10 finished successfully
2025-07-30 02:17:08,362 - INFO - [Process 2120894] kanana-1.5-2.1b-instruct-2505_harness_11 assigned to cuda:0
2025-07-30 02:17:08,362 - INFO - [Process 2120894] kanana-1.5-2.1b-instruct-2505_harness_11 - full_run: True, limit: None (full dataset)
2025-07-30 02:17:09,772 - INFO - WandB run initialized: kanana-1.5-2.1b-instruct-2505_20250730_021708 (ID: cf7b9a03)
2025-07-30 02:17:10,097 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 1/10: kmmlu
2025-07-30 02:17:10,097 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kmmlu' will use num_fewshot=5
2025-07-30 02:17:10,097 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-30 02:17:10,097 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-30 02:17:10,097 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 02:18:18,833 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-30 02:18:18,833 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-30 02:18:18,833 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-30 02:18:18,833 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-30 02:18:18,833 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-30 02:18:18,834 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-30 02:18:18,835 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-30 02:18:18,836 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-30 02:18:18,837 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-30 02:18:18,837 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-30 02:18:18,837 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-30 02:18:18,837 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-30 02:18:18,837 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-30 02:18:18,837 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-30 02:47:36,272 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-30 02:47:36,274 - INFO - 
============================================================
2025-07-30 02:47:36,278 - INFO - Task 'kmmlu' Results:
2025-07-30 02:47:36,282 - INFO - ============================================================
2025-07-30 02:47:36,285 - INFO -   kmmlu:
2025-07-30 02:47:36,285 - INFO -     - accuracy: 0.4268
2025-07-30 02:47:36,285 - INFO -   kmmlu_applied_science:
2025-07-30 02:47:36,285 - INFO -     - accuracy: 0.3868
2025-07-30 02:47:36,285 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-30 02:47:36,285 - INFO -     - accuracy: 0.3830
2025-07-30 02:47:36,285 - INFO -   kmmlu_electronics_engineering:
2025-07-30 02:47:36,285 - INFO -     - accuracy: 0.4650
2025-07-30 02:47:36,286 - INFO -   kmmlu_energy_management:
2025-07-30 02:47:36,286 - INFO -     - accuracy: 0.3200
2025-07-30 02:47:36,286 - INFO -   kmmlu_environmental_science:
2025-07-30 02:47:36,286 - INFO -     - accuracy: 0.3090
2025-07-30 02:47:36,286 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-30 02:47:36,286 - INFO -     - accuracy: 0.3050
2025-07-30 02:47:36,286 - INFO -   kmmlu_geomatics:
2025-07-30 02:47:36,286 - INFO -     - accuracy: 0.3530
2025-07-30 02:47:36,286 - INFO -   kmmlu_industrial_engineer:
2025-07-30 02:47:36,286 - INFO -     - accuracy: 0.4140
2025-07-30 02:47:36,287 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-30 02:47:36,287 - INFO -     - accuracy: 0.3980
2025-07-30 02:47:36,287 - INFO -   kmmlu_maritime_engineering:
2025-07-30 02:47:36,287 - INFO -     - accuracy: 0.4350
2025-07-30 02:47:36,287 - INFO -   kmmlu_nondestructive_testing:
2025-07-30 02:47:36,287 - INFO -     - accuracy: 0.4110
2025-07-30 02:47:36,287 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-30 02:47:36,287 - INFO -     - accuracy: 0.3270
2025-07-30 02:47:36,287 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-30 02:47:36,287 - INFO -     - accuracy: 0.5410
2025-07-30 02:47:36,288 - INFO -   kmmlu_humss:
2025-07-30 02:47:36,288 - INFO -     - accuracy: 0.4704
2025-07-30 02:47:36,288 - INFO -   kmmlu_accounting:
2025-07-30 02:47:36,288 - INFO -     - accuracy: 0.4400
2025-07-30 02:47:36,288 - INFO -   kmmlu_criminal_law:
2025-07-30 02:47:36,288 - INFO -     - accuracy: 0.4250
2025-07-30 02:47:36,288 - INFO -   kmmlu_economics:
2025-07-30 02:47:36,288 - INFO -     - accuracy: 0.5462
2025-07-30 02:47:36,288 - INFO -   kmmlu_education:
2025-07-30 02:47:36,288 - INFO -     - accuracy: 0.7000
2025-07-30 02:47:36,289 - INFO -   kmmlu_korean_history:
2025-07-30 02:47:36,289 - INFO -     - accuracy: 0.3800
2025-07-30 02:47:36,289 - INFO -   kmmlu_law:
2025-07-30 02:47:36,289 - INFO -     - accuracy: 0.4460
2025-07-30 02:47:36,289 - INFO -   kmmlu_management:
2025-07-30 02:47:36,289 - INFO -     - accuracy: 0.4990
2025-07-30 02:47:36,289 - INFO -   kmmlu_political_science_and_sociology:
2025-07-30 02:47:36,289 - INFO -     - accuracy: 0.5167
2025-07-30 02:47:36,289 - INFO -   kmmlu_psychology:
2025-07-30 02:47:36,289 - INFO -     - accuracy: 0.4360
2025-07-30 02:47:36,290 - INFO -   kmmlu_social_welfare:
2025-07-30 02:47:36,290 - INFO -     - accuracy: 0.4970
2025-07-30 02:47:36,290 - INFO -   kmmlu_taxation:
2025-07-30 02:47:36,290 - INFO -     - accuracy: 0.3600
2025-07-30 02:47:36,290 - INFO -   kmmlu_other:
2025-07-30 02:47:36,290 - INFO -     - accuracy: 0.4367
2025-07-30 02:47:36,290 - INFO -   kmmlu_agricultural_sciences:
2025-07-30 02:47:36,290 - INFO -     - accuracy: 0.3460
2025-07-30 02:47:36,290 - INFO -   kmmlu_construction:
2025-07-30 02:47:36,290 - INFO -     - accuracy: 0.3460
2025-07-30 02:47:36,291 - INFO -   kmmlu_fashion:
2025-07-30 02:47:36,291 - INFO -     - accuracy: 0.4470
2025-07-30 02:47:36,291 - INFO -   kmmlu_food_processing:
2025-07-30 02:47:36,291 - INFO -     - accuracy: 0.3980
2025-07-30 02:47:36,291 - INFO -   kmmlu_health:
2025-07-30 02:47:36,291 - INFO -     - accuracy: 0.6000
2025-07-30 02:47:36,291 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-30 02:47:36,291 - INFO -     - accuracy: 0.5670
2025-07-30 02:47:36,291 - INFO -   kmmlu_marketing:
2025-07-30 02:47:36,291 - INFO -     - accuracy: 0.7270
2025-07-30 02:47:36,292 - INFO -   kmmlu_patent:
2025-07-30 02:47:36,292 - INFO -     - accuracy: 0.4000
2025-07-30 02:47:36,292 - INFO -   kmmlu_public_safety:
2025-07-30 02:47:36,292 - INFO -     - accuracy: 0.3350
2025-07-30 02:47:36,292 - INFO -   kmmlu_real_estate:
2025-07-30 02:47:36,292 - INFO -     - accuracy: 0.4150
2025-07-30 02:47:36,292 - INFO -   kmmlu_refrigerating_machinery:
2025-07-30 02:47:36,292 - INFO -     - accuracy: 0.3190
2025-07-30 02:47:36,292 - INFO -   kmmlu_stem:
2025-07-30 02:47:36,292 - INFO -     - accuracy: 0.4426
2025-07-30 02:47:36,293 - INFO -   kmmlu_biology:
2025-07-30 02:47:36,293 - INFO -     - accuracy: 0.3790
2025-07-30 02:47:36,397 - INFO -   kmmlu_chemical_engineering:
2025-07-30 02:47:36,398 - INFO -     - accuracy: 0.4210
2025-07-30 02:47:36,398 - INFO -   kmmlu_chemistry:
2025-07-30 02:47:36,398 - INFO -     - accuracy: 0.4033
2025-07-30 02:47:36,398 - INFO -   kmmlu_civil_engineering:
2025-07-30 02:47:36,398 - INFO -     - accuracy: 0.3730
2025-07-30 02:47:36,399 - INFO -   kmmlu_computer_science:
2025-07-30 02:47:36,399 - INFO -     - accuracy: 0.6710
2025-07-30 02:47:36,399 - INFO -   kmmlu_ecology:
2025-07-30 02:47:36,399 - INFO -     - accuracy: 0.4850
2025-07-30 02:47:36,399 - INFO -   kmmlu_electrical_engineering:
2025-07-30 02:47:36,399 - INFO -     - accuracy: 0.3310
2025-07-30 02:47:36,399 - INFO -   kmmlu_information_technology:
2025-07-30 02:47:36,399 - INFO -     - accuracy: 0.6410
2025-07-30 02:47:36,399 - INFO -   kmmlu_materials_engineering:
2025-07-30 02:47:36,400 - INFO -     - accuracy: 0.3980
2025-07-30 02:47:36,400 - INFO -   kmmlu_math:
2025-07-30 02:47:36,400 - INFO -     - accuracy: 0.2667
2025-07-30 02:47:36,400 - INFO -   kmmlu_mechanical_engineering:
2025-07-30 02:47:36,400 - INFO -     - accuracy: 0.3610
2025-07-30 02:47:36,400 - INFO - ============================================================

2025-07-30 02:47:36,417 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 2/10: kmmlu_hard
2025-07-30 02:47:36,423 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-30 02:47:36,423 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-30 02:47:36,423 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-30 02:47:36,424 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 02:48:46,158 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-30 02:48:46,159 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-30 02:48:46,159 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-30 02:48:46,159 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-30 02:48:46,159 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-30 02:48:46,160 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-30 02:48:46,161 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-30 02:48:46,162 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-30 02:48:46,163 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-30 02:48:46,163 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-30 02:48:46,163 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-30 02:48:46,163 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-30 02:48:46,163 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-30 02:48:46,163 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-30 02:52:29,346 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-30 02:52:29,348 - INFO - 
============================================================
2025-07-30 02:52:29,350 - INFO - Task 'kmmlu_hard' Results:
2025-07-30 02:52:29,351 - INFO - ============================================================
2025-07-30 02:52:29,354 - INFO -   kmmlu_hard:
2025-07-30 02:52:29,355 - INFO -     - accuracy: 0.2181
2025-07-30 02:52:29,355 - INFO -   kmmlu_hard_applied_science:
2025-07-30 02:52:29,355 - INFO -     - accuracy: 0.2125
2025-07-30 02:52:29,355 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-30 02:52:29,355 - INFO -     - accuracy: 0.1800
2025-07-30 02:52:29,356 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-30 02:52:29,356 - INFO -     - accuracy: 0.2300
2025-07-30 02:52:29,356 - INFO -   kmmlu_hard_energy_management:
2025-07-30 02:52:29,356 - INFO -     - accuracy: 0.2600
2025-07-30 02:52:29,356 - INFO -   kmmlu_hard_environmental_science:
2025-07-30 02:52:29,356 - INFO -     - accuracy: 0.1900
2025-07-30 02:52:29,356 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-30 02:52:29,356 - INFO -     - accuracy: 0.2100
2025-07-30 02:52:29,356 - INFO -   kmmlu_hard_geomatics:
2025-07-30 02:52:29,357 - INFO -     - accuracy: 0.2000
2025-07-30 02:52:29,357 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-30 02:52:29,357 - INFO -     - accuracy: 0.2100
2025-07-30 02:52:29,357 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-30 02:52:29,357 - INFO -     - accuracy: 0.1500
2025-07-30 02:52:29,357 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-30 02:52:29,357 - INFO -     - accuracy: 0.2300
2025-07-30 02:52:29,357 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-30 02:52:29,357 - INFO -     - accuracy: 0.3200
2025-07-30 02:52:29,391 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-30 02:52:29,391 - INFO -     - accuracy: 0.1300
2025-07-30 02:52:29,391 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-30 02:52:29,391 - INFO -     - accuracy: 0.2400
2025-07-30 02:52:29,391 - INFO -   kmmlu_hard_humss:
2025-07-30 02:52:29,391 - INFO -     - accuracy: 0.2307
2025-07-30 02:52:29,392 - INFO -   kmmlu_hard_accounting:
2025-07-30 02:52:29,392 - INFO -     - accuracy: 0.2609
2025-07-30 02:52:29,392 - INFO -   kmmlu_hard_criminal_law:
2025-07-30 02:52:29,392 - INFO -     - accuracy: 0.2500
2025-07-30 02:52:29,392 - INFO -   kmmlu_hard_economics:
2025-07-30 02:52:29,392 - INFO -     - accuracy: 0.3095
2025-07-30 02:52:29,392 - INFO -   kmmlu_hard_education:
2025-07-30 02:52:29,392 - INFO -     - accuracy: 0.3043
2025-07-30 02:52:29,393 - INFO -   kmmlu_hard_korean_history:
2025-07-30 02:52:29,393 - INFO -     - accuracy: 0.2727
2025-07-30 02:52:29,393 - INFO -   kmmlu_hard_law:
2025-07-30 02:52:29,393 - INFO -     - accuracy: 0.2300
2025-07-30 02:52:29,393 - INFO -   kmmlu_hard_management:
2025-07-30 02:52:29,393 - INFO -     - accuracy: 0.1800
2025-07-30 02:52:29,393 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-30 02:52:29,393 - INFO -     - accuracy: 0.2222
2025-07-30 02:52:29,393 - INFO -   kmmlu_hard_psychology:
2025-07-30 02:52:29,394 - INFO -     - accuracy: 0.2300
2025-07-30 02:52:29,394 - INFO -   kmmlu_hard_social_welfare:
2025-07-30 02:52:29,394 - INFO -     - accuracy: 0.2300
2025-07-30 02:52:29,394 - INFO -   kmmlu_hard_taxation:
2025-07-30 02:52:29,394 - INFO -     - accuracy: 0.1875
2025-07-30 02:52:29,394 - INFO -   kmmlu_hard_other:
2025-07-30 02:52:29,394 - INFO -     - accuracy: 0.2253
2025-07-30 02:52:29,394 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-30 02:52:29,394 - INFO -     - accuracy: 0.2000
2025-07-30 02:52:29,395 - INFO -   kmmlu_hard_construction:
2025-07-30 02:52:29,395 - INFO -     - accuracy: 0.1900
2025-07-30 02:52:29,395 - INFO -   kmmlu_hard_fashion:
2025-07-30 02:52:29,395 - INFO -     - accuracy: 0.2000
2025-07-30 02:52:29,395 - INFO -   kmmlu_hard_food_processing:
2025-07-30 02:52:29,395 - INFO -     - accuracy: 0.2000
2025-07-30 02:52:29,395 - INFO -   kmmlu_hard_health:
2025-07-30 02:52:29,395 - INFO -     - accuracy: 0.1304
2025-07-30 02:52:29,395 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-30 02:52:29,396 - INFO -     - accuracy: 0.2700
2025-07-30 02:52:29,396 - INFO -   kmmlu_hard_marketing:
2025-07-30 02:52:29,396 - INFO -     - accuracy: 0.3500
2025-07-30 02:52:29,396 - INFO -   kmmlu_hard_patent:
2025-07-30 02:52:29,396 - INFO -     - accuracy: 0.1961
2025-07-30 02:52:29,396 - INFO -   kmmlu_hard_public_safety:
2025-07-30 02:52:29,396 - INFO -     - accuracy: 0.2200
2025-07-30 02:52:29,396 - INFO -   kmmlu_hard_real_estate:
2025-07-30 02:52:29,396 - INFO -     - accuracy: 0.2584
2025-07-30 02:52:29,397 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-30 02:52:29,397 - INFO -     - accuracy: 0.1800
2025-07-30 02:52:29,397 - INFO -   kmmlu_hard_stem:
2025-07-30 02:52:29,397 - INFO -     - accuracy: 0.2082
2025-07-30 02:52:29,397 - INFO -   kmmlu_hard_biology:
2025-07-30 02:52:29,397 - INFO -     - accuracy: 0.2400
2025-07-30 02:52:29,397 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-30 02:52:29,397 - INFO -     - accuracy: 0.1500
2025-07-30 02:52:29,397 - INFO -   kmmlu_hard_chemistry:
2025-07-30 02:52:29,398 - INFO -     - accuracy: 0.2500
2025-07-30 02:52:29,398 - INFO -   kmmlu_hard_civil_engineering:
2025-07-30 02:52:29,398 - INFO -     - accuracy: 0.2000
2025-07-30 02:52:29,398 - INFO -   kmmlu_hard_computer_science:
2025-07-30 02:52:29,398 - INFO -     - accuracy: 0.2200
2025-07-30 02:52:29,398 - INFO -   kmmlu_hard_ecology:
2025-07-30 02:52:29,398 - INFO -     - accuracy: 0.2300
2025-07-30 02:52:29,398 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-30 02:52:29,398 - INFO -     - accuracy: 0.1900
2025-07-30 02:52:29,399 - INFO -   kmmlu_hard_information_technology:
2025-07-30 02:52:29,399 - INFO -     - accuracy: 0.2200
2025-07-30 02:52:29,399 - INFO -   kmmlu_hard_materials_engineering:
2025-07-30 02:52:29,399 - INFO -     - accuracy: 0.2000
2025-07-30 02:52:29,399 - INFO -   kmmlu_hard_math:
2025-07-30 02:52:29,399 - INFO -     - accuracy: 0.1900
2025-07-30 02:52:29,399 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-30 02:52:29,399 - INFO -     - accuracy: 0.2000
2025-07-30 02:52:29,400 - INFO - ============================================================

2025-07-30 02:52:29,415 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 3/10: haerae
2025-07-30 02:52:29,417 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'haerae' will use num_fewshot=5
2025-07-30 02:52:29,417 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'haerae' with num_fewshot=5
2025-07-30 02:52:29,417 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-30 02:52:29,417 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 02:52:47,467 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-30 02:52:47,467 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-30 02:52:47,468 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-30 02:52:47,468 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-30 02:52:47,468 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-30 02:55:59,195 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'haerae' with 6 subtasks
2025-07-30 02:55:59,197 - INFO - 
============================================================
2025-07-30 02:55:59,199 - INFO - Task 'haerae' Results:
2025-07-30 02:55:59,202 - INFO - ============================================================
2025-07-30 02:55:59,204 - INFO -   haerae:
2025-07-30 02:55:59,206 - INFO -     - accuracy: 0.7910
2025-07-30 02:55:59,206 - INFO -     - accuracy_norm: 0.7910
2025-07-30 02:55:59,206 - INFO -   haerae_general_knowledge:
2025-07-30 02:55:59,206 - INFO -     - accuracy: 0.3693
2025-07-30 02:55:59,206 - INFO -     - accuracy_norm: 0.3693
2025-07-30 02:55:59,207 - INFO -   haerae_history:
2025-07-30 02:55:59,207 - INFO -     - accuracy: 0.8936
2025-07-30 02:55:59,207 - INFO -     - accuracy_norm: 0.8936
2025-07-30 02:55:59,207 - INFO -   haerae_loan_word:
2025-07-30 02:55:59,207 - INFO -     - accuracy: 0.8462
2025-07-30 02:55:59,207 - INFO -     - accuracy_norm: 0.8462
2025-07-30 02:55:59,208 - INFO -   haerae_rare_word:
2025-07-30 02:55:59,208 - INFO -     - accuracy: 0.8667
2025-07-30 02:55:59,208 - INFO -     - accuracy_norm: 0.8667
2025-07-30 02:55:59,208 - INFO -   haerae_standard_nomenclature:
2025-07-30 02:55:59,208 - INFO -     - accuracy: 0.8889
2025-07-30 02:55:59,208 - INFO -     - accuracy_norm: 0.8889
2025-07-30 02:55:59,209 - INFO - ============================================================

2025-07-30 02:55:59,222 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 4/10: kobest
2025-07-30 02:55:59,223 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kobest' will use num_fewshot=5
2025-07-30 02:55:59,224 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kobest' with num_fewshot=5
2025-07-30 02:55:59,224 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-30 02:55:59,224 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 02:56:19,123 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-30 02:56:19,123 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-30 02:56:19,124 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-30 02:56:19,124 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-30 02:56:19,124 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-30 03:02:27,445 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kobest' with 6 subtasks
2025-07-30 03:02:27,447 - INFO - 
============================================================
2025-07-30 03:02:27,448 - INFO - Task 'kobest' Results:
2025-07-30 03:02:27,450 - INFO - ============================================================
2025-07-30 03:02:27,451 - INFO -   kobest:
2025-07-30 03:02:27,453 - INFO -     - accuracy: 0.7786
2025-07-30 03:02:27,453 - INFO -     - accuracy_norm: 0.6140
2025-07-30 03:02:27,453 - INFO -     - f1: 0.7780
2025-07-30 03:02:27,453 - INFO -   kobest_boolq:
2025-07-30 03:02:27,453 - INFO -     - accuracy: 0.8697
2025-07-30 03:02:27,454 - INFO -     - f1: 0.8693
2025-07-30 03:02:27,454 - INFO -   kobest_copa:
2025-07-30 03:02:27,454 - INFO -     - accuracy: 0.8360
2025-07-30 03:02:27,454 - INFO -     - f1: 0.8358
2025-07-30 03:02:27,454 - INFO -   kobest_hellaswag:
2025-07-30 03:02:27,454 - INFO -     - accuracy: 0.5140
2025-07-30 03:02:27,454 - INFO -     - accuracy_norm: 0.6140
2025-07-30 03:02:27,456 - INFO -     - f1: 0.5102
2025-07-30 03:02:27,456 - INFO -   kobest_sentineg:
2025-07-30 03:02:27,456 - INFO -     - accuracy: 0.9622
2025-07-30 03:02:27,456 - INFO -     - f1: 0.9622
2025-07-30 03:02:27,456 - INFO -   kobest_wic:
2025-07-30 03:02:27,456 - INFO -     - accuracy: 0.6786
2025-07-30 03:02:27,456 - INFO -     - f1: 0.6785
2025-07-30 03:02:27,457 - INFO - ============================================================

2025-07-30 03:02:27,470 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 5/10: csatqa
2025-07-30 03:02:27,471 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'csatqa' detected as zero-shot task
2025-07-30 03:02:27,471 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'csatqa' with num_fewshot=0
2025-07-30 03:02:27,472 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-30 03:02:27,472 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 03:02:44,013 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-30 03:02:44,014 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-30 03:02:44,014 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-30 03:02:44,014 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-30 03:02:44,014 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-30 03:02:44,014 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-30 03:03:46,638 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'csatqa' with 7 subtasks
2025-07-30 03:03:46,643 - INFO - 
============================================================
2025-07-30 03:03:46,645 - INFO - Task 'csatqa' Results:
2025-07-30 03:03:46,645 - INFO - ============================================================
2025-07-30 03:03:46,645 - INFO -   csatqa:
2025-07-30 03:03:46,645 - INFO -     - accuracy: 0.3690
2025-07-30 03:03:46,646 - INFO -     - accuracy_norm: 0.3690
2025-07-30 03:03:46,646 - INFO -   csatqa_gr:
2025-07-30 03:03:46,646 - INFO -     - accuracy: 0.0800
2025-07-30 03:03:46,646 - INFO -     - accuracy_norm: 0.0800
2025-07-30 03:03:46,646 - INFO -   csatqa_li:
2025-07-30 03:03:46,646 - INFO -     - accuracy: 0.4865
2025-07-30 03:03:46,646 - INFO -     - accuracy_norm: 0.4865
2025-07-30 03:03:46,647 - INFO -   csatqa_rch:
2025-07-30 03:03:46,647 - INFO -     - accuracy: 0.3714
2025-07-30 03:03:46,647 - INFO -     - accuracy_norm: 0.3714
2025-07-30 03:03:46,647 - INFO -   csatqa_rcs:
2025-07-30 03:03:46,647 - INFO -     - accuracy: 0.3514
2025-07-30 03:03:46,647 - INFO -     - accuracy_norm: 0.3514
2025-07-30 03:03:46,647 - INFO -   csatqa_rcss:
2025-07-30 03:03:46,647 - INFO -     - accuracy: 0.4762
2025-07-30 03:03:46,647 - INFO -     - accuracy_norm: 0.4762
2025-07-30 03:03:46,648 - INFO -   csatqa_wr:
2025-07-30 03:03:46,648 - INFO -     - accuracy: 0.2727
2025-07-30 03:03:46,648 - INFO -     - accuracy_norm: 0.2727
2025-07-30 03:03:46,648 - INFO - ============================================================

2025-07-30 03:03:46,667 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 6/10: kormedmcqa
2025-07-30 03:03:46,668 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'kormedmcqa' will use num_fewshot=5
2025-07-30 03:03:46,669 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-30 03:03:46,669 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-30 03:03:46,669 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 03:04:05,070 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-30 03:04:05,071 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-30 03:04:05,071 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-30 03:04:05,071 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
2025-07-30 03:08:02,541 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-30 03:08:02,543 - INFO - 
============================================================
2025-07-30 03:08:02,544 - INFO - Task 'kormedmcqa' Results:
2025-07-30 03:08:02,546 - INFO - ============================================================
2025-07-30 03:08:02,547 - INFO -   kormedmcqa:
2025-07-30 03:08:02,548 - INFO -     - exact_match: 0.5224
2025-07-30 03:08:02,549 - INFO -   kormedmcqa_dentist:
2025-07-30 03:08:02,549 - INFO -     - exact_match: 0.4451
2025-07-30 03:08:02,550 - INFO -   kormedmcqa_doctor:
2025-07-30 03:08:02,550 - INFO -     - exact_match: 0.4460
2025-07-30 03:08:02,551 - INFO -   kormedmcqa_nurse:
2025-07-30 03:08:02,551 - INFO -     - exact_match: 0.6310
2025-07-30 03:08:02,551 - INFO -   kormedmcqa_pharm:
2025-07-30 03:08:02,551 - INFO -     - exact_match: 0.5232
2025-07-30 03:08:02,551 - INFO - ============================================================

2025-07-30 03:08:02,563 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 7/10: mmlu
2025-07-30 03:08:02,564 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'mmlu' will use num_fewshot=5
2025-07-30 03:08:02,564 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'mmlu' with num_fewshot=5
2025-07-30 03:08:02,564 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-30 03:08:02,565 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 03:10:45,522 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5
2025-07-30 03:10:45,523 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5
2025-07-30 03:10:45,523 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 5
2025-07-30 03:10:45,523 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5
2025-07-30 03:10:45,523 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5
2025-07-30 03:10:45,523 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 5
2025-07-30 03:10:45,523 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 5
2025-07-30 03:10:45,523 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 5
2025-07-30 03:10:45,524 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 5
2025-07-30 03:10:45,525 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 5
2025-07-30 03:10:45,526 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 5
2025-07-30 03:10:45,527 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 5
2025-07-30 03:10:45,528 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5
2025-07-30 03:10:45,528 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 5
2025-07-30 03:10:45,528 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 5
2025-07-30 03:10:45,528 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5
2025-07-30 03:24:52,979 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'mmlu' with 62 subtasks
2025-07-30 03:24:52,981 - INFO - 
============================================================
2025-07-30 03:24:52,982 - INFO - Task 'mmlu' Results:
2025-07-30 03:24:52,984 - INFO - ============================================================
2025-07-30 03:24:52,987 - INFO -   mmlu:
2025-07-30 03:24:52,987 - INFO -     - accuracy: 0.5598
2025-07-30 03:24:52,987 - INFO -   mmlu_humanities:
2025-07-30 03:24:52,987 - INFO -     - accuracy: 0.5126
2025-07-30 03:24:52,987 - INFO -   mmlu_formal_logic:
2025-07-30 03:24:52,987 - INFO -     - accuracy: 0.4365
2025-07-30 03:24:52,987 - INFO -   mmlu_high_school_european_history:
2025-07-30 03:24:52,988 - INFO -     - accuracy: 0.6848
2025-07-30 03:24:52,988 - INFO -   mmlu_high_school_us_history:
2025-07-30 03:24:52,988 - INFO -     - accuracy: 0.7255
2025-07-30 03:24:52,988 - INFO -   mmlu_high_school_world_history:
2025-07-30 03:24:52,988 - INFO -     - accuracy: 0.7426
2025-07-30 03:24:52,988 - INFO -   mmlu_international_law:
2025-07-30 03:24:52,988 - INFO -     - accuracy: 0.6529
2025-07-30 03:24:52,988 - INFO -   mmlu_jurisprudence:
2025-07-30 03:24:52,988 - INFO -     - accuracy: 0.6852
2025-07-30 03:24:52,988 - INFO -   mmlu_logical_fallacies:
2025-07-30 03:24:52,989 - INFO -     - accuracy: 0.7301
2025-07-30 03:24:52,989 - INFO -   mmlu_moral_disputes:
2025-07-30 03:24:52,989 - INFO -     - accuracy: 0.6156
2025-07-30 03:24:52,989 - INFO -   mmlu_moral_scenarios:
2025-07-30 03:24:52,989 - INFO -     - accuracy: 0.3855
2025-07-30 03:24:52,989 - INFO -   mmlu_philosophy:
2025-07-30 03:24:52,989 - INFO -     - accuracy: 0.5884
2025-07-30 03:24:52,989 - INFO -   mmlu_prehistory:
2025-07-30 03:24:52,989 - INFO -     - accuracy: 0.5957
2025-07-30 03:24:52,989 - INFO -   mmlu_professional_law:
2025-07-30 03:24:52,989 - INFO -     - accuracy: 0.3827
2025-07-30 03:24:52,990 - INFO -   mmlu_world_religions:
2025-07-30 03:24:52,990 - INFO -     - accuracy: 0.7427
2025-07-30 03:24:52,990 - INFO -   mmlu_other:
2025-07-30 03:24:52,990 - INFO -     - accuracy: 0.6138
2025-07-30 03:24:52,990 - INFO -   mmlu_business_ethics:
2025-07-30 03:24:52,990 - INFO -     - accuracy: 0.5400
2025-07-30 03:24:52,990 - INFO -   mmlu_clinical_knowledge:
2025-07-30 03:24:52,990 - INFO -     - accuracy: 0.6453
2025-07-30 03:24:52,990 - INFO -   mmlu_college_medicine:
2025-07-30 03:24:52,990 - INFO -     - accuracy: 0.6185
2025-07-30 03:24:52,991 - INFO -   mmlu_global_facts:
2025-07-30 03:24:52,991 - INFO -     - accuracy: 0.3300
2025-07-30 03:24:52,991 - INFO -   mmlu_human_aging:
2025-07-30 03:24:52,991 - INFO -     - accuracy: 0.6099
2025-07-30 03:24:52,991 - INFO -   mmlu_management:
2025-07-30 03:24:52,991 - INFO -     - accuracy: 0.6602
2025-07-30 03:24:52,991 - INFO -   mmlu_marketing:
2025-07-30 03:24:52,991 - INFO -     - accuracy: 0.8376
2025-07-30 03:24:52,991 - INFO -   mmlu_medical_genetics:
2025-07-30 03:24:52,991 - INFO -     - accuracy: 0.6700
2025-07-30 03:24:52,992 - INFO -   mmlu_miscellaneous:
2025-07-30 03:24:52,992 - INFO -     - accuracy: 0.7280
2025-07-30 03:24:52,992 - INFO -   mmlu_nutrition:
2025-07-30 03:24:52,992 - INFO -     - accuracy: 0.5948
2025-07-30 03:24:52,992 - INFO -   mmlu_professional_accounting:
2025-07-30 03:24:52,992 - INFO -     - accuracy: 0.3617
2025-07-30 03:24:52,992 - INFO -   mmlu_professional_medicine:
2025-07-30 03:24:52,992 - INFO -     - accuracy: 0.5147
2025-07-30 03:24:52,992 - INFO -   mmlu_virology:
2025-07-30 03:24:52,992 - INFO -     - accuracy: 0.4880
2025-07-30 03:24:52,992 - INFO -   mmlu_social_sciences:
2025-07-30 03:24:52,993 - INFO -     - accuracy: 0.6412
2025-07-30 03:24:52,993 - INFO -   mmlu_econometrics:
2025-07-30 03:24:52,993 - INFO -     - accuracy: 0.3421
2025-07-30 03:24:52,993 - INFO -   mmlu_high_school_geography:
2025-07-30 03:24:52,993 - INFO -     - accuracy: 0.7677
2025-07-30 03:24:52,993 - INFO -   mmlu_high_school_government_and_politics:
2025-07-30 03:24:52,993 - INFO -     - accuracy: 0.7824
2025-07-30 03:24:52,993 - INFO -   mmlu_high_school_macroeconomics:
2025-07-30 03:24:52,993 - INFO -     - accuracy: 0.5487
2025-07-30 03:24:52,993 - INFO -   mmlu_high_school_microeconomics:
2025-07-30 03:24:52,994 - INFO -     - accuracy: 0.5840
2025-07-30 03:24:52,994 - INFO -   mmlu_high_school_psychology:
2025-07-30 03:24:52,994 - INFO -     - accuracy: 0.7725
2025-07-30 03:24:52,994 - INFO -   mmlu_human_sexuality:
2025-07-30 03:24:52,994 - INFO -     - accuracy: 0.6489
2025-07-30 03:24:52,994 - INFO -   mmlu_professional_psychology:
2025-07-30 03:24:52,994 - INFO -     - accuracy: 0.5507
2025-07-30 03:24:52,994 - INFO -   mmlu_public_relations:
2025-07-30 03:24:52,994 - INFO -     - accuracy: 0.5727
2025-07-30 03:24:53,061 - INFO -   mmlu_security_studies:
2025-07-30 03:24:53,061 - INFO -     - accuracy: 0.6286
2025-07-30 03:24:53,061 - INFO -   mmlu_sociology:
2025-07-30 03:24:53,061 - INFO -     - accuracy: 0.7264
2025-07-30 03:24:53,062 - INFO -   mmlu_us_foreign_policy:
2025-07-30 03:24:53,062 - INFO -     - accuracy: 0.7200
2025-07-30 03:24:53,062 - INFO -   mmlu_stem:
2025-07-30 03:24:53,062 - INFO -     - accuracy: 0.4976
2025-07-30 03:24:53,062 - INFO -   mmlu_abstract_algebra:
2025-07-30 03:24:53,062 - INFO -     - accuracy: 0.3400
2025-07-30 03:24:53,062 - INFO -   mmlu_anatomy:
2025-07-30 03:24:53,062 - INFO -     - accuracy: 0.5704
2025-07-30 03:24:53,062 - INFO -   mmlu_astronomy:
2025-07-30 03:24:53,063 - INFO -     - accuracy: 0.6447
2025-07-30 03:24:53,063 - INFO -   mmlu_college_biology:
2025-07-30 03:24:53,063 - INFO -     - accuracy: 0.6597
2025-07-30 03:24:53,063 - INFO -   mmlu_college_chemistry:
2025-07-30 03:24:53,063 - INFO -     - accuracy: 0.4500
2025-07-30 03:24:53,063 - INFO -   mmlu_college_computer_science:
2025-07-30 03:24:53,063 - INFO -     - accuracy: 0.5100
2025-07-30 03:24:53,063 - INFO -   mmlu_college_mathematics:
2025-07-30 03:24:53,063 - INFO -     - accuracy: 0.3800
2025-07-30 03:24:53,064 - INFO -   mmlu_college_physics:
2025-07-30 03:24:53,064 - INFO -     - accuracy: 0.3824
2025-07-30 03:24:53,064 - INFO -   mmlu_computer_security:
2025-07-30 03:24:53,064 - INFO -     - accuracy: 0.7300
2025-07-30 03:24:53,064 - INFO -   mmlu_conceptual_physics:
2025-07-30 03:24:53,064 - INFO -     - accuracy: 0.5362
2025-07-30 03:24:53,064 - INFO -   mmlu_electrical_engineering:
2025-07-30 03:24:53,064 - INFO -     - accuracy: 0.5931
2025-07-30 03:24:53,064 - INFO -   mmlu_elementary_mathematics:
2025-07-30 03:24:53,065 - INFO -     - accuracy: 0.3730
2025-07-30 03:24:53,065 - INFO -   mmlu_high_school_biology:
2025-07-30 03:24:53,065 - INFO -     - accuracy: 0.6968
2025-07-30 03:24:53,065 - INFO -   mmlu_high_school_chemistry:
2025-07-30 03:24:53,065 - INFO -     - accuracy: 0.4286
2025-07-30 03:24:53,065 - INFO -   mmlu_high_school_computer_science:
2025-07-30 03:24:53,065 - INFO -     - accuracy: 0.6300
2025-07-30 03:24:53,065 - INFO -   mmlu_high_school_mathematics:
2025-07-30 03:24:53,065 - INFO -     - accuracy: 0.3185
2025-07-30 03:24:53,066 - INFO -   mmlu_high_school_physics:
2025-07-30 03:24:53,066 - INFO -     - accuracy: 0.4040
2025-07-30 03:24:53,066 - INFO -   mmlu_high_school_statistics:
2025-07-30 03:24:53,066 - INFO -     - accuracy: 0.5000
2025-07-30 03:24:53,066 - INFO -   mmlu_machine_learning:
2025-07-30 03:24:53,066 - INFO -     - accuracy: 0.4018
2025-07-30 03:24:53,066 - INFO - ============================================================

2025-07-30 03:24:53,085 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 8/10: arc_challenge
2025-07-30 03:24:53,089 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'arc_challenge' will use num_fewshot=5
2025-07-30 03:24:53,089 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'arc_challenge' with num_fewshot=5
2025-07-30 03:24:53,089 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-30 03:24:53,089 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 03:25:02,219 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 5
2025-07-30 03:27:23,230 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-30 03:27:23,233 - INFO - 
============================================================
2025-07-30 03:27:23,235 - INFO - Task 'arc_challenge' Results:
2025-07-30 03:27:23,237 - INFO - ============================================================
2025-07-30 03:27:23,237 - INFO -   arc_challenge:
2025-07-30 03:27:23,238 - INFO -     - accuracy: 0.5375
2025-07-30 03:27:23,238 - INFO -     - accuracy_norm: 0.5691
2025-07-30 03:27:23,239 - INFO - ============================================================

2025-07-30 03:27:23,250 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 9/10: arc_easy
2025-07-30 03:27:23,252 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'arc_easy' will use num_fewshot=5
2025-07-30 03:27:23,252 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'arc_easy' with num_fewshot=5
2025-07-30 03:27:23,252 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-30 03:27:23,252 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 03:27:31,839 - WARNING - Overwriting default num_fewshot of arc_easy from None to 5
2025-07-30 03:31:57,709 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-30 03:31:57,712 - INFO - 
============================================================
2025-07-30 03:31:57,714 - INFO - Task 'arc_easy' Results:
2025-07-30 03:31:57,716 - INFO - ============================================================
2025-07-30 03:31:57,717 - INFO -   arc_easy:
2025-07-30 03:31:57,717 - INFO -     - accuracy: 0.8056
2025-07-30 03:31:57,717 - INFO -     - accuracy_norm: 0.7980
2025-07-30 03:31:57,718 - INFO - ============================================================

2025-07-30 03:31:57,729 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Processing task 10/10: hellaswag
2025-07-30 03:31:57,730 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Task 'hellaswag' will use num_fewshot=5
2025-07-30 03:31:57,731 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Evaluating task 'hellaswag' with num_fewshot=5
2025-07-30 03:31:57,731 - WARNING - Instruct model detected, but chat template not applied. Recommend setting `apply_chat_template` (optionally `fewshot_as_multiturn`).
2025-07-30 03:31:57,731 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 03:32:12,909 - WARNING - Overwriting default num_fewshot of hellaswag from None to 5
2025-07-30 03:55:23,932 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-30 03:55:23,934 - INFO - 
============================================================
2025-07-30 03:55:23,936 - INFO - Task 'hellaswag' Results:
2025-07-30 03:55:23,937 - INFO - ============================================================
2025-07-30 03:55:23,940 - INFO -   hellaswag:
2025-07-30 03:55:23,941 - INFO -     - accuracy: 0.5123
2025-07-30 03:55:23,941 - INFO -     - accuracy_norm: 0.6747
2025-07-30 03:55:23,941 - INFO - ============================================================

2025-07-30 03:55:23,955 - INFO - kanana-1.5-2.1b-instruct-2505_harness_11: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-30 03:55:23,957 - INFO - [Process 2120894] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/kanana-1.5-2.1b-instruct-2505/kanana-1.5-2.1b-instruct-2505_harness_11.json
2025-07-30 03:55:24,228 - INFO - Results uploaded to WandB as artifact
2025-07-30 03:55:24,238 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-30 03:55:24,240 - INFO - [Process 2120894] Successfully completed kanana-1.5-2.1b-instruct-2505_harness_11
2025-07-30 03:55:27,337 - INFO - Run kanana-1.5-2.1b-instruct-2505_harness_11 finished successfully
2025-07-30 03:55:27,337 - INFO - [Process 2120894] eagle-3b-preview_harness_12 assigned to cuda:0
2025-07-30 03:55:27,337 - INFO - [Process 2120894] eagle-3b-preview_harness_12 - full_run: True, limit: None (full dataset)
2025-07-30 03:55:28,654 - INFO - WandB run initialized: eagle-3b-preview_20250730_035527 (ID: f227ef58)
2025-07-30 03:55:28,951 - INFO - eagle-3b-preview_harness_12: Processing task 1/10: kmmlu
2025-07-30 03:55:28,952 - INFO - eagle-3b-preview_harness_12: Task 'kmmlu' will use num_fewshot=5
2025-07-30 03:55:28,952 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-30 03:55:28,952 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 03:56:46,419 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-30 03:56:46,419 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-30 03:56:46,419 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-30 03:56:46,419 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-30 03:56:46,419 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-30 03:56:46,419 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-30 03:56:46,420 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-30 03:56:46,420 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-30 03:56:46,420 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-30 03:56:46,420 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-30 03:56:46,420 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-30 03:56:46,420 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-30 03:56:46,420 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-30 03:56:46,420 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-30 03:56:46,420 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-30 03:56:46,421 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-30 03:56:46,421 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-30 03:56:46,421 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-30 03:56:46,421 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-30 03:56:46,421 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-30 03:56:46,421 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-30 03:56:46,421 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-30 03:56:46,421 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-30 03:56:46,421 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-30 03:56:46,421 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-30 03:56:46,422 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-30 03:56:46,422 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-30 03:56:46,422 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-30 03:56:46,422 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-30 03:56:46,422 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-30 03:56:46,422 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-30 03:56:46,422 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-30 03:56:46,422 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-30 03:56:46,422 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-30 03:56:46,423 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-30 03:56:46,423 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-30 03:56:46,423 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-30 03:56:46,423 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-30 03:56:46,423 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-30 03:56:46,423 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-30 03:56:46,423 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-30 03:56:46,423 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-30 03:56:46,423 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-30 03:56:46,423 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-30 03:56:46,424 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-30 04:18:50,628 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-30 04:18:50,629 - INFO - 
============================================================
2025-07-30 04:18:50,629 - INFO - Task 'kmmlu' Results:
2025-07-30 04:18:50,629 - INFO - ============================================================
2025-07-30 04:18:50,630 - INFO -   kmmlu:
2025-07-30 04:18:50,630 - INFO -     - accuracy: 0.1639
2025-07-30 04:18:50,630 - INFO -   kmmlu_applied_science:
2025-07-30 04:18:50,630 - INFO -     - accuracy: 0.1491
2025-07-30 04:18:50,630 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-30 04:18:50,630 - INFO -     - accuracy: 0.1830
2025-07-30 04:18:50,630 - INFO -   kmmlu_electronics_engineering:
2025-07-30 04:18:50,630 - INFO -     - accuracy: 0.1120
2025-07-30 04:18:50,631 - INFO -   kmmlu_energy_management:
2025-07-30 04:18:50,631 - INFO -     - accuracy: 0.1960
2025-07-30 04:18:50,631 - INFO -   kmmlu_environmental_science:
2025-07-30 04:18:50,631 - INFO -     - accuracy: 0.0820
2025-07-30 04:18:50,631 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-30 04:18:50,631 - INFO -     - accuracy: 0.2090
2025-07-30 04:18:50,631 - INFO -   kmmlu_geomatics:
2025-07-30 04:18:50,631 - INFO -     - accuracy: 0.2390
2025-07-30 04:18:50,631 - INFO -   kmmlu_industrial_engineer:
2025-07-30 04:18:50,631 - INFO -     - accuracy: 0.0680
2025-07-30 04:18:50,632 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-30 04:18:50,632 - INFO -     - accuracy: 0.1140
2025-07-30 04:18:50,632 - INFO -   kmmlu_maritime_engineering:
2025-07-30 04:18:50,632 - INFO -     - accuracy: 0.1750
2025-07-30 04:18:50,632 - INFO -   kmmlu_nondestructive_testing:
2025-07-30 04:18:50,632 - INFO -     - accuracy: 0.1480
2025-07-30 04:18:50,632 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-30 04:18:50,632 - INFO -     - accuracy: 0.1930
2025-07-30 04:18:50,632 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-30 04:18:50,632 - INFO -     - accuracy: 0.0810
2025-07-30 04:18:50,632 - INFO -   kmmlu_humss:
2025-07-30 04:18:50,633 - INFO -     - accuracy: 0.2185
2025-07-30 04:18:50,633 - INFO -   kmmlu_accounting:
2025-07-30 04:18:50,633 - INFO -     - accuracy: 0.2100
2025-07-30 04:18:50,633 - INFO -   kmmlu_criminal_law:
2025-07-30 04:18:50,633 - INFO -     - accuracy: 0.2450
2025-07-30 04:18:50,633 - INFO -   kmmlu_economics:
2025-07-30 04:18:50,633 - INFO -     - accuracy: 0.2846
2025-07-30 04:18:50,633 - INFO -   kmmlu_education:
2025-07-30 04:18:50,633 - INFO -     - accuracy: 0.2300
2025-07-30 04:18:50,633 - INFO -   kmmlu_korean_history:
2025-07-30 04:18:50,634 - INFO -     - accuracy: 0.1900
2025-07-30 04:18:50,634 - INFO -   kmmlu_law:
2025-07-30 04:18:50,634 - INFO -     - accuracy: 0.2290
2025-07-30 04:18:50,634 - INFO -   kmmlu_management:
2025-07-30 04:18:50,634 - INFO -     - accuracy: 0.2190
2025-07-30 04:18:50,634 - INFO -   kmmlu_political_science_and_sociology:
2025-07-30 04:18:50,634 - INFO -     - accuracy: 0.2067
2025-07-30 04:18:50,634 - INFO -   kmmlu_psychology:
2025-07-30 04:18:50,634 - INFO -     - accuracy: 0.2250
2025-07-30 04:18:50,634 - INFO -   kmmlu_social_welfare:
2025-07-30 04:18:50,635 - INFO -     - accuracy: 0.1880
2025-07-30 04:18:50,635 - INFO -   kmmlu_taxation:
2025-07-30 04:18:50,635 - INFO -     - accuracy: 0.2450
2025-07-30 04:18:50,635 - INFO -   kmmlu_other:
2025-07-30 04:18:50,635 - INFO -     - accuracy: 0.1604
2025-07-30 04:18:50,635 - INFO -   kmmlu_agricultural_sciences:
2025-07-30 04:18:50,635 - INFO -     - accuracy: 0.1900
2025-07-30 04:18:50,635 - INFO -   kmmlu_construction:
2025-07-30 04:18:50,635 - INFO -     - accuracy: 0.1660
2025-07-30 04:18:50,635 - INFO -   kmmlu_fashion:
2025-07-30 04:18:50,636 - INFO -     - accuracy: 0.1650
2025-07-30 04:18:50,636 - INFO -   kmmlu_food_processing:
2025-07-30 04:18:50,636 - INFO -     - accuracy: 0.1910
2025-07-30 04:18:50,636 - INFO -   kmmlu_health:
2025-07-30 04:18:50,636 - INFO -     - accuracy: 0.2500
2025-07-30 04:18:50,636 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-30 04:18:50,636 - INFO -     - accuracy: 0.1250
2025-07-30 04:18:50,636 - INFO -   kmmlu_marketing:
2025-07-30 04:18:50,636 - INFO -     - accuracy: 0.1300
2025-07-30 04:18:50,636 - INFO -   kmmlu_patent:
2025-07-30 04:18:50,636 - INFO -     - accuracy: 0.3000
2025-07-30 04:18:50,637 - INFO -   kmmlu_public_safety:
2025-07-30 04:18:50,637 - INFO -     - accuracy: 0.0690
2025-07-30 04:18:50,637 - INFO -   kmmlu_real_estate:
2025-07-30 04:18:50,637 - INFO -     - accuracy: 0.2000
2025-07-30 04:18:50,637 - INFO -   kmmlu_refrigerating_machinery:
2025-07-30 04:18:50,637 - INFO -     - accuracy: 0.2160
2025-07-30 04:18:50,637 - INFO -   kmmlu_stem:
2025-07-30 04:18:50,637 - INFO -     - accuracy: 0.1561
2025-07-30 04:18:50,637 - INFO -   kmmlu_biology:
2025-07-30 04:18:50,637 - INFO -     - accuracy: 0.2020
2025-07-30 04:18:50,638 - INFO -   kmmlu_chemical_engineering:
2025-07-30 04:18:50,638 - INFO -     - accuracy: 0.2340
2025-07-30 04:18:50,638 - INFO -   kmmlu_chemistry:
2025-07-30 04:18:50,638 - INFO -     - accuracy: 0.2133
2025-07-30 04:18:50,638 - INFO -   kmmlu_civil_engineering:
2025-07-30 04:18:50,638 - INFO -     - accuracy: 0.0730
2025-07-30 04:18:50,638 - INFO -   kmmlu_computer_science:
2025-07-30 04:18:50,638 - INFO -     - accuracy: 0.1520
2025-07-30 04:18:50,638 - INFO -   kmmlu_ecology:
2025-07-30 04:18:50,639 - INFO -     - accuracy: 0.1510
2025-07-30 04:18:50,639 - INFO -   kmmlu_electrical_engineering:
2025-07-30 04:18:50,639 - INFO -     - accuracy: 0.1500
2025-07-30 04:18:50,639 - INFO -   kmmlu_information_technology:
2025-07-30 04:18:50,639 - INFO -     - accuracy: 0.0670
2025-07-30 04:18:50,639 - INFO -   kmmlu_materials_engineering:
2025-07-30 04:18:50,639 - INFO -     - accuracy: 0.1860
2025-07-30 04:18:50,639 - INFO -   kmmlu_math:
2025-07-30 04:18:50,639 - INFO -     - accuracy: 0.2267
2025-07-30 04:18:50,639 - INFO -   kmmlu_mechanical_engineering:
2025-07-30 04:18:50,640 - INFO -     - accuracy: 0.1340
2025-07-30 04:18:50,640 - INFO - ============================================================

2025-07-30 04:18:50,656 - INFO - eagle-3b-preview_harness_12: Processing task 2/10: kmmlu_hard
2025-07-30 04:18:50,658 - INFO - eagle-3b-preview_harness_12: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-30 04:18:50,659 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-30 04:18:50,659 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 04:20:05,442 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-30 04:20:05,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-30 04:20:05,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-30 04:20:05,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-30 04:20:05,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-30 04:20:05,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-30 04:20:05,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-30 04:20:05,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-30 04:20:05,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-30 04:20:05,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-30 04:20:05,443 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-30 04:20:05,444 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-30 04:20:05,445 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-30 04:20:05,446 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-30 04:20:05,447 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-30 04:22:59,345 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-30 04:22:59,347 - INFO - 
============================================================
2025-07-30 04:22:59,347 - INFO - Task 'kmmlu_hard' Results:
2025-07-30 04:22:59,348 - INFO - ============================================================
2025-07-30 04:22:59,348 - INFO -   kmmlu_hard:
2025-07-30 04:22:59,348 - INFO -     - accuracy: 0.2113
2025-07-30 04:22:59,348 - INFO -   kmmlu_hard_applied_science:
2025-07-30 04:22:59,348 - INFO -     - accuracy: 0.1917
2025-07-30 04:22:59,348 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-30 04:22:59,348 - INFO -     - accuracy: 0.1700
2025-07-30 04:22:59,349 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-30 04:22:59,349 - INFO -     - accuracy: 0.0600
2025-07-30 04:22:59,349 - INFO -   kmmlu_hard_energy_management:
2025-07-30 04:22:59,349 - INFO -     - accuracy: 0.3100
2025-07-30 04:22:59,349 - INFO -   kmmlu_hard_environmental_science:
2025-07-30 04:22:59,349 - INFO -     - accuracy: 0.0300
2025-07-30 04:22:59,349 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-30 04:22:59,349 - INFO -     - accuracy: 0.2600
2025-07-30 04:22:59,349 - INFO -   kmmlu_hard_geomatics:
2025-07-30 04:22:59,350 - INFO -     - accuracy: 0.2800
2025-07-30 04:22:59,350 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-30 04:22:59,350 - INFO -     - accuracy: 0.0700
2025-07-30 04:22:59,350 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-30 04:22:59,350 - INFO -     - accuracy: 0.2100
2025-07-30 04:22:59,350 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-30 04:22:59,350 - INFO -     - accuracy: 0.3500
2025-07-30 04:22:59,350 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-30 04:22:59,351 - INFO -     - accuracy: 0.2200
2025-07-30 04:22:59,351 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-30 04:22:59,351 - INFO -     - accuracy: 0.2400
2025-07-30 04:22:59,351 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-30 04:22:59,351 - INFO -     - accuracy: 0.1000
2025-07-30 04:22:59,351 - INFO -   kmmlu_hard_humss:
2025-07-30 04:22:59,351 - INFO -     - accuracy: 0.2616
2025-07-30 04:22:59,351 - INFO -   kmmlu_hard_accounting:
2025-07-30 04:22:59,352 - INFO -     - accuracy: 0.2609
2025-07-30 04:22:59,352 - INFO -   kmmlu_hard_criminal_law:
2025-07-30 04:22:59,352 - INFO -     - accuracy: 0.3200
2025-07-30 04:22:59,352 - INFO -   kmmlu_hard_economics:
2025-07-30 04:22:59,352 - INFO -     - accuracy: 0.3333
2025-07-30 04:22:59,352 - INFO -   kmmlu_hard_education:
2025-07-30 04:22:59,352 - INFO -     - accuracy: 0.0870
2025-07-30 04:22:59,352 - INFO -   kmmlu_hard_korean_history:
2025-07-30 04:22:59,352 - INFO -     - accuracy: 0.2727
2025-07-30 04:22:59,353 - INFO -   kmmlu_hard_law:
2025-07-30 04:22:59,353 - INFO -     - accuracy: 0.2400
2025-07-30 04:22:59,353 - INFO -   kmmlu_hard_management:
2025-07-30 04:22:59,353 - INFO -     - accuracy: 0.2500
2025-07-30 04:22:59,353 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-30 04:22:59,353 - INFO -     - accuracy: 0.2556
2025-07-30 04:22:59,353 - INFO -   kmmlu_hard_psychology:
2025-07-30 04:22:59,353 - INFO -     - accuracy: 0.3100
2025-07-30 04:22:59,354 - INFO -   kmmlu_hard_social_welfare:
2025-07-30 04:22:59,354 - INFO -     - accuracy: 0.2000
2025-07-30 04:22:59,354 - INFO -   kmmlu_hard_taxation:
2025-07-30 04:22:59,354 - INFO -     - accuracy: 0.2604
2025-07-30 04:22:59,354 - INFO -   kmmlu_hard_other:
2025-07-30 04:22:59,354 - INFO -     - accuracy: 0.2108
2025-07-30 04:22:59,354 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-30 04:22:59,354 - INFO -     - accuracy: 0.2400
2025-07-30 04:22:59,354 - INFO -   kmmlu_hard_construction:
2025-07-30 04:22:59,355 - INFO -     - accuracy: 0.1300
2025-07-30 04:22:59,355 - INFO -   kmmlu_hard_fashion:
2025-07-30 04:22:59,355 - INFO -     - accuracy: 0.2700
2025-07-30 04:22:59,355 - INFO -   kmmlu_hard_food_processing:
2025-07-30 04:22:59,355 - INFO -     - accuracy: 0.1900
2025-07-30 04:22:59,355 - INFO -   kmmlu_hard_health:
2025-07-30 04:22:59,355 - INFO -     - accuracy: 0.2609
2025-07-30 04:22:59,355 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-30 04:22:59,356 - INFO -     - accuracy: 0.1700
2025-07-30 04:22:59,356 - INFO -   kmmlu_hard_marketing:
2025-07-30 04:22:59,356 - INFO -     - accuracy: 0.2700
2025-07-30 04:22:59,356 - INFO -   kmmlu_hard_patent:
2025-07-30 04:22:59,356 - INFO -     - accuracy: 0.3529
2025-07-30 04:22:59,356 - INFO -   kmmlu_hard_public_safety:
2025-07-30 04:22:59,356 - INFO -     - accuracy: 0.0800
2025-07-30 04:22:59,356 - INFO -   kmmlu_hard_real_estate:
2025-07-30 04:22:59,356 - INFO -     - accuracy: 0.2135
2025-07-30 04:22:59,357 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-30 04:22:59,357 - INFO -     - accuracy: 0.2500
2025-07-30 04:22:59,357 - INFO -   kmmlu_hard_stem:
2025-07-30 04:22:59,357 - INFO -     - accuracy: 0.1945
2025-07-30 04:22:59,357 - INFO -   kmmlu_hard_biology:
2025-07-30 04:22:59,357 - INFO -     - accuracy: 0.3300
2025-07-30 04:22:59,357 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-30 04:22:59,357 - INFO -     - accuracy: 0.2600
2025-07-30 04:22:59,358 - INFO -   kmmlu_hard_chemistry:
2025-07-30 04:22:59,358 - INFO -     - accuracy: 0.2400
2025-07-30 04:22:59,358 - INFO -   kmmlu_hard_civil_engineering:
2025-07-30 04:22:59,358 - INFO -     - accuracy: 0.1100
2025-07-30 04:22:59,358 - INFO -   kmmlu_hard_computer_science:
2025-07-30 04:22:59,358 - INFO -     - accuracy: 0.1000
2025-07-30 04:22:59,358 - INFO -   kmmlu_hard_ecology:
2025-07-30 04:22:59,358 - INFO -     - accuracy: 0.2800
2025-07-30 04:22:59,358 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-30 04:22:59,359 - INFO -     - accuracy: 0.1000
2025-07-30 04:22:59,359 - INFO -   kmmlu_hard_information_technology:
2025-07-30 04:22:59,359 - INFO -     - accuracy: 0.0900
2025-07-30 04:22:59,359 - INFO -   kmmlu_hard_materials_engineering:
2025-07-30 04:22:59,359 - INFO -     - accuracy: 0.2100
2025-07-30 04:22:59,359 - INFO -   kmmlu_hard_math:
2025-07-30 04:22:59,359 - INFO -     - accuracy: 0.2800
2025-07-30 04:22:59,359 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-30 04:22:59,359 - INFO -     - accuracy: 0.1400
2025-07-30 04:22:59,360 - INFO - ============================================================

2025-07-30 04:22:59,376 - INFO - eagle-3b-preview_harness_12: Processing task 3/10: haerae
2025-07-30 04:22:59,378 - INFO - eagle-3b-preview_harness_12: Task 'haerae' will use num_fewshot=5
2025-07-30 04:22:59,378 - INFO - eagle-3b-preview_harness_12: Evaluating task 'haerae' with num_fewshot=5
2025-07-30 04:22:59,378 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 04:23:16,365 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-30 04:23:16,365 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-30 04:23:16,365 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-30 04:23:16,366 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-30 04:23:16,366 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-30 04:26:15,064 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'haerae' with 6 subtasks
2025-07-30 04:26:15,066 - INFO - 
============================================================
2025-07-30 04:26:15,066 - INFO - Task 'haerae' Results:
2025-07-30 04:26:15,066 - INFO - ============================================================
2025-07-30 04:26:15,066 - INFO -   haerae:
2025-07-30 04:26:15,066 - INFO -     - accuracy: 0.1952
2025-07-30 04:26:15,066 - INFO -     - accuracy_norm: 0.1952
2025-07-30 04:26:15,067 - INFO -   haerae_general_knowledge:
2025-07-30 04:26:15,067 - INFO -     - accuracy: 0.1534
2025-07-30 04:26:15,067 - INFO -     - accuracy_norm: 0.1534
2025-07-30 04:26:15,067 - INFO -   haerae_history:
2025-07-30 04:26:15,067 - INFO -     - accuracy: 0.1809
2025-07-30 04:26:15,067 - INFO -     - accuracy_norm: 0.1809
2025-07-30 04:26:15,067 - INFO -   haerae_loan_word:
2025-07-30 04:26:15,067 - INFO -     - accuracy: 0.2604
2025-07-30 04:26:15,068 - INFO -     - accuracy_norm: 0.2604
2025-07-30 04:26:15,068 - INFO -   haerae_rare_word:
2025-07-30 04:26:15,068 - INFO -     - accuracy: 0.1901
2025-07-30 04:26:15,068 - INFO -     - accuracy_norm: 0.1901
2025-07-30 04:26:15,068 - INFO -   haerae_standard_nomenclature:
2025-07-30 04:26:15,068 - INFO -     - accuracy: 0.2026
2025-07-30 04:26:15,068 - INFO -     - accuracy_norm: 0.2026
2025-07-30 04:26:15,068 - INFO - ============================================================

2025-07-30 04:26:15,083 - INFO - eagle-3b-preview_harness_12: Processing task 4/10: kobest
2025-07-30 04:26:15,085 - INFO - eagle-3b-preview_harness_12: Task 'kobest' will use num_fewshot=5
2025-07-30 04:26:15,085 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kobest' with num_fewshot=5
2025-07-30 04:26:15,086 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 04:26:34,855 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-30 04:26:34,856 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-30 04:26:34,856 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-30 04:26:34,856 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-30 04:26:34,856 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-30 04:30:53,191 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kobest' with 6 subtasks
2025-07-30 04:30:53,193 - INFO - 
============================================================
2025-07-30 04:30:53,193 - INFO - Task 'kobest' Results:
2025-07-30 04:30:53,193 - INFO - ============================================================
2025-07-30 04:30:53,193 - INFO -   kobest:
2025-07-30 04:30:53,193 - INFO -     - accuracy: 0.5387
2025-07-30 04:30:53,193 - INFO -     - accuracy_norm: 0.4920
2025-07-30 04:30:53,193 - INFO -     - f1: 0.5163
2025-07-30 04:30:53,194 - INFO -   kobest_boolq:
2025-07-30 04:30:53,194 - INFO -     - accuracy: 0.5228
2025-07-30 04:30:53,194 - INFO -     - f1: 0.5150
2025-07-30 04:30:53,194 - INFO -   kobest_copa:
2025-07-30 04:30:53,194 - INFO -     - accuracy: 0.6460
2025-07-30 04:30:53,194 - INFO -     - f1: 0.6453
2025-07-30 04:30:53,194 - INFO -   kobest_hellaswag:
2025-07-30 04:30:53,194 - INFO -     - accuracy: 0.3800
2025-07-30 04:30:53,194 - INFO -     - accuracy_norm: 0.4920
2025-07-30 04:30:53,194 - INFO -     - f1: 0.3768
2025-07-30 04:30:53,195 - INFO -   kobest_sentineg:
2025-07-30 04:30:53,195 - INFO -     - accuracy: 0.5743
2025-07-30 04:30:53,195 - INFO -     - f1: 0.5012
2025-07-30 04:30:53,195 - INFO -   kobest_wic:
2025-07-30 04:30:53,195 - INFO -     - accuracy: 0.5230
2025-07-30 04:30:53,195 - INFO -     - f1: 0.4756
2025-07-30 04:30:53,195 - INFO - ============================================================

2025-07-30 04:30:53,211 - INFO - eagle-3b-preview_harness_12: Processing task 5/10: csatqa
2025-07-30 04:30:53,212 - INFO - eagle-3b-preview_harness_12: Task 'csatqa' detected as zero-shot task
2025-07-30 04:30:53,212 - INFO - eagle-3b-preview_harness_12: Evaluating task 'csatqa' with num_fewshot=0
2025-07-30 04:30:53,213 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 04:31:06,824 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-30 04:31:06,825 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-30 04:31:06,825 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-30 04:31:06,825 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-30 04:31:06,825 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-30 04:31:06,825 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-30 04:32:01,682 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'csatqa' with 7 subtasks
2025-07-30 04:32:01,684 - INFO - 
============================================================
2025-07-30 04:32:01,685 - INFO - Task 'csatqa' Results:
2025-07-30 04:32:01,685 - INFO - ============================================================
2025-07-30 04:32:01,685 - INFO -   csatqa:
2025-07-30 04:32:01,685 - INFO -     - accuracy: 0.1604
2025-07-30 04:32:01,685 - INFO -     - accuracy_norm: 0.1604
2025-07-30 04:32:01,685 - INFO -   csatqa_gr:
2025-07-30 04:32:01,685 - INFO -     - accuracy: 0.1200
2025-07-30 04:32:01,685 - INFO -     - accuracy_norm: 0.1200
2025-07-30 04:32:01,685 - INFO -   csatqa_li:
2025-07-30 04:32:01,685 - INFO -     - accuracy: 0.2162
2025-07-30 04:32:01,686 - INFO -     - accuracy_norm: 0.2162
2025-07-30 04:32:01,686 - INFO -   csatqa_rch:
2025-07-30 04:32:01,686 - INFO -     - accuracy: 0.1429
2025-07-30 04:32:01,686 - INFO -     - accuracy_norm: 0.1429
2025-07-30 04:32:01,686 - INFO -   csatqa_rcs:
2025-07-30 04:32:01,686 - INFO -     - accuracy: 0.1351
2025-07-30 04:32:01,686 - INFO -     - accuracy_norm: 0.1351
2025-07-30 04:32:01,686 - INFO -   csatqa_rcss:
2025-07-30 04:32:01,686 - INFO -     - accuracy: 0.1667
2025-07-30 04:32:01,686 - INFO -     - accuracy_norm: 0.1667
2025-07-30 04:32:01,687 - INFO -   csatqa_wr:
2025-07-30 04:32:01,687 - INFO -     - accuracy: 0.1818
2025-07-30 04:32:01,687 - INFO -     - accuracy_norm: 0.1818
2025-07-30 04:32:01,687 - INFO - ============================================================

2025-07-30 04:32:01,705 - INFO - eagle-3b-preview_harness_12: Processing task 6/10: kormedmcqa
2025-07-30 04:32:01,706 - INFO - eagle-3b-preview_harness_12: Task 'kormedmcqa' will use num_fewshot=5
2025-07-30 04:32:01,706 - INFO - eagle-3b-preview_harness_12: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-30 04:32:01,707 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 04:32:20,599 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-30 04:32:20,599 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-30 04:32:20,600 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-30 04:32:20,600 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
2025-07-30 04:36:22,017 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-30 04:36:22,019 - INFO - 
============================================================
2025-07-30 04:36:22,020 - INFO - Task 'kormedmcqa' Results:
2025-07-30 04:36:22,020 - INFO - ============================================================
2025-07-30 04:36:22,020 - INFO -   kormedmcqa:
2025-07-30 04:36:22,020 - INFO -     - exact_match: 0.1805
2025-07-30 04:36:22,020 - INFO -   kormedmcqa_dentist:
2025-07-30 04:36:22,020 - INFO -     - exact_match: 0.1677
2025-07-30 04:36:22,021 - INFO -   kormedmcqa_doctor:
2025-07-30 04:36:22,021 - INFO -     - exact_match: 0.1977
2025-07-30 04:36:22,021 - INFO -   kormedmcqa_nurse:
2025-07-30 04:36:22,021 - INFO -     - exact_match: 0.1811
2025-07-30 04:36:22,021 - INFO -   kormedmcqa_pharm:
2025-07-30 04:36:22,021 - INFO -     - exact_match: 0.1831
2025-07-30 04:36:22,021 - INFO - ============================================================

2025-07-30 04:36:22,036 - INFO - eagle-3b-preview_harness_12: Processing task 7/10: mmlu
2025-07-30 04:36:22,038 - INFO - eagle-3b-preview_harness_12: Task 'mmlu' will use num_fewshot=5
2025-07-30 04:36:22,038 - INFO - eagle-3b-preview_harness_12: Evaluating task 'mmlu' with num_fewshot=5
2025-07-30 04:36:22,039 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 04:39:03,344 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5
2025-07-30 04:39:03,344 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 5
2025-07-30 04:39:03,345 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 5
2025-07-30 04:39:03,346 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5
2025-07-30 04:39:03,347 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 5
2025-07-30 04:39:03,348 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 5
2025-07-30 04:39:03,349 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5
2025-07-30 04:51:45,030 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'mmlu' with 62 subtasks
2025-07-30 04:51:45,032 - INFO - 
============================================================
2025-07-30 04:51:45,032 - INFO - Task 'mmlu' Results:
2025-07-30 04:51:45,032 - INFO - ============================================================
2025-07-30 04:51:45,032 - INFO -   mmlu:
2025-07-30 04:51:45,032 - INFO -     - accuracy: 0.2531
2025-07-30 04:51:45,033 - INFO -   mmlu_humanities:
2025-07-30 04:51:45,033 - INFO -     - accuracy: 0.2621
2025-07-30 04:51:45,033 - INFO -   mmlu_formal_logic:
2025-07-30 04:51:45,033 - INFO -     - accuracy: 0.2540
2025-07-30 04:51:45,033 - INFO -   mmlu_high_school_european_history:
2025-07-30 04:51:45,033 - INFO -     - accuracy: 0.2424
2025-07-30 04:51:45,033 - INFO -   mmlu_high_school_us_history:
2025-07-30 04:51:45,033 - INFO -     - accuracy: 0.2990
2025-07-30 04:51:45,034 - INFO -   mmlu_high_school_world_history:
2025-07-30 04:51:45,034 - INFO -     - accuracy: 0.2658
2025-07-30 04:51:45,034 - INFO -   mmlu_international_law:
2025-07-30 04:51:45,034 - INFO -     - accuracy: 0.3471
2025-07-30 04:51:45,034 - INFO -   mmlu_jurisprudence:
2025-07-30 04:51:45,034 - INFO -     - accuracy: 0.3333
2025-07-30 04:51:45,034 - INFO -   mmlu_logical_fallacies:
2025-07-30 04:51:45,034 - INFO -     - accuracy: 0.2393
2025-07-30 04:51:45,035 - INFO -   mmlu_moral_disputes:
2025-07-30 04:51:45,035 - INFO -     - accuracy: 0.2601
2025-07-30 04:51:45,035 - INFO -   mmlu_moral_scenarios:
2025-07-30 04:51:45,035 - INFO -     - accuracy: 0.2469
2025-07-30 04:51:45,035 - INFO -   mmlu_philosophy:
2025-07-30 04:51:45,035 - INFO -     - accuracy: 0.2637
2025-07-30 04:51:45,035 - INFO -   mmlu_prehistory:
2025-07-30 04:51:45,035 - INFO -     - accuracy: 0.2500
2025-07-30 04:51:45,035 - INFO -   mmlu_professional_law:
2025-07-30 04:51:45,035 - INFO -     - accuracy: 0.2588
2025-07-30 04:51:45,036 - INFO -   mmlu_world_religions:
2025-07-30 04:51:45,036 - INFO -     - accuracy: 0.2865
2025-07-30 04:51:45,036 - INFO -   mmlu_other:
2025-07-30 04:51:45,036 - INFO -     - accuracy: 0.2395
2025-07-30 04:51:45,036 - INFO -   mmlu_business_ethics:
2025-07-30 04:51:45,036 - INFO -     - accuracy: 0.2100
2025-07-30 04:51:45,036 - INFO -   mmlu_clinical_knowledge:
2025-07-30 04:51:45,036 - INFO -     - accuracy: 0.3208
2025-07-30 04:51:45,036 - INFO -   mmlu_college_medicine:
2025-07-30 04:51:45,036 - INFO -     - accuracy: 0.2601
2025-07-30 04:51:45,037 - INFO -   mmlu_global_facts:
2025-07-30 04:51:45,037 - INFO -     - accuracy: 0.2800
2025-07-30 04:51:45,037 - INFO -   mmlu_human_aging:
2025-07-30 04:51:45,037 - INFO -     - accuracy: 0.1435
2025-07-30 04:51:45,037 - INFO -   mmlu_management:
2025-07-30 04:51:45,037 - INFO -     - accuracy: 0.2136
2025-07-30 04:51:45,037 - INFO -   mmlu_marketing:
2025-07-30 04:51:45,037 - INFO -     - accuracy: 0.2479
2025-07-30 04:51:45,037 - INFO -   mmlu_medical_genetics:
2025-07-30 04:51:45,038 - INFO -     - accuracy: 0.2600
2025-07-30 04:51:45,038 - INFO -   mmlu_miscellaneous:
2025-07-30 04:51:45,038 - INFO -     - accuracy: 0.2312
2025-07-30 04:51:45,038 - INFO -   mmlu_nutrition:
2025-07-30 04:51:45,038 - INFO -     - accuracy: 0.2745
2025-07-30 04:51:45,038 - INFO -   mmlu_professional_accounting:
2025-07-30 04:51:45,038 - INFO -     - accuracy: 0.2695
2025-07-30 04:51:45,039 - INFO -   mmlu_professional_medicine:
2025-07-30 04:51:45,039 - INFO -     - accuracy: 0.1691
2025-07-30 04:51:45,039 - INFO -   mmlu_virology:
2025-07-30 04:51:45,039 - INFO -     - accuracy: 0.2410
2025-07-30 04:51:45,039 - INFO -   mmlu_social_sciences:
2025-07-30 04:51:45,039 - INFO -     - accuracy: 0.2476
2025-07-30 04:51:45,039 - INFO -   mmlu_econometrics:
2025-07-30 04:51:45,039 - INFO -     - accuracy: 0.2632
2025-07-30 04:51:45,040 - INFO -   mmlu_high_school_geography:
2025-07-30 04:51:45,040 - INFO -     - accuracy: 0.2778
2025-07-30 04:51:45,040 - INFO -   mmlu_high_school_government_and_politics:
2025-07-30 04:51:45,040 - INFO -     - accuracy: 0.2228
2025-07-30 04:51:45,040 - INFO -   mmlu_high_school_macroeconomics:
2025-07-30 04:51:45,040 - INFO -     - accuracy: 0.2128
2025-07-30 04:51:45,040 - INFO -   mmlu_high_school_microeconomics:
2025-07-30 04:51:45,040 - INFO -     - accuracy: 0.1975
2025-07-30 04:51:45,040 - INFO -   mmlu_high_school_psychology:
2025-07-30 04:51:45,041 - INFO -     - accuracy: 0.3009
2025-07-30 04:51:45,041 - INFO -   mmlu_human_sexuality:
2025-07-30 04:51:45,041 - INFO -     - accuracy: 0.2443
2025-07-30 04:51:45,041 - INFO -   mmlu_professional_psychology:
2025-07-30 04:51:45,041 - INFO -     - accuracy: 0.2467
2025-07-30 04:51:45,041 - INFO -   mmlu_public_relations:
2025-07-30 04:51:45,041 - INFO -     - accuracy: 0.2273
2025-07-30 04:51:45,041 - INFO -   mmlu_security_studies:
2025-07-30 04:51:45,041 - INFO -     - accuracy: 0.2408
2025-07-30 04:51:45,042 - INFO -   mmlu_sociology:
2025-07-30 04:51:45,042 - INFO -     - accuracy: 0.2786
2025-07-30 04:51:45,042 - INFO -   mmlu_us_foreign_policy:
2025-07-30 04:51:45,042 - INFO -     - accuracy: 0.1700
2025-07-30 04:51:45,042 - INFO -   mmlu_stem:
2025-07-30 04:51:45,042 - INFO -     - accuracy: 0.2585
2025-07-30 04:51:45,042 - INFO -   mmlu_abstract_algebra:
2025-07-30 04:51:45,042 - INFO -     - accuracy: 0.2400
2025-07-30 04:51:45,042 - INFO -   mmlu_anatomy:
2025-07-30 04:51:45,043 - INFO -     - accuracy: 0.2815
2025-07-30 04:51:45,043 - INFO -   mmlu_astronomy:
2025-07-30 04:51:45,043 - INFO -     - accuracy: 0.1842
2025-07-30 04:51:45,043 - INFO -   mmlu_college_biology:
2025-07-30 04:51:45,043 - INFO -     - accuracy: 0.2569
2025-07-30 04:51:45,043 - INFO -   mmlu_college_chemistry:
2025-07-30 04:51:45,043 - INFO -     - accuracy: 0.2100
2025-07-30 04:51:45,043 - INFO -   mmlu_college_computer_science:
2025-07-30 04:51:45,043 - INFO -     - accuracy: 0.2500
2025-07-30 04:51:45,044 - INFO -   mmlu_college_mathematics:
2025-07-30 04:51:45,044 - INFO -     - accuracy: 0.3600
2025-07-30 04:51:45,044 - INFO -   mmlu_college_physics:
2025-07-30 04:51:45,044 - INFO -     - accuracy: 0.2353
2025-07-30 04:51:45,044 - INFO -   mmlu_computer_security:
2025-07-30 04:51:45,044 - INFO -     - accuracy: 0.2000
2025-07-30 04:51:45,044 - INFO -   mmlu_conceptual_physics:
2025-07-30 04:51:45,044 - INFO -     - accuracy: 0.3447
2025-07-30 04:51:45,044 - INFO -   mmlu_electrical_engineering:
2025-07-30 04:51:45,045 - INFO -     - accuracy: 0.2552
2025-07-30 04:51:45,045 - INFO -   mmlu_elementary_mathematics:
2025-07-30 04:51:45,045 - INFO -     - accuracy: 0.2619
2025-07-30 04:51:45,045 - INFO -   mmlu_high_school_biology:
2025-07-30 04:51:45,045 - INFO -     - accuracy: 0.2194
2025-07-30 04:51:45,045 - INFO -   mmlu_high_school_chemistry:
2025-07-30 04:51:45,045 - INFO -     - accuracy: 0.2709
2025-07-30 04:51:45,045 - INFO -   mmlu_high_school_computer_science:
2025-07-30 04:51:45,045 - INFO -     - accuracy: 0.2600
2025-07-30 04:51:45,046 - INFO -   mmlu_high_school_mathematics:
2025-07-30 04:51:45,046 - INFO -     - accuracy: 0.2667
2025-07-30 04:51:45,046 - INFO -   mmlu_high_school_physics:
2025-07-30 04:51:45,046 - INFO -     - accuracy: 0.2517
2025-07-30 04:51:45,046 - INFO -   mmlu_high_school_statistics:
2025-07-30 04:51:45,046 - INFO -     - accuracy: 0.2593
2025-07-30 04:51:45,046 - INFO -   mmlu_machine_learning:
2025-07-30 04:51:45,046 - INFO -     - accuracy: 0.2679
2025-07-30 04:51:45,047 - INFO - ============================================================

2025-07-30 04:51:45,064 - INFO - eagle-3b-preview_harness_12: Processing task 8/10: arc_challenge
2025-07-30 04:51:45,066 - INFO - eagle-3b-preview_harness_12: Task 'arc_challenge' will use num_fewshot=5
2025-07-30 04:51:45,067 - INFO - eagle-3b-preview_harness_12: Evaluating task 'arc_challenge' with num_fewshot=5
2025-07-30 04:51:45,067 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 04:51:54,912 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 5
2025-07-30 04:53:21,571 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-30 04:53:21,573 - INFO - 
============================================================
2025-07-30 04:53:21,573 - INFO - Task 'arc_challenge' Results:
2025-07-30 04:53:21,573 - INFO - ============================================================
2025-07-30 04:53:21,574 - INFO -   arc_challenge:
2025-07-30 04:53:21,574 - INFO -     - accuracy: 0.2474
2025-07-30 04:53:21,574 - INFO -     - accuracy_norm: 0.2850
2025-07-30 04:53:21,574 - INFO - ============================================================

2025-07-30 04:53:21,590 - INFO - eagle-3b-preview_harness_12: Processing task 9/10: arc_easy
2025-07-30 04:53:21,591 - INFO - eagle-3b-preview_harness_12: Task 'arc_easy' will use num_fewshot=5
2025-07-30 04:53:21,591 - INFO - eagle-3b-preview_harness_12: Evaluating task 'arc_easy' with num_fewshot=5
2025-07-30 04:53:21,592 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 04:53:30,629 - WARNING - Overwriting default num_fewshot of arc_easy from None to 5
2025-07-30 04:56:06,570 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-30 04:56:06,572 - INFO - 
============================================================
2025-07-30 04:56:06,573 - INFO - Task 'arc_easy' Results:
2025-07-30 04:56:06,573 - INFO - ============================================================
2025-07-30 04:56:06,573 - INFO -   arc_easy:
2025-07-30 04:56:06,573 - INFO -     - accuracy: 0.5795
2025-07-30 04:56:06,573 - INFO -     - accuracy_norm: 0.5825
2025-07-30 04:56:06,575 - INFO - ============================================================

2025-07-30 04:56:06,591 - INFO - eagle-3b-preview_harness_12: Processing task 10/10: hellaswag
2025-07-30 04:56:06,592 - INFO - eagle-3b-preview_harness_12: Task 'hellaswag' will use num_fewshot=5
2025-07-30 04:56:06,593 - INFO - eagle-3b-preview_harness_12: Evaluating task 'hellaswag' with num_fewshot=5
2025-07-30 04:56:06,593 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 04:56:21,163 - WARNING - Overwriting default num_fewshot of hellaswag from None to 5
2025-07-30 05:14:36,760 - INFO - eagle-3b-preview_harness_12: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-30 05:14:36,762 - INFO - 
============================================================
2025-07-30 05:14:36,763 - INFO - Task 'hellaswag' Results:
2025-07-30 05:14:36,763 - INFO - ============================================================
2025-07-30 05:14:36,763 - INFO -   hellaswag:
2025-07-30 05:14:36,763 - INFO -     - accuracy: 0.3731
2025-07-30 05:14:36,763 - INFO -     - accuracy_norm: 0.4752
2025-07-30 05:14:36,763 - INFO - ============================================================

2025-07-30 05:14:36,779 - INFO - eagle-3b-preview_harness_12: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-30 05:14:36,781 - INFO - [Process 2120894] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/eagle-3b-preview/eagle-3b-preview_harness_12.json
2025-07-30 05:14:37,069 - INFO - Results uploaded to WandB as artifact
2025-07-30 05:14:37,079 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-30 05:14:37,081 - INFO - [Process 2120894] Successfully completed eagle-3b-preview_harness_12
2025-07-30 05:14:40,270 - INFO - Run eagle-3b-preview_harness_12 finished successfully
2025-07-30 05:14:41,736 - INFO - Processing 3 large models with single GPU
2025-07-30 05:14:41,738 - INFO - [Process 1941996] gemma-3-12b-it_harness_3 assigned to cuda:0
2025-07-30 05:14:41,738 - INFO - [Process 1941996] gemma-3-12b-it_harness_3 - full_run: True, limit: None (full dataset)
2025-07-30 05:14:43,324 - INFO - WandB run initialized: gemma-3-12b-it_20250730_051441 (ID: 8a9e3e52)
2025-07-30 05:14:45,156 - INFO - gemma-3-12b-it_harness_3: Gemma settings applied - max_gen_toks=256
2025-07-30 05:14:45,156 - INFO - GPU memory available: 79.3GB
2025-07-30 05:14:45,156 - INFO - gemma-3-12b-it_harness_3: Using 8bit=True, batch_size=1
2025-07-30 05:14:45,157 - INFO - gemma-3-12b-it_harness_3: Gemma model detected, will handle cache settings after loading
2025-07-30 05:15:10,143 - INFO - gemma-3-12b-it_harness_3: Processing task 1/10: kmmlu
2025-07-30 05:15:10,144 - INFO - gemma-3-12b-it_harness_3: Task 'kmmlu' will use num_fewshot=5
2025-07-30 05:15:10,271 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-30 05:15:10,271 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 05:16:21,307 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-30 05:16:21,307 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-30 05:16:21,307 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-30 05:16:21,307 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-30 05:16:21,307 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-30 05:16:21,307 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-30 05:16:21,308 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-30 05:16:21,309 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-30 05:16:21,310 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-30 05:16:21,311 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-30 05:16:21,311 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-30 05:16:21,311 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-30 05:16:21,311 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-30 05:16:21,311 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-30 05:16:21,311 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-30 09:06:25,546 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-30 09:06:25,806 - INFO - 
============================================================
2025-07-30 09:06:25,806 - INFO - Task 'kmmlu' Results:
2025-07-30 09:06:25,806 - INFO - ============================================================
2025-07-30 09:06:25,806 - INFO -   kmmlu:
2025-07-30 09:06:25,807 - INFO -     - accuracy: 0.4890
2025-07-30 09:06:25,807 - INFO -   kmmlu_applied_science:
2025-07-30 09:06:25,807 - INFO -     - accuracy: 0.4602
2025-07-30 09:06:25,807 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-30 09:06:25,807 - INFO -     - accuracy: 0.4940
2025-07-30 09:06:25,807 - INFO -   kmmlu_electronics_engineering:
2025-07-30 09:06:25,807 - INFO -     - accuracy: 0.5520
2025-07-30 09:06:25,808 - INFO -   kmmlu_energy_management:
2025-07-30 09:06:25,808 - INFO -     - accuracy: 0.3530
2025-07-30 09:06:25,808 - INFO -   kmmlu_environmental_science:
2025-07-30 09:06:25,808 - INFO -     - accuracy: 0.3820
2025-07-30 09:06:25,808 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-30 09:06:25,808 - INFO -     - accuracy: 0.3890
2025-07-30 09:06:25,808 - INFO -   kmmlu_geomatics:
2025-07-30 09:06:25,808 - INFO -     - accuracy: 0.4190
2025-07-30 09:06:25,809 - INFO -   kmmlu_industrial_engineer:
2025-07-30 09:06:25,809 - INFO -     - accuracy: 0.4500
2025-07-30 09:06:25,809 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-30 09:06:25,809 - INFO -     - accuracy: 0.4990
2025-07-30 09:06:25,809 - INFO -   kmmlu_maritime_engineering:
2025-07-30 09:06:25,809 - INFO -     - accuracy: 0.5133
2025-07-30 09:06:25,809 - INFO -   kmmlu_nondestructive_testing:
2025-07-30 09:06:25,809 - INFO -     - accuracy: 0.4960
2025-07-30 09:06:25,809 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-30 09:06:25,810 - INFO -     - accuracy: 0.3960
2025-07-30 09:06:25,810 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-30 09:06:25,810 - INFO -     - accuracy: 0.6000
2025-07-30 09:06:25,810 - INFO -   kmmlu_humss:
2025-07-30 09:06:25,810 - INFO -     - accuracy: 0.5296
2025-07-30 09:06:25,810 - INFO -   kmmlu_accounting:
2025-07-30 09:06:25,810 - INFO -     - accuracy: 0.4700
2025-07-30 09:06:25,810 - INFO -   kmmlu_criminal_law:
2025-07-30 09:06:25,810 - INFO -     - accuracy: 0.3800
2025-07-30 09:06:25,811 - INFO -   kmmlu_economics:
2025-07-30 09:06:25,811 - INFO -     - accuracy: 0.5923
2025-07-30 09:06:25,811 - INFO -   kmmlu_education:
2025-07-30 09:06:25,811 - INFO -     - accuracy: 0.6700
2025-07-30 09:06:25,811 - INFO -   kmmlu_korean_history:
2025-07-30 09:06:25,811 - INFO -     - accuracy: 0.3700
2025-07-30 09:06:25,811 - INFO -   kmmlu_law:
2025-07-30 09:06:25,811 - INFO -     - accuracy: 0.4700
2025-07-30 09:06:25,811 - INFO -   kmmlu_management:
2025-07-30 09:06:25,811 - INFO -     - accuracy: 0.5890
2025-07-30 09:06:25,812 - INFO -   kmmlu_political_science_and_sociology:
2025-07-30 09:06:25,812 - INFO -     - accuracy: 0.6233
2025-07-30 09:06:25,812 - INFO -   kmmlu_psychology:
2025-07-30 09:06:25,812 - INFO -     - accuracy: 0.4750
2025-07-30 09:06:25,812 - INFO -   kmmlu_social_welfare:
2025-07-30 09:06:25,812 - INFO -     - accuracy: 0.6130
2025-07-30 09:06:25,812 - INFO -   kmmlu_taxation:
2025-07-30 09:06:25,812 - INFO -     - accuracy: 0.3950
2025-07-30 09:06:25,812 - INFO -   kmmlu_other:
2025-07-30 09:06:25,813 - INFO -     - accuracy: 0.4862
2025-07-30 09:06:25,813 - INFO -   kmmlu_agricultural_sciences:
2025-07-30 09:06:25,813 - INFO -     - accuracy: 0.4000
2025-07-30 09:06:25,813 - INFO -   kmmlu_construction:
2025-07-30 09:06:25,813 - INFO -     - accuracy: 0.3620
2025-07-30 09:06:25,813 - INFO -   kmmlu_fashion:
2025-07-30 09:06:25,813 - INFO -     - accuracy: 0.5060
2025-07-30 09:06:25,813 - INFO -   kmmlu_food_processing:
2025-07-30 09:06:25,813 - INFO -     - accuracy: 0.4500
2025-07-30 09:06:25,813 - INFO -   kmmlu_health:
2025-07-30 09:06:25,814 - INFO -     - accuracy: 0.6700
2025-07-30 09:06:25,814 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-30 09:06:25,814 - INFO -     - accuracy: 0.5950
2025-07-30 09:06:25,814 - INFO -   kmmlu_marketing:
2025-07-30 09:06:25,814 - INFO -     - accuracy: 0.7870
2025-07-30 09:06:25,814 - INFO -   kmmlu_patent:
2025-07-30 09:06:25,814 - INFO -     - accuracy: 0.3800
2025-07-30 09:06:25,814 - INFO -   kmmlu_public_safety:
2025-07-30 09:06:25,814 - INFO -     - accuracy: 0.3940
2025-07-30 09:06:25,815 - INFO -   kmmlu_real_estate:
2025-07-30 09:06:25,815 - INFO -     - accuracy: 0.4600
2025-07-30 09:06:25,815 - INFO -   kmmlu_refrigerating_machinery:
2025-07-30 09:06:25,815 - INFO -     - accuracy: 0.3930
2025-07-30 09:06:25,815 - INFO -   kmmlu_stem:
2025-07-30 09:06:25,815 - INFO -     - accuracy: 0.5040
2025-07-30 09:06:25,815 - INFO -   kmmlu_biology:
2025-07-30 09:06:25,815 - INFO -     - accuracy: 0.4360
2025-07-30 09:06:25,815 - INFO -   kmmlu_chemical_engineering:
2025-07-30 09:06:25,815 - INFO -     - accuracy: 0.5060
2025-07-30 09:06:25,816 - INFO -   kmmlu_chemistry:
2025-07-30 09:06:25,816 - INFO -     - accuracy: 0.5517
2025-07-30 09:06:25,816 - INFO -   kmmlu_civil_engineering:
2025-07-30 09:06:25,816 - INFO -     - accuracy: 0.4030
2025-07-30 09:06:25,816 - INFO -   kmmlu_computer_science:
2025-07-30 09:06:25,816 - INFO -     - accuracy: 0.7130
2025-07-30 09:06:25,816 - INFO -   kmmlu_ecology:
2025-07-30 09:06:25,816 - INFO -     - accuracy: 0.5270
2025-07-30 09:06:25,816 - INFO -   kmmlu_electrical_engineering:
2025-07-30 09:06:25,817 - INFO -     - accuracy: 0.3520
2025-07-30 09:06:25,817 - INFO -   kmmlu_information_technology:
2025-07-30 09:06:25,817 - INFO -     - accuracy: 0.7080
2025-07-30 09:06:25,817 - INFO -   kmmlu_materials_engineering:
2025-07-30 09:06:25,817 - INFO -     - accuracy: 0.5140
2025-07-30 09:06:25,817 - INFO -   kmmlu_math:
2025-07-30 09:06:25,817 - INFO -     - accuracy: 0.3100
2025-07-30 09:06:25,817 - INFO -   kmmlu_mechanical_engineering:
2025-07-30 09:06:25,817 - INFO -     - accuracy: 0.4070
2025-07-30 09:06:25,818 - INFO - ============================================================

2025-07-30 09:06:25,831 - INFO - gemma-3-12b-it_harness_3: Processing task 2/10: kmmlu_hard
2025-07-30 09:06:25,846 - INFO - gemma-3-12b-it_harness_3: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-30 09:06:25,972 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-30 09:06:25,972 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 09:07:40,624 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-30 09:07:40,624 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-30 09:07:40,624 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-30 09:07:40,625 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-30 09:07:40,626 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-30 09:07:40,627 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-30 09:07:40,628 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-30 09:07:40,628 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-30 09:07:40,628 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-30 09:07:40,628 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-30 09:07:40,628 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-30 09:07:40,628 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-30 09:07:40,628 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-30 09:07:40,628 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-30 09:35:52,967 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-30 09:35:53,115 - INFO - 
============================================================
2025-07-30 09:35:53,115 - INFO - Task 'kmmlu_hard' Results:
2025-07-30 09:35:53,115 - INFO - ============================================================
2025-07-30 09:35:53,116 - INFO -   kmmlu_hard:
2025-07-30 09:35:53,116 - INFO -     - accuracy: 0.2405
2025-07-30 09:35:53,116 - INFO -   kmmlu_hard_applied_science:
2025-07-30 09:35:53,116 - INFO -     - accuracy: 0.2442
2025-07-30 09:35:53,116 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-30 09:35:53,116 - INFO -     - accuracy: 0.2600
2025-07-30 09:35:53,116 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-30 09:35:53,116 - INFO -     - accuracy: 0.3000
2025-07-30 09:35:53,117 - INFO -   kmmlu_hard_energy_management:
2025-07-30 09:35:53,117 - INFO -     - accuracy: 0.2500
2025-07-30 09:35:53,117 - INFO -   kmmlu_hard_environmental_science:
2025-07-30 09:35:53,117 - INFO -     - accuracy: 0.1700
2025-07-30 09:35:53,117 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-30 09:35:53,117 - INFO -     - accuracy: 0.2600
2025-07-30 09:35:53,117 - INFO -   kmmlu_hard_geomatics:
2025-07-30 09:35:53,117 - INFO -     - accuracy: 0.2500
2025-07-30 09:35:53,117 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-30 09:35:53,118 - INFO -     - accuracy: 0.2100
2025-07-30 09:35:53,118 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-30 09:35:53,118 - INFO -     - accuracy: 0.2500
2025-07-30 09:35:53,118 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-30 09:35:53,118 - INFO -     - accuracy: 0.2400
2025-07-30 09:35:53,118 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-30 09:35:53,118 - INFO -     - accuracy: 0.2700
2025-07-30 09:35:53,118 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-30 09:35:53,118 - INFO -     - accuracy: 0.2100
2025-07-30 09:35:53,119 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-30 09:35:53,119 - INFO -     - accuracy: 0.2600
2025-07-30 09:35:53,119 - INFO -   kmmlu_hard_humss:
2025-07-30 09:35:53,119 - INFO -     - accuracy: 0.2568
2025-07-30 09:35:53,119 - INFO -   kmmlu_hard_accounting:
2025-07-30 09:35:53,119 - INFO -     - accuracy: 0.3261
2025-07-30 09:35:53,119 - INFO -   kmmlu_hard_criminal_law:
2025-07-30 09:35:53,119 - INFO -     - accuracy: 0.1800
2025-07-30 09:35:53,120 - INFO -   kmmlu_hard_economics:
2025-07-30 09:35:53,120 - INFO -     - accuracy: 0.1905
2025-07-30 09:35:53,120 - INFO -   kmmlu_hard_education:
2025-07-30 09:35:53,120 - INFO -     - accuracy: 0.4348
2025-07-30 09:35:53,120 - INFO -   kmmlu_hard_korean_history:
2025-07-30 09:35:53,120 - INFO -     - accuracy: 0.2727
2025-07-30 09:35:53,120 - INFO -   kmmlu_hard_law:
2025-07-30 09:35:53,120 - INFO -     - accuracy: 0.2000
2025-07-30 09:35:53,120 - INFO -   kmmlu_hard_management:
2025-07-30 09:35:53,120 - INFO -     - accuracy: 0.3500
2025-07-30 09:35:53,121 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-30 09:35:53,121 - INFO -     - accuracy: 0.2667
2025-07-30 09:35:53,121 - INFO -   kmmlu_hard_psychology:
2025-07-30 09:35:53,121 - INFO -     - accuracy: 0.2100
2025-07-30 09:35:53,121 - INFO -   kmmlu_hard_social_welfare:
2025-07-30 09:35:53,121 - INFO -     - accuracy: 0.3600
2025-07-30 09:35:53,121 - INFO -   kmmlu_hard_taxation:
2025-07-30 09:35:53,121 - INFO -     - accuracy: 0.1771
2025-07-30 09:35:53,121 - INFO -   kmmlu_hard_other:
2025-07-30 09:35:53,122 - INFO -     - accuracy: 0.2077
2025-07-30 09:35:53,122 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-30 09:35:53,122 - INFO -     - accuracy: 0.1700
2025-07-30 09:35:53,122 - INFO -   kmmlu_hard_construction:
2025-07-30 09:35:53,122 - INFO -     - accuracy: 0.1700
2025-07-30 09:35:53,122 - INFO -   kmmlu_hard_fashion:
2025-07-30 09:35:53,122 - INFO -     - accuracy: 0.2300
2025-07-30 09:35:53,122 - INFO -   kmmlu_hard_food_processing:
2025-07-30 09:35:53,122 - INFO -     - accuracy: 0.1800
2025-07-30 09:35:53,123 - INFO -   kmmlu_hard_health:
2025-07-30 09:35:53,123 - INFO -     - accuracy: 0.2609
2025-07-30 09:35:53,123 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-30 09:35:53,123 - INFO -     - accuracy: 0.2400
2025-07-30 09:35:53,123 - INFO -   kmmlu_hard_marketing:
2025-07-30 09:35:53,123 - INFO -     - accuracy: 0.2900
2025-07-30 09:35:53,123 - INFO -   kmmlu_hard_patent:
2025-07-30 09:35:53,123 - INFO -     - accuracy: 0.1569
2025-07-30 09:35:53,123 - INFO -   kmmlu_hard_public_safety:
2025-07-30 09:35:53,123 - INFO -     - accuracy: 0.1800
2025-07-30 09:35:53,124 - INFO -   kmmlu_hard_real_estate:
2025-07-30 09:35:53,124 - INFO -     - accuracy: 0.1910
2025-07-30 09:35:53,124 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-30 09:35:53,124 - INFO -     - accuracy: 0.2300
2025-07-30 09:35:53,124 - INFO -   kmmlu_hard_stem:
2025-07-30 09:35:53,124 - INFO -     - accuracy: 0.2527
2025-07-30 09:35:53,124 - INFO -   kmmlu_hard_biology:
2025-07-30 09:35:53,124 - INFO -     - accuracy: 0.2800
2025-07-30 09:35:53,124 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-30 09:35:53,125 - INFO -     - accuracy: 0.2300
2025-07-30 09:35:53,125 - INFO -   kmmlu_hard_chemistry:
2025-07-30 09:35:53,125 - INFO -     - accuracy: 0.3300
2025-07-30 09:35:53,125 - INFO -   kmmlu_hard_civil_engineering:
2025-07-30 09:35:53,125 - INFO -     - accuracy: 0.2200
2025-07-30 09:35:53,125 - INFO -   kmmlu_hard_computer_science:
2025-07-30 09:35:53,125 - INFO -     - accuracy: 0.2300
2025-07-30 09:35:53,125 - INFO -   kmmlu_hard_ecology:
2025-07-30 09:35:53,125 - INFO -     - accuracy: 0.1700
2025-07-30 09:35:53,125 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-30 09:35:53,126 - INFO -     - accuracy: 0.2300
2025-07-30 09:35:53,126 - INFO -   kmmlu_hard_information_technology:
2025-07-30 09:35:53,126 - INFO -     - accuracy: 0.2900
2025-07-30 09:35:53,126 - INFO -   kmmlu_hard_materials_engineering:
2025-07-30 09:35:53,126 - INFO -     - accuracy: 0.3500
2025-07-30 09:35:53,126 - INFO -   kmmlu_hard_math:
2025-07-30 09:35:53,126 - INFO -     - accuracy: 0.2800
2025-07-30 09:35:53,126 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-30 09:35:53,126 - INFO -     - accuracy: 0.1700
2025-07-30 09:35:53,127 - INFO - ============================================================

2025-07-30 09:35:53,136 - INFO - gemma-3-12b-it_harness_3: Processing task 3/10: haerae
2025-07-30 09:35:53,139 - INFO - gemma-3-12b-it_harness_3: Task 'haerae' will use num_fewshot=5
2025-07-30 09:35:53,263 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'haerae' with num_fewshot=5
2025-07-30 09:35:53,264 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 09:36:10,819 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-30 09:36:10,819 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-30 09:36:10,819 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-30 09:36:10,819 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-30 09:36:10,820 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-30 10:11:57,304 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'haerae' with 6 subtasks
2025-07-30 10:11:57,454 - INFO - 
============================================================
2025-07-30 10:11:57,455 - INFO - Task 'haerae' Results:
2025-07-30 10:11:57,455 - INFO - ============================================================
2025-07-30 10:11:57,455 - INFO -   haerae:
2025-07-30 10:11:57,455 - INFO -     - accuracy: 0.7379
2025-07-30 10:11:57,455 - INFO -     - accuracy_norm: 0.7379
2025-07-30 10:11:57,458 - INFO -   haerae_general_knowledge:
2025-07-30 10:11:57,459 - INFO -     - accuracy: 0.5625
2025-07-30 10:11:57,459 - INFO -     - accuracy_norm: 0.5625
2025-07-30 10:11:57,459 - INFO -   haerae_history:
2025-07-30 10:11:57,459 - INFO -     - accuracy: 0.6755
2025-07-30 10:11:57,459 - INFO -     - accuracy_norm: 0.6755
2025-07-30 10:11:57,459 - INFO -   haerae_loan_word:
2025-07-30 10:11:57,459 - INFO -     - accuracy: 0.8343
2025-07-30 10:11:57,459 - INFO -     - accuracy_norm: 0.8343
2025-07-30 10:11:57,460 - INFO -   haerae_rare_word:
2025-07-30 10:11:57,460 - INFO -     - accuracy: 0.7654
2025-07-30 10:11:57,460 - INFO -     - accuracy_norm: 0.7654
2025-07-30 10:11:57,460 - INFO -   haerae_standard_nomenclature:
2025-07-30 10:11:57,460 - INFO -     - accuracy: 0.8366
2025-07-30 10:11:57,460 - INFO -     - accuracy_norm: 0.8366
2025-07-30 10:11:57,460 - INFO - ============================================================

2025-07-30 10:11:57,466 - INFO - gemma-3-12b-it_harness_3: Processing task 4/10: kobest
2025-07-30 10:11:57,467 - INFO - gemma-3-12b-it_harness_3: Task 'kobest' will use num_fewshot=5
2025-07-30 10:11:57,595 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kobest' with num_fewshot=5
2025-07-30 10:11:57,595 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 10:12:16,300 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-30 10:12:16,300 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-30 10:12:16,301 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-30 10:12:16,301 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-30 10:12:16,301 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-30 11:16:50,864 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kobest' with 6 subtasks
2025-07-30 11:16:51,030 - INFO - 
============================================================
2025-07-30 11:16:51,030 - INFO - Task 'kobest' Results:
2025-07-30 11:16:51,030 - INFO - ============================================================
2025-07-30 11:16:51,031 - INFO -   kobest:
2025-07-30 11:16:51,031 - INFO -     - accuracy: 0.8323
2025-07-30 11:16:51,031 - INFO -     - accuracy_norm: 0.5560
2025-07-30 11:16:51,031 - INFO -     - f1: 0.8319
2025-07-30 11:16:51,031 - INFO -   kobest_boolq:
2025-07-30 11:16:51,031 - INFO -     - accuracy: 0.9452
2025-07-30 11:16:51,032 - INFO -     - f1: 0.9452
2025-07-30 11:16:51,032 - INFO -   kobest_copa:
2025-07-30 11:16:51,032 - INFO -     - accuracy: 0.8510
2025-07-30 11:16:51,032 - INFO -     - f1: 0.8509
2025-07-30 11:16:51,032 - INFO -   kobest_hellaswag:
2025-07-30 11:16:51,032 - INFO -     - accuracy: 0.4840
2025-07-30 11:16:51,032 - INFO -     - accuracy_norm: 0.5560
2025-07-30 11:16:51,032 - INFO -     - f1: 0.4805
2025-07-30 11:16:51,033 - INFO -   kobest_sentineg:
2025-07-30 11:16:51,033 - INFO -     - accuracy: 0.9748
2025-07-30 11:16:51,033 - INFO -     - f1: 0.9748
2025-07-30 11:16:51,033 - INFO -   kobest_wic:
2025-07-30 11:16:51,033 - INFO -     - accuracy: 0.7849
2025-07-30 11:16:51,033 - INFO -     - f1: 0.7849
2025-07-30 11:16:51,033 - INFO - ============================================================

2025-07-30 11:16:51,041 - INFO - gemma-3-12b-it_harness_3: Processing task 5/10: csatqa
2025-07-30 11:16:51,042 - INFO - gemma-3-12b-it_harness_3: Task 'csatqa' detected as zero-shot task
2025-07-30 11:16:51,167 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'csatqa' with num_fewshot=0
2025-07-30 11:16:51,168 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 11:17:02,906 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-30 11:17:02,906 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-30 11:17:02,907 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-30 11:17:02,907 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-30 11:17:02,907 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-30 11:17:02,907 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-30 11:24:49,999 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'csatqa' with 7 subtasks
2025-07-30 11:24:50,167 - INFO - 
============================================================
2025-07-30 11:24:50,167 - INFO - Task 'csatqa' Results:
2025-07-30 11:24:50,168 - INFO - ============================================================
2025-07-30 11:24:50,168 - INFO -   csatqa:
2025-07-30 11:24:50,168 - INFO -     - accuracy: 0.5080
2025-07-30 11:24:50,168 - INFO -     - accuracy_norm: 0.5080
2025-07-30 11:24:50,168 - INFO -   csatqa_gr:
2025-07-30 11:24:50,168 - INFO -     - accuracy: 0.2000
2025-07-30 11:24:50,168 - INFO -     - accuracy_norm: 0.2000
2025-07-30 11:24:50,168 - INFO -   csatqa_li:
2025-07-30 11:24:50,169 - INFO -     - accuracy: 0.5405
2025-07-30 11:24:50,169 - INFO -     - accuracy_norm: 0.5405
2025-07-30 11:24:50,169 - INFO -   csatqa_rch:
2025-07-30 11:24:50,169 - INFO -     - accuracy: 0.6286
2025-07-30 11:24:50,169 - INFO -     - accuracy_norm: 0.6286
2025-07-30 11:24:50,169 - INFO -   csatqa_rcs:
2025-07-30 11:24:50,169 - INFO -     - accuracy: 0.5135
2025-07-30 11:24:50,169 - INFO -     - accuracy_norm: 0.5135
2025-07-30 11:24:50,169 - INFO -   csatqa_rcss:
2025-07-30 11:24:50,170 - INFO -     - accuracy: 0.5714
2025-07-30 11:24:50,170 - INFO -     - accuracy_norm: 0.5714
2025-07-30 11:24:50,170 - INFO -   csatqa_wr:
2025-07-30 11:24:50,170 - INFO -     - accuracy: 0.4545
2025-07-30 11:24:50,170 - INFO -     - accuracy_norm: 0.4545
2025-07-30 11:24:50,170 - INFO - ============================================================

2025-07-30 11:24:50,184 - INFO - gemma-3-12b-it_harness_3: Processing task 6/10: kormedmcqa
2025-07-30 11:24:50,186 - INFO - gemma-3-12b-it_harness_3: Task 'kormedmcqa' will use num_fewshot=5
2025-07-30 11:24:50,313 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-30 11:24:50,314 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 11:25:07,956 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-30 11:25:07,957 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-30 11:25:07,957 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-30 11:25:07,957 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
2025-07-30 11:56:57,941 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'kormedmcqa' with 5 subtasks
2025-07-30 11:56:58,090 - INFO - 
============================================================
2025-07-30 11:56:58,090 - INFO - Task 'kormedmcqa' Results:
2025-07-30 11:56:58,090 - INFO - ============================================================
2025-07-30 11:56:58,090 - INFO -   kormedmcqa:
2025-07-30 11:56:58,090 - INFO -     - exact_match: 0.6434
2025-07-30 11:56:58,094 - INFO -   kormedmcqa_dentist:
2025-07-30 11:56:58,095 - INFO -     - exact_match: 0.5228
2025-07-30 11:56:58,095 - INFO -   kormedmcqa_doctor:
2025-07-30 11:56:58,095 - INFO -     - exact_match: 0.6230
2025-07-30 11:56:58,095 - INFO -   kormedmcqa_nurse:
2025-07-30 11:56:58,095 - INFO -     - exact_match: 0.7597
2025-07-30 11:56:58,096 - INFO -   kormedmcqa_pharm:
2025-07-30 11:56:58,096 - INFO -     - exact_match: 0.6486
2025-07-30 11:56:58,096 - INFO - ============================================================

2025-07-30 11:56:58,098 - INFO - gemma-3-12b-it_harness_3: Processing task 7/10: mmlu
2025-07-30 11:56:58,098 - INFO - gemma-3-12b-it_harness_3: Task 'mmlu' will use num_fewshot=5
2025-07-30 11:56:58,226 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'mmlu' with num_fewshot=5
2025-07-30 11:56:58,227 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 11:59:38,660 - WARNING - Overwriting default num_fewshot of mmlu_conceptual_physics from None to 5
2025-07-30 11:59:38,660 - WARNING - Overwriting default num_fewshot of mmlu_high_school_statistics from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_astronomy from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_electrical_engineering from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_high_school_computer_science from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_college_mathematics from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_machine_learning from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_high_school_chemistry from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_high_school_biology from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_college_chemistry from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_college_physics from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_high_school_physics from None to 5
2025-07-30 11:59:38,661 - WARNING - Overwriting default num_fewshot of mmlu_computer_security from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_abstract_algebra from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_high_school_mathematics from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_college_biology from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_college_computer_science from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_elementary_mathematics from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_anatomy from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_marketing from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_global_facts from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_nutrition from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_virology from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_management from None to 5
2025-07-30 11:59:38,662 - WARNING - Overwriting default num_fewshot of mmlu_professional_medicine from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_medical_genetics from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_business_ethics from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_miscellaneous from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_college_medicine from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_human_aging from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_professional_accounting from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_clinical_knowledge from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_high_school_microeconomics from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_high_school_government_and_politics from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_high_school_macroeconomics from None to 5
2025-07-30 11:59:38,663 - WARNING - Overwriting default num_fewshot of mmlu_public_relations from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_human_sexuality from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_sociology from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_security_studies from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_professional_psychology from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_econometrics from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_high_school_geography from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_us_foreign_policy from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_high_school_psychology from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_jurisprudence from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_formal_logic from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_moral_scenarios from None to 5
2025-07-30 11:59:38,664 - WARNING - Overwriting default num_fewshot of mmlu_high_school_european_history from None to 5
2025-07-30 11:59:38,665 - WARNING - Overwriting default num_fewshot of mmlu_international_law from None to 5
2025-07-30 11:59:38,665 - WARNING - Overwriting default num_fewshot of mmlu_professional_law from None to 5
2025-07-30 11:59:38,665 - WARNING - Overwriting default num_fewshot of mmlu_logical_fallacies from None to 5
2025-07-30 11:59:38,665 - WARNING - Overwriting default num_fewshot of mmlu_world_religions from None to 5
2025-07-30 11:59:38,665 - WARNING - Overwriting default num_fewshot of mmlu_moral_disputes from None to 5
2025-07-30 11:59:38,665 - WARNING - Overwriting default num_fewshot of mmlu_high_school_world_history from None to 5
2025-07-30 11:59:38,665 - WARNING - Overwriting default num_fewshot of mmlu_prehistory from None to 5
2025-07-30 11:59:38,665 - WARNING - Overwriting default num_fewshot of mmlu_philosophy from None to 5
2025-07-30 11:59:38,665 - WARNING - Overwriting default num_fewshot of mmlu_high_school_us_history from None to 5
2025-07-30 13:40:59,830 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'mmlu' with 62 subtasks
2025-07-30 13:40:59,982 - INFO - 
============================================================
2025-07-30 13:40:59,982 - INFO - Task 'mmlu' Results:
2025-07-30 13:40:59,983 - INFO - ============================================================
2025-07-30 13:40:59,983 - INFO -   mmlu:
2025-07-30 13:40:59,983 - INFO -     - accuracy: 0.7182
2025-07-30 13:40:59,984 - INFO -   mmlu_humanities:
2025-07-30 13:40:59,985 - INFO -     - accuracy: 0.6612
2025-07-30 13:40:59,985 - INFO -   mmlu_formal_logic:
2025-07-30 13:40:59,985 - INFO -     - accuracy: 0.5556
2025-07-30 13:40:59,985 - INFO -   mmlu_high_school_european_history:
2025-07-30 13:40:59,985 - INFO -     - accuracy: 0.8545
2025-07-30 13:40:59,985 - INFO -   mmlu_high_school_us_history:
2025-07-30 13:40:59,986 - INFO -     - accuracy: 0.8775
2025-07-30 13:40:59,986 - INFO -   mmlu_high_school_world_history:
2025-07-30 13:40:59,986 - INFO -     - accuracy: 0.8945
2025-07-30 13:40:59,986 - INFO -   mmlu_international_law:
2025-07-30 13:40:59,986 - INFO -     - accuracy: 0.8347
2025-07-30 13:40:59,987 - INFO -   mmlu_jurisprudence:
2025-07-30 13:40:59,987 - INFO -     - accuracy: 0.8241
2025-07-30 13:40:59,987 - INFO -   mmlu_logical_fallacies:
2025-07-30 13:40:59,987 - INFO -     - accuracy: 0.8282
2025-07-30 13:40:59,987 - INFO -   mmlu_moral_disputes:
2025-07-30 13:40:59,988 - INFO -     - accuracy: 0.7428
2025-07-30 13:40:59,988 - INFO -   mmlu_moral_scenarios:
2025-07-30 13:40:59,988 - INFO -     - accuracy: 0.4905
2025-07-30 13:40:59,988 - INFO -   mmlu_philosophy:
2025-07-30 13:40:59,988 - INFO -     - accuracy: 0.7621
2025-07-30 13:40:59,988 - INFO -   mmlu_prehistory:
2025-07-30 13:40:59,988 - INFO -     - accuracy: 0.8025
2025-07-30 13:40:59,989 - INFO -   mmlu_professional_law:
2025-07-30 13:40:59,989 - INFO -     - accuracy: 0.5522
2025-07-30 13:40:59,989 - INFO -   mmlu_world_religions:
2025-07-30 13:40:59,989 - INFO -     - accuracy: 0.8421
2025-07-30 13:40:59,989 - INFO -   mmlu_other:
2025-07-30 13:40:59,989 - INFO -     - accuracy: 0.7696
2025-07-30 13:40:59,990 - INFO -   mmlu_business_ethics:
2025-07-30 13:40:59,990 - INFO -     - accuracy: 0.7700
2025-07-30 13:40:59,990 - INFO -   mmlu_clinical_knowledge:
2025-07-30 13:40:59,990 - INFO -     - accuracy: 0.8038
2025-07-30 13:40:59,990 - INFO -   mmlu_college_medicine:
2025-07-30 13:40:59,990 - INFO -     - accuracy: 0.7283
2025-07-30 13:40:59,991 - INFO -   mmlu_global_facts:
2025-07-30 13:40:59,991 - INFO -     - accuracy: 0.4900
2025-07-30 13:40:59,991 - INFO -   mmlu_human_aging:
2025-07-30 13:40:59,991 - INFO -     - accuracy: 0.7758
2025-07-30 13:40:59,991 - INFO -   mmlu_management:
2025-07-30 13:40:59,991 - INFO -     - accuracy: 0.8350
2025-07-30 13:40:59,991 - INFO -   mmlu_marketing:
2025-07-30 13:40:59,991 - INFO -     - accuracy: 0.8803
2025-07-30 13:40:59,992 - INFO -   mmlu_medical_genetics:
2025-07-30 13:40:59,992 - INFO -     - accuracy: 0.8100
2025-07-30 13:40:59,992 - INFO -   mmlu_miscellaneous:
2025-07-30 13:40:59,992 - INFO -     - accuracy: 0.8633
2025-07-30 13:40:59,992 - INFO -   mmlu_nutrition:
2025-07-30 13:40:59,992 - INFO -     - accuracy: 0.7876
2025-07-30 13:40:59,992 - INFO -   mmlu_professional_accounting:
2025-07-30 13:40:59,992 - INFO -     - accuracy: 0.5142
2025-07-30 13:40:59,992 - INFO -   mmlu_professional_medicine:
2025-07-30 13:40:59,993 - INFO -     - accuracy: 0.8125
2025-07-30 13:40:59,993 - INFO -   mmlu_virology:
2025-07-30 13:40:59,993 - INFO -     - accuracy: 0.5843
2025-07-30 13:40:59,993 - INFO -   mmlu_social_sciences:
2025-07-30 13:40:59,993 - INFO -     - accuracy: 0.8125
2025-07-30 13:40:59,994 - INFO -   mmlu_econometrics:
2025-07-30 13:40:59,994 - INFO -     - accuracy: 0.6316
2025-07-30 13:40:59,994 - INFO -   mmlu_high_school_geography:
2025-07-30 13:40:59,994 - INFO -     - accuracy: 0.8333
2025-07-30 13:40:59,994 - INFO -   mmlu_high_school_government_and_politics:
2025-07-30 13:40:59,994 - INFO -     - accuracy: 0.9275
2025-07-30 13:40:59,995 - INFO -   mmlu_high_school_macroeconomics:
2025-07-30 13:40:59,995 - INFO -     - accuracy: 0.7744
2025-07-30 13:40:59,995 - INFO -   mmlu_high_school_microeconomics:
2025-07-30 13:40:59,995 - INFO -     - accuracy: 0.8235
2025-07-30 13:40:59,995 - INFO -   mmlu_high_school_psychology:
2025-07-30 13:40:59,995 - INFO -     - accuracy: 0.8881
2025-07-30 13:40:59,996 - INFO -   mmlu_human_sexuality:
2025-07-30 13:40:59,996 - INFO -     - accuracy: 0.8168
2025-07-30 13:40:59,996 - INFO -   mmlu_professional_psychology:
2025-07-30 13:40:59,996 - INFO -     - accuracy: 0.7565
2025-07-30 13:40:59,996 - INFO -   mmlu_public_relations:
2025-07-30 13:40:59,997 - INFO -     - accuracy: 0.7182
2025-07-30 13:40:59,997 - INFO -   mmlu_security_studies:
2025-07-30 13:40:59,997 - INFO -     - accuracy: 0.7714
2025-07-30 13:40:59,997 - INFO -   mmlu_sociology:
2025-07-30 13:40:59,997 - INFO -     - accuracy: 0.8706
2025-07-30 13:40:59,998 - INFO -   mmlu_us_foreign_policy:
2025-07-30 13:40:59,998 - INFO -     - accuracy: 0.8900
2025-07-30 13:40:59,998 - INFO -   mmlu_stem:
2025-07-30 13:40:59,998 - INFO -     - accuracy: 0.6606
2025-07-30 13:40:59,999 - INFO -   mmlu_abstract_algebra:
2025-07-30 13:40:59,999 - INFO -     - accuracy: 0.4900
2025-07-30 13:40:59,999 - INFO -   mmlu_anatomy:
2025-07-30 13:40:59,999 - INFO -     - accuracy: 0.7259
2025-07-30 13:40:59,999 - INFO -   mmlu_astronomy:
2025-07-30 13:41:00,000 - INFO -     - accuracy: 0.8158
2025-07-30 13:41:00,000 - INFO -   mmlu_college_biology:
2025-07-30 13:41:00,000 - INFO -     - accuracy: 0.8333
2025-07-30 13:41:00,000 - INFO -   mmlu_college_chemistry:
2025-07-30 13:41:00,000 - INFO -     - accuracy: 0.4700
2025-07-30 13:41:00,082 - INFO -   mmlu_college_computer_science:
2025-07-30 13:41:00,082 - INFO -     - accuracy: 0.5000
2025-07-30 13:41:00,082 - INFO -   mmlu_college_mathematics:
2025-07-30 13:41:00,082 - INFO -     - accuracy: 0.4400
2025-07-30 13:41:00,082 - INFO -   mmlu_college_physics:
2025-07-30 13:41:00,082 - INFO -     - accuracy: 0.5588
2025-07-30 13:41:00,083 - INFO -   mmlu_computer_security:
2025-07-30 13:41:00,083 - INFO -     - accuracy: 0.7900
2025-07-30 13:41:00,083 - INFO -   mmlu_conceptual_physics:
2025-07-30 13:41:00,083 - INFO -     - accuracy: 0.7617
2025-07-30 13:41:00,083 - INFO -   mmlu_electrical_engineering:
2025-07-30 13:41:00,083 - INFO -     - accuracy: 0.6621
2025-07-30 13:41:00,084 - INFO -   mmlu_elementary_mathematics:
2025-07-30 13:41:00,084 - INFO -     - accuracy: 0.6481
2025-07-30 13:41:00,084 - INFO -   mmlu_high_school_biology:
2025-07-30 13:41:00,084 - INFO -     - accuracy: 0.8484
2025-07-30 13:41:00,084 - INFO -   mmlu_high_school_chemistry:
2025-07-30 13:41:00,085 - INFO -     - accuracy: 0.6700
2025-07-30 13:41:00,085 - INFO -   mmlu_high_school_computer_science:
2025-07-30 13:41:00,085 - INFO -     - accuracy: 0.8100
2025-07-30 13:41:00,085 - INFO -   mmlu_high_school_mathematics:
2025-07-30 13:41:00,085 - INFO -     - accuracy: 0.4630
2025-07-30 13:41:00,086 - INFO -   mmlu_high_school_physics:
2025-07-30 13:41:00,086 - INFO -     - accuracy: 0.5497
2025-07-30 13:41:00,086 - INFO -   mmlu_high_school_statistics:
2025-07-30 13:41:00,086 - INFO -     - accuracy: 0.6343
2025-07-30 13:41:00,086 - INFO -   mmlu_machine_learning:
2025-07-30 13:41:00,086 - INFO -     - accuracy: 0.6250
2025-07-30 13:41:00,087 - INFO - ============================================================

2025-07-30 13:41:00,103 - INFO - gemma-3-12b-it_harness_3: Processing task 8/10: arc_challenge
2025-07-30 13:41:00,112 - INFO - gemma-3-12b-it_harness_3: Task 'arc_challenge' will use num_fewshot=5
2025-07-30 13:41:00,238 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'arc_challenge' with num_fewshot=5
2025-07-30 13:41:00,239 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 13:41:07,971 - WARNING - Overwriting default num_fewshot of arc_challenge from None to 5
2025-07-30 14:05:59,102 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'arc_challenge' with 1 subtasks
2025-07-30 14:05:59,266 - INFO - 
============================================================
2025-07-30 14:05:59,267 - INFO - Task 'arc_challenge' Results:
2025-07-30 14:05:59,267 - INFO - ============================================================
2025-07-30 14:05:59,267 - INFO -   arc_challenge:
2025-07-30 14:05:59,267 - INFO -     - accuracy: 0.6886
2025-07-30 14:05:59,267 - INFO -     - accuracy_norm: 0.7090
2025-07-30 14:05:59,267 - INFO - ============================================================

2025-07-30 14:05:59,272 - INFO - gemma-3-12b-it_harness_3: Processing task 9/10: arc_easy
2025-07-30 14:05:59,273 - INFO - gemma-3-12b-it_harness_3: Task 'arc_easy' will use num_fewshot=5
2025-07-30 14:05:59,400 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'arc_easy' with num_fewshot=5
2025-07-30 14:05:59,400 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 14:06:06,817 - WARNING - Overwriting default num_fewshot of arc_easy from None to 5
2025-07-30 14:51:44,139 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'arc_easy' with 1 subtasks
2025-07-30 14:51:44,292 - INFO - 
============================================================
2025-07-30 14:51:44,292 - INFO - Task 'arc_easy' Results:
2025-07-30 14:51:44,292 - INFO - ============================================================
2025-07-30 14:51:44,292 - INFO -   arc_easy:
2025-07-30 14:51:44,292 - INFO -     - accuracy: 0.8817
2025-07-30 14:51:44,292 - INFO -     - accuracy_norm: 0.8965
2025-07-30 14:51:44,293 - INFO - ============================================================

2025-07-30 14:51:44,297 - INFO - gemma-3-12b-it_harness_3: Processing task 10/10: hellaswag
2025-07-30 14:51:44,298 - INFO - gemma-3-12b-it_harness_3: Task 'hellaswag' will use num_fewshot=5
2025-07-30 14:51:44,424 - INFO - gemma-3-12b-it_harness_3: Evaluating task 'hellaswag' with num_fewshot=5
2025-07-30 14:51:44,424 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 14:51:58,764 - WARNING - Overwriting default num_fewshot of hellaswag from None to 5
2025-07-30 18:59:20,694 - INFO - gemma-3-12b-it_harness_3: Successfully completed task 'hellaswag' with 1 subtasks
2025-07-30 18:59:20,923 - INFO - 
============================================================
2025-07-30 18:59:20,923 - INFO - Task 'hellaswag' Results:
2025-07-30 18:59:20,923 - INFO - ============================================================
2025-07-30 18:59:20,923 - INFO -   hellaswag:
2025-07-30 18:59:20,924 - INFO -     - accuracy: 0.6372
2025-07-30 18:59:20,924 - INFO -     - accuracy_norm: 0.8319
2025-07-30 18:59:20,924 - INFO - ============================================================

2025-07-30 18:59:20,932 - INFO - gemma-3-12b-it_harness_3: Completed evaluation - 189 subtasks from 10 requested tasks
2025-07-30 18:59:20,976 - INFO - [Process 1941996] Results saved to /home/gwlee/Benchmark/AIDE_Benchmark/experiments_results/exp_20250729_041113/model_results/gemma-3-12b-it/gemma-3-12b-it_harness_3.json
2025-07-30 18:59:20,992 - INFO - [Process 1941996] Legacy results saved to /home/gwlee/Benchmark/AIDE_Benchmark/results/gemma-3-12b-it/gemma-3-12b-it_harness_3.json
2025-07-30 18:59:21,297 - INFO - Results uploaded to WandB as artifact
2025-07-30 18:59:21,307 - WARNING - lm-eval WandB logging failed, using direct logging: 'NoneType' object has no attribute 'get'
2025-07-30 18:59:21,309 - INFO - [Process 1941996] Successfully completed gemma-3-12b-it_harness_3
2025-07-30 18:59:24,628 - INFO - Run gemma-3-12b-it_harness_3 finished successfully
2025-07-30 18:59:24,630 - INFO - [Process 1941996] EXAONE-3.5-32B-Instruct_harness_8 assigned to cuda:0
2025-07-30 18:59:24,630 - INFO - [Process 1941996] EXAONE-3.5-32B-Instruct_harness_8 - full_run: True, limit: None (full dataset)
2025-07-30 18:59:26,004 - INFO - WandB run initialized: EXAONE-3.5-32B-Instruct_20250730_185924 (ID: 36f11146)
2025-07-30 18:59:26,385 - INFO - GPU memory available: 79.3GB
2025-07-30 18:59:26,387 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Using 8bit=True, batch_size=1
2025-07-30 19:01:13,014 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 1/10: kmmlu
2025-07-30 19:01:13,015 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kmmlu' will use num_fewshot=5
2025-07-30 19:01:13,144 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kmmlu' with num_fewshot=5
2025-07-30 19:01:13,144 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 19:02:26,274 - WARNING - Overwriting default num_fewshot of kmmlu_civil_engineering from None to 5
2025-07-30 19:02:26,275 - WARNING - Overwriting default num_fewshot of kmmlu_materials_engineering from None to 5
2025-07-30 19:02:26,275 - WARNING - Overwriting default num_fewshot of kmmlu_chemical_engineering from None to 5
2025-07-30 19:02:26,275 - WARNING - Overwriting default num_fewshot of kmmlu_ecology from None to 5
2025-07-30 19:02:26,275 - WARNING - Overwriting default num_fewshot of kmmlu_math from None to 5
2025-07-30 19:02:26,275 - WARNING - Overwriting default num_fewshot of kmmlu_electrical_engineering from None to 5
2025-07-30 19:02:26,275 - WARNING - Overwriting default num_fewshot of kmmlu_biology from None to 5
2025-07-30 19:02:26,275 - WARNING - Overwriting default num_fewshot of kmmlu_mechanical_engineering from None to 5
2025-07-30 19:02:26,275 - WARNING - Overwriting default num_fewshot of kmmlu_information_technology from None to 5
2025-07-30 19:02:26,275 - WARNING - Overwriting default num_fewshot of kmmlu_chemistry from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_computer_science from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_agricultural_sciences from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_patent from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_interior_architecture_and_design from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_real_estate from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_food_processing from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_public_safety from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_refrigerating_machinery from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_health from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_marketing from None to 5
2025-07-30 19:02:26,276 - WARNING - Overwriting default num_fewshot of kmmlu_fashion from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_construction from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_environmental_science from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_electronics_engineering from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_industrial_engineer from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_geomatics from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_railway_and_automotive_engineering from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_maritime_engineering from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_nondestructive_testing from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_energy_management from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_telecommunications_and_wireless_technology from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_gas_technology_and_engineering from None to 5
2025-07-30 19:02:26,277 - WARNING - Overwriting default num_fewshot of kmmlu_machine_design_and_manufacturing from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_aviation_engineering_and_maintenance from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_korean_history from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_taxation from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_management from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_accounting from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_criminal_law from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_law from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_psychology from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_political_science_and_sociology from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_economics from None to 5
2025-07-30 19:02:26,278 - WARNING - Overwriting default num_fewshot of kmmlu_social_welfare from None to 5
2025-07-30 19:02:26,279 - WARNING - Overwriting default num_fewshot of kmmlu_education from None to 5
2025-07-30 19:12:17,566 - WARNING - We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
2025-07-30 23:13:16,569 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kmmlu' with 50 subtasks
2025-07-30 23:13:16,728 - INFO - 
============================================================
2025-07-30 23:13:16,728 - INFO - Task 'kmmlu' Results:
2025-07-30 23:13:16,728 - INFO - ============================================================
2025-07-30 23:13:16,728 - INFO -   kmmlu:
2025-07-30 23:13:16,728 - INFO -     - accuracy: 0.5038
2025-07-30 23:13:16,728 - INFO -   kmmlu_applied_science:
2025-07-30 23:13:16,729 - INFO -     - accuracy: 0.4676
2025-07-30 23:13:16,729 - INFO -   kmmlu_aviation_engineering_and_maintenance:
2025-07-30 23:13:16,729 - INFO -     - accuracy: 0.4850
2025-07-30 23:13:16,729 - INFO -   kmmlu_electronics_engineering:
2025-07-30 23:13:16,729 - INFO -     - accuracy: 0.5880
2025-07-30 23:13:16,729 - INFO -   kmmlu_energy_management:
2025-07-30 23:13:16,729 - INFO -     - accuracy: 0.3670
2025-07-30 23:13:16,729 - INFO -   kmmlu_environmental_science:
2025-07-30 23:13:16,730 - INFO -     - accuracy: 0.3710
2025-07-30 23:13:16,730 - INFO -   kmmlu_gas_technology_and_engineering:
2025-07-30 23:13:16,730 - INFO -     - accuracy: 0.3960
2025-07-30 23:13:16,730 - INFO -   kmmlu_geomatics:
2025-07-30 23:13:16,730 - INFO -     - accuracy: 0.4350
2025-07-30 23:13:16,730 - INFO -   kmmlu_industrial_engineer:
2025-07-30 23:13:16,730 - INFO -     - accuracy: 0.4700
2025-07-30 23:13:16,730 - INFO -   kmmlu_machine_design_and_manufacturing:
2025-07-30 23:13:16,730 - INFO -     - accuracy: 0.4940
2025-07-30 23:13:16,730 - INFO -   kmmlu_maritime_engineering:
2025-07-30 23:13:16,731 - INFO -     - accuracy: 0.4983
2025-07-30 23:13:16,731 - INFO -   kmmlu_nondestructive_testing:
2025-07-30 23:13:16,731 - INFO -     - accuracy: 0.4800
2025-07-30 23:13:16,731 - INFO -   kmmlu_railway_and_automotive_engineering:
2025-07-30 23:13:16,732 - INFO -     - accuracy: 0.4090
2025-07-30 23:13:16,732 - INFO -   kmmlu_telecommunications_and_wireless_technology:
2025-07-30 23:13:16,732 - INFO -     - accuracy: 0.6300
2025-07-30 23:13:16,732 - INFO -   kmmlu_humss:
2025-07-30 23:13:16,732 - INFO -     - accuracy: 0.5647
2025-07-30 23:13:16,732 - INFO -   kmmlu_accounting:
2025-07-30 23:13:16,732 - INFO -     - accuracy: 0.5400
2025-07-30 23:13:16,732 - INFO -   kmmlu_criminal_law:
2025-07-30 23:13:16,732 - INFO -     - accuracy: 0.4150
2025-07-30 23:13:16,733 - INFO -   kmmlu_economics:
2025-07-30 23:13:16,733 - INFO -     - accuracy: 0.5923
2025-07-30 23:13:16,733 - INFO -   kmmlu_education:
2025-07-30 23:13:16,733 - INFO -     - accuracy: 0.6300
2025-07-30 23:13:16,733 - INFO -   kmmlu_korean_history:
2025-07-30 23:13:16,733 - INFO -     - accuracy: 0.4300
2025-07-30 23:13:16,733 - INFO -   kmmlu_law:
2025-07-30 23:13:16,733 - INFO -     - accuracy: 0.5380
2025-07-30 23:13:16,733 - INFO -   kmmlu_management:
2025-07-30 23:13:16,734 - INFO -     - accuracy: 0.6020
2025-07-30 23:13:16,734 - INFO -   kmmlu_political_science_and_sociology:
2025-07-30 23:13:16,734 - INFO -     - accuracy: 0.6533
2025-07-30 23:13:16,734 - INFO -   kmmlu_psychology:
2025-07-30 23:13:16,734 - INFO -     - accuracy: 0.5290
2025-07-30 23:13:16,734 - INFO -   kmmlu_social_welfare:
2025-07-30 23:13:16,734 - INFO -     - accuracy: 0.6200
2025-07-30 23:13:16,734 - INFO -   kmmlu_taxation:
2025-07-30 23:13:16,734 - INFO -     - accuracy: 0.4600
2025-07-30 23:13:16,735 - INFO -   kmmlu_other:
2025-07-30 23:13:16,735 - INFO -     - accuracy: 0.5018
2025-07-30 23:13:16,735 - INFO -   kmmlu_agricultural_sciences:
2025-07-30 23:13:16,735 - INFO -     - accuracy: 0.4020
2025-07-30 23:13:16,735 - INFO -   kmmlu_construction:
2025-07-30 23:13:16,735 - INFO -     - accuracy: 0.3950
2025-07-30 23:13:16,735 - INFO -   kmmlu_fashion:
2025-07-30 23:13:16,735 - INFO -     - accuracy: 0.5240
2025-07-30 23:13:16,735 - INFO -   kmmlu_food_processing:
2025-07-30 23:13:16,736 - INFO -     - accuracy: 0.4560
2025-07-30 23:13:16,736 - INFO -   kmmlu_health:
2025-07-30 23:13:16,736 - INFO -     - accuracy: 0.6400
2025-07-30 23:13:16,736 - INFO -   kmmlu_interior_architecture_and_design:
2025-07-30 23:13:16,736 - INFO -     - accuracy: 0.6350
2025-07-30 23:13:16,736 - INFO -   kmmlu_marketing:
2025-07-30 23:13:16,736 - INFO -     - accuracy: 0.8170
2025-07-30 23:13:16,736 - INFO -   kmmlu_patent:
2025-07-30 23:13:16,736 - INFO -     - accuracy: 0.3900
2025-07-30 23:13:16,737 - INFO -   kmmlu_public_safety:
2025-07-30 23:13:16,737 - INFO -     - accuracy: 0.4070
2025-07-30 23:13:16,737 - INFO -   kmmlu_real_estate:
2025-07-30 23:13:16,737 - INFO -     - accuracy: 0.5000
2025-07-30 23:13:16,737 - INFO -   kmmlu_refrigerating_machinery:
2025-07-30 23:13:16,737 - INFO -     - accuracy: 0.3760
2025-07-30 23:13:16,737 - INFO -   kmmlu_stem:
2025-07-30 23:13:16,737 - INFO -     - accuracy: 0.5165
2025-07-30 23:13:16,737 - INFO -   kmmlu_biology:
2025-07-30 23:13:16,738 - INFO -     - accuracy: 0.4370
2025-07-30 23:13:16,738 - INFO -   kmmlu_chemical_engineering:
2025-07-30 23:13:16,738 - INFO -     - accuracy: 0.5160
2025-07-30 23:13:16,738 - INFO -   kmmlu_chemistry:
2025-07-30 23:13:16,738 - INFO -     - accuracy: 0.5500
2025-07-30 23:13:16,738 - INFO -   kmmlu_civil_engineering:
2025-07-30 23:13:16,738 - INFO -     - accuracy: 0.4010
2025-07-30 23:13:16,738 - INFO -   kmmlu_computer_science:
2025-07-30 23:13:16,738 - INFO -     - accuracy: 0.7560
2025-07-30 23:13:16,739 - INFO -   kmmlu_ecology:
2025-07-30 23:13:16,739 - INFO -     - accuracy: 0.5280
2025-07-30 23:13:16,739 - INFO -   kmmlu_electrical_engineering:
2025-07-30 23:13:16,739 - INFO -     - accuracy: 0.3730
2025-07-30 23:13:16,739 - INFO -   kmmlu_information_technology:
2025-07-30 23:13:16,739 - INFO -     - accuracy: 0.7410
2025-07-30 23:13:16,739 - INFO -   kmmlu_materials_engineering:
2025-07-30 23:13:16,739 - INFO -     - accuracy: 0.5230
2025-07-30 23:13:16,739 - INFO -   kmmlu_math:
2025-07-30 23:13:16,740 - INFO -     - accuracy: 0.3300
2025-07-30 23:13:16,740 - INFO -   kmmlu_mechanical_engineering:
2025-07-30 23:13:16,740 - INFO -     - accuracy: 0.4090
2025-07-30 23:13:16,740 - INFO - ============================================================

2025-07-30 23:13:16,753 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 2/10: kmmlu_hard
2025-07-30 23:13:16,758 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kmmlu_hard' will use num_fewshot=5
2025-07-30 23:13:16,885 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kmmlu_hard' with num_fewshot=5
2025-07-30 23:13:16,886 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 23:14:29,805 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electrical_engineering from None to 5
2025-07-30 23:14:29,805 - WARNING - Overwriting default num_fewshot of kmmlu_hard_mechanical_engineering from None to 5
2025-07-30 23:14:29,805 - WARNING - Overwriting default num_fewshot of kmmlu_hard_information_technology from None to 5
2025-07-30 23:14:29,805 - WARNING - Overwriting default num_fewshot of kmmlu_hard_civil_engineering from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_biology from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemical_engineering from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_chemistry from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_computer_science from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_materials_engineering from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_math from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_ecology from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_agricultural_sciences from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_health from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_construction from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_refrigerating_machinery from None to 5
2025-07-30 23:14:29,806 - WARNING - Overwriting default num_fewshot of kmmlu_hard_patent from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_fashion from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_real_estate from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_interior_architecture_and_design from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_public_safety from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_marketing from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_food_processing from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_railway_and_automotive_engineering from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_energy_management from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_geomatics from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_aviation_engineering_and_maintenance from None to 5
2025-07-30 23:14:29,807 - WARNING - Overwriting default num_fewshot of kmmlu_hard_maritime_engineering from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_telecommunications_and_wireless_technology from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_gas_technology_and_engineering from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_electronics_engineering from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_machine_design_and_manufacturing from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_nondestructive_testing from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_environmental_science from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_industrial_engineer from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_law from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_management from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_psychology from None to 5
2025-07-30 23:14:29,808 - WARNING - Overwriting default num_fewshot of kmmlu_hard_education from None to 5
2025-07-30 23:14:29,809 - WARNING - Overwriting default num_fewshot of kmmlu_hard_taxation from None to 5
2025-07-30 23:14:29,809 - WARNING - Overwriting default num_fewshot of kmmlu_hard_accounting from None to 5
2025-07-30 23:14:29,809 - WARNING - Overwriting default num_fewshot of kmmlu_hard_social_welfare from None to 5
2025-07-30 23:14:29,809 - WARNING - Overwriting default num_fewshot of kmmlu_hard_political_science_and_sociology from None to 5
2025-07-30 23:14:29,809 - WARNING - Overwriting default num_fewshot of kmmlu_hard_criminal_law from None to 5
2025-07-30 23:14:29,809 - WARNING - Overwriting default num_fewshot of kmmlu_hard_economics from None to 5
2025-07-30 23:14:29,809 - WARNING - Overwriting default num_fewshot of kmmlu_hard_korean_history from None to 5
2025-07-30 23:45:38,378 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kmmlu_hard' with 50 subtasks
2025-07-30 23:45:38,525 - INFO - 
============================================================
2025-07-30 23:45:38,525 - INFO - Task 'kmmlu_hard' Results:
2025-07-30 23:45:38,525 - INFO - ============================================================
2025-07-30 23:45:38,526 - INFO -   kmmlu_hard:
2025-07-30 23:45:38,526 - INFO -     - accuracy: 0.2558
2025-07-30 23:45:38,526 - INFO -   kmmlu_hard_applied_science:
2025-07-30 23:45:38,526 - INFO -     - accuracy: 0.2325
2025-07-30 23:45:38,527 - INFO -   kmmlu_hard_aviation_engineering_and_maintenance:
2025-07-30 23:45:38,527 - INFO -     - accuracy: 0.2600
2025-07-30 23:45:38,527 - INFO -   kmmlu_hard_electronics_engineering:
2025-07-30 23:45:38,527 - INFO -     - accuracy: 0.2700
2025-07-30 23:45:38,530 - INFO -   kmmlu_hard_energy_management:
2025-07-30 23:45:38,530 - INFO -     - accuracy: 0.2900
2025-07-30 23:45:38,530 - INFO -   kmmlu_hard_environmental_science:
2025-07-30 23:45:38,530 - INFO -     - accuracy: 0.1700
2025-07-30 23:45:38,531 - INFO -   kmmlu_hard_gas_technology_and_engineering:
2025-07-30 23:45:38,531 - INFO -     - accuracy: 0.2600
2025-07-30 23:45:38,531 - INFO -   kmmlu_hard_geomatics:
2025-07-30 23:45:38,531 - INFO -     - accuracy: 0.2500
2025-07-30 23:45:38,531 - INFO -   kmmlu_hard_industrial_engineer:
2025-07-30 23:45:38,531 - INFO -     - accuracy: 0.1600
2025-07-30 23:45:38,531 - INFO -   kmmlu_hard_machine_design_and_manufacturing:
2025-07-30 23:45:38,531 - INFO -     - accuracy: 0.2400
2025-07-30 23:45:38,532 - INFO -   kmmlu_hard_maritime_engineering:
2025-07-30 23:45:38,532 - INFO -     - accuracy: 0.2000
2025-07-30 23:45:38,532 - INFO -   kmmlu_hard_nondestructive_testing:
2025-07-30 23:45:38,532 - INFO -     - accuracy: 0.2700
2025-07-30 23:45:38,532 - INFO -   kmmlu_hard_railway_and_automotive_engineering:
2025-07-30 23:45:38,532 - INFO -     - accuracy: 0.2200
2025-07-30 23:45:38,532 - INFO -   kmmlu_hard_telecommunications_and_wireless_technology:
2025-07-30 23:45:38,532 - INFO -     - accuracy: 0.2000
2025-07-30 23:45:38,532 - INFO -   kmmlu_hard_humss:
2025-07-30 23:45:38,533 - INFO -     - accuracy: 0.2842
2025-07-30 23:45:38,533 - INFO -   kmmlu_hard_accounting:
2025-07-30 23:45:38,533 - INFO -     - accuracy: 0.3696
2025-07-30 23:45:38,533 - INFO -   kmmlu_hard_criminal_law:
2025-07-30 23:45:38,533 - INFO -     - accuracy: 0.1900
2025-07-30 23:45:38,533 - INFO -   kmmlu_hard_economics:
2025-07-30 23:45:38,533 - INFO -     - accuracy: 0.1905
2025-07-30 23:45:38,533 - INFO -   kmmlu_hard_education:
2025-07-30 23:45:38,533 - INFO -     - accuracy: 0.4348
2025-07-30 23:45:38,534 - INFO -   kmmlu_hard_korean_history:
2025-07-30 23:45:38,534 - INFO -     - accuracy: 0.2955
2025-07-30 23:45:38,534 - INFO -   kmmlu_hard_law:
2025-07-30 23:45:38,534 - INFO -     - accuracy: 0.2600
2025-07-30 23:45:38,534 - INFO -   kmmlu_hard_management:
2025-07-30 23:45:38,534 - INFO -     - accuracy: 0.3500
2025-07-30 23:45:38,534 - INFO -   kmmlu_hard_political_science_and_sociology:
2025-07-30 23:45:38,534 - INFO -     - accuracy: 0.3111
2025-07-30 23:45:38,534 - INFO -   kmmlu_hard_psychology:
2025-07-30 23:45:38,535 - INFO -     - accuracy: 0.2900
2025-07-30 23:45:38,535 - INFO -   kmmlu_hard_social_welfare:
2025-07-30 23:45:38,535 - INFO -     - accuracy: 0.3500
2025-07-30 23:45:38,535 - INFO -   kmmlu_hard_taxation:
2025-07-30 23:45:38,535 - INFO -     - accuracy: 0.1979
2025-07-30 23:45:38,535 - INFO -   kmmlu_hard_other:
2025-07-30 23:45:38,535 - INFO -     - accuracy: 0.2596
2025-07-30 23:45:38,535 - INFO -   kmmlu_hard_agricultural_sciences:
2025-07-30 23:45:38,535 - INFO -     - accuracy: 0.2600
2025-07-30 23:45:38,536 - INFO -   kmmlu_hard_construction:
2025-07-30 23:45:38,536 - INFO -     - accuracy: 0.2100
2025-07-30 23:45:38,536 - INFO -   kmmlu_hard_fashion:
2025-07-30 23:45:38,536 - INFO -     - accuracy: 0.2400
2025-07-30 23:45:38,536 - INFO -   kmmlu_hard_food_processing:
2025-07-30 23:45:38,536 - INFO -     - accuracy: 0.2300
2025-07-30 23:45:38,536 - INFO -   kmmlu_hard_health:
2025-07-30 23:45:38,536 - INFO -     - accuracy: 0.3478
2025-07-30 23:45:38,537 - INFO -   kmmlu_hard_interior_architecture_and_design:
2025-07-30 23:45:38,537 - INFO -     - accuracy: 0.3300
2025-07-30 23:45:38,537 - INFO -   kmmlu_hard_marketing:
2025-07-30 23:45:38,537 - INFO -     - accuracy: 0.2900
2025-07-30 23:45:38,537 - INFO -   kmmlu_hard_patent:
2025-07-30 23:45:38,537 - INFO -     - accuracy: 0.1961
2025-07-30 23:45:38,537 - INFO -   kmmlu_hard_public_safety:
2025-07-30 23:45:38,537 - INFO -     - accuracy: 0.2500
2025-07-30 23:45:38,537 - INFO -   kmmlu_hard_real_estate:
2025-07-30 23:45:38,538 - INFO -     - accuracy: 0.2697
2025-07-30 23:45:38,538 - INFO -   kmmlu_hard_refrigerating_machinery:
2025-07-30 23:45:38,538 - INFO -     - accuracy: 0.2700
2025-07-30 23:45:38,538 - INFO -   kmmlu_hard_stem:
2025-07-30 23:45:38,538 - INFO -     - accuracy: 0.2564
2025-07-30 23:45:38,538 - INFO -   kmmlu_hard_biology:
2025-07-30 23:45:38,538 - INFO -     - accuracy: 0.2000
2025-07-30 23:45:38,538 - INFO -   kmmlu_hard_chemical_engineering:
2025-07-30 23:45:38,538 - INFO -     - accuracy: 0.2400
2025-07-30 23:45:38,539 - INFO -   kmmlu_hard_chemistry:
2025-07-30 23:45:38,539 - INFO -     - accuracy: 0.4100
2025-07-30 23:45:38,539 - INFO -   kmmlu_hard_civil_engineering:
2025-07-30 23:45:38,539 - INFO -     - accuracy: 0.2000
2025-07-30 23:45:38,539 - INFO -   kmmlu_hard_computer_science:
2025-07-30 23:45:38,539 - INFO -     - accuracy: 0.2800
2025-07-30 23:45:38,539 - INFO -   kmmlu_hard_ecology:
2025-07-30 23:45:38,539 - INFO -     - accuracy: 0.2800
2025-07-30 23:45:38,539 - INFO -   kmmlu_hard_electrical_engineering:
2025-07-30 23:45:38,540 - INFO -     - accuracy: 0.2200
2025-07-30 23:45:38,540 - INFO -   kmmlu_hard_information_technology:
2025-07-30 23:45:38,540 - INFO -     - accuracy: 0.3300
2025-07-30 23:45:38,540 - INFO -   kmmlu_hard_materials_engineering:
2025-07-30 23:45:38,540 - INFO -     - accuracy: 0.3000
2025-07-30 23:45:38,540 - INFO -   kmmlu_hard_math:
2025-07-30 23:45:38,540 - INFO -     - accuracy: 0.2200
2025-07-30 23:45:38,540 - INFO -   kmmlu_hard_mechanical_engineering:
2025-07-30 23:45:38,540 - INFO -     - accuracy: 0.1400
2025-07-30 23:45:38,541 - INFO - ============================================================

2025-07-30 23:45:38,552 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 3/10: haerae
2025-07-30 23:45:38,554 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'haerae' will use num_fewshot=5
2025-07-30 23:45:38,743 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'haerae' with num_fewshot=5
2025-07-30 23:45:38,743 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-30 23:45:54,472 - WARNING - Overwriting default num_fewshot of haerae_general_knowledge from None to 5
2025-07-30 23:45:54,472 - WARNING - Overwriting default num_fewshot of haerae_history from None to 5
2025-07-30 23:45:54,473 - WARNING - Overwriting default num_fewshot of haerae_loan_word from None to 5
2025-07-30 23:45:54,473 - WARNING - Overwriting default num_fewshot of haerae_rare_word from None to 5
2025-07-30 23:45:54,473 - WARNING - Overwriting default num_fewshot of haerae_standard_nomenclature from None to 5
2025-07-31 00:25:20,285 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'haerae' with 6 subtasks
2025-07-31 00:25:20,457 - INFO - 
============================================================
2025-07-31 00:25:20,458 - INFO - Task 'haerae' Results:
2025-07-31 00:25:20,458 - INFO - ============================================================
2025-07-31 00:25:20,458 - INFO -   haerae:
2025-07-31 00:25:20,458 - INFO -     - accuracy: 0.8304
2025-07-31 00:25:20,458 - INFO -     - accuracy_norm: 0.8304
2025-07-31 00:25:20,458 - INFO -   haerae_general_knowledge:
2025-07-31 00:25:20,458 - INFO -     - accuracy: 0.5682
2025-07-31 00:25:20,458 - INFO -     - accuracy_norm: 0.5682
2025-07-31 00:25:20,459 - INFO -   haerae_history:
2025-07-31 00:25:20,459 - INFO -     - accuracy: 0.8830
2025-07-31 00:25:20,459 - INFO -     - accuracy_norm: 0.8830
2025-07-31 00:25:20,459 - INFO -   haerae_loan_word:
2025-07-31 00:25:20,459 - INFO -     - accuracy: 0.8639
2025-07-31 00:25:20,459 - INFO -     - accuracy_norm: 0.8639
2025-07-31 00:25:20,459 - INFO -   haerae_rare_word:
2025-07-31 00:25:20,459 - INFO -     - accuracy: 0.8864
2025-07-31 00:25:20,459 - INFO -     - accuracy_norm: 0.8864
2025-07-31 00:25:20,460 - INFO -   haerae_standard_nomenclature:
2025-07-31 00:25:20,460 - INFO -     - accuracy: 0.8824
2025-07-31 00:25:20,460 - INFO -     - accuracy_norm: 0.8824
2025-07-31 00:25:20,460 - INFO - ============================================================

2025-07-31 00:25:20,465 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 4/10: kobest
2025-07-31 00:25:20,466 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kobest' will use num_fewshot=5
2025-07-31 00:25:20,593 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kobest' with num_fewshot=5
2025-07-31 00:25:20,594 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-31 00:25:39,254 - WARNING - Overwriting default num_fewshot of kobest_boolq from None to 5
2025-07-31 00:25:39,255 - WARNING - Overwriting default num_fewshot of kobest_copa from None to 5
2025-07-31 00:25:39,255 - WARNING - Overwriting default num_fewshot of kobest_hellaswag from None to 5
2025-07-31 00:25:39,255 - WARNING - Overwriting default num_fewshot of kobest_sentineg from None to 5
2025-07-31 00:25:39,255 - WARNING - Overwriting default num_fewshot of kobest_wic from None to 5
2025-07-31 01:28:58,426 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'kobest' with 6 subtasks
2025-07-31 01:28:58,594 - INFO - 
============================================================
2025-07-31 01:28:58,594 - INFO - Task 'kobest' Results:
2025-07-31 01:28:58,595 - INFO - ============================================================
2025-07-31 01:28:58,595 - INFO -   kobest:
2025-07-31 01:28:58,595 - INFO -     - accuracy: 0.8660
2025-07-31 01:28:58,595 - INFO -     - accuracy_norm: 0.6300
2025-07-31 01:28:58,595 - INFO -     - f1: 0.8656
2025-07-31 01:28:58,595 - INFO -   kobest_boolq:
2025-07-31 01:28:58,595 - INFO -     - accuracy: 0.9544
2025-07-31 01:28:58,595 - INFO -     - f1: 0.9544
2025-07-31 01:28:58,596 - INFO -   kobest_copa:
2025-07-31 01:28:58,596 - INFO -     - accuracy: 0.8940
2025-07-31 01:28:58,596 - INFO -     - f1: 0.8939
2025-07-31 01:28:58,596 - INFO -   kobest_hellaswag:
2025-07-31 01:28:58,596 - INFO -     - accuracy: 0.5300
2025-07-31 01:28:58,596 - INFO -     - accuracy_norm: 0.6300
2025-07-31 01:28:58,596 - INFO -     - f1: 0.5278
2025-07-31 01:28:58,596 - INFO -   kobest_sentineg:
2025-07-31 01:28:58,597 - INFO -     - accuracy: 0.9849
2025-07-31 01:28:58,597 - INFO -     - f1: 0.9849
2025-07-31 01:28:58,597 - INFO -   kobest_wic:
2025-07-31 01:28:58,597 - INFO -     - accuracy: 0.8413
2025-07-31 01:28:58,597 - INFO -     - f1: 0.8405
2025-07-31 01:28:58,597 - INFO - ============================================================

2025-07-31 01:28:58,603 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 5/10: csatqa
2025-07-31 01:28:58,604 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'csatqa' detected as zero-shot task
2025-07-31 01:28:58,734 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'csatqa' with num_fewshot=0
2025-07-31 01:28:58,735 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-31 01:29:10,372 - WARNING - Overwriting default num_fewshot of csatqa_gr from None to 0
2025-07-31 01:29:10,372 - WARNING - Overwriting default num_fewshot of csatqa_li from None to 0
2025-07-31 01:29:10,372 - WARNING - Overwriting default num_fewshot of csatqa_rch from None to 0
2025-07-31 01:29:10,372 - WARNING - Overwriting default num_fewshot of csatqa_rcs from None to 0
2025-07-31 01:29:10,372 - WARNING - Overwriting default num_fewshot of csatqa_rcss from None to 0
2025-07-31 01:29:10,373 - WARNING - Overwriting default num_fewshot of csatqa_wr from None to 0
2025-07-31 01:39:35,498 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Successfully completed task 'csatqa' with 7 subtasks
2025-07-31 01:39:35,652 - INFO - 
============================================================
2025-07-31 01:39:35,652 - INFO - Task 'csatqa' Results:
2025-07-31 01:39:35,652 - INFO - ============================================================
2025-07-31 01:39:35,652 - INFO -   csatqa:
2025-07-31 01:39:35,653 - INFO -     - accuracy: 0.5187
2025-07-31 01:39:35,653 - INFO -     - accuracy_norm: 0.5187
2025-07-31 01:39:35,653 - INFO -   csatqa_gr:
2025-07-31 01:39:35,653 - INFO -     - accuracy: 0.1600
2025-07-31 01:39:35,653 - INFO -     - accuracy_norm: 0.1600
2025-07-31 01:39:35,653 - INFO -   csatqa_li:
2025-07-31 01:39:35,653 - INFO -     - accuracy: 0.7027
2025-07-31 01:39:35,653 - INFO -     - accuracy_norm: 0.7027
2025-07-31 01:39:35,654 - INFO -   csatqa_rch:
2025-07-31 01:39:35,654 - INFO -     - accuracy: 0.6000
2025-07-31 01:39:35,654 - INFO -     - accuracy_norm: 0.6000
2025-07-31 01:39:35,654 - INFO -   csatqa_rcs:
2025-07-31 01:39:35,654 - INFO -     - accuracy: 0.4324
2025-07-31 01:39:35,654 - INFO -     - accuracy_norm: 0.4324
2025-07-31 01:39:35,654 - INFO -   csatqa_rcss:
2025-07-31 01:39:35,654 - INFO -     - accuracy: 0.6429
2025-07-31 01:39:35,654 - INFO -     - accuracy_norm: 0.6429
2025-07-31 01:39:35,655 - INFO -   csatqa_wr:
2025-07-31 01:39:35,655 - INFO -     - accuracy: 0.2727
2025-07-31 01:39:35,655 - INFO -     - accuracy_norm: 0.2727
2025-07-31 01:39:35,655 - INFO - ============================================================

2025-07-31 01:39:35,666 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Processing task 6/10: kormedmcqa
2025-07-31 01:39:35,667 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Task 'kormedmcqa' will use num_fewshot=5
2025-07-31 01:39:35,795 - INFO - EXAONE-3.5-32B-Instruct_harness_8: Evaluating task 'kormedmcqa' with num_fewshot=5
2025-07-31 01:39:35,796 - WARNING - generation_kwargs: {'max_gen_toks': 256} specified through cli, these settings will update set parameters in yaml tasks. Ensure 'do_sample=True' for non-greedy decoding!
2025-07-31 01:39:53,122 - WARNING - Overwriting default num_fewshot of kormedmcqa_doctor from None to 5
2025-07-31 01:39:53,123 - WARNING - Overwriting default num_fewshot of kormedmcqa_nurse from None to 5
2025-07-31 01:39:53,123 - WARNING - Overwriting default num_fewshot of kormedmcqa_pharm from None to 5
2025-07-31 01:39:53,123 - WARNING - Overwriting default num_fewshot of kormedmcqa_dentist from None to 5
